Search.setIndex({"alltitles": {"0. Introduction to version control": [[173, null]], "1. Atomic Symbols": [[156, "atomic-symbols"]], "1. Cookiecutter: The Industry Standard": [[69, "cookiecutter-the-industry-standard"]], "1. Create a new user": [[81, "create-a-new-user"]], "1. Data Quality and Integrity": [[12, "data-quality-and-integrity"]], "1. Defining the Tag Set": [[144, "defining-the-tag-set"]], "1. Definition of AI Agents": [[44, "definition-of-ai-agents"]], "1. Download and install FortiClient": [[82, "download-and-install-forticlient"]], "1. Executive Summary": [[167, "executive-summary"], [170, "executive-summary"]], "1. Feasibility Study": [[165, "feasibility-study"]], "1. Fork repository": [[178, "fork-repository"]], "1. Install BuildKit": [[60, "install-buildkit"]], "1. Install containerd": [[80, "install-containerd"]], "1. Installation:": [[64, "installation"], [159, "installation"]], "1. Installing containerd": [[60, "installing-containerd"]], "1. Introduction to GitHub Workflow": [[68, "introduction-to-github-workflow"]], "1. Natural Language Processing (NLP) for Sentiment Analysis": [[12, "natural-language-processing-nlp-for-sentiment-analysis"]], "1. Objective": [[43, "objective"]], "1. Overview of containerd": [[60, "overview-of-containerd"]], "1. Project planning and team organization": [[75, "project-planning-and-team-organization"]], "1. Real-Time Economic Indicators": [[12, "real-time-economic-indicators"]], "1. Real-Time Economic Monitoring Using Social Media Data": [[12, "real-time-economic-monitoring-using-social-media-data"]], "1. Segmentation": [[147, "segmentation"]], "1. Set up the server": [[81, "set-up-the-server"]], "1. Solo work with git": [[174, null]], "1. Textual Data": [[12, "textual-data"]], "1. Undersea Tunnel": [[3, "undersea-tunnel"]], "1. Understanding Fork & Pull Workflow": [[67, "understanding-fork-pull-workflow"]], "10. Example Usage": [[68, "example-usage"]], "10. Monitor the pipeline": [[80, "monitor-the-pipeline"]], "10. Rebasing": [[183, null]], "10. Silicon Valley": [[3, "silicon-valley"]], "10. Technical Specifications": [[167, "technical-specifications"], [170, "technical-specifications"]], "11. Debugging With git bisect": [[184, null]], "11. Mars": [[3, "mars"]], "11. Timeline and Deliverables": [[167, "timeline-and-deliverables"], [170, "timeline-and-deliverables"]], "11. Update the pipeline": [[80, "update-the-pipeline"]], "12. Conclusion": [[167, "conclusion"], [170, "conclusion"]], "12. Undersea Tunnel": [[3, "id1"]], "12. Working with multiple remotes": [[185, null]], "2. Add a user to the sudoers group": [[81, "add-a-user-to-the-sudoers-group"]], "2. Amazon": [[3, "amazon"]], "2. Background": [[167, "background"], [170, "background"]], "2. Characteristics of AI Agents": [[44, "characteristics-of-ai-agents"]], "2. Clone your forked repo": [[178, "clone-your-forked-repo"]], "2. Collecting and Annotating Data": [[144, "collecting-and-annotating-data"]], "2. Configure containerd": [[80, "configure-containerd"]], "2. Configure inventory file:": [[64, "configure-inventory-file"], [159, "configure-inventory-file"]], "2. Create a Dockerfile": [[60, "create-a-dockerfile"]], "2. Data Security and Privacy": [[12, "data-security-and-privacy"]], "2. Fixing mistakes": [[175, null]], "2. Forking a Repository": [[67, "forking-a-repository"], [68, "forking-a-repository"]], "2. Key components of containerd": [[60, "key-components-of-containerd"]], "2. Market Sentiment Analysis": [[12, "market-sentiment-analysis"]], "2. Obtain VPN connection details": [[82, "obtain-vpn-connection-details"]], "2. Operating system setup": [[75, "operating-system-setup"]], "2. Probability Calculation": [[147, "probability-calculation"]], "2. Requirement Elicitation and Analysis": [[165, "requirement-elicitation-and-analysis"]], "2. Social Media Analytics": [[12, "social-media-analytics"]], "2. Sparse Vectors": [[156, "sparse-vectors"]], "2. Specifications": [[43, "specifications"]], "2. Update the server": [[81, "update-the-server"]], "2. Using the ctr command-line tool": [[60, "using-the-ctr-command-line-tool"]], "2. Web-Scraping for Inflation Expectations": [[12, "web-scraping-for-inflation-expectations"], [12, "id1"]], "2. Yeoman: A New Alternative for Web Apps": [[69, "yeoman-a-new-alternative-for-web-apps"]], "3. Build the image using BuildKit": [[60, "build-the-image-using-buildkit"]], "3. Choosing a Model": [[144, "choosing-a-model"]], "3. Classification of AI Agents": [[44, "classification-of-ai-agents"]], "3. Cloning a Repository": [[68, "cloning-a-repository"]], "3. Cloning the Forked Repository": [[67, "cloning-the-forked-repository"]], "3. Configure FortiClient": [[82, "configure-forticlient"]], "3. Confirmation Measure": [[147, "confirmation-measure"]], "3. Copier: A Newer Alternative (Main Focus)": [[69, "copier-a-newer-alternative-main-focus"]], "3. Create a feature branch": [[178, "create-a-feature-branch"]], "3. Dense Vectors (Word Embeddings)": [[156, "dense-vectors-word-embeddings"]], "3. ESG Risk Assessment": [[12, "esg-risk-assessment"]], "3. Install MicroK8s": [[80, "install-microk8s"]], "3. Install the necessary software": [[81, "install-the-necessary-software"]], "3. Machine Learning for Financial Risk Assessment": [[12, "machine-learning-for-financial-risk-assessment"], [12, "id2"]], "3. Machine learning framework setup": [[75, "machine-learning-framework-setup"]], "3. Model Interpretability": [[12, "model-interpretability"]], "3. Objectives": [[167, "objectives"], [170, "objectives"]], "3. Publishing": [[176, null]], "3. Remove a user": [[81, "remove-a-user"]], "3. Running a simple container": [[60, "running-a-simple-container"]], "3. Serengeti": [[3, "serengeti"]], "3. Software Requirement Specification (SRS)": [[165, "software-requirement-specification-srs"]], "3. Technical Approach": [[43, "technical-approach"]], "3. Transactional Data": [[12, "transactional-data"]], "3. Working with containerd": [[60, "working-with-containerd"]], "3. Write playbooks:": [[64, "write-playbooks"], [159, "write-playbooks"]], "4. Collaboration": [[177, null]], "4. Configure MicroK8s": [[80, "configure-microk8s"]], "4. Connect to the VPN": [[82, "connect-to-the-vpn"]], "4. Convolutional Neural Networks (CNN) for Satellite Imagery": [[12, "convolutional-neural-networks-cnn-for-satellite-imagery"]], "4. Creating a New Branch": [[67, "creating-a-new-branch"], [68, "creating-a-new-branch"]], "4. Evolution to LLM Agents": [[44, "evolution-to-llm-agents"]], "4. Financial Stability Monitoring": [[12, "financial-stability-monitoring"]], "4. Geospatial Data": [[12, "geospatial-data"]], "4. Instructions for AutoGen Agent": [[43, "instructions-for-autogen-agent"]], "4. Make, commit and push changes to new branch": [[178, "make-commit-and-push-changes-to-new-branch"]], "4. Managing container images": [[60, "managing-container-images"]], "4. Mariana Trench": [[3, "mariana-trench"]], "4. Model development": [[75, "model-development"]], "4. Regulatory Compliance": [[12, "regulatory-compliance"]], "4. Run playbooks:": [[64, "run-playbooks"], [159, "run-playbooks"]], "4. Scope": [[167, "scope"], [170, "scope"]], "4. Set up SSH access for the team": [[81, "set-up-ssh-access-for-the-team"]], "4. Software Requirement Validation": [[165, "software-requirement-validation"]], "4. Switch between users": [[81, "switch-between-users"]], "4. Training the Model": [[144, "training-the-model"]], "4. Use cases and scenarios": [[60, "use-cases-and-scenarios"]], "4. Utilizing Satellite Imagery for Agricultural Output Predictions": [[12, "utilizing-satellite-imagery-for-agricultural-output-predictions"]], "4. Verify the image in containerd": [[60, "verify-the-image-in-containerd"]], "5. Clone the GitHub repository": [[81, "clone-the-github-repository"]], "5. Connect to the server via SSH": [[82, "connect-to-the-server-via-ssh"]], "5. Create Pull Request": [[178, "create-pull-request"]], "5. Ethical Dilemmas": [[12, "ethical-dilemmas"]], "5. Evaluating the Model": [[144, "evaluating-the-model"]], "5. Fork and Pull": [[178, null]], "5. Hallasan Mountain": [[3, "hallasan-mountain"]], "5. Inflation Targeting Through Social Media": [[12, "inflation-targeting-through-social-media"]], "5. Inspecting container details": [[60, "inspecting-container-details"]], "5. List users on the server": [[81, "list-users-on-the-server"]], "5. MLOps setup": [[75, "mlops-setup"]], "5. Making Changes and Committing": [[67, "making-changes-and-committing"], [68, "making-changes-and-committing"]], "5. Multi-Agent Interaction with AutoGen": [[44, "multi-agent-interaction-with-autogen"]], "5. Set up SSH access for the team": [[80, "set-up-ssh-access-for-the-team"]], "5. Software Process Model": [[167, "software-process-model"], [170, "software-process-model"]], "5. Software Requirement Management": [[165, "software-requirement-management"]], "5. Use roles for modularity:": [[64, "use-roles-for-modularity"], [159, "use-roles-for-modularity"]], "6. Budget": [[167, "budget"], [170, "budget"]], "6. Change a user\u2019s password": [[81, "change-a-users-password"]], "6. Create a dedicated directory for the project": [[81, "create-a-dedicated-directory-for-the-project"]], "6. Feedback from team leader": [[178, "feedback-from-team-leader"]], "6. Finalization and documentation": [[75, "finalization-and-documentation"]], "6. Git Theory": [[179, null]], "6. Pushing Changes to GitHub": [[68, "pushing-changes-to-github"]], "6. Pushing Changes to Your Fork": [[67, "pushing-changes-to-your-fork"]], "6. Real-World Examples of AI Agents": [[44, "real-world-examples-of-ai-agents"]], "6. Resource Constraints": [[12, "resource-constraints"]], "6. Set up the GitHub repository": [[80, "set-up-the-github-repository"]], "6. Use Ansible Vault for secrets management:": [[64, "use-ansible-vault-for-secrets-management"], [159, "use-ansible-vault-for-secrets-management"]], "6. Using and Updating the Model": [[144, "using-and-updating-the-model"]], "6. Venice": [[3, "venice"]], "7. Antarctica": [[3, "antarctica"]], "7. Branches": [[180, null]], "7. Conclusion": [[44, "conclusion"]], "7. Connect to the server": [[81, "connect-to-the-server"]], "7. Create a simple MLOps pipeline": [[80, "create-a-simple-mlops-pipeline"]], "7. Creating a Pull Request": [[67, "creating-a-pull-request"], [68, "creating-a-pull-request"]], "7. Fixes by collaborator": [[178, "fixes-by-collaborator"]], "7. System Architecture": [[167, "system-architecture"], [170, "system-architecture"]], "7. Use Ansible modules and plugins:": [[64, "use-ansible-modules-and-plugins"], [159, "use-ansible-modules-and-plugins"]], "8. Advanced git concepts": [[181, null]], "8. Collaborating and Merging": [[67, "collaborating-and-merging"]], "8. Configure Kubernetes resources": [[80, "configure-kubernetes-resources"]], "8. Leader accepts pull request": [[178, "leader-accepts-pull-request"]], "8. Manage the server": [[81, "manage-the-server"]], "8. Merging a Pull Request": [[68, "merging-a-pull-request"]], "8. Reykjavik": [[3, "reykjavik"]], "8. Risks Assessment": [[167, "risks-assessment"], [170, "risks-assessment"]], "8.Test and validate playbooks:": [[64, "test-and-validate-playbooks"], [159, "test-and-validate-playbooks"]], "9. Apply the Kubernetes configurations": [[80, "apply-the-kubernetes-configurations"]], "9. Publishing from GitHub": [[182, null]], "9. Resources": [[167, "resources"], [170, "resources"]], "9. Sun": [[3, "sun"]], "9. Syncing Your Fork": [[68, "syncing-your-fork"]], "9. Use the server for the project": [[81, "use-the-server-for-the-project"]], "A Brave New World": [[3, null]], "A Systematic Study of Transfer Learning Methodology": [[117, "a-systematic-study-of-transfer-learning-methodology"]], "A Traditional Tokenization Pipeline": [[146, "a-traditional-tokenization-pipeline"]], "A first example file": [[174, "a-first-example-file"]], "A good branch strategy": [[180, "a-good-branch-strategy"]], "A new lie": [[175, "a-new-lie"]], "A. Data collection and preprocessing": [[89, "a-data-collection-and-preprocessing"]], "A. Digital Signatures": [[77, "a-digital-signatures"]], "A. Identifying your research interests": [[89, "a-identifying-your-research-interests"]], "A. Importance of SSH in Git and GitHub Operations": [[76, "a-importance-of-ssh-in-git-and-github-operations"]], "A. Quantum Computing": [[77, "a-quantum-computing"]], "A. Secure Web Applications": [[77, "a-secure-web-applications"]], "A. The importance of a comprehensive literature review": [[89, "a-the-importance-of-a-comprehensive-literature-review"]], "A. The significance of a well-defined methodology": [[89, "a-the-significance-of-a-well-defined-methodology"]], "A. The structure of a thesis": [[89, "a-the-structure-of-a-thesis"]], "A. Types of Authentication": [[77, "a-types-of-authentication"]], "A. Types of Encryption": [[77, "a-types-of-encryption"]], "AARON": [[5, "aaron"]], "AFINN": [[135, "afinn"]], "AI Agents": [[44, null]], "AI Agents vs Standalone LLMs": [[42, "ai-agents-vs-standalone-llms"]], "AI Art (Generative AI)": [[4, null]], "AI as a Collaborator": [[2, "ai-as-a-collaborator"]], "AI as a Muse": [[2, "ai-as-a-muse"]], "AI as a Tool": [[2, "ai-as-a-tool"]], "AIHub": [[121, "aihub"]], "AI\u2019s Evolutionary Role in Development": [[56, "ais-evolutionary-role-in-development"]], "ALBERT": [[99, "albert"]], "ALPACA": [[83, "alpaca"]], "API Calls": [[121, "api-calls"]], "AWS Lambda": [[73, "aws-lambda"]], "Ablation Study": [[115, "ablation-study"]], "About": [[1, null]], "Accessing Company Overview Information": [[123, "accessing-company-overview-information"]], "Accessing Disclosure Documents": [[123, "accessing-disclosure-documents"]], "Accessing Public Disclosure Information": [[123, "accessing-public-disclosure-information"]], "Accessor Variety": [[145, "accessor-variety"]], "Acquiring High-Quality Datasets": [[93, "acquiring-high-quality-datasets"]], "Activities for Each Phase": [[167, "activities-for-each-phase"]], "Adapters": [[73, "adapters"]], "Adapting AlphaGo\u2019s Strategies to Large Language Models (LLMs)": [[53, "adapting-alphagos-strategies-to-large-language-models-llms"]], "Adaptive and Layer-wise Fine-Tuning": [[50, "adaptive-and-layer-wise-fine-tuning"]], "Add Quantitative Easing as a Lower event": [[23, "add-quantitative-easing-as-a-lower-event"]], "Add Rate and Decisions": [[23, "add-rate-and-decisions"]], "Add Taylor Rule": [[23, "add-taylor-rule"]], "Adding Passwords": [[79, "adding-passwords"]], "Adding Special Tokens": [[108, "adding-special-tokens"]], "Adding a new remote to your repository": [[176, "adding-a-new-remote-to-your-repository"]], "Additional Features": [[79, "additional-features"]], "Additive Methods": [[52, "additive-methods"]], "Adjusting for Confounding with Text Matching": [[120, "adjusting-for-confounding-with-text-matching"]], "Advanced Search Techniques": [[53, "advanced-search-techniques"]], "Advanced Techniques: TTC and TTA": [[54, "advanced-techniques-ttc-and-tta"]], "Advancement to Tree of Thought (ToT)": [[53, "advancement-to-tree-of-thought-tot"]], "Advancements and Variants": [[53, "advancements-and-variants"]], "Advances in AI and NLP": [[87, null]], "Advancing Research in PEFT": [[50, "advancing-research-in-peft"]], "Advantages of Data Science Technologies": [[40, "advantages-of-data-science-technologies"]], "Advantages of PRMs": [[53, "advantages-of-prms"]], "Advantages of randomized algorithms:": [[150, "advantages-of-randomized-algorithms"]], "Agglutinative Languages": [[140, "agglutinative-languages"]], "Aggregate sentiment scores": [[30, "aggregate-sentiment-scores"]], "Aggregation": [[147, "aggregation"]], "Agile Development Techniques": [[171, "agile-development-techniques"]], "Agile Model": [[166, "agile-model"]], "Agile Project Management": [[171, "agile-project-management"]], "Agile Software Development": [[171, null]], "Agile vs Plan-Driven Development": [[171, "agile-vs-plan-driven-development"]], "Algorithms for Subword Tokenization": [[106, "algorithms-for-subword-tokenization"]], "AlphaGo: A Case Study in AI Mastery": [[53, "alphago-a-case-study-in-ai-mastery"]], "Alternative Approaches": [[167, "alternative-approaches"]], "Alternative Approaches and Further Considerations": [[170, "alternative-approaches-and-further-considerations"]], "Alternative Considerations": [[38, "alternative-considerations"]], "Alternative Data Sources for Central Banks": [[12, null]], "Ambiguity": [[130, "ambiguity"]], "An embedding layer is matrix multiplication:": [[126, "an-embedding-layer-is-matrix-multiplication"]], "An example rebase": [[183, "an-example-rebase"]], "An example repository": [[184, "an-example-repository"]], "An example using the Brown Corpus": [[133, "an-example-using-the-brown-corpus"]], "Analyzing the dataset": [[94, "analyzing-the-dataset"]], "Ansible": [[64, "ansible"], [159, "ansible"]], "Antipatch": [[175, "antipatch"]], "Application Methods for Leveraging Large Language Models": [[49, "application-methods-for-leveraging-large-language-models"]], "Application in AI": [[53, "application-in-ai"]], "Applications": [[98, "applications"], [151, "applications"], [151, "id3"]], "Applications and Implications": [[53, "applications-and-implications"]], "Applications and Utilities of Large Language Models": [[49, "applications-and-utilities-of-large-language-models"]], "Applications in Central Banking": [[12, "applications-in-central-banking"]], "Applications in Economics": [[41, "applications-in-economics"]], "Applications of Sentiment Analysis": [[134, "applications-of-sentiment-analysis"]], "App\u2019s Architecture": [[72, "apps-architecture"]], "Architectural Evolution of LLMs": [[49, "architectural-evolution-of-llms"]], "Architectural Insights": [[53, "architectural-insights"]], "Architecture": [[128, "architecture"]], "Architectures": [[117, "architectures"]], "Architectures and Applications": [[41, "architectures-and-applications"]], "Art and Music in Light of AI": [[2, null]], "Artifacts": [[73, "artifacts"]], "Ascendancy of Large Language Models": [[49, "ascendancy-of-large-language-models"]], "Assessing PEFT\u2019s Limitations": [[50, "assessing-pefts-limitations"]], "Assessing the overall performance": [[55, "assessing-the-overall-performance"]], "Assessment": [[37, "assessment"]], "Assumptions and Probability Calculation": [[106, "assumptions-and-probability-calculation"]], "Assumptions of traditional NLP pipelines": [[130, "assumptions-of-traditional-nlp-pipelines"]], "Attending to Language": [[113, "attending-to-language"]], "Attention Is Not All You Need": [[116, "attention-is-not-all-you-need"]], "Attention Mechanism": [[113, "attention-mechanism"]], "Attention Mechanism: A Partial Solution": [[49, "attention-mechanism-a-partial-solution"]], "Attention in BERT (Easy Version)": [[113, "attention-in-bert-easy-version"]], "Attention is all you need?": [[116, "attention-is-all-you-need"]], "Attention to identical/related words in other sentence": [[114, "attention-to-identical-related-words-in-other-sentence"]], "Attention to identical/related words pattern": [[114, "attention-to-identical-related-words-pattern"]], "Attention to other words predictive of word": [[114, "attention-to-other-words-predictive-of-word"]], "Attention to previous word": [[114, "attention-to-previous-word"]], "Audio to Body Dynamics": [[6, "audio-to-body-dynamics"]], "Augmentation Problems": [[55, "augmentation-problems"]], "Authentication, Encryption, and Signing": [[77, null]], "Auto ML": [[29, "auto-ml"]], "Auto ML with LM tones": [[35, "auto-ml-with-lm-tones"]], "Auto ML with T5 tones": [[35, "auto-ml-with-t5-tones"]], "Auto ML with econ data": [[35, "auto-ml-with-econ-data"]], "Auto ML with finbert tones": [[35, "auto-ml-with-finbert-tones"]], "AutoGen": [[42, null]], "AutoGen AutoScraper Agent": [[43, null]], "Autoencoders": [[8, "autoencoders"]], "Autonomous LLM Agents": [[57, "autonomous-llm-agents"]], "Availability:": [[85, "availability"]], "Azure Functions": [[73, "azure-functions"]], "B. Authentication Protocols": [[77, "b-authentication-protocols"]], "B. Biometric Authentication": [[77, "b-biometric-authentication"]], "B. Consult with your supervisor": [[89, "b-consult-with-your-supervisor"]], "B. Creating and Verifying Digital Signatures": [[77, "b-creating-and-verifying-digital-signatures"]], "B. Developing AI models and algorithms": [[89, "b-developing-ai-models-and-algorithms"]], "B. Identifying relevant sources": [[89, "b-identifying-relevant-sources"]], "B. IoT Security": [[77, "b-iot-security"]], "B. Key Management and Distribution": [[77, "b-key-management-and-distribution"]], "B. Setting Up SSH for Git and GitHub Operations": [[76, "b-setting-up-ssh-for-git-and-github-operations"]], "B. The writing process": [[89, "b-the-writing-process"]], "B. Types of AI research methodologies": [[89, "b-types-of-ai-research-methodologies"]], "BART": [[99, "bart"]], "BERT": [[99, "bert"], [154, "bert"]], "BERT: Bidirectional Encoder Representations from Transformers": [[113, null]], "BERT: Visualizing Attention": [[114, null]], "BIG-Bench (67 tasks):": [[98, "big-bench-67-tasks"]], "BPE Implementation": [[101, "bpe-implementation"]], "BPE Step-by-Step Implementation": [[101, null]], "BPE-Dropout": [[106, "bpe-dropout"]], "Backup and sharing tools:": [[66, "backup-and-sharing-tools"]], "Bag of Words attention pattern": [[114, "bag-of-words-attention-pattern"]], "Bags of Words Model": [[153, null]], "Balancing Efficiency with Performance": [[50, "balancing-efficiency-with-performance"]], "Baseline": [[117, "baseline"]], "Basic Docker Commands": [[61, "basic-docker-commands"]], "Basic User Management for an Ubuntu Server": [[81, "basic-user-management-for-an-ubuntu-server"]], "Basic statistics": [[94, "basic-statistics"]], "Beam search": [[97, "beam-search"]], "Benefits of Copier:": [[69, "benefits-of-copier"]], "Benefits of DevOps": [[65, "benefits-of-devops"], [160, "benefits-of-devops"]], "Benefits of GitOps": [[64, "benefits-of-gitops"], [159, "benefits-of-gitops"]], "Benefits of Pretraining and Finetuning": [[109, "benefits-of-pretraining-and-finetuning"]], "BentoML Service": [[72, "bentoml-service"]], "BentoService": [[73, "bentoservice"]], "Best Practices for Implementing DevSecOps": [[63, "best-practices-for-implementing-devsecops"]], "Best Practices for LLMOps": [[74, "best-practices-for-llmops"]], "Best Practices for Setting up GitOps Tools": [[64, "best-practices-for-setting-up-gitops-tools"], [159, "best-practices-for-setting-up-gitops-tools"]], "Bias in Lexicons": [[137, "bias-in-lexicons"]], "Bibliography": [[0, null]], "Big Bang Model": [[166, "big-bang-model"]], "Bigram Counts": [[101, "bigram-counts"]], "Bigram Model": [[132, "bigram-model"]], "Bigram Probability Calculation": [[132, "bigram-probability-calculation"]], "Bisecting manually": [[184, "bisecting-manually"]], "Branching Entropy": [[145, "branching-entropy"]], "Build a corpus": [[15, "build-a-corpus"]], "Build a dataset using the data generated by the label model": [[20, "build-a-dataset-using-the-data-generated-by-the-label-model"]], "Build a valid polarity dataset": [[16, "build-a-valid-polarity-dataset"]], "Build a valid topic dataset": [[16, "build-a-valid-topic-dataset"]], "Build an invalid dataset": [[16, "build-an-invalid-dataset"]], "Build and load a feature set": [[28, "build-and-load-a-feature-set"]], "Build and load a feature set with tones": [[33, "build-and-load-a-feature-set-with-tones"]], "Build cross-validated esg_cv_polarity_kr dataset": [[16, "build-cross-validated-esg-cv-polarity-kr-dataset"]], "Build cross-validated esg_cv_topics_kr dataset": [[16, "build-cross-validated-esg-cv-topics-kr-dataset"]], "Build the Image": [[61, "build-the-image"]], "Building Docker Images with Dockerfile": [[61, "building-docker-images-with-dockerfile"]], "Building Your Own Lexicons": [[137, "building-your-own-lexicons"]], "Building econ_news_kr corpus": [[15, null]], "Building the Dataset": [[95, "building-the-dataset"]], "Building your own dataset through web crawling": [[93, "building-your-own-dataset-through-web-crawling"]], "ByT5: Towards a token-free future with pre-trained byte-to-byte models": [[115, null]], "Byte Pair Encoding (BPE)": [[103, "byte-pair-encoding-bpe"], [106, "byte-pair-encoding-bpe"]], "Byte Pair Encoding (BPE) - A Detailed Example": [[106, "byte-pair-encoding-bpe-a-detailed-example"]], "Byte Pair Encoding (BPE) - GPT": [[103, "byte-pair-encoding-bpe-gpt"]], "Byte-level Byte Pair Encoding (BBPE)": [[106, "byte-level-byte-pair-encoding-bbpe"]], "C. Blockchain and Distributed Ledger Technologies": [[77, "c-blockchain-and-distributed-ledger-technologies"]], "C. Defining the scope of your research": [[89, "c-defining-the-scope-of-your-research"]], "C. Encryption Protocols": [[77, "c-encryption-protocols"]], "C. Experimentation and evaluation": [[89, "c-experimentation-and-evaluation"]], "C. Justifying your chosen methodology": [[89, "c-justifying-your-chosen-methodology"]], "C. Organizing and synthesizing the literature": [[89, "c-organizing-and-synthesizing-the-literature"]], "C. Practical Applications of Digital Signatures": [[77, "c-practical-applications-of-digital-signatures"]], "C. Secure Mobile Applications": [[77, "c-secure-mobile-applications"]], "C. Seeking feedback": [[89, "c-seeking-feedback"]], "C. Using SSH for Git and GitHub Operations": [[76, "c-using-ssh-for-git-and-github-operations"]], "C4: Colossal Clean Crawled Corpus": [[117, "c4-colossal-clean-crawled-corpus"]], "CLIP": [[9, "clip"]], "CLIP applications": [[9, "clip-applications"]], "CLIP image encoders": [[9, "clip-image-encoders"]], "CLIP prompt engineering: CLIPDraw": [[9, "clip-prompt-engineering-clipdraw"]], "CLIP prompt engineering: VQGAN-CLIP": [[9, "clip-prompt-engineering-vqgan-clip"]], "CLIP text encoders": [[9, "clip-text-encoders"]], "CLIP: technical details": [[9, "clip-technical-details"]], "Capabilities and Applications": [[53, "capabilities-and-applications"]], "Capabilities of LLMs": [[98, "capabilities-of-llms"]], "Capability vs. Alignment": [[92, "capability-vs-alignment"]], "Capitalization": [[146, "capitalization"]], "Caption Conditioning": [[10, "caption-conditioning"], [10, "id1"]], "Carry on regardless": [[174, "carry-on-regardless"]], "Case Studies Across Domains": [[50, "case-studies-across-domains"]], "Case Studies and Best Practices": [[171, "case-studies-and-best-practices"]], "Categorical Embeddings": [[126, "categorical-embeddings"]], "Categories of Pretrained Language Models": [[99, "categories-of-pretrained-language-models"]], "Categories of Software Requirements": [[165, "categories-of-software-requirements"]], "Causal Masked Language Modeling": [[99, "causal-masked-language-modeling"]], "Central Banks": [[13, null]], "Chain of Thought (CoT)": [[53, "chain-of-thought-cot"]], "Chain-of-thought prompting": [[57, "chain-of-thought-prompting"]], "Chairpersons": [[23, "chairpersons"]], "Challenges": [[41, "challenges"]], "Challenges and Achievements": [[53, "challenges-and-achievements"]], "Challenges and Considerations": [[53, "challenges-and-considerations"]], "Challenges and Ethical Considerations": [[12, "challenges-and-ethical-considerations"]], "Challenges and Future Prospects in Advanced LLM Training": [[53, "challenges-and-future-prospects-in-advanced-llm-training"]], "Challenges and Limitations": [[53, "challenges-and-limitations"], [109, "challenges-and-limitations"]], "Challenges and Methods in Customizing LLMs": [[57, "challenges-and-methods-in-customizing-llms"]], "Challenges and Solutions": [[53, "challenges-and-solutions"]], "Challenges and Solutions in AI Problem-Solving": [[54, "challenges-and-solutions-in-ai-problem-solving"]], "Challenges in Adaptation": [[53, "challenges-in-adaptation"]], "Challenges in Collecting Data": [[93, "challenges-in-collecting-data"]], "Challenges in Conversational AI": [[91, "challenges-in-conversational-ai"]], "Challenges in Machine Learning Systems": [[71, "challenges-in-machine-learning-systems"]], "Challenges in Scaling": [[171, "challenges-in-scaling"]], "Challenges in Sentiment Analysis": [[134, "challenges-in-sentiment-analysis"]], "Challenges of scaling LLM applications": [[55, "challenges-of-scaling-llm-applications"]], "Changing two files at once": [[176, "changing-two-files-at-once"]], "Character Tokenization": [[102, "character-tokenization"]], "Character n-grams": [[124, "character-n-grams"]], "Characteristics of a Good Software Engineer": [[163, "characteristics-of-a-good-software-engineer"]], "Check and label predictions": [[19, "check-and-label-predictions"]], "Checking Baseline with AutoML": [[29, null]], "Choosing a Research Topic": [[89, "choosing-a-research-topic"]], "Classifier-Free Guidance": [[10, "classifier-free-guidance"]], "Cleaning and standardizing the data": [[55, "cleaning-and-standardizing-the-data"]], "Cleaning up after a branch": [[180, "cleaning-up-after-a-branch"]], "Cleaning your directory": [[181, "cleaning-your-directory"]], "Clustering": [[138, "clustering"]], "Clustering Algorithms": [[148, "clustering-algorithms"]], "Co-occurrence matrix": [[125, "co-occurrence-matrix"]], "Code Generation and Automation": [[49, "code-generation-and-automation"]], "Cognitive and Reasoning Limitations": [[49, "cognitive-and-reasoning-limitations"]], "Collaboration": [[74, "collaboration"]], "Collaborations:": [[85, "collaborations"]], "Collocations": [[143, "collocations"]], "Colossal Clean Crawled Corpus": [[117, "colossal-clean-crawled-corpus"]], "Combining Lexicon-Based Methods with Machine Learning": [[137, "combining-lexicon-based-methods-with-machine-learning"]], "Commit logs": [[174, "commit-logs"]], "Commit the resolved file": [[177, "commit-the-resolved-file"]], "Commit with a built-in-add": [[174, "commit-with-a-built-in-add"]], "Common Crawl": [[117, "common-crawl"], [121, "common-crawl"]], "Comparative Analysis": [[52, "comparative-analysis"]], "Compare distributions by rate decisions": [[26, "compare-distributions-by-rate-decisions"]], "Compare number of records": [[24, "compare-number-of-records"]], "Comparison": [[10, "comparison"], [76, "comparison"]], "Comparison of Methods": [[52, "comparison-of-methods"]], "Comparison of Project Templating Tools": [[69, "comparison-of-project-templating-tools"]], "Comparison to Related Models": [[95, "comparison-to-related-models"]], "Comparison with CountVectorizer": [[158, "comparison-with-countvectorizer"]], "Components of Conversational AI": [[91, "components-of-conversational-ai"]], "Computational and Financial Costs": [[49, "computational-and-financial-costs"]], "Compute Scores": [[107, "compute-scores"]], "Computing Coherence Scores": [[149, "computing-coherence-scores"]], "Computing Pair Scores": [[108, "computing-pair-scores"]], "Conceptual Foundation": [[53, "conceptual-foundation"]], "Concluding Remarks": [[56, "concluding-remarks"]], "Conclusion": [[2, "conclusion"], [8, "conclusion"], [10, "conclusion"], [46, "conclusion"], [51, "conclusion"], [52, "conclusion"], [53, "conclusion"], [54, "conclusion"], [57, "conclusion"], [61, "conclusion"], [63, "conclusion"], [67, "conclusion"], [72, "conclusion"], [74, "conclusion"], [76, "conclusion"], [79, "conclusion"], [80, "conclusion"], [81, "conclusion"], [82, "conclusion"], [85, "conclusion"], [88, "conclusion"], [89, "conclusion"], [93, "conclusion"], [94, "conclusion"], [106, "conclusion"], [115, "conclusion"], [116, "conclusion"], [146, "conclusion"], [154, "conclusion"], [155, "conclusion"], [156, "conclusion"], [158, "conclusion"], [171, "conclusion"]], "Conclusion and Alternative Thinking": [[169, "conclusion-and-alternative-thinking"]], "Conclusion and Considerations": [[45, "conclusion-and-considerations"]], "Conclusion and Future Directions": [[12, "conclusion-and-future-directions"]], "Conducting a Literature Review": [[89, "conducting-a-literature-review"]], "Configuration Management and Infrastructure as Code (IaC):": [[65, "configuration-management-and-infrastructure-as-code-iac"], [160, "configuration-management-and-infrastructure-as-code-iac"]], "Configuration frameworks:": [[66, "configuration-frameworks"]], "Configuring Git with your editor": [[174, "configuring-git-with-your-editor"]], "Configuring Git with your name and email": [[173, "configuring-git-with-your-name-and-email"]], "Conflicted reverts": [[175, "conflicted-reverts"]], "Conflicting commits": [[177, "conflicting-commits"]], "Conjugation (\ud65c\uc6a9)": [[140, "conjugation"]], "Cons": [[115, "cons"]], "Constituency Parsing": [[144, "constituency-parsing"]], "Constraints of RNNs, LSTMs, and GRUs": [[49, "constraints-of-rnns-lstms-and-grus"]], "Containerization": [[62, null]], "Containerization and Orchestration:": [[65, "containerization-and-orchestration"], [160, "containerization-and-orchestration"]], "Contents": [[36, "contents"], [109, "contents"]], "Contextualized Word Embeddings": [[99, "contextualized-word-embeddings"]], "Continuous Bag of Words (CBOW)": [[128, "continuous-bag-of-words-cbow"]], "Continuous Delivery and Automation Pipelines": [[71, "continuous-delivery-and-automation-pipelines"]], "Continuous Integration and Continuous Delivery (CI/CD):": [[65, "continuous-integration-and-continuous-delivery-ci-cd"], [160, "continuous-integration-and-continuous-delivery-ci-cd"]], "Continuous Integration and Deployment (CI/CD)": [[74, "continuous-integration-and-deployment-ci-cd"]], "Continuous Integration and Test-Driven Development": [[171, "continuous-integration-and-test-driven-development"]], "Contrasting with Traditional Fine-Tuning Approaches": [[50, "contrasting-with-traditional-fine-tuning-approaches"]], "Contrastive pre-training": [[9, "contrastive-pre-training"]], "Controlling Attributes": [[8, "controlling-attributes"]], "Conversational AI and Chatbots": [[91, null]], "Convolutional Neural Networks (CNN)": [[138, "convolutional-neural-networks-cnn"]], "Core Components of Docker": [[61, "core-components-of-docker"]], "Core Concepts": [[50, "core-concepts"]], "Core Concepts of BentoML": [[73, "core-concepts-of-bentoml"]], "Core Concepts of Transformer Architecture": [[52, "core-concepts-of-transformer-architecture"]], "Corpora": [[130, "corpora"], [130, "id1"]], "Corpora Sources": [[121, "corpora-sources"]], "Corpus and transform": [[152, "corpus-and-transform"]], "Corpus-Specific Lexicons": [[137, "corpus-specific-lexicons"]], "Correcting mistakes": [[174, "correcting-mistakes"]], "Correlated Topic Model (CTM)": [[151, "correlated-topic-model-ctm"]], "Correlation": [[25, "correlation"], [31, "correlation"]], "Correlation between Taylor rule and actual rates": [[25, "correlation-between-taylor-rule-and-actual-rates"]], "Corrupted Span Length": [[117, "corrupted-span-length"]], "Corruption Rates": [[117, "corruption-rates"]], "Cosine Similarity": [[148, "cosine-similarity"]], "Cost Management": [[163, "cost-management"]], "Course Content": [[37, "course-content"]], "Course Description": [[47, "course-description"], [70, "course-description"], [161, "course-description"]], "Course Description:": [[87, "course-description"]], "Course Objectives": [[37, "course-objectives"]], "Course Outline": [[47, "course-outline"], [161, "course-outline"]], "Courses": [[1, null]], "Covering your tracks": [[175, "covering-your-tracks"]], "Crawling the MD&A Section from the Financial Statement": [[123, "crawling-the-md-a-section-from-the-financial-statement"]], "Create Training Data Set": [[26, "create-training-data-set"]], "Create Training Datasets": [[27, null]], "Create a Dockerfile": [[61, "create-a-dockerfile"]], "Create a Volume": [[61, "create-a-volume"]], "Create a docker-compose.yml File": [[61, "create-a-docker-compose-yml-file"]], "Create and Run a Container": [[61, "create-and-run-a-container"]], "Creating a POS Tagger": [[144, "creating-a-pos-tagger"]], "Creating a Template": [[69, "creating-a-template"]], "Creating a Tokenizer": [[111, "creating-a-tokenizer"], [112, "creating-a-tokenizer"]], "Creating a repository": [[176, "creating-a-repository"]], "Creating the vector database": [[55, "creating-the-vector-database"]], "Creative Writing and Artistic Generation": [[49, "creative-writing-and-artistic-generation"]], "Credits": [[186, "credits"]], "Cross validating datasets": [[16, null]], "Cross validation of esg_topics dataset": [[17, "cross-validation-of-esg-topics-dataset"]], "Cross-lingual Benchmarks": [[115, "cross-lingual-benchmarks"]], "Cross-validate esg_polarity_kr dataset": [[16, "cross-validate-esg-polarity-kr-dataset"]], "Cross-validate esg_valid_topics_kr dataset": [[16, "cross-validate-esg-valid-topics-kr-dataset"]], "Crowdworker labeling functions": [[20, "crowdworker-labeling-functions"]], "Current Adoption of PEFT": [[52, "current-adoption-of-peft"]], "Current Challenges": [[53, "current-challenges"]], "D. AI and Machine Learning in Cybersecurity": [[77, "d-ai-and-machine-learning-in-cybersecurity"]], "D. Financial Services": [[77, "d-financial-services"]], "D. Handling challenges": [[89, "d-handling-challenges"]], "D. Identifying gaps and opportunities": [[89, "d-identifying-gaps-and-opportunities"]], "D. SSH Signing": [[76, "d-ssh-signing"]], "DALL\u00b7E 1": [[8, null]], "DALL\u00b7E 1 Architecture": [[8, "dalle-1-architecture"]], "DALL\u00b7E 1 Charateristics": [[8, "dalle-1-charateristics"]], "DALL\u00b7E 1 Results": [[8, "dalle-1-results"]], "DALL\u00b7E 2": [[5, "dalle-2"], [9, null]], "DALL\u00b7E 2 technical details": [[9, "dalle-2-technical-details"]], "DALL\u00b7E 2 technical details: decoders": [[9, "dalle-2-technical-details-decoders"]], "DALL\u00b7E 2 technical details: encoders": [[9, "dalle-2-technical-details-encoders"]], "DALL\u00b7E 2 technical details: the prior": [[9, "dalle-2-technical-details-the-prior"]], "DALL\u00b7E 2 technical details: training": [[9, "dalle-2-technical-details-training"]], "DALL\u00b7E 2/unCLIP": [[9, "dalle-2-unclip"]], "Data Analytics Methods": [[41, null]], "Data Description": [[95, "data-description"]], "Data Dumps": [[121, "data-dumps"]], "Data Instances": [[94, "data-instances"]], "Data Integration and Sharing": [[38, "data-integration-and-sharing"]], "Data Management and Infrastructures": [[38, "data-management-and-infrastructures"]], "Data Processing": [[150, "data-processing"]], "Data Quality and Provenance": [[38, "data-quality-and-provenance"]], "Data Quantity and Ground Truth": [[38, "data-quantity-and-ground-truth"]], "Data Science for Economics and Finance": [[37, null]], "Data Science in Economics": [[40, null]], "Data Security and Privacy Concerns": [[52, "data-security-and-privacy-concerns"]], "Data science steps for ML": [[71, "data-science-steps-for-ml"]], "Dataset Construction": [[95, "dataset-construction"]], "Dataset Preparation": [[101, "dataset-preparation"], [107, "dataset-preparation"], [108, "dataset-preparation"]], "Datasets": [[93, null], [122, null]], "Dealing with ambiguity": [[130, "dealing-with-ambiguity"]], "Deciphering Monetary Policy Board Minutes with Text Mining": [[120, "deciphering-monetary-policy-board-minutes-with-text-mining"]], "Decoder": [[8, "decoder"], [116, "decoder"]], "Decoding": [[101, "decoding"]], "Decoding and Search Strategies": [[97, null]], "Deconstructing Attention": [[113, "deconstructing-attention"]], "Deep Learning Techniques": [[138, "deep-learning-techniques"]], "Deep Learning for NLP": [[96, null]], "DeepLabCut": [[6, "deeplabcut"]], "DeepLabCut-Live!": [[6, "deeplabcut-live"]], "Defining the Model": [[111, "defining-the-model"], [112, "defining-the-model"]], "Definition and Overview": [[50, "definition-and-overview"], [53, "definition-and-overview"]], "Delimiter-focused attention patterns": [[114, "delimiter-focused-attention-patterns"]], "Dependency Parsing": [[144, "dependency-parsing"]], "Deploy a Voice-Based Chatbot with BentoML, LangChain, and Gradio": [[72, null]], "Deploy to BentoCloud": [[72, "deploy-to-bentocloud"]], "Deployment": [[73, "deployment"]], "Deployment Guides with BentoML": [[73, "deployment-guides-with-bentoml"]], "Deployment and Inference for LLMs": [[74, "deployment-and-inference-for-llms"]], "Description": [[37, "description"]], "Designing the application for scalability": [[55, "designing-the-application-for-scalability"]], "DetectGPT": [[84, null]], "DetectGPT: Zero-shot Machine-Generated Text Detection with Random Perturbations": [[84, "detectgpt-zero-shot-machine-generated-text-detection-with-random-perturbations"]], "DevOps": [[65, null], [160, null]], "DevOps Tools": [[65, "devops-tools"], [160, "devops-tools"]], "DevOps versus MLOps": [[71, "devops-versus-mlops"]], "DevSecOps": [[63, null]], "Developing a Research Methodology": [[89, "developing-a-research-methodology"]], "Differences between pass and passage": [[79, "differences-between-pass-and-passage"]], "Different LLM Fine-Tuning Techniques": [[46, "different-llm-fine-tuning-techniques"]], "Different ways of collaborating": [[178, "different-ways-of-collaborating"]], "Difficulty of Korean Tokenization": [[140, "difficulty-of-korean-tokenization"]], "Diffusion model": [[9, "diffusion-model"]], "Dimensionality Reduction": [[138, "dimensionality-reduction"], [148, "dimensionality-reduction"]], "Direct Confirmation Measure": [[147, "direct-confirmation-measure"]], "Disadvantages of Copier:": [[69, "disadvantages-of-copier"]], "Disagreement among Lexicons": [[137, "disagreement-among-lexicons"]], "Disambiguating entities and terms": [[55, "disambiguating-entities-and-terms"]], "Discrete Spaces": [[8, "discrete-spaces"]], "Displaying Text in this Tutorial": [[173, "displaying-text-in-this-tutorial"]], "Distinctive Features of AutoGen": [[42, "distinctive-features-of-autogen"]], "Distributed VCS in teams with conflicts": [[177, "distributed-vcs-in-teams-with-conflicts"]], "Distributed versus centralised": [[185, "distributed-versus-centralised"]], "Distribution of chunks": [[24, "distribution-of-chunks"]], "Distribution of corpus": [[24, "distribution-of-corpus"]], "Distribution of sectons": [[24, "distribution-of-sectons"]], "Distribution of sentences": [[24, "distribution-of-sentences"]], "Distributional Semantics": [[156, "distributional-semantics"]], "Distributional Similarity": [[157, "distributional-similarity"]], "Doc2Vec": [[154, "doc2vec"]], "Docker": [[61, null], [73, "docker"]], "Docker Compose": [[61, "docker-compose"]], "Docker Containers": [[61, "docker-containers"]], "Docker Engine": [[61, "docker-engine"]], "Docker Images": [[61, "docker-images"]], "Docker Registry": [[61, "docker-registry"]], "Docker Volumes": [[61, "docker-volumes"]], "Dockerfile": [[61, "dockerfile"]], "Document Clustering": [[148, "document-clustering"]], "Document Embeddings": [[154, "document-embeddings"]], "Documents in the Model and out of the Model": [[152, "documents-in-the-model-and-out-of-the-model"]], "Domain Specificity and Personalization": [[49, "domain-specificity-and-personalization"]], "Dot Product as Similarity": [[157, "dot-product-as-similarity"]], "Dotfiles": [[66, null]], "Dotfiles in a GitOps workflow": [[66, "dotfiles-in-a-gitops-workflow"]], "Dotfiles managers:": [[66, "dotfiles-managers"]], "Download and Extract Company Disclosure from DART": [[123, "download-and-extract-company-disclosure-from-dart"]], "Drawing Multiple Objects": [[8, "drawing-multiple-objects"]], "Dynamic Nature": [[163, "dynamic-nature"]], "Dynamic Programming": [[145, "dynamic-programming"]], "Dynamic Thresholding": [[10, "dynamic-thresholding"]], "Dynamic Topic Models (DTM)": [[151, "dynamic-topic-models-dtm"]], "E. Healthcare": [[77, "e-healthcare"]], "E. Privacy-Preserving Technologies": [[77, "e-privacy-preserving-technologies"]], "EDA on Numerical Data": [[25, null], [26, null]], "EDA on Sentiment Data": [[32, null]], "EDA on Sentiments: Correlation": [[31, null]], "EDA on numerical data": [[25, "id1"], [26, "id1"], [27, "eda-on-numerical-data"]], "ELECTRA": [[99, "electra"]], "ESG Ratings": [[18, null]], "Editing directly on GitHub": [[177, "editing-directly-on-github"]], "Educational Platforms": [[49, "educational-platforms"]], "Effective FED Rate": [[23, "effective-fed-rate"]], "Eliminating duplicate or redundant information": [[55, "eliminating-duplicate-or-redundant-information"]], "Embedding Layers vs. Dense Layers": [[126, "embedding-layers-vs-dense-layers"]], "Embedding the query and retrieved context": [[55, "embedding-the-query-and-retrieved-context"]], "Emergent abilities of large language models": [[98, "emergent-abilities-of-large-language-models"]], "Encoder": [[116, "encoder"]], "Encoder-Decoder Framework": [[49, "encoder-decoder-framework"]], "Encoder-Decoder Transformer Model": [[117, "encoder-decoder-transformer-model"]], "Encoding": [[101, "encoding"]], "Encoding Words": [[108, "encoding-words"]], "Encoding and Decoding": [[101, "encoding-and-decoding"]], "End-to-end MLOps Solutions": [[71, "end-to-end-mlops-solutions"]], "English Classification Tasks (GLUE, SuperGLUE)": [[115, "english-classification-tasks-glue-superglue"]], "English Generation Tasks (XSum, TweetQA, DROP)": [[115, "english-generation-tasks-xsum-tweetqa-drop"]], "Enhanced LLM Inferences": [[42, "enhanced-llm-inferences"]], "Ensuring factuality of the data": [[55, "ensuring-factuality-of-the-data"]], "Estimating Bigram or N-gram Probabilities using Maximum Likelihood Estimation (MLE)": [[132, "estimating-bigram-or-n-gram-probabilities-using-maximum-likelihood-estimation-mle"]], "Estimating Joint Probabilities of Word Sequences": [[132, "estimating-joint-probabilities-of-word-sequences"]], "Estimating Probabilities from Counts": [[132, "estimating-probabilities-from-counts"]], "Estimating Subword Occurrence Probabilities": [[106, "estimating-subword-occurrence-probabilities"]], "Ethical Issues in NLP": [[130, "ethical-issues-in-nlp"]], "Ethical and Societal Concerns": [[49, "ethical-and-societal-concerns"]], "Ethical and Technical Challenges": [[53, "ethical-and-technical-challenges"]], "Evaluating Language Models": [[132, "evaluating-language-models"]], "Evaluating Topics": [[147, "evaluating-topics"]], "Evaluating individual parts of the application": [[55, "evaluating-individual-parts-of-the-application"]], "Evaluation": [[128, "evaluation"], [128, "id5"]], "Evaluation of Compositions": [[145, "evaluation-of-compositions"]], "Everybody Dance Now": [[6, "everybody-dance-now"]], "Evolution": [[53, "evolution"]], "Evolution into Language Modeling": [[49, "evolution-into-language-modeling"]], "Example": [[132, "example"]], "Example 1: Part-of-Speech Tagging with eKoNLPy": [[141, "example-1-part-of-speech-tagging-with-ekonlpy"]], "Example 2: Adding Words to Dictionary": [[141, "example-2-adding-words-to-dictionary"]], "Example 3: Sentence Segmentation with KSS": [[141, "example-3-sentence-segmentation-with-kss"]], "Example Exercise": [[173, "example-exercise"]], "Example Python Code for AutoGen Agent": [[43, "example-python-code-for-autogen-agent"]], "Example of PEFT model inference using \ud83e\udd17 Accelerate\u2019s Big Model Inferencing capabilities": [[51, "example-of-peft-model-inference-using-accelerates-big-model-inferencing-capabilities"]], "Example of PEFT model training using \ud83e\udd17 Accelerate\u2019s DeepSpeed integration": [[51, "example-of-peft-model-training-using-accelerates-deepspeed-integration"]], "Examples": [[152, "examples"]], "Examples of MLE": [[132, "examples-of-mle"]], "Executing Multi-Agent Conversations": [[42, "executing-multi-agent-conversations"]], "Experimenting with different configurations": [[55, "experimenting-with-different-configurations"]], "Experiments on Synthetic Noise": [[115, "experiments-on-synthetic-noise"]], "Explaining BERT\u2019s attention patterns": [[114, "explaining-berts-attention-patterns"]], "Exploratory Data Analysis (EDA)": [[136, "exploratory-data-analysis-eda"]], "Exploring Public Templates": [[69, "exploring-public-templates"]], "FLAME: Free-form Language-based Motion Synthesis & Editing": [[6, "flame-free-form-language-based-motion-synthesis-editing"]], "FOMC contents": [[36, "fomc-contents"]], "Fast Forwards": [[183, "fast-forwards"]], "Fast Robotic Pencil Drawing": [[7, "fast-robotic-pencil-drawing"]], "Fast.ai": [[73, "fast-ai"]], "FastText": [[124, null], [154, "fasttext"]], "Feature Comparison": [[69, "feature-comparison"]], "Feature Engineering": [[136, "feature-engineering"], [136, "id1"], [138, "feature-engineering"]], "Feature Learning in Deep Learning Models": [[138, "feature-learning-in-deep-learning-models"]], "Fetch the labeled dataset from the labelstudio server": [[20, "fetch-the-labeled-dataset-from-the-labelstudio-server"]], "Few-shot learning:": [[100, "few-shot-learning"]], "Filter out data without code info": [[15, "filter-out-data-without-code-info"]], "Filter out invalid data": [[14, "filter-out-invalid-data"], [21, "filter-out-invalid-data"]], "Filter out invalid topics": [[14, "filter-out-invalid-topics"]], "Final Project": [[47, "final-project"]], "Financial Services and Risk Management": [[49, "financial-services-and-risk-management"]], "Find out what is on a branch": [[180, "find-out-what-is-on-a-branch"]], "Finding Corporate Codes": [[123, "finding-corporate-codes"]], "Finding the Best Pair": [[108, "finding-the-best-pair"]], "Fine-Tuning": [[59, "fine-tuning"]], "Fine-Tuning LLMs with Hugging Face AutoTrain": [[45, null]], "Fine-Tuning Methods": [[117, "fine-tuning-methods"]], "Fine-tuning": [[113, "fine-tuning"]], "Fine-tuning as a Transfer Learning Strategy": [[49, "fine-tuning-as-a-transfer-learning-strategy"]], "Finetuning": [[109, "finetuning"]], "Finetuning of PLMs": [[99, "finetuning-of-plms"]], "Firm-Level Political Risk: Measurement and Effects": [[119, "firm-level-political-risk-measurement-and-effects"]], "First Iteration": [[106, "first-iteration"]], "Forking a repository on GitHub": [[178, "forking-a-repository-on-github"]], "Form a team": [[177, "form-a-team"]], "Format": [[124, "format"]], "Formatting the Data": [[111, "formatting-the-data"], [112, "formatting-the-data"]], "Foundation Models: An Extension or Subset?": [[49, "foundation-models-an-extension-or-subset"]], "Framework Overview": [[42, "framework-overview"]], "Frameworks Supported by BentoML": [[73, "frameworks-supported-by-bentoml"]], "Frameworks for Scaling Agile": [[171, "frameworks-for-scaling-agile"]], "From Pork to Policy": [[120, "from-pork-to-policy"]], "Functioning of PRMs": [[53, "functioning-of-prms"]], "Fundamentals of Q-Learning": [[53, "fundamentals-of-q-learning"]], "Future Prospects": [[53, "future-prospects"]], "Future of Agile Methodologies": [[171, "future-of-agile-methodologies"]], "Future of Conversational AI": [[91, "future-of-conversational-ai"]], "GATO: A Generalist Agent": [[116, "gato-a-generalist-agent"]], "GLIDE": [[9, "glide"]], "GLIDE finetuning": [[9, "glide-finetuning"]], "GLIDE technical details": [[9, "glide-technical-details"]], "GNU Privacy Guard (GPG)": [[76, "gnu-privacy-guard-gpg"]], "GPT Family": [[99, "gpt-family"]], "GPT-4": [[85, null]], "GPT-4 Overview:": [[85, "gpt-4-overview"]], "GPT-4 System Card": [[85, "gpt-4-system-card"]], "GPT-4 Technical Report": [[85, "gpt-4-technical-report"]], "GPT-4-assisted Safety Research:": [[85, "gpt-4-assisted-safety-research"]], "GUANACO": [[83, "guanaco"]], "General Concept": [[131, "general-concept"]], "General Dictionaries": [[137, "general-dictionaries"]], "Generating Diverse and Natural 3D Human Motions from Text": [[6, "generating-diverse-and-natural-3d-human-motions-from-text"]], "Generating Passwords": [[79, "generating-passwords"]], "Generating a Project from a Template": [[69, "generating-a-project-from-a-template"]], "Generating a response using the LLM": [[55, "generating-a-response-using-the-llm"]], "Generating segment variants": [[145, "generating-segment-variants"]], "Generation": [[130, "generation"]], "Generation Problems": [[55, "generation-problems"]], "Generative AI Infrastructure Stack": [[59, null]], "Generative Language Models": [[86, null]], "Genesis of Natural Language Processing": [[49, "genesis-of-natural-language-processing"]], "Geometric Mean": [[147, "geometric-mean"]], "Get comparable performance to full finetuning by adapting LLMs to downstream tasks using consumer hardware": [[51, "get-comparable-performance-to-full-finetuning-by-adapting-llms-to-downstream-tasks-using-consumer-hardware"]], "Getting Started": [[152, "getting-started"]], "Getting Started with AutoTrain": [[45, "getting-started-with-autotrain"]], "Getting Started with Containerd": [[60, "getting-started-with-containerd"]], "Getting Started with PEFT": [[51, "getting-started-with-peft"]], "Getting from US Treasury Site as xml": [[23, "getting-from-us-treasury-site-as-xml"]], "Getting started": [[174, "getting-started"]], "Git != GitHub": [[173, "git-github"]], "Git Solo Workflow": [[174, "git-solo-workflow"]], "Git concepts": [[179, "git-concepts"]], "Git hunks": [[181, "git-hunks"]], "Git log": [[174, "git-log"]], "Git will not by default commit your new file": [[176, "git-will-not-by-default-commit-your-new-file"]], "GitHub Workflow": [[68, null]], "GitHub as a social network": [[177, "github-as-a-social-network"]], "GitHub authentication for Google Colaboratory": [[176, "github-authentication-for-google-colaboratory"]], "GitHub private repositories": [[176, "github-private-repositories"]], "GitOps": [[64, null], [159, null]], "GitOps Tools": [[64, "gitops-tools"], [159, "gitops-tools"]], "GitOps vs. DevOps": [[64, "gitops-vs-devops"], [159, "gitops-vs-devops"]], "Github\u2019s Fork & Pull Workflow": [[67, null]], "Giving permission": [[177, "giving-permission"]], "GloVe": [[125, null], [154, "glove"]], "GloVe vs word2vec": [[125, "glove-vs-word2vec"]], "Goals of NLP": [[130, "goals-of-nlp"]], "Goals of Tokenization": [[146, "goals-of-tokenization"]], "Google Cloud Run": [[73, "google-cloud-run"]], "Google\u2019s Vertex AI": [[52, "googles-vertex-ai"]], "Grab changes from a branch": [[180, "grab-changes-from-a-branch"]], "Grading": [[47, "grading"], [70, "grading"], [161, "grading"]], "Grading:": [[87, "grading"]], "Gradio UI": [[72, "gradio-ui"]], "Graph of Thoughts (GoT)": [[53, "graph-of-thoughts-got"]], "Graph of Thoughts and Chain of Thought in Large Language Models (LLMs)": [[53, "graph-of-thoughts-and-chain-of-thought-in-large-language-models-llms"]], "Greedy Search": [[97, "greedy-search"]], "Groundtruth Signal for LLMs": [[53, "groundtruth-signal-for-llms"]], "H2O": [[73, "h2o"]], "Handling Negations and Modifiers": [[137, "handling-negations-and-modifiers"]], "Hannanum": [[141, "hannanum"]], "Harvard General Inquirer": [[137, "harvard-general-inquirer"]], "Hash Codes": [[174, "hash-codes"]], "Hashing Vectorizer": [[143, "hashing-vectorizer"]], "Healthcare Analytics and Prediction": [[49, "healthcare-analytics-and-prediction"]], "Hidden Technical Debt in Machine Learning Systems": [[71, "hidden-technical-debt-in-machine-learning-systems"]], "Hierarchical softmax": [[128, "hierarchical-softmax"]], "High Dimensionality in N-grams": [[143, "high-dimensionality-in-n-grams"]], "High level differences between SentencePiece and other tokenizers": [[105, "high-level-differences-between-sentencepiece-and-other-tokenizers"]], "High-Quality vs. Low-Quality Data": [[93, "high-quality-vs-low-quality-data"]], "Highlighting Applications in NLP and Transformer Models": [[50, "highlighting-applications-in-nlp-and-transformer-models"]], "Home-made SSH servers": [[185, "home-made-ssh-servers"]], "Hosting Servers": [[185, "hosting-servers"]], "Hosting a local server": [[185, "hosting-a-local-server"]], "How DevOps works": [[65, "how-devops-works"], [160, "how-devops-works"]], "How GitOps works": [[64, "how-gitops-works"], [159, "how-gitops-works"]], "How Imagen Works: A Bird\u2019s-Eye View": [[10, "how-imagen-works-a-birds-eye-view"]], "How Imagen Works: A Deep Dive": [[10, "how-imagen-works-a-deep-dive"]], "How Q-Learning Works": [[53, "how-q-learning-works"]], "How SAM works: Promptable segmentation": [[88, "how-sam-works-promptable-segmentation"]], "How Tokens Are Used": [[115, "how-tokens-are-used"]], "How artists are using and confronting machine learning": [[2, "how-artists-are-using-and-confronting-machine-learning"]], "How do we Represent Words to Capture Word Similarities?": [[156, "how-do-we-represent-words-to-capture-word-similarities"]], "How do we implement this attention mechanism?": [[116, "how-do-we-implement-this-attention-mechanism"]], "How do we use version control?": [[173, "how-do-we-use-version-control"]], "How does it work?": [[153, "how-does-it-work"]], "How many different words are there in English?": [[139, "how-many-different-words-are-there-in-english"]], "How to Spot Machine-Written Texts": [[90, null]], "How to create a container image": [[60, "how-to-create-a-container-image"]], "How to generate n-grams using NLTK": [[132, "how-to-generate-n-grams-using-nltk"]], "How to implement MLOps": [[71, "how-to-implement-mlops"]], "How to input images into a transformer?": [[116, "how-to-input-images-into-a-transformer"]], "Huge Language Models and Stupid Backoff": [[133, "huge-language-models-and-stupid-backoff"]], "Hugging Face \ud83e\udd17": [[52, "hugging-face"]], "Hunks": [[181, "hunks"]], "I. Introduction": [[7, "i-introduction"], [77, "i-introduction"]], "I. Introduction to Large Language Models (LLMs)": [[55, "i-introduction-to-large-language-models-llms"]], "I. Introduction to PEFT": [[50, "i-introduction-to-peft"]], "I. Setup": [[141, "i-setup"]], "IBM\u2019s Watson: Winning at Jeopardy and Beyond": [[130, "ibms-watson-winning-at-jeopardy-and-beyond"]], "II. Authentication": [[77, "ii-authentication"]], "II. Edge Detection in Robotic Drawing Systems": [[7, "ii-edge-detection-in-robotic-drawing-systems"]], "II. Foundational Concepts": [[50, "ii-foundational-concepts"]], "II. Strategies for Enhanced Performance": [[55, "ii-strategies-for-enhanced-performance"]], "II. eKoNLPy": [[141, "ii-ekonlpy"]], "III. Data Preparation": [[55, "iii-data-preparation"]], "III. Encryption": [[77, "iii-encryption"]], "III. KSS (Korean Sentence Splitter)": [[141, "iii-kss-korean-sentence-splitter"]], "III. Semantic Segmentation and Object Detection Models": [[7, "iii-semantic-segmentation-and-object-detection-models"]], "III. Techniques and Methods in PEFT": [[50, "iii-techniques-and-methods-in-peft"]], "INT8 training of large models in Colab using PEFT LoRA and bits_and_bytes": [[51, "int8-training-of-large-models-in-colab-using-peft-lora-and-bits-and-bytes"]], "IV. Building the RAG Pipeline": [[55, "iv-building-the-rag-pipeline"]], "IV. Practical Applications of PEFT": [[50, "iv-practical-applications-of-peft"]], "IV. Signing": [[77, "iv-signing"]], "IV. Stroke Generation Techniques": [[7, "iv-stroke-generation-techniques"]], "Ignoring files": [[181, "ignoring-files"]], "Illustrative Examples of AutoGen Functionality": [[42, "illustrative-examples-of-autogen-functionality"]], "Image GPT": [[5, "image-gpt"]], "Image Generator": [[10, "image-generator"]], "Image Generator: Network Architecture": [[10, "image-generator-network-architecture"]], "Image Super-Resolution": [[10, "image-super-resolution"]], "Image encoder": [[88, "image-encoder"]], "Imagen": [[10, null]], "Implementation in LLMs": [[53, "implementation-in-llms"]], "Implementing Tokenization in Python": [[104, "implementing-tokenization-in-python"]], "Implementing a Simple MLOps Pipeline": [[80, "implementing-a-simple-mlops-pipeline"]], "Implementing the Research": [[89, "implementing-the-research"]], "Implications and Potential of Q-Star": [[54, "implications-and-potential-of-q-star"]], "Implications for AI and Machine Learning": [[50, "implications-for-ai-and-machine-learning"]], "Import data to labelstudio": [[21, "import-data-to-labelstudio"]], "Importance in Machine Learning and AI": [[50, "importance-in-machine-learning-and-ai"]], "Importance in PEFT": [[52, "importance-in-peft"]], "Importance in Word Representation": [[156, "importance-in-word-representation"]], "Importance of Corpus and Datasets": [[122, "importance-of-corpus-and-datasets"]], "Importance of Data Quality": [[52, "importance-of-data-quality"]], "Importance of DevSecOps": [[63, "importance-of-devsecops"]], "Importance of Ongoing Optimization and Improvement in RAG Systems": [[55, "importance-of-ongoing-optimization-and-improvement-in-rag-systems"]], "Importance of Software Engineering": [[163, "importance-of-software-engineering"]], "Improved Performance:": [[85, "improved-performance"]], "Improvement over word2vec": [[125, "improvement-over-word2vec"]], "Improving classification datasets": [[17, null]], "Improving predictive functions": [[128, "improving-predictive-functions"]], "Incorporating Syntax and Semantics": [[137, "incorporating-syntax-and-semantics"]], "Incremental Development Benefits": [[172, "incremental-development-benefits"]], "Incremental Development Problems": [[172, "incremental-development-problems"]], "Incremental Model": [[166, "incremental-model"], [172, "incremental-model"]], "Indirect Confirmation Measure": [[147, "indirect-confirmation-measure"]], "Individual emergent tasks from papers:": [[98, "individual-emergent-tasks-from-papers"]], "Industry-Specific Applications": [[50, "industry-specific-applications"]], "Inference": [[151, "inference"], [151, "id2"]], "Inference for Unseen Documents": [[152, "inference-for-unseen-documents"]], "Inferring Contextual Details": [[8, "inferring-contextual-details"]], "Inflectional Languages": [[140, "inflectional-languages"]], "Infrastructure for Fine-Tuning LLMs": [[74, "infrastructure-for-fine-tuning-llms"]], "Initial Framework: Self-supervised Learning & RNNs": [[49, "initial-framework-self-supervised-learning-rnns"]], "Initialising the repository": [[173, "initialising-the-repository"]], "Initialization": [[79, "initialization"], [101, "initialization"]], "Initializing pass": [[79, "initializing-pass"]], "Initializing passage": [[79, "initializing-passage"]], "Input/output/hidden layer": [[128, "input-output-hidden-layer"]], "Input:": [[146, "input"]], "Install Docker Compose": [[61, "install-docker-compose"]], "Install or upgrade of ekorpkit": [[152, "install-or-upgrade-of-ekorpkit"]], "Installation": [[42, "installation"], [61, "installation"], [69, "installation"], [79, "installation"], [114, "installation"], [123, "installation"]], "Installing age and rage": [[79, "installing-age-and-rage"]], "Installing pass": [[79, "installing-pass"]], "Installing \u2018age-plugin-yubikey\u2019": [[79, "installing-age-plugin-yubikey"]], "Instructor Tuning for Zero-Shot Prompting": [[49, "instructor-tuning-for-zero-shot-prompting"]], "Integrating AlphaGo\u2019s Principles in LLMs": [[53, "integrating-alphagos-principles-in-llms"]], "Integrating Q-Learning with Large Language Model (LLM) Training": [[53, "integrating-q-learning-with-large-language-model-llm-training"]], "Integrating with fzf": [[79, "integrating-with-fzf"]], "Integration into Existing ML Pipelines": [[50, "integration-into-existing-ml-pipelines"]], "Integration with LLMs": [[53, "integration-with-llms"]], "Interactive add": [[181, "interactive-add"]], "Internal System Data": [[121, "internal-system-data"]], "Interpretability Challenge": [[40, "interpretability-challenge"]], "Introduction": [[1, null], [2, "introduction"], [5, null], [6, "introduction"], [12, "introduction"], [39, null], [41, "introduction"], [48, null], [56, "introduction"], [60, "introduction"], [67, "introduction"], [69, "introduction"], [72, "introduction"], [74, "introduction"], [76, "introduction"], [79, "introduction"], [81, "introduction"], [83, "introduction"], [84, "introduction"], [88, "introduction"], [89, "introduction"], [91, "introduction"], [92, "introduction"], [93, "introduction"], [102, "introduction"], [106, "introduction"], [110, "introduction"], [111, "introduction"], [112, "introduction"], [122, "introduction"], [130, null], [134, "introduction"], [136, "introduction"], [147, "introduction"], [148, "introduction"], [151, "introduction"], [154, "introduction"], [155, "introduction"], [156, "introduction"], [162, null], [167, "introduction"], [169, "introduction"]], "Introduction to Agile Software Development": [[171, "introduction-to-agile-software-development"]], "Introduction to BentoML": [[73, null]], "Introduction to Large Language Models": [[53, "introduction-to-large-language-models"]], "Introduction to MLOps": [[71, null]], "Introduction to NLP": [[129, null]], "Introduction to OpenDartReader": [[123, "introduction-to-opendartreader"]], "Introduction to Part-of-Speech (POS)": [[144, "introduction-to-part-of-speech-pos"]], "Introduction to RAG-based LLM applications": [[55, "introduction-to-rag-based-llm-applications"]], "Isolating Languages": [[140, "isolating-languages"]], "Isolating, Inflectional, and Agglutinative Languages": [[140, "isolating-inflectional-and-agglutinative-languages"]], "Iterative Learning and Self-Improvement": [[53, "iterative-learning-and-self-improvement"]], "Iterative Model": [[166, "iterative-model"], [172, "iterative-model"]], "Iterative Model Benefits": [[172, "iterative-model-benefits"]], "Iterative Model Problems": [[172, "iterative-model-problems"]], "Jean Tinguely\u2019s drawing machine": [[5, "jean-tinguelys-drawing-machine"]], "Key Benefits of Fine-Tuning LLMs:": [[45, "key-benefits-of-fine-tuning-llms"]], "Key Changes To the mT5 Architecture": [[115, "key-changes-to-the-mt5-architecture"]], "Key Components of AlphaGo": [[53, "key-components-of-alphago"]], "Key Components of LLMOps": [[74, "key-components-of-llmops"]], "Key Concepts": [[41, "key-concepts"]], "Key Differences": [[69, "key-differences"]], "Key Differentiators of LLM Agents**:": [[42, "key-differentiators-of-llm-agents"]], "Key Features:": [[69, "key-features"]], "Key Practices and Techniques": [[171, "key-practices-and-techniques"]], "Key Principles of DevSecOps": [[63, "key-principles-of-devsecops"]], "Kkma": [[141, "kkma"]], "Komoran": [[141, "komoran"]], "Korean Part-of-Speech (POS) Tagging": [[140, "korean-part-of-speech-pos-tagging"]], "Kubernetes": [[73, "kubernetes"]], "LDA Basics": [[152, "lda-basics"]], "LDA Visualization": [[152, "lda-visualization"]], "LDA coherence": [[152, "lda-coherence"]], "LIWC: Linguistic Inquiry and Word Count": [[137, "liwc-linguistic-inquiry-and-word-count"]], "LLAMA": [[83, "llama"]], "LLM App Ecosystem": [[56, null]], "LLM Application Architectures": [[57, null]], "LLM Debugging and Monitoring": [[57, "llm-debugging-and-monitoring"]], "LLM Fine-tuning": [[46, null]], "LLM Ops": [[56, "llm-ops"]], "LLM Stacks": [[58, null]], "LLMOps": [[74, null]], "LLMOps Landscape": [[74, "llmops-landscape"]], "Lab Exercise: Calculating PMI": [[155, "lab-exercise-calculating-pmi"]], "Lab: Crawling DART Data": [[123, null]], "Lab: Exploratory Data Analysis (EDA)": [[94, null]], "Lab: Finetuining a MLM": [[110, null]], "Lab: Korean Text Processing": [[141, null]], "Lab: Lexicon-based Sentiment Analysis": [[135, null]], "Lab: ML-based Sentiment Classification": [[136, null]], "Lab: Pretraining LMs - CLM": [[111, null]], "Lab: Pretraining LMs - MLM": [[112, null]], "Lab: Tokenization and Pre-processing": [[142, null]], "Lab: Tomotopy": [[152, null]], "Lab: Topic Coherence": [[149, null]], "Lab: Topic Modeling": [[150, null]], "Lab: Training Tokenizers": [[103, null]], "Lab: Word Similarity": [[155, null]], "Labeling": [[59, "labeling"]], "Language Models": [[99, "language-models"], [131, null]], "Large Guidance Weight Samplers": [[10, "large-guidance-weight-samplers"]], "Large Language & Foundational Models": [[59, "large-language-foundational-models"]], "Large Language Models": [[47, null], [98, null]], "Large Language Models?": [[49, null]], "Latent Dirichlet Allocation (LDA)": [[151, "latent-dirichlet-allocation-lda"]], "Layout for GitHub pages": [[182, "layout-for-github-pages"]], "Learning Goals": [[47, "learning-goals"], [161, "learning-goals"]], "Learning Objectives": [[70, "learning-objectives"]], "Learning Objectives:": [[87, "learning-objectives"]], "Learning Outcomes": [[37, "learning-outcomes"]], "Legal Issues in Web Crawling": [[121, "legal-issues-in-web-crawling"]], "Lexical Semantics": [[156, "lexical-semantics"]], "Lexicon-Based Methods": [[137, null]], "Lightweight mask decoder": [[88, "lightweight-mask-decoder"]], "Limitations & Challenges of Large Language Models": [[49, "limitations-challenges-of-large-language-models"]], "Limitations of Traditional Models": [[40, "limitations-of-traditional-models"]], "Limitations of base LLMs": [[55, "limitations-of-base-llms"]], "Limitations of the Bag of Words Model": [[153, "limitations-of-the-bag-of-words-model"]], "Linguistic (Grammatical) Classification": [[140, "linguistic-grammatical-classification"]], "Linguistic Knowledge": [[139, "linguistic-knowledge"]], "List Containers": [[61, "list-containers"]], "List Images": [[61, "list-images"]], "Load Calendar": [[23, "load-calendar"]], "Load Economic Indices": [[23, "load-economic-indices"]], "Load FOMC Corpus": [[30, "load-fomc-corpus"]], "Load FOMC class": [[23, "load-fomc-class"], [24, "load-fomc-class"]], "Load FOMC corpus": [[24, "load-fomc-corpus"]], "Load Market Data": [[23, "load-market-data"]], "Load a corpus": [[15, "load-a-corpus"]], "Load a dataset": [[152, "load-a-dataset"]], "Load a feature set": [[29, "load-a-feature-set"], [35, "load-a-feature-set"]], "Load company code info": [[14, "load-company-code-info"], [15, "load-company-code-info"], [21, "load-company-code-info"]], "Load data": [[19, "load-data"], [21, "load-data"]], "Load data to predict": [[14, "load-data-to-predict"]], "Load datasets": [[31, "load-datasets"], [32, "load-datasets"]], "Load preprocessed data": [[25, "load-preprocessed-data"], [26, "load-preprocessed-data"], [27, "load-preprocessed-data"]], "Load the mC4 dataset": [[94, "load-the-mc4-dataset"]], "Loading the Data": [[149, "loading-the-data"]], "Loading the Dataset": [[55, "loading-the-dataset"], [136, "loading-the-dataset"]], "Loading the Model": [[112, "loading-the-model"]], "Loading the Pretrained Model and Tokenizer": [[110, "loading-the-pretrained-model-and-tokenizer"]], "Loss Computation": [[107, "loss-computation"]], "Losses": [[88, "losses"]], "Low-Rank Adaptation and Sparse Fine-Tuning": [[50, "low-rank-adaptation-and-sparse-fine-tuning"]], "MARGE": [[95, "marge"]], "MDM: Human Motion Diffusion Model": [[6, "mdm-human-motion-diffusion-model"]], "MLOps Level 0": [[71, "mlops-level-0"]], "MLOps Level 1": [[71, "mlops-level-1"]], "MLOps Level 2": [[71, "mlops-level-2"]], "MLOps Project": [[75, null]], "MMLU (51 tasks; see Chinchilla paper for results):": [[98, "mmlu-51-tasks-see-chinchilla-paper-for-results"]], "MPQA Subjectivity Lexicon": [[137, "mpqa-subjectivity-lexicon"]], "Machine Learning Systems Design": [[70, null]], "Machine Learning and Statistical Methods": [[139, "machine-learning-and-statistical-methods"]], "Machine Learning-Based Methods": [[138, null]], "Main idea": [[128, "main-idea"]], "Managing Complexity": [[163, "managing-complexity"]], "Markdown": [[173, "markdown"]], "Masked Language Modeling": [[99, "masked-language-modeling"]], "Maximum Matching Algorithm": [[145, "maximum-matching-algorithm"]], "Mean": [[147, "mean"]], "Measuring Economic Policy Uncertainty": [[119, "measuring-economic-policy-uncertainty"]], "Mecab": [[141, "mecab"]], "Mechanism and Adaptation": [[53, "mechanism-and-adaptation"]], "Median": [[147, "median"]], "Meet the Camelids: A Family of LLMs": [[83, null]], "Merge Operations": [[101, "merge-operations"]], "Merge commits": [[177, "merge-commits"]], "Merge with fed rate data": [[31, "merge-with-fed-rate-data"]], "Merging branches": [[180, "merging-branches"]], "Merging the Best Pair": [[108, "merging-the-best-pair"]], "Method 1: Language Model Based Approaches": [[90, "method-1-language-model-based-approaches"]], "Method 2: Statistical Methods": [[90, "method-2-statistical-methods"]], "Method 3: Curvature-Based Approaches": [[90, "method-3-curvature-based-approaches"]], "Method 4: Human Evaluation": [[90, "method-4-human-evaluation"]], "Methodologies": [[12, "methodologies"], [98, "methodologies"]], "Methods for Detecting Machine-Written Texts": [[90, "methods-for-detecting-machine-written-texts"]], "Methods of Tokenization": [[102, "methods-of-tokenization"]], "Migrating from pass to passage": [[79, "migrating-from-pass-to-passage"]], "Missing Values": [[26, "missing-values"], [27, "missing-values"]], "Model": [[104, "model"]], "Model Hallucination": [[57, "model-hallucination"]], "Model Initialization": [[107, "model-initialization"]], "Model Monitoring and Maintenance": [[74, "model-monitoring-and-maintenance"]], "Model Optimization": [[107, "model-optimization"]], "Model Safety": [[59, "model-safety"]], "Model Save and Load": [[152, "model-save-and-load"]], "Model Supervision / AI Observability": [[59, "model-supervision-ai-observability"]], "Modifying the Model for Sentiment Analysis": [[110, "modifying-the-model-for-sentiment-analysis"]], "Monetary Policy Shocks": [[34, null]], "Monitoring and Logging:": [[65, "monitoring-and-logging"], [160, "monitoring-and-logging"]], "Morphemes and Morphs": [[139, "morphemes-and-morphs"]], "Morphemes: Stems and Affixes": [[139, "morphemes-stems-and-affixes"]], "Morphological Analysis (Part of Speech Tagging)": [[140, "morphological-analysis-part-of-speech-tagging"]], "Morphological Analysis in Korean": [[140, "morphological-analysis-in-korean"]], "Motion Capture and Motion Synthesis": [[6, null]], "MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model": [[6, "motiondiffuse-text-driven-human-motion-generation-with-diffusion-model"]], "Motivation": [[150, "motivation"]], "Multi-Task Learning": [[117, "multi-task-learning"]], "Multi-head Attention": [[113, "multi-head-attention"]], "Multi-head attention": [[116, "multi-head-attention"]], "Multilingual datasets": [[93, "multilingual-datasets"]], "Multimodal Machine Learning": [[116, "multimodal-machine-learning"]], "N-Grams and Probability Estimation": [[132, "n-grams-and-probability-estimation"]], "N-gram Language Models": [[132, null]], "N-gram Models and Markov Assumption": [[132, "n-gram-models-and-markov-assumption"]], "N-grams for Tokenization": [[143, null]], "N-grams in Tokenization": [[143, "n-grams-in-tokenization"]], "N-grams, Dimensionality, and Managing Vocabulary": [[143, "n-grams-dimensionality-and-managing-vocabulary"]], "NLP Application - Chatbot": [[130, "nlp-application-chatbot"]], "NLP Application - Machine Translation": [[130, "nlp-application-machine-translation"]], "NLP Application - OpenAI CODEX": [[130, "nlp-application-openai-codex"]], "NLP Application - OpenAI GPT-3": [[130, "nlp-application-openai-gpt-3"]], "NLP Application - Text to Image Generation": [[130, "nlp-application-text-to-image-generation"]], "NLP Application - Virtual Assistants": [[130, "nlp-application-virtual-assistants"]], "NLP Applications": [[118, null]], "NLP in Low-Resource Languages": [[130, "nlp-in-low-resource-languages"]], "NLP in the Korean Language": [[130, "nlp-in-the-korean-language"]], "NLP \u201cBias\u201d is statistical bias": [[137, "nlp-bias-is-statistical-bias"]], "NMF Applications": [[150, "nmf-applications"]], "NMF using scikit-learn": [[150, "nmf-using-scikit-learn"]], "Naive Recursive Algorithm": [[145, "naive-recursive-algorithm"]], "National Institute of Korean Language\u2019s Everyone\u2019s Corpus": [[121, "national-institute-of-korean-languages-everyones-corpus"]], "Necessity and Benefits": [[41, "necessity-and-benefits"]], "Need for SDLC": [[166, "need-for-sdlc"]], "Negative sampling": [[128, "negative-sampling"], [128, "id6"]], "Neural Language Models": [[127, null]], "Neural Nets for NLP": [[130, "neural-nets-for-nlp"]], "Neuro-Symbolic AI and Q-Star": [[54, "neuro-symbolic-ai-and-q-star"]], "New Data Sources": [[40, "new-data-sources"]], "Next": [[65, "next"], [66, "next"], [68, "next"], [74, "next"], [80, "next"], [91, "next"], [93, "next"], [98, "next"], [102, "next"], [116, "next"], [118, "next"], [122, "next"], [126, "next"], [131, "next"], [134, "next"], [139, "next"], [148, "next"], [154, "next"], [160, "next"]], "Next Contents": [[44, "next-contents"], [46, "next-contents"], [50, "next-contents"], [53, "next-contents"]], "Next-word attention pattern": [[114, "next-word-attention-pattern"]], "Noise-contrastive estimation": [[128, "noise-contrastive-estimation"]], "Non-Functional Requirements Categories:": [[165, "non-functional-requirements-categories"]], "Non-negative Matrix Factorization (NMF)": [[150, "non-negative-matrix-factorization-nmf"], [151, "non-negative-matrix-factorization-nmf"]], "Nonconflicted commits to the same file": [[177, "nonconflicted-commits-to-the-same-file"]], "Nonconflicting changes": [[177, "nonconflicting-changes"]], "Normalization": [[104, "normalization"]], "Normalized Pointwise Mutual Information": [[147, "normalized-pointwise-mutual-information"]], "Nothing to see here": [[174, "nothing-to-see-here"]], "Numbers": [[146, "numbers"]], "Objective": [[75, "objective"]], "Objectives": [[172, "objectives"]], "Obtaining a colleague\u2019s code": [[177, "obtaining-a-colleagues-code"]], "Obtaining the Vocabulary": [[106, "obtaining-the-vocabulary"]], "Offline Batch Serving": [[73, "offline-batch-serving"]], "Offline Data": [[121, "offline-data"]], "One-shot learning:": [[100, "one-shot-learning"]], "Open Korean Text (Okt)": [[141, "open-korean-text-okt"]], "OpenAI": [[52, "openai"]], "Optimizing for the best quality responses": [[55, "optimizing-for-the-best-quality-responses"]], "Orchestration Layer / Application Frameworks": [[59, "orchestration-layer-application-frameworks"]], "Other Approaches to Enhancing LLM Performance": [[46, "other-approaches-to-enhancing-llm-performance"]], "Other Korean Tokenizers": [[141, "other-korean-tokenizers"]], "Other Tasks": [[130, "other-tasks"]], "Our first commit": [[174, "our-first-commit"]], "Out-of-Vocabulary Words (OOV) for N-grams": [[143, "out-of-vocabulary-words-oov-for-n-grams"]], "Outcomes": [[75, "outcomes"]], "Outline": [[172, "outline"]], "Output:": [[146, "output"]], "Overfitting and Underfitting Challenges": [[50, "overfitting-and-underfitting-challenges"]], "Overview": [[85, "overview"], [109, "overview"], [139, "overview"], [151, "overview"], [151, "id1"], [171, "overview"]], "Overview of Agile Project Management": [[171, "overview-of-agile-project-management"]], "Overview of AlphaGo": [[53, "overview-of-alphago"]], "Overview of PEFT Techniques": [[50, "overview-of-peft-techniques"]], "Overview of PRMs": [[53, "overview-of-prms"]], "PEFT + \ud83e\udd17 Accelerate": [[51, "peft-accelerate"]], "PEFT Techniques Overview": [[52, "peft-techniques-overview"]], "PEFT for LLMs": [[52, null]], "PEFT in Conjunction with Emerging AI Technologies": [[50, "peft-in-conjunction-with-emerging-ai-technologies"]], "PEFT in HuggingFace Libraries": [[51, null]], "PEFT\u2019s Impact on Large-Scale Models": [[50, "pefts-impact-on-large-scale-models"]], "PMI": [[147, "pmi"]], "PMI and Smoothing": [[157, "pmi-and-smoothing"]], "Paradigms of Software Development": [[164, "paradigms-of-software-development"]], "Parameter Efficient Tuning of Diffusion Models": [[51, "parameter-efficient-tuning-of-diffusion-models"]], "Parameter Efficient Tuning of LLMs for RLHF components such as Ranker and Policy": [[51, "parameter-efficient-tuning-of-llms-for-rlhf-components-such-as-ranker-and-policy"]], "Parameter-Efficient Fine-Tuning (PEFT)": [[50, null]], "Part 1: Understanding Tokenization": [[142, "part-1-understanding-tokenization"]], "Part 2: Different Types of Tokenization with Examples": [[142, "part-2-different-types-of-tokenization-with-examples"]], "Part 3: Pre-processing Steps in NLP": [[142, "part-3-pre-processing-steps-in-nlp"]], "Part 4: Tokenization in Different Languages with Examples": [[142, "part-4-tokenization-in-different-languages-with-examples"]], "Part-of-Speech Tagging and Parsing": [[144, null]], "Performing sentiment analysis using AFINN": [[135, "performing-sentiment-analysis-using-afinn"]], "Performing sentiment analysis using TextBlob": [[135, "performing-sentiment-analysis-using-textblob"]], "Performing sentiment analysis using VADER": [[135, "performing-sentiment-analysis-using-vader"]], "Permutation Language Modeling": [[99, "permutation-language-modeling"]], "Perplexity": [[132, "perplexity"]], "Perplexity Sampling": [[95, "perplexity-sampling"]], "Perplexity\u2019s Relation to Entropy": [[132, "perplexitys-relation-to-entropy"]], "Phase-Functioned Neural Networks for Character Control": [[6, "phase-functioned-neural-networks-for-character-control"]], "Physics-based Human Motion Estimation and Synthesis from Videos": [[6, "physics-based-human-motion-estimation-and-synthesis-from-videos"]], "Pining Topics using Word Priors": [[152, "pining-topics-using-word-priors"], [152, "id2"]], "Plan-Driven vs Agile Processes": [[172, "plan-driven-vs-agile-processes"]], "Playground Tools": [[56, "playground-tools"]], "Playing with GitHub": [[176, "playing-with-github"]], "Plot impulse response functions": [[34, "plot-impulse-response-functions"]], "Plot rate decision count": [[25, "plot-rate-decision-count"]], "Plot the results and compare to the economical uncertainty / systemic risk periods": [[32, "plot-the-results-and-compare-to-the-economical-uncertainty-systemic-risk-periods"]], "Plot the sentiment scores": [[32, "plot-the-sentiment-scores"]], "Pointwise Mutual Information": [[143, "pointwise-mutual-information"]], "Pointwise Mutual Information (PMI)": [[155, "pointwise-mutual-information-pmi"], [157, "pointwise-mutual-information-pmi"]], "Policy Neural Network Adaptation": [[53, "policy-neural-network-adaptation"]], "Popular NLP Datasets": [[122, "popular-nlp-datasets"]], "Popular Traditional Machine Learning Algorithms": [[138, "popular-traditional-machine-learning-algorithms"]], "Positive Pointwise Mutual Information (PPMI)": [[157, "positive-pointwise-mutual-information-ppmi"]], "Post-processing": [[104, "post-processing"]], "Postprocess FOMC corpus": [[24, "postprocess-fomc-corpus"]], "Postprocess metadata": [[24, "postprocess-metadata"]], "Postprocessing": [[104, "postprocessing"]], "Potential and Implications": [[53, "potential-and-implications"]], "Practical Issues in N-gram Models": [[132, "practical-issues-in-n-gram-models"]], "Practical example - Team up!": [[178, "practical-example-team-up"]], "Practice": [[155, "practice"]], "Pre-processing: The Art of Text Analysis": [[146, "pre-processing-the-art-of-text-analysis"]], "Pre-tokenization": [[104, "pre-tokenization"], [108, "pre-tokenization"]], "Pre-training": [[113, "pre-training"]], "Pre-training and Fine-tuning": [[113, "pre-training-and-fine-tuning"]], "Predetermined Number of Unique Tokens": [[105, "predetermined-number-of-unique-tokens"]], "Predict polarities": [[14, "predict-polarities"], [21, "predict-polarities"]], "Predict sentiments and aggregate scores with a pipeline": [[30, "predict-sentiments-and-aggregate-scores-with-a-pipeline"]], "Predict sentiments of sentences": [[30, "predict-sentiments-of-sentences"]], "Predict sentiments with the LM sentiment analyser": [[30, "predict-sentiments-with-the-lm-sentiment-analyser"]], "Predict sentiments with the T5": [[30, "predict-sentiments-with-the-t5"]], "Predict sentiments with the finbert": [[30, "predict-sentiments-with-the-finbert"]], "Predicting ESG Categories and Polarities": [[19, null]], "Predicting Sentiments of FOMC Corpus": [[30, null]], "Predicting categories": [[14, "predicting-categories"], [19, "predicting-categories"], [21, "predicting-categories"]], "Predicting polarities": [[19, "predicting-polarities"]], "Predicting the next decisions with tones": [[35, null]], "Preparation": [[123, "preparation"]], "Prepare an environment": [[15, "prepare-an-environment"]], "Prepare esg_polarity_kr dataset": [[16, "prepare-esg-polarity-kr-dataset"]], "Prepare esg_topics_improved dataset": [[16, "prepare-esg-topics-improved-dataset"]], "Preparing Numerical Data": [[23, null]], "Preparing Textual Data": [[24, null]], "Preparing active learning data": [[21, null]], "Preparing additional polarity data": [[14, "preparing-additional-polarity-data"]], "Preparing esg_polarity_kr dataset": [[22, "preparing-esg-polarity-kr-dataset"]], "Preparing esg_topics dataset": [[17, "preparing-esg-topics-dataset"]], "Preparing esg_topics_improved dataset": [[22, "preparing-esg-topics-improved-dataset"]], "Preparing invalid topic data": [[14, "preparing-invalid-topic-data"]], "Preparing the Dataset": [[110, "preparing-the-dataset"], [111, "preparing-the-dataset"], [112, "preparing-the-dataset"]], "Preparing the Environment": [[110, "preparing-the-environment"], [111, "preparing-the-environment"], [112, "preparing-the-environment"]], "Preparing training datasets": [[20, null]], "Prerequisites": [[37, "prerequisites"], [70, "prerequisites"]], "Prerequisites:": [[81, "prerequisites"], [87, "prerequisites"]], "Prerequisites: Before Diving into Simple MLOps Pipeline": [[80, "prerequisites-before-diving-into-simple-mlops-pipeline"]], "Pretrained Language Models": [[99, null], [99, "id1"]], "Pretraining": [[109, "pretraining"]], "Probabilistic Latent Semantic Analysis (pLSA)": [[151, "probabilistic-latent-semantic-analysis-plsa"]], "Problems with the Transformer architecture": [[116, "problems-with-the-transformer-architecture"]], "Process-Supervised Reward Models (PRMs) in Large Language Models": [[53, "process-supervised-reward-models-prms-in-large-language-models"]], "Program vs. Software": [[164, "program-vs-software"]], "Programming and documents": [[173, "programming-and-documents"]], "Project Overview": [[75, "project-overview"]], "Project Proposal": [[4, "project-proposal"], [168, null]], "Project Proposal Template": [[170, null]], "Project Templating Tools": [[69, null]], "Project Title:": [[170, "project-title"]], "Projecting the Future of PEFT in AI and ML": [[50, "projecting-the-future-of-peft-in-ai-and-ml"]], "Prompt Chaining": [[57, "prompt-chaining"]], "Prompt Engineering": [[57, "prompt-engineering"], [97, "prompt-engineering"], [100, "prompt-engineering"]], "Prompt Engineering and In-Context Learning": [[49, "prompt-engineering-and-in-context-learning"]], "Prompt encoder": [[88, "prompt-encoder"]], "Prompt-based and Adapter-based Methods": [[50, "prompt-based-and-adapter-based-methods"]], "Prompting on LLMs": [[100, "prompting-on-llms"]], "Prompts and Queries": [[56, "prompts-and-queries"]], "Proposal Components": [[167, "proposal-components"]], "Proprietary datasets": [[93, "proprietary-datasets"]], "Pros": [[115, "pros"]], "Prototype Model": [[166, "prototype-model"]], "Public datasets": [[93, "public-datasets"]], "Publishing branches": [[180, "publishing-branches"]], "Pull Request": [[178, "pull-request"]], "Pull an Image": [[61, "pull-an-image"]], "Punctuation": [[146, "punctuation"]], "Putting Everything Together": [[147, "putting-everything-together"]], "Putting them together in a pipeline": [[14, null]], "PyTorch": [[73, "pytorch"]], "Python Code Examples": [[158, "python-code-examples"]], "Q-Learning": [[53, null]], "Q-Learning in AI": [[53, "q-learning-in-ai"]], "Q-Star (Q*)": [[54, null]], "Quality Management": [[163, "quality-management"]], "Question Answering Systems": [[49, "question-answering-systems"]], "Question Answering on SQuAD 1.1": [[130, "question-answering-on-squad-1-1"]], "Quick Start": [[123, "quick-start"]], "Quick Transformer Review": [[52, "quick-transformer-review"]], "RAD Model": [[166, "rad-model"]], "Rationale and Advantages": [[41, "rationale-and-advantages"]], "Real-World Applications of Large Language Models": [[49, "real-world-applications-of-large-language-models"]], "Real-world applications of NLP": [[130, "real-world-applications-of-nlp"]], "Rebase vs merge": [[183, "rebase-vs-merge"]], "Rebasing pros and cons": [[183, "rebasing-pros-and-cons"]], "Recap: What is Software Engineering?": [[172, "recap-what-is-software-engineering"]], "Recurrent Neural Networks (RNN)": [[138, "recurrent-neural-networks-rnn"]], "Reference Books": [[129, "reference-books"]], "References": [[0, "references"], [2, "references"], [6, "references"], [7, "references"], [10, "references"], [36, "references"], [56, "references"], [57, "references"], [59, "references"], [67, "references"], [73, "references"], [83, "references"], [85, "references"], [88, "references"], [99, "references"], [114, "references"], [115, "references"], [117, "references"], [133, "references"], [145, "references"]], "References and Further Reading": [[53, "references-and-further-reading"]], "Referencing remotes": [[185, "referencing-remotes"]], "Referencs": [[90, "referencs"]], "Referring to changes with HEAD and ~": [[175, "referring-to-changes-with-head-and"]], "Reinforcement Learning from Human Feedback (RLHF)": [[46, "reinforcement-learning-from-human-feedback-rlhf"]], "Reinforcement Learning with Human Feedback (RLHF)": [[92, null]], "Rejected push": [[177, "rejected-push"]], "Related Areas of NLP": [[130, "related-areas-of-nlp"]], "Relationship between containerd and Kubernetes": [[60, "relationship-between-containerd-and-kubernetes"]], "Remotes": [[176, "remotes"]], "Remove a Container": [[61, "remove-a-container"]], "Remove an Image": [[61, "remove-an-image"]], "Reparameterization-Based Methods": [[52, "reparameterization-based-methods"]], "Repeating the Process": [[108, "repeating-the-process"]], "Requirement Engineering Process": [[165, "requirement-engineering-process"]], "Requirements": [[75, "requirements"]], "Requirements Engineering (RE)": [[165, null]], "Research Part I": [[119, null]], "Research Part II": [[120, null]], "Research, Infrastructure & Limitations:": [[85, "research-infrastructure-limitations"]], "Resetting the working area": [[175, "resetting-the-working-area"]], "Resolving ambiguity": [[88, "resolving-ambiguity"]], "Resolving conflicts": [[177, "resolving-conflicts"]], "Resources": [[70, "resources"]], "Responsible AI Principles": [[74, "responsible-ai-principles"]], "Results": [[115, "results"]], "Results and Analysis": [[10, "results-and-analysis"]], "Retrieval Augmented Generation (RAG)": [[55, null], [57, "retrieval-augmented-generation-rag"]], "Retrieval Problems": [[55, "retrieval-problems"]], "Retrieval process": [[55, "retrieval-process"]], "Retrieving Passwords": [[79, "retrieving-passwords"]], "Reverting": [[175, "reverting"]], "Review of changes": [[174, "review-of-changes"], [175, "review-of-changes"]], "Review of status": [[174, "review-of-status"]], "Rewriting history": [[175, "rewriting-history"]], "RoBERTa": [[99, "roberta"]], "Robot Drawing System": [[7, null]], "Robust Cascaded Diffusion Models": [[10, "robust-cascaded-diffusion-models"]], "Roles and Ceremonies in Scrum": [[171, "roles-and-ceremonies-in-scrum"]], "SAM: A generalized approach to segmentation": [[88, "sam-a-generalized-approach-to-segmentation"]], "SFV: Reinforcement Learning of Physical Skills from Videos": [[6, "sfv-reinforcement-learning-of-physical-skills-from-videos"]], "SOTA Comparisons": [[117, "sota-comparisons"]], "SSH in Git and GitHub Operations": [[76, "ssh-in-git-and-github-operations"]], "SSH keys and GitHub": [[185, "ssh-keys-and-github"]], "SSH, GPG, and AGE": [[76, null]], "Safety & Alignment:": [[85, "safety-alignment"]], "Sampling": [[97, "sampling"]], "Sampling From a Trained DALL-E": [[8, "sampling-from-a-trained-dall-e"]], "Sampling Sentences from a Language Model": [[133, "sampling-sentences-from-a-language-model"]], "Save Data": [[26, "save-data"], [27, "save-data"]], "Save compute and storage even for medium and small models": [[51, "save-compute-and-storage-even-for-medium-and-small-models"]], "Saving Models as BentoML Artifacts": [[72, "saving-models-as-bentoml-artifacts"]], "Saving and Loading the Model": [[110, "saving-and-loading-the-model"], [111, "saving-and-loading-the-model"], [112, "saving-and-loading-the-model"]], "Saving and loading a model object": [[124, "saving-and-loading-a-model-object"]], "Saving the Model": [[112, "saving-the-model"]], "Saving the re-labelled dataset": [[17, "saving-the-re-labelled-dataset"]], "Scalability": [[163, "scalability"]], "Scaling": [[117, "scaling"]], "Scaling Agile Methods": [[171, "scaling-agile-methods"]], "Scaling and Computational Efficiency": [[50, "scaling-and-computational-efficiency"]], "Scikit-learn": [[73, "scikit-learn"]], "Scope": [[173, "scope"]], "Second Iteration": [[106, "second-iteration"]], "Sections": [[13, "sections"], [39, "sections"], [48, "sections"], [58, "sections"], [162, "sections"], [168, "sections"], [172, "sections"], [186, "sections"]], "Secure Shell (SSH)": [[76, "secure-shell-ssh"]], "Security Management": [[78, null]], "Security and Compliance": [[74, "security-and-compliance"]], "Segment Anything": [[88, null]], "Segment Anything Data Engine": [[88, "segment-anything-data-engine"]], "Segmenting 1 billion masks": [[88, "segmenting-1-billion-masks"]], "Segmenting Text into Sentences and Paragraphs": [[146, "segmenting-text-into-sentences-and-paragraphs"]], "Selective Methods": [[52, "selective-methods"]], "Self-Attention Mechanism": [[52, "self-attention-mechanism"]], "Self-Supervised Learning vs Supervised Fine-Tuning": [[46, "self-supervised-learning-vs-supervised-fine-tuning"]], "Semantic Web Technologies": [[41, "semantic-web-technologies"]], "Semiconductors, Chips, Cloud Hosting, Inference, Deployment": [[59, "semiconductors-chips-cloud-hosting-inference-deployment"]], "Sentence Tokenization": [[142, "sentence-tokenization"]], "Sentence Tokenization in Korean": [[140, "sentence-tokenization-in-korean"]], "SentencePiece": [[103, "sentencepiece"]], "SentencePiece Tokenizer": [[105, null]], "SentiWordNet": [[137, "sentiwordnet"]], "Sentiment Ambiguity and Context": [[137, "sentiment-ambiguity-and-context"]], "Sentiment Analysis": [[134, null]], "Serve the App Locally": [[72, "serve-the-app-locally"]], "Server Setup & Usage": [[81, null]], "Serving the application in a highly scalable and available manner": [[55, "serving-the-application-in-a-highly-scalable-and-available-manner"]], "Setting up a Bare Metal System": [[64, "setting-up-a-bare-metal-system"], [159, "setting-up-a-bare-metal-system"]], "Setting up a GitOps workflow": [[64, "setting-up-a-gitops-workflow"], [159, "setting-up-a-gitops-workflow"]], "Setting up somewhere to work": [[173, "setting-up-somewhere-to-work"]], "Setting up the environment": [[94, "setting-up-the-environment"]], "Setup": [[135, "setup"]], "Setup with Password-Protected Key": [[79, "setup-with-password-protected-key"]], "Setup with age-plugin-yubikey": [[79, "setup-with-age-plugin-yubikey"]], "Sharing your work": [[176, "sharing-your-work"]], "Shortcomings of classical algorithms for decomposition:": [[150, "shortcomings-of-classical-algorithms-for-decomposition"]], "Shortcomings of traditional NLP pipelines": [[130, "shortcomings-of-traditional-nlp-pipelines"]], "Sidestepping the NLP pipeline": [[130, "sidestepping-the-nlp-pipeline"]], "Simple MLOps Pipeline": [[80, null]], "Simple Setup": [[79, "simple-setup"]], "Singular Value Decomposition (SVD)": [[150, "singular-value-decomposition-svd"]], "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale": [[7, "sketch-generation-with-drawing-process-guided-by-vector-flow-and-grayscale"]], "Skip-gram model": [[128, "skip-gram-model"]], "Smoothing": [[133, "smoothing"]], "Snorkel LabelModel": [[20, "snorkel-labelmodel"]], "So why are transformers so powerful?": [[116, "so-why-are-transformers-so-powerful"]], "Soft-Prompts": [[52, "soft-prompts"]], "Softmax": [[128, "softmax"]], "Software Development Life Cycle (SDLC)": [[166, null]], "Software Development Life Cycle Models": [[166, "software-development-life-cycle-models"]], "Software Engineering": [[161, null]], "Software Engineering Proposal Guideline": [[167, null]], "Software Engineering?": [[163, null]], "Software Process Descriptions": [[172, "software-process-descriptions"]], "Software Process Models": [[164, "software-process-models"], [172, null], [172, "id1"]], "Software Processes": [[164, null]], "Solo work": [[173, "solo-work"]], "Solutions and Emerging Techniques": [[57, "solutions-and-emerging-techniques"]], "Solving Manually": [[184, "solving-manually"]], "Solving automatically": [[184, "solving-automatically"]], "Some Common Pre-processing Techniques": [[146, "some-common-pre-processing-techniques"]], "Some Considerations": [[178, "some-considerations"]], "Some new content": [[176, "some-new-content"]], "Sources and Transmission of Country Risk": [[119, "sources-and-transmission-of-country-risk"]], "Sparsity": [[130, "sparsity"]], "Specialized domains": [[93, "specialized-domains"]], "Spelling variants, typos, etc.": [[139, "spelling-variants-typos-etc"]], "Spiral Model": [[166, "spiral-model"], [172, "spiral-model"]], "Spiral Model Benefits": [[172, "spiral-model-benefits"]], "Spiral Model Problems": [[172, "spiral-model-problems"]], "Spiral vs Waterfall vs Iterative Model": [[172, "spiral-vs-waterfall-vs-iterative-model"]], "Split corpus into sections": [[24, "split-corpus-into-sections"]], "Split sections into chunks": [[24, "split-sections-into-chunks"]], "Split sections into sentences": [[24, "split-sections-into-sentences"]], "Splitting Words into Characters": [[108, "splitting-words-into-characters"]], "Spotlight on Key Techniques: BitFit, LoRA, and More": [[50, "spotlight-on-key-techniques-bitfit-lora-and-more"]], "Squashing": [[183, "squashing"]], "Stage 1: Planning and Requirement Analysis": [[166, "stage-1-planning-and-requirement-analysis"]], "Stage 2: Defining Requirements": [[166, "stage-2-defining-requirements"]], "Stage 3: Designing the Software": [[166, "stage-3-designing-the-software"]], "Stage 4: Developing the Project": [[166, "stage-4-developing-the-project"]], "Stage 5: Testing": [[166, "stage-5-testing"]], "Stage 6: Deployment": [[166, "stage-6-deployment"]], "Stage 7: Maintenance": [[166, "stage-7-maintenance"]], "Staging a file to be included in the next commit": [[174, "staging-a-file-to-be-included-in-the-next-commit"]], "Staging changes": [[174, "staging-changes"]], "Standard Autoregressive Language Modeling": [[99, "standard-autoregressive-language-modeling"]], "Standard Fine-Tuning vs. PEFT": [[52, "standard-fine-tuning-vs-peft"]], "Start Services": [[61, "start-services"]], "Stashing changes": [[181, "stashing-changes"]], "Static Thresholding": [[10, "static-thresholding"]], "Static and Dynamic Data Collection": [[121, "static-and-dynamic-data-collection"]], "Static vs. Dynamic Web Pages": [[121, "static-vs-dynamic-web-pages"]], "Stemming/Lemmatizing": [[146, "stemming-lemmatizing"]], "Step 0: Prepare the data": [[128, "step-0-prepare-the-data"]], "Step 1: Define a function to create a context and a target word": [[128, "step-1-define-a-function-to-create-a-context-and-a-target-word"]], "Step 1: Indexing the words.": [[127, "step-1-indexing-the-words"]], "Step 1: Install Necessary Libraries and Set Up AutoTrain": [[45, "step-1-install-necessary-libraries-and-set-up-autotrain"]], "Step 1: Install necessary libraries": [[103, "step-1-install-necessary-libraries"]], "Step 1: Setting target and context variable": [[128, "step-1-setting-target-and-context-variable"]], "Step 2: Build the model": [[128, "step-2-build-the-model"]], "Step 2: Building the model": [[128, "step-2-building-the-model"]], "Step 2: Building the model.": [[127, "step-2-building-the-model"]], "Step 2: Load the dataset": [[103, "step-2-load-the-dataset"]], "Step 2: Prepare Dataset and Define Task": [[45, "step-2-prepare-dataset-and-define-task"]], "Step 3: Loss and optimization function": [[128, "step-3-loss-and-optimization-function"]], "Step 3: Loss and optimization function.": [[127, "step-3-loss-and-optimization-function"], [128, "id2"]], "Step 3: Prepare Your Dataset": [[45, "step-3-prepare-your-dataset"]], "Step 3: Prepare the text": [[103, "step-3-prepare-the-text"]], "Step 4: Train the tokenizers": [[103, "step-4-train-the-tokenizers"]], "Step 4: Training the model": [[128, "step-4-training-the-model"]], "Step 4: Training the model.": [[127, "step-4-training-the-model"], [128, "id3"]], "Step 4: Training with AutoTrain": [[45, "step-4-training-with-autotrain"]], "Step 5: Compare the tokenizers": [[103, "step-5-compare-the-tokenizers"]], "Step 5: Evaluation and Deployment": [[45, "step-5-evaluation-and-deployment"]], "Step-by-Step Lab: Fine-Tuning Falcon-7B on OpenAssistant": [[45, "step-by-step-lab-fine-tuning-falcon-7b-on-openassistant"]], "Steps in Software Engineering Projects": [[169, null], [169, "id1"]], "Stewardship and Protection": [[38, "stewardship-and-protection"]], "Stock Prices and Markov Assumption": [[132, "stock-prices-and-markov-assumption"]], "Stop Services": [[61, "stop-services"]], "Stop a Container": [[61, "stop-a-container"]], "Stopwords": [[146, "stopwords"]], "Subword Regularization in NMT": [[105, "subword-regularization-in-nmt"]], "Subword Sampling": [[106, "subword-sampling"]], "Subword Tokenization": [[102, "subword-tokenization"], [106, null]], "Subword Tokenization for Sequence Models": [[146, "subword-tokenization-for-sequence-models"]], "Subword regularization and BPE-dropout": [[105, "subword-regularization-and-bpe-dropout"]], "Summary": [[85, "summary"], [97, "summary"], [127, "summary"], [133, "summary"], [135, "summary"], [149, "summary"], [165, "summary"], [166, "summary"]], "Summary and Alternative Considerations": [[41, "summary-and-alternative-considerations"]], "Summary of Key Points": [[171, "summary-of-key-points"]], "Summary of the Lecture": [[55, "summary-of-the-lecture"]], "Super-Resolution Models": [[10, "super-resolution-models"]], "Supervised Learning": [[138, "supervised-learning"]], "Supervised and Unsupervised Methods": [[138, "supervised-and-unsupervised-methods"]], "Supported Languages": [[95, "supported-languages"]], "Supported PEFT Methods": [[51, "supported-peft-methods"]], "Surface and Deep Structure": [[139, "surface-and-deep-structure"]], "Surrounding Issues": [[98, "surrounding-issues"]], "Synchronization tools:": [[66, "synchronization-tools"]], "Synsets and Relations": [[137, "synsets-and-relations"]], "Synthesizing the Discussion": [[50, "synthesizing-the-discussion"]], "Synthetic Data": [[59, "synthetic-data"]], "T5": [[99, "t5"]], "T5: Text-To-Text Transfer Transformer": [[117, null]], "T5: Text-to-Text Framework": [[117, "t5-text-to-text-framework"]], "TF-IDF Model": [[158, null]], "Table of Contents": [[87, "table-of-contents"], [170, "table-of-contents"]], "Tackling the Challenges: The Strategies": [[139, "tackling-the-challenges-the-strategies"]], "Tagging": [[181, "tagging"]], "Target FED Rate": [[23, "target-fed-rate"]], "Task Details": [[136, "task-details"]], "Technical Breakthroughs": [[53, "technical-breakthroughs"]], "Technical Challenges": [[38, null]], "Technical highlights": [[105, "technical-highlights"]], "Techniques for Sentiment Analysis": [[134, "techniques-for-sentiment-analysis"]], "Tell git about the new file": [[176, "tell-git-about-the-new-file"]], "Telling Git about the File": [[174, "telling-git-about-the-file"]], "TensorFlow and Keras": [[73, "tensorflow-and-keras"]], "Terminology": [[57, "terminology"]], "Text Data Collection": [[121, null]], "Text Data Collection Overview": [[121, "text-data-collection-overview"]], "Text Data Collection Types": [[121, "text-data-collection-types"]], "Text Encoder": [[10, "text-encoder"]], "Text Encoder: T5": [[10, "text-encoder-t5"]], "Text Generation Across Multiple Formats": [[49, "text-generation-across-multiple-formats"]], "Text Summarization": [[49, "text-summarization"]], "Text and Image: Interdisciplinary Techniques for NLP": [[130, "text-and-image-interdisciplinary-techniques-for-nlp"]], "Text length distribution": [[94, "text-length-distribution"]], "Text to Image Generation Models": [[5, "text-to-image-generation-models"]], "Text-Based Network Industries and Endogenous Product Differentiation": [[119, "text-based-network-industries-and-endogenous-product-differentiation"]], "Text-to-Image Models": [[11, null]], "Text-to-image model": [[10, "text-to-image-model"]], "TextBlob": [[135, "textblob"]], "Textbook": [[37, "textbook"], [70, "textbook"]], "Textual Analysis of FOMC contents": [[36, null]], "Textual analysis": [[118, "textual-analysis"]], "The Advent of Transformers": [[49, "the-advent-of-transformers"]], "The All-Important Data Layer": [[56, "the-all-important-data-layer"]], "The Architecture of BERT": [[113, "the-architecture-of-bert"]], "The Bad": [[139, "the-bad"]], "The ChatWrapper Utility Class": [[72, "the-chatwrapper-utility-class"]], "The Creative Partnership": [[2, "the-creative-partnership"]], "The Dataset": [[136, "the-dataset"]], "The Diffusion of Disruptive Technologies": [[120, "the-diffusion-of-disruptive-technologies"]], "The Distributional Hypothesis": [[156, "the-distributional-hypothesis"]], "The Good": [[139, "the-good"]], "The Intricacies of Tokenization": [[139, "the-intricacies-of-tokenization"]], "The Key Concept of Model Generalization": [[50, "the-key-concept-of-model-generalization"]], "The Legislative Influence Detector": [[120, "the-legislative-influence-detector"]], "The Levels of Git": [[174, "the-levels-of-git"], [177, "the-levels-of-git"]], "The Long Tail of Tokenization: Zipf\u2019s Law": [[139, "the-long-tail-of-tokenization-zipfs-law"]], "The Model": [[117, "the-model"]], "The Origin of Query and Key Vectors": [[113, "the-origin-of-query-and-key-vectors"]], "The Pros And Cons Of ByT5": [[115, "the-pros-and-cons-of-byt5"]], "The Results": [[115, "the-results"]], "The Role of Process in Software Engineering": [[172, "the-role-of-process-in-software-engineering"]], "The Role of Word Embeddings": [[49, "the-role-of-word-embeddings"]], "The Scrum Framework": [[171, "the-scrum-framework"]], "The Significance of Efficient Fine-Tuning": [[50, "the-significance-of-efficient-fine-tuning"]], "The Software Crisis": [[164, "the-software-crisis"]], "The Software Process": [[172, "the-software-process"]], "The Stages of SDLC": [[166, "the-stages-of-sdlc"]], "The State of LLMs Today": [[93, "the-state-of-llms-today"]], "The Technical Details": [[115, "the-technical-details"]], "The Ugly": [[139, "the-ugly"]], "The Zero-Shot Machine-Generated Text Detection Problem": [[84, "the-zero-shot-machine-generated-text-detection-problem"]], "The eKorpkit Corpus": [[121, "the-ekorpkit-corpus"], [130, "the-ekorpkit-corpus"]], "The gh-pages branch": [[182, "the-gh-pages-branch"]], "The levels of Git": [[179, "the-levels-of-git"]], "The problem": [[150, "the-problem"]], "The revision Graph": [[179, "the-revision-graph"]], "The staging area": [[174, "the-staging-area"]], "The struggles of unCLIP": [[9, "the-struggles-of-unclip"]], "Third Iteration": [[106, "third-iteration"]], "Three Data Must-Haves for NLP": [[93, "three-data-must-haves-for-nlp"]], "TimeSformers": [[116, "timesformers"]], "Timeline of ML Art": [[5, "timeline-of-ml-art"]], "Timestamp distribution": [[94, "timestamp-distribution"]], "Timestep Conditioning": [[10, "timestep-conditioning"]], "Timing comparison": [[150, "timing-comparison"]], "Token Examples:": [[146, "token-examples"]], "Token Extraction": [[101, "token-extraction"]], "Tokenization": [[102, null], [107, "tokenization"], [139, null]], "Tokenization Pipeline": [[104, null]], "Tokenization in French": [[142, "tokenization-in-french"]], "Tokenization in Korean": [[140, null], [142, "tokenization-in-korean"]], "Tokenizing Text": [[108, "tokenizing-text"]], "Tokenizing and Formatting the Data": [[110, "tokenizing-and-formatting-the-data"]], "Tools for Dotfiles Management": [[66, "tools-for-dotfiles-management"]], "Tools for Interpretability": [[40, "tools-for-interpretability"]], "Top-K Sampling": [[97, "top-k-sampling"]], "Top-p (nucleus) sampling": [[97, "top-p-nucleus-sampling"]], "Topic Coherence": [[147, "topic-coherence"]], "Topic Coherence Measures": [[147, null]], "Topic Modeling": [[138, "topic-modeling"], [147, "topic-modeling"], [148, null]], "Topic Modeling Methodologies": [[151, null]], "Traditional Machine Learning Techniques": [[138, "traditional-machine-learning-techniques"]], "Traditional NLP Pipelines": [[130, "traditional-nlp-pipelines"]], "Train LabelModel And Generate Probabilistic Labels": [[20, "train-labelmodel-and-generate-probabilistic-labels"]], "Train an invalid classficiation model": [[16, "train-an-invalid-classficiation-model"]], "Train and evaluate esg_cv_polarity_kr dataset": [[16, "train-and-evaluate-esg-cv-polarity-kr-dataset"]], "Train and evaluate esg_cv_topics_kr dataset": [[16, "train-and-evaluate-esg-cv-topics-kr-dataset"]], "Training": [[88, "training"]], "Training Classifiers for ESG Ratings": [[22, null]], "Training FastText": [[124, "training-fasttext"]], "Training GloVe": [[125, "training-glove"]], "Training Language Models": [[109, null]], "Training Objectives": [[99, "training-objectives"]], "Training Tokenizers for GPT, BERT, and T5": [[103, "training-tokenizers-for-gpt-bert-and-t5"]], "Training a category classficiation model with esg_topics_improved dataset": [[22, "training-a-category-classficiation-model-with-esg-topics-improved-dataset"]], "Training a polarity classficiation model with esg_polarity_kr dataset": [[22, "training-a-polarity-classficiation-model-with-esg-polarity-kr-dataset"]], "Training an invalid topic classifier": [[14, "training-an-invalid-topic-classifier"]], "Training and Improvement Loop": [[53, "training-and-improvement-loop"]], "Training and Self-Play": [[53, "training-and-self-play"]], "Training from Raw Sentences": [[105, "training-from-raw-sentences"]], "Training further on the additional polarity data": [[14, "training-further-on-the-additional-polarity-data"]], "Training further on the additional topic data": [[14, "training-further-on-the-additional-topic-data"]], "Training the Model": [[110, "training-the-model"], [111, "training-the-model"], [112, "training-the-model"], [136, "training-the-model"]], "Tranformer Architecture": [[116, "tranformer-architecture"]], "Transfer Learning: Basics and Relevance": [[50, "transfer-learning-basics-and-relevance"]], "Transformer Architecture and PLMs": [[99, "transformer-architecture-and-plms"]], "Transformer Block Structure": [[52, "transformer-block-structure"]], "Transformer Networks": [[138, "transformer-networks"]], "Transformer in Transformer": [[116, "transformer-in-transformer"]], "Transformers": [[116, null]], "Translation": [[130, "translation"]], "Translation Services": [[49, "translation-services"]], "Transparency and Deliberation Within the FOMC": [[120, "transparency-and-deliberation-within-the-fomc"]], "Treasury Yield": [[23, "treasury-yield"]], "Triangular Matrix": [[145, "triangular-matrix"]], "Truncated SVD": [[150, "truncated-svd"]], "Two models": [[128, "two-models"]], "Types of Alternative Data": [[12, "types-of-alternative-data"]], "Types of Chatbots": [[91, "types-of-chatbots"]], "Types of Datasets": [[122, "types-of-datasets"]], "Types of Sentiment Analysis": [[134, "types-of-sentiment-analysis"]], "Types of Software Engineering Projects": [[169, "types-of-software-engineering-projects"]], "Uncertainty in the Posterior": [[8, "uncertainty-in-the-posterior"]], "Uncertainty of word boundaries": [[145, "uncertainty-of-word-boundaries"]], "Understanding": [[130, "understanding"]], "Understanding Cosine Similarity": [[147, "understanding-cosine-similarity"]], "Understanding Model Parameters and Architectures": [[50, "understanding-model-parameters-and-architectures"]], "Understanding N-grams": [[143, "understanding-n-grams"]], "Understanding Pointwise Mutual Information": [[147, "understanding-pointwise-mutual-information"]], "Understanding Q-Star (Q*)": [[54, "understanding-q-star-q"]], "Understanding texts": [[130, "understanding-texts"]], "Understanding the Basics": [[146, null]], "Unicode Normalization": [[104, "unicode-normalization"]], "Unified Input & Output Format": [[117, "unified-input-output-format"]], "Unigram": [[103, "unigram"]], "Unigram - T5": [[103, "unigram-t5"]], "Unigram Language Model": [[106, "unigram-language-model"]], "Unigram Step-by-Step Implementation": [[107, null]], "Unix Password Managers": [[79, null]], "Unknown Words": [[133, "unknown-words"], [145, "unknown-words"]], "Unknown representation": [[130, "unknown-representation"]], "Unlabeled Dataset Sizes": [[117, "unlabeled-dataset-sizes"]], "Unlabeled Datasets": [[117, "unlabeled-datasets"]], "Unmodeled variables": [[130, "unmodeled-variables"]], "Unstaged changes": [[174, "unstaged-changes"]], "Unsupervised Learning Techniques": [[138, "unsupervised-learning-techniques"]], "Unsupervised Objective": [[117, "unsupervised-objective"]], "Updating Passwords": [[79, "updating-passwords"]], "Usage": [[79, "usage"], [105, "usage"], [114, "usage"]], "Usage of Copier": [[69, "usage-of-copier"]], "Usage of Language Models": [[133, null]], "Use Cases": [[51, "use-cases"]], "Use a Volume in a Container": [[61, "use-a-volume-in-a-container"]], "Use rubrix to find potential label errors": [[17, "use-rubrix-to-find-potential-label-errors"]], "Use-Cases": [[12, "use-cases"]], "User Stories and Timeboxing": [[171, "user-stories-and-timeboxing"]], "Using AGE": [[76, "using-age"]], "Using Copier CLI": [[69, "using-copier-cli"]], "Using Copier as a Library": [[69, "using-copier-as-a-library"]], "Using FastText": [[124, "using-fasttext"]], "Using FortiClient for VPN Connectivity": [[82, "using-forticlient-for-vpn-connectivity"]], "Using GPG": [[76, "using-gpg"]], "Using GloVe": [[125, "using-glove"]], "Using SSH": [[76, "using-ssh"]], "Using SSH, GPG, and AGE: A Practical Guide": [[76, "using-ssh-gpg-and-age-a-practical-guide"]], "Using mC4 Dataset with Hugging Face Datasets Library": [[95, "using-mc4-dataset-with-hugging-face-datasets-library"]], "Using rebase to squash": [[183, "using-rebase-to-squash"]], "Using reset to rewrite history": [[175, "using-reset-to-rewrite-history"]], "V-Model": [[166, "v-model"]], "V-model": [[172, "v-model"]], "V-model Benefits": [[172, "v-model-benefits"]], "V-model Problems": [[172, "v-model-problems"]], "V. Challenges and Limitations": [[50, "v-challenges-and-limitations"]], "V. Conclusion": [[77, "v-conclusion"]], "V. Developing an Advanced Robotic Drawing System": [[7, "v-developing-an-advanced-robotic-drawing-system"]], "V. Scaling and Serving the Application": [[55, "v-scaling-and-serving-the-application"]], "VADER": [[135, "vader"]], "VATT: Transformers for Multimodal Self-Supervised Learning": [[116, "vatt-transformers-for-multimodal-self-supervised-learning"]], "VI. Current Trends and Future Directions": [[50, "vi-current-trends-and-future-directions"]], "VI. Evaluation and Performance Optimization": [[55, "vi-evaluation-and-performance-optimization"]], "VI. Practical Applications": [[77, "vi-practical-applications"]], "VICU\u00d1A": [[83, "vicuna"]], "VII. Conclusion": [[50, "vii-conclusion"]], "VII. Future Trends and Challenges": [[77, "vii-future-trends-and-challenges"]], "VII.Conclusion": [[55, "vii-conclusion"]], "VPN Connectivity": [[82, null]], "VQ-VAE": [[8, "vq-vae"]], "Validating the Model": [[110, "validating-the-model"], [111, "validating-the-model"], [112, "validating-the-model"]], "Value Neural Network in LLM Context": [[53, "value-neural-network-in-llm-context"]], "Variational Autoencoders (VAE)": [[8, "variational-autoencoders-vae"]], "Vector Databases": [[59, "vector-databases"]], "Vector Representation": [[154, null]], "Vector Semantics": [[156, null]], "Vector Similarity: Cosine": [[157, "vector-similarity-cosine"]], "Vector Space Models": [[154, "vector-space-models"]], "Version Control Systems": [[186, null]], "Version Control:": [[65, "version-control"], [160, "version-control"]], "Version control systems:": [[66, "version-control-systems"]], "Virtual Assistants": [[49, "virtual-assistants"]], "Vision Transformer Architecture": [[116, "vision-transformer-architecture"]], "Vision Transformers": [[116, "vision-transformers"]], "Visualization": [[155, "visualization"]], "Visualize Features": [[28, "visualize-features"], [33, null], [33, "id1"]], "Visualizing Features": [[28, null]], "Visualizing Internal and External Structure": [[8, "visualizing-internal-and-external-structure"]], "Visualizing Perspective and Three-Dimensionality": [[8, "visualizing-perspective-and-three-dimensionality"]], "Visualizing the Coherence Scores": [[149, "visualizing-the-coherence-scores"]], "Visualizing the embeddings": [[128, "visualizing-the-embeddings"], [128, "id4"]], "Vocabulary Initialization": [[107, "vocabulary-initialization"], [108, "vocabulary-initialization"]], "Waterfall Model": [[166, "waterfall-model"], [172, "waterfall-model"]], "Waterfall Model Drawbacks": [[172, "waterfall-model-drawbacks"]], "Waterfall Model Phases": [[172, "waterfall-model-phases"]], "Web Crawling": [[121, "web-crawling"], [121, "id1"]], "Web Crawling vs. Web Scraping": [[121, "web-crawling-vs-web-scraping"]], "What Are Large Language Models?": [[49, "what-are-large-language-models"]], "What Exactly is Tokenization?": [[139, "what-exactly-is-tokenization"]], "What Is A Token In Machine Learning?": [[115, "what-is-a-token-in-machine-learning"]], "What Is ByT5?": [[115, "what-is-byt5"]], "What are Large Language Models?": [[98, "what-are-large-language-models"]], "What are word embeddings?": [[126, "what-are-word-embeddings"]], "What can you do with NLP?": [[130, "what-can-you-do-with-nlp"]], "What does BERT actually learn?": [[114, "what-does-bert-actually-learn"]], "What does it take to understand the text?": [[130, "what-does-it-take-to-understand-the-text"]], "What is Bag of Words Model?": [[153, "what-is-bag-of-words-model"]], "What is GitOps?": [[64, "what-is-gitops"], [159, "what-is-gitops"]], "What is Morphological Analysis?": [[140, "what-is-morphological-analysis"]], "What is NLP?": [[130, "what-is-nlp"]], "What is POS Tagging?": [[144, "what-is-pos-tagging"]], "What is Reinforcement Learning?": [[92, "what-is-reinforcement-learning"]], "What is SentencePiece?": [[105, "what-is-sentencepiece"]], "What is Subword Tokenization?": [[106, "what-is-subword-tokenization"]], "What is TF-IDF?": [[158, "what-is-tf-idf"]], "What is Tokenization?": [[102, "what-is-tokenization"], [146, "what-is-tokenization"]], "What is a \u2018context\u2019?": [[157, "what-is-a-context"]], "What is fine-tuning?": [[46, "what-is-fine-tuning"]], "What is tomotopy?": [[152, "what-is-tomotopy"]], "What is version control? (Team version)": [[173, "what-is-version-control-team-version"]], "What\u2019s version control?": [[173, "whats-version-control"]], "When Words Sweat": [[120, "when-words-sweat"]], "When to use the skip-gram model and when to use CBOW?": [[128, "when-to-use-the-skip-gram-model-and-when-to-use-cbow"]], "Whitespace as a Basic Symbol": [[105, "whitespace-as-a-basic-symbol"]], "Who Uses PEFT?": [[52, "who-uses-peft"]], "Why BentoML?": [[73, "why-bentoml"]], "Why Do We Need POS Tagging?": [[144, "why-do-we-need-pos-tagging"]], "Why Large Language Models (LLMs) use Reinforcement Learning": [[92, "why-large-language-models-llms-use-reinforcement-learning"]], "Why NLP is more difficult in Korean?": [[130, "why-nlp-is-more-difficult-in-korean"]], "Why Software Engineering?": [[163, "why-software-engineering"]], "Why Subword Tokenization?": [[106, "why-subword-tokenization"]], "Why do we need language models?": [[131, "why-do-we-need-language-models"]], "Why do we need neural networks for word embeddings?": [[126, "why-do-we-need-neural-networks-for-word-embeddings"]], "Why do we need transformers?": [[116, "why-do-we-need-transformers"]], "Why does MLOps matter?": [[71, "why-does-mlops-matter"]], "Why is Imagen Better than DALL-E 2?": [[10, "why-is-imagen-better-than-dall-e-2"]], "Why is NLP hard?": [[130, "why-is-nlp-hard"]], "Why is Tokenization Important?": [[102, "why-is-tokenization-important"]], "Why should we segment words?": [[145, "why-should-we-segment-words"]], "Why study or research NLP?": [[130, "why-study-or-research-nlp"]], "Why use DeepLabCut?": [[6, "why-use-deeplabcut"]], "Why use N-grams?": [[143, "why-use-n-grams"]], "Why use version control?": [[173, "why-use-version-control"]], "Word Embeddings": [[126, null], [126, "id1"], [138, "word-embeddings"], [154, "word-embeddings"]], "Word Encoding": [[107, "word-encoding"]], "Word Formation Processes": [[139, "word-formation-processes"]], "Word Segmentation": [[145, "word-segmentation"]], "Word Segmentation and Association": [[145, null]], "Word Segmentation for Korean": [[145, "word-segmentation-for-korean"]], "Word Segmentation in Practice": [[145, "word-segmentation-in-practice"]], "Word Similarity": [[155, "word-similarity"], [157, null]], "Word Tokenization": [[102, "word-tokenization"], [142, "word-tokenization"]], "Word-Level Tasks": [[115, "word-level-tasks"]], "Word-Word Matrix": [[157, "word-word-matrix"]], "Word2Vec": [[128, null], [154, "word2vec"]], "WordNet": [[137, "wordnet"]], "WordNet Supersenses": [[137, "wordnet-supersenses"]], "WordNet in NLP and Sentiment Analysis": [[137, "wordnet-in-nlp-and-sentiment-analysis"]], "WordPiece": [[103, "wordpiece"], [106, "wordpiece"]], "WordPiece - BERT": [[103, "wordpiece-bert"]], "WordPiece Step-by-Step Implementation": [[108, null]], "Words aren\u2019t just defined by blanks": [[139, "words-arent-just-defined-by-blanks"]], "Workflow for a Simple MLOps Pipeline Project": [[81, "workflow-for-a-simple-mlops-pipeline-project"]], "Working with multiple files": [[176, "working-with-multiple-files"]], "Working with news article samples": [[145, "working-with-news-article-samples"]], "Writing Labeling Functions": [[20, "writing-labeling-functions"]], "Writing a Thesis": [[89, null]], "Writing the Thesis": [[89, "writing-the-thesis"]], "XGBoost and LightGBM": [[73, "xgboost-and-lightgbm"]], "XLM": [[95, "xlm"]], "XLM-R": [[95, "xlm-r"]], "XLNet": [[99, "xlnet"]], "Yaml Frontmatter": [[182, "yaml-frontmatter"]], "Zero Shot and Few Shot Learners": [[100, "zero-shot-and-few-shot-learners"]], "Zero Shot and Prompt Engineering": [[100, null]], "Zero-Shot Reasoners and Chain-of-Thought Prompting": [[100, "zero-shot-reasoners-and-chain-of-thought-prompting"]], "Zero-shot classification with CLIP": [[9, "zero-shot-classification-with-clip"]], "Zero-shot learning:": [[100, "zero-shot-learning"]], "age": [[76, "age"]], "containerd": [[60, null]], "mBART": [[95, "mbart"]], "mBERT": [[95, "mbert"]], "mC4 Dataset": [[95, null]], "mC4 Dataset and Perplexity Sampling": [[95, "mc4-dataset-and-perplexity-sampling"]], "mC4 Sampling": [[95, "mc4-sampling"]], "\u267e\ufe0f\u00a0Learning Goals": [[4, "learning-goals"], [96, "learning-goals"], [129, "learning-goals"]], "\ud83c\udfb2 Whole Game of NLP": [[96, "whole-game-of-nlp"], [129, "whole-game-of-nlp"]], "\ud83c\udfc6 Grading": [[96, "grading"], [129, "grading"]], "\ud83d\udcd2 Lecture Notes": [[96, "lecture-notes"]], "\ud83d\udcda Textbook": [[129, "textbook"]], "\ud83d\udcdc Course Description": [[4, "course-description"], [96, "course-description"], [129, "course-description"]], "\ud83d\uddd3\ufe0f\u00a0Table of Contents": [[4, "table-of-contents"], [70, "table-of-contents"], [96, "table-of-contents"], [129, "table-of-contents"]], "\ud83e\udde0 Term Project": [[4, "term-project"], [96, "term-project"], [129, "term-project"]]}, "docnames": ["about/index", "index", "lectures/aiart/aiart/index", "lectures/aiart/brave/index", "lectures/aiart/index", "lectures/aiart/intro/index", "lectures/aiart/motion-capture-and-synthesis/index", "lectures/aiart/robot/index", "lectures/aiart/text-to-image/dalle1", "lectures/aiart/text-to-image/dalle2", "lectures/aiart/text-to-image/imagen", "lectures/aiart/text-to-image/index", "lectures/dsecon/cb/altdata", "lectures/dsecon/cb/index", "lectures/dsecon/esg-ratings/all_in_one_pipeline", "lectures/dsecon/esg-ratings/build_news_corpus", "lectures/dsecon/esg-ratings/cross_validate_datasets", "lectures/dsecon/esg-ratings/improve_datasets", "lectures/dsecon/esg-ratings/index", "lectures/dsecon/esg-ratings/predict_esg_classes", "lectures/dsecon/esg-ratings/prepare_datasets", "lectures/dsecon/esg-ratings/prepare_datasets_for_labeling", "lectures/dsecon/esg-ratings/train_classifiers", "lectures/dsecon/fomc/01_numerical_data", "lectures/dsecon/fomc/02_textual_data", "lectures/dsecon/fomc/03_EDA_numericals1", "lectures/dsecon/fomc/03_EDA_numericals2", "lectures/dsecon/fomc/04_training_datasets", "lectures/dsecon/fomc/05_features", "lectures/dsecon/fomc/06_AutoML", "lectures/dsecon/fomc/07_predict_sentiments", "lectures/dsecon/fomc/08_EDA_sentiments1", "lectures/dsecon/fomc/08_EDA_sentiments2", "lectures/dsecon/fomc/09_visualize_features", "lectures/dsecon/fomc/10_monetary_shocks", "lectures/dsecon/fomc/11_AutoML_with_tones", "lectures/dsecon/fomc/index", "lectures/dsecon/index", "lectures/dsecon/intro/challenges", "lectures/dsecon/intro/index", "lectures/dsecon/intro/introduction", "lectures/dsecon/intro/methods", "lectures/llms/agents/autogen", "lectures/llms/agents/autoscraper", "lectures/llms/agents/index", "lectures/llms/finetune/autotrain", "lectures/llms/finetune/index", "lectures/llms/index", "lectures/llms/intro/index", "lectures/llms/intro/llms", "lectures/llms/peft/index", "lectures/llms/peft/peft-hf", "lectures/llms/peft/peft-llms", "lectures/llms/q-learning/index", "lectures/llms/q-learning/qstar", "lectures/llms/rag/index", "lectures/llms/stack/app", "lectures/llms/stack/architecture", "lectures/llms/stack/index", "lectures/llms/stack/infra", "lectures/mlops/containerization/containerd", "lectures/mlops/containerization/docker", "lectures/mlops/containerization/index", "lectures/mlops/devops/devsecops", "lectures/mlops/devops/gitops", "lectures/mlops/devops/index", "lectures/mlops/dotfiles/index", "lectures/mlops/github/fork-pull", "lectures/mlops/github/index", "lectures/mlops/github/template", "lectures/mlops/index", "lectures/mlops/intro", "lectures/mlops/llmops/bentochain", "lectures/mlops/llmops/bentoml", "lectures/mlops/llmops/index", "lectures/mlops/project", "lectures/mlops/security/age-gpg-ssh", "lectures/mlops/security/auth-enc-sign", "lectures/mlops/security/index", "lectures/mlops/security/pass", "lectures/mlops/simple-pipeline/index", "lectures/mlops/simple-pipeline/server", "lectures/mlops/simple-pipeline/vpn", "lectures/nlp_advances/gpt/camelids", "lectures/nlp_advances/gpt/detectGPT", "lectures/nlp_advances/gpt/gpt4", "lectures/nlp_advances/gpt/index", "lectures/nlp_advances/index", "lectures/nlp_advances/sam/index", "lectures/nlp_advances/thesis", "lectures/nlp_deep/chatbots/detectGPT", "lectures/nlp_deep/chatbots/index", "lectures/nlp_deep/chatbots/rlhf", "lectures/nlp_deep/datasets/index", "lectures/nlp_deep/datasets/lab-eda", "lectures/nlp_deep/datasets/mc4", "lectures/nlp_deep/index", "lectures/nlp_deep/llms/decoding", "lectures/nlp_deep/llms/index", "lectures/nlp_deep/llms/plms", "lectures/nlp_deep/llms/zeroshot", "lectures/nlp_deep/tokenization/bpe", "lectures/nlp_deep/tokenization/index", "lectures/nlp_deep/tokenization/lab-train-tokenizers", "lectures/nlp_deep/tokenization/pipeline", "lectures/nlp_deep/tokenization/sentencepiece", "lectures/nlp_deep/tokenization/subword", "lectures/nlp_deep/tokenization/unigram", "lectures/nlp_deep/tokenization/wordpiece", "lectures/nlp_deep/training/index", "lectures/nlp_deep/training/lab-finetune-mlm", "lectures/nlp_deep/training/lab-pretrain-clm", "lectures/nlp_deep/training/lab-pretrain-mlm", "lectures/nlp_deep/transformers/bert", "lectures/nlp_deep/transformers/bertviz", "lectures/nlp_deep/transformers/byt5", "lectures/nlp_deep/transformers/index", "lectures/nlp_deep/transformers/t5", "lectures/nlp_intro/apps/index", "lectures/nlp_intro/apps/research1", "lectures/nlp_intro/apps/research2", "lectures/nlp_intro/datasets/corpus", "lectures/nlp_intro/datasets/index", "lectures/nlp_intro/datasets/lab-dart", "lectures/nlp_intro/embeddings/fasttext", "lectures/nlp_intro/embeddings/glove", "lectures/nlp_intro/embeddings/index", "lectures/nlp_intro/embeddings/nlm", "lectures/nlp_intro/embeddings/w2v", "lectures/nlp_intro/index", "lectures/nlp_intro/intro/index", "lectures/nlp_intro/lm/index", "lectures/nlp_intro/lm/ngram", "lectures/nlp_intro/lm/usage", "lectures/nlp_intro/sentiments/index", "lectures/nlp_intro/sentiments/lab-lexicon", "lectures/nlp_intro/sentiments/lab-ml", "lectures/nlp_intro/sentiments/lexicon", "lectures/nlp_intro/sentiments/ml", "lectures/nlp_intro/tokenization/index", "lectures/nlp_intro/tokenization/korean", "lectures/nlp_intro/tokenization/lab-korean", "lectures/nlp_intro/tokenization/lab-tokenization", "lectures/nlp_intro/tokenization/ngrams", "lectures/nlp_intro/tokenization/pos", "lectures/nlp_intro/tokenization/segmentation", "lectures/nlp_intro/tokenization/tokenization", "lectures/nlp_intro/topic/coherence", "lectures/nlp_intro/topic/index", "lectures/nlp_intro/topic/lab-coherence", "lectures/nlp_intro/topic/lab-methods", "lectures/nlp_intro/topic/methods", "lectures/nlp_intro/topic/tomotopy", "lectures/nlp_intro/vectorization/bow", "lectures/nlp_intro/vectorization/index", "lectures/nlp_intro/vectorization/lab-similarity", "lectures/nlp_intro/vectorization/semantics", "lectures/nlp_intro/vectorization/similarity", "lectures/nlp_intro/vectorization/tf-idf", "lectures/softeng/devops/gitops", "lectures/softeng/devops/index", "lectures/softeng/index", "lectures/softeng/intro/index", "lectures/softeng/intro/introduction", "lectures/softeng/intro/processes", "lectures/softeng/intro/requirements", "lectures/softeng/intro/sdlc", "lectures/softeng/proposal/guidelines", "lectures/softeng/proposal/index", "lectures/softeng/proposal/steps", "lectures/softeng/proposal/template", "lectures/softeng/spm/agile", "lectures/softeng/spm/index", "lectures/softeng/vcs/00_introduction", "lectures/softeng/vcs/01_solo_work_with_git", "lectures/softeng/vcs/02_fixing_mistakes", "lectures/softeng/vcs/03_publishing", "lectures/softeng/vcs/04_collaboration", "lectures/softeng/vcs/05_fork_and_pull", "lectures/softeng/vcs/06_git_theory", "lectures/softeng/vcs/07_branches", "lectures/softeng/vcs/08_advanced_git_concepts", "lectures/softeng/vcs/09_github_pages", "lectures/softeng/vcs/10_rebasing", "lectures/softeng/vcs/11_debugging_with_git_bisect", "lectures/softeng/vcs/12_multiple_remotes", "lectures/softeng/vcs/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "lectures/aiart/aiart/index.md", "lectures/aiart/brave/index.md", "lectures/aiart/index.md", "lectures/aiart/intro/index.md", "lectures/aiart/motion-capture-and-synthesis/index.md", "lectures/aiart/robot/index.md", "lectures/aiart/text-to-image/dalle1.md", "lectures/aiart/text-to-image/dalle2.md", "lectures/aiart/text-to-image/imagen.ipynb", "lectures/aiart/text-to-image/index.md", "lectures/dsecon/cb/altdata.md", "lectures/dsecon/cb/index.md", "lectures/dsecon/esg-ratings/all_in_one_pipeline.ipynb", "lectures/dsecon/esg-ratings/build_news_corpus.ipynb", "lectures/dsecon/esg-ratings/cross_validate_datasets.ipynb", "lectures/dsecon/esg-ratings/improve_datasets.ipynb", "lectures/dsecon/esg-ratings/index.md", "lectures/dsecon/esg-ratings/predict_esg_classes.ipynb", "lectures/dsecon/esg-ratings/prepare_datasets.ipynb", "lectures/dsecon/esg-ratings/prepare_datasets_for_labeling.ipynb", "lectures/dsecon/esg-ratings/train_classifiers.ipynb", "lectures/dsecon/fomc/01_numerical_data.ipynb", "lectures/dsecon/fomc/02_textual_data.ipynb", "lectures/dsecon/fomc/03_EDA_numericals1.ipynb", "lectures/dsecon/fomc/03_EDA_numericals2.ipynb", "lectures/dsecon/fomc/04_training_datasets.ipynb", "lectures/dsecon/fomc/05_features.ipynb", "lectures/dsecon/fomc/06_AutoML.ipynb", "lectures/dsecon/fomc/07_predict_sentiments.ipynb", "lectures/dsecon/fomc/08_EDA_sentiments1.ipynb", "lectures/dsecon/fomc/08_EDA_sentiments2.ipynb", "lectures/dsecon/fomc/09_visualize_features.ipynb", "lectures/dsecon/fomc/10_monetary_shocks.ipynb", "lectures/dsecon/fomc/11_AutoML_with_tones.ipynb", "lectures/dsecon/fomc/index.md", "lectures/dsecon/index.md", "lectures/dsecon/intro/challenges.md", "lectures/dsecon/intro/index.md", "lectures/dsecon/intro/introduction.md", "lectures/dsecon/intro/methods.md", "lectures/llms/agents/autogen.md", "lectures/llms/agents/autoscraper.md", "lectures/llms/agents/index.md", "lectures/llms/finetune/autotrain.md", "lectures/llms/finetune/index.md", "lectures/llms/index.md", "lectures/llms/intro/index.md", "lectures/llms/intro/llms.md", "lectures/llms/peft/index.md", "lectures/llms/peft/peft-hf.md", "lectures/llms/peft/peft-llms.md", "lectures/llms/q-learning/index.md", "lectures/llms/q-learning/qstar.md", "lectures/llms/rag/index.md", "lectures/llms/stack/app.md", "lectures/llms/stack/architecture.md", "lectures/llms/stack/index.md", "lectures/llms/stack/infra.md", "lectures/mlops/containerization/containerd.md", "lectures/mlops/containerization/docker.md", "lectures/mlops/containerization/index.md", "lectures/mlops/devops/devsecops.md", "lectures/mlops/devops/gitops.md", "lectures/mlops/devops/index.md", "lectures/mlops/dotfiles/index.md", "lectures/mlops/github/fork-pull.md", "lectures/mlops/github/index.md", "lectures/mlops/github/template.md", "lectures/mlops/index.md", "lectures/mlops/intro.md", "lectures/mlops/llmops/bentochain.md", "lectures/mlops/llmops/bentoml.md", "lectures/mlops/llmops/index.md", "lectures/mlops/project.md", "lectures/mlops/security/age-gpg-ssh.md", "lectures/mlops/security/auth-enc-sign.md", "lectures/mlops/security/index.md", "lectures/mlops/security/pass.md", "lectures/mlops/simple-pipeline/index.md", "lectures/mlops/simple-pipeline/server.md", "lectures/mlops/simple-pipeline/vpn.md", "lectures/nlp_advances/gpt/camelids.md", "lectures/nlp_advances/gpt/detectGPT.md", "lectures/nlp_advances/gpt/gpt4.md", "lectures/nlp_advances/gpt/index.md", "lectures/nlp_advances/index.md", "lectures/nlp_advances/sam/index.md", "lectures/nlp_advances/thesis.md", "lectures/nlp_deep/chatbots/detectGPT.md", "lectures/nlp_deep/chatbots/index.md", "lectures/nlp_deep/chatbots/rlhf.md", "lectures/nlp_deep/datasets/index.md", "lectures/nlp_deep/datasets/lab-eda.ipynb", "lectures/nlp_deep/datasets/mc4.md", "lectures/nlp_deep/index.md", "lectures/nlp_deep/llms/decoding.ipynb", "lectures/nlp_deep/llms/index.md", "lectures/nlp_deep/llms/plms.ipynb", "lectures/nlp_deep/llms/zeroshot.ipynb", "lectures/nlp_deep/tokenization/bpe.ipynb", "lectures/nlp_deep/tokenization/index.md", "lectures/nlp_deep/tokenization/lab-train-tokenizers.ipynb", "lectures/nlp_deep/tokenization/pipeline.ipynb", "lectures/nlp_deep/tokenization/sentencepiece.md", "lectures/nlp_deep/tokenization/subword.md", "lectures/nlp_deep/tokenization/unigram.ipynb", "lectures/nlp_deep/tokenization/wordpiece.ipynb", "lectures/nlp_deep/training/index.md", "lectures/nlp_deep/training/lab-finetune-mlm.ipynb", "lectures/nlp_deep/training/lab-pretrain-clm.ipynb", "lectures/nlp_deep/training/lab-pretrain-mlm.ipynb", "lectures/nlp_deep/transformers/bert.ipynb", "lectures/nlp_deep/transformers/bertviz.ipynb", "lectures/nlp_deep/transformers/byt5.ipynb", "lectures/nlp_deep/transformers/index.ipynb", "lectures/nlp_deep/transformers/t5.ipynb", "lectures/nlp_intro/apps/index.md", "lectures/nlp_intro/apps/research1.md", "lectures/nlp_intro/apps/research2.md", "lectures/nlp_intro/datasets/corpus.md", "lectures/nlp_intro/datasets/index.md", "lectures/nlp_intro/datasets/lab-dart.ipynb", "lectures/nlp_intro/embeddings/fasttext.ipynb", "lectures/nlp_intro/embeddings/glove.ipynb", "lectures/nlp_intro/embeddings/index.md", "lectures/nlp_intro/embeddings/nlm.ipynb", "lectures/nlp_intro/embeddings/w2v.ipynb", "lectures/nlp_intro/index.md", "lectures/nlp_intro/intro/index.ipynb", "lectures/nlp_intro/lm/index.md", "lectures/nlp_intro/lm/ngram.ipynb", "lectures/nlp_intro/lm/usage.ipynb", "lectures/nlp_intro/sentiments/index.md", "lectures/nlp_intro/sentiments/lab-lexicon.ipynb", "lectures/nlp_intro/sentiments/lab-ml.ipynb", "lectures/nlp_intro/sentiments/lexicon.md", "lectures/nlp_intro/sentiments/ml.md", "lectures/nlp_intro/tokenization/index.md", "lectures/nlp_intro/tokenization/korean.md", "lectures/nlp_intro/tokenization/lab-korean.ipynb", "lectures/nlp_intro/tokenization/lab-tokenization.ipynb", "lectures/nlp_intro/tokenization/ngrams.md", "lectures/nlp_intro/tokenization/pos.md", "lectures/nlp_intro/tokenization/segmentation.ipynb", "lectures/nlp_intro/tokenization/tokenization.md", "lectures/nlp_intro/topic/coherence.md", "lectures/nlp_intro/topic/index.md", "lectures/nlp_intro/topic/lab-coherence.ipynb", "lectures/nlp_intro/topic/lab-methods.ipynb", "lectures/nlp_intro/topic/methods.md", "lectures/nlp_intro/topic/tomotopy.ipynb", "lectures/nlp_intro/vectorization/bow.md", "lectures/nlp_intro/vectorization/index.md", "lectures/nlp_intro/vectorization/lab-similarity.ipynb", "lectures/nlp_intro/vectorization/semantics.md", "lectures/nlp_intro/vectorization/similarity.md", "lectures/nlp_intro/vectorization/tf-idf.md", "lectures/softeng/devops/gitops.md", "lectures/softeng/devops/index.md", "lectures/softeng/index.md", "lectures/softeng/intro/index.md", "lectures/softeng/intro/introduction.md", "lectures/softeng/intro/processes.md", "lectures/softeng/intro/requirements.md", "lectures/softeng/intro/sdlc.md", "lectures/softeng/proposal/guidelines.md", "lectures/softeng/proposal/index.md", "lectures/softeng/proposal/steps.md", "lectures/softeng/proposal/template.md", "lectures/softeng/spm/agile.md", "lectures/softeng/spm/index.md", "lectures/softeng/vcs/00_introduction.ipynb", "lectures/softeng/vcs/01_solo_work_with_git.ipynb", "lectures/softeng/vcs/02_fixing_mistakes.ipynb", "lectures/softeng/vcs/03_publishing.ipynb", "lectures/softeng/vcs/04_collaboration.ipynb", "lectures/softeng/vcs/05_fork_and_pull.ipynb", "lectures/softeng/vcs/06_git_theory.ipynb", "lectures/softeng/vcs/07_branches.ipynb", "lectures/softeng/vcs/08_advanced_git_concepts.ipynb", "lectures/softeng/vcs/09_github_pages.ipynb", "lectures/softeng/vcs/10_rebasing.ipynb", "lectures/softeng/vcs/11_debugging_with_git_bisect.ipynb", "lectures/softeng/vcs/12_multiple_remotes.ipynb", "lectures/softeng/vcs/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 3, 6, 8, 9, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 29, 30, 35, 37, 38, 42, 45, 46, 49, 54, 55, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 122, 123, 126, 127, 128, 129, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 164, 165, 166, 167, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 182, 183, 184, 185], "0": [0, 1, 9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 45, 51, 76, 77, 78, 79, 88, 94, 95, 97, 100, 101, 103, 104, 105, 107, 108, 110, 111, 112, 113, 114, 117, 119, 123, 124, 126, 127, 132, 133, 135, 136, 139, 141, 142, 145, 147, 149, 150, 152, 153, 154, 155, 156, 157, 161, 181, 184, 186], "00": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 35, 51, 94, 100, 101, 103, 104, 107, 108, 110, 111, 112, 114, 132, 135, 136, 150, 181], "000": [17, 20, 95, 103, 105, 111, 112, 119, 120, 122, 128, 139, 143, 150, 152, 167], "0000": [110, 152], "000000": [25, 26, 27, 28, 30, 33, 149], "00000000": 112, "000001": 30, "000013296724692": 152, "000020": 14, "0001": 152, "00020": 9, "000270": [15, 21], "00027956522535532713": 152, "0004308223724365": 152, "0004752098843655948": 108, "000523405953129051": 14, "0006194999520653675": 14, "000642749081254596": 21, "000660": [14, 15, 21], "00070333480835": 152, "00082": 21, "0009028980666769455": 19, "0009417470597143389": 19, "00096": 21, "0009765625": 35, "000977778226698302": 19, "000km": 141, "001": 127, "0010": 152, "0010000319093906645": 14, "0010086221579924967": 19, "001021931625316696": 19, "001043796539307": 152, "0010603860605236683": 14, "0010913496344655172": 19, "0011111111108024763": 152, "0011744614247291812": 19, "0012780994727015953": 19, "0013324": 14, "0013614120427519083": 152, "0013657693473079205": 16, "0013807213841885606": 19, "001460": [31, 33], "0015103125334617502": 19, "001511": 33, "0015561782752413472": 29, "001653071269117536": 19, "001680": 14, "0017191542850923725": 152, "001750": 14, "0017750745406374334": 152, "001785838507319488": 35, "0018075713776912943": 21, "0018410125274279446": 16, "001962865950724563": 14, "001974979448829106": 16, "002": 21, "0020": 152, "00200496373839086": 19, "002177574671804905": 152, "0022369285449255986": 14, "0022407311684219168": 152, "002255635923122306": 14, "0022622254938860858": 19, "002297": 28, "002322": 25, "002442110228841302": 19, "0024603015855481497": 14, "002513": 34, "0025242881090182714": 14, "002576": 25, "0026033215690404177": 152, "002610116498544812": 152, "00277139162106223": 17, "0028065557235574324": 16, "0028207603159319233": 16, "002900": 14, "0029720626114525e": 108, "003": [83, 100], "0030": 152, "00303316": 14, "0030561790387218834": 17, "0031223123848645212": 152, "0031752510759462086": 152, "003179272280394612": 16, "0031880621893694222": 17, "003234388916771163": 19, "0032603326981582993": 35, "0033662562749769104": 19, "00349": [0, 6], "003495981109249": 152, "0035235610749915036": 19, "003535776093569": 152, "003550": [14, 21], "003586996406117": 152, "0035985502573076407": 17, "003644": 30, "003709836775138507": 17, "0037565036432219917": 17, "003873849489889034": 19, "003903": 28, "003973197078848794": 19, "003998241574432772": 16, "0040": 152, "004097158461809159": 152, "004175689859563079": 19, "004244009032845497": 152, "004376": 33, "004414455632531461": 16, "004594": 28, "004619": 33, "00476169941298804": 19, "004797083325684071": 152, "004800": 14, "004940841001211258": 17, "0050": 152, "0050339171614286": 152, "005058959626738143": 17, "005107979290187359": 152, "005134203936904669": 152, "005179156956969719": 19, "005238": 25, "005380": [14, 21], "005563": 25, "005687928438936715": 16, "005930": [14, 15, 21, 123], "0060": 152, "006023058667778969": 152, "006048532224020738": 14, "006059555336833": 152, "006127732509048656": 152, "00613": 16, "006324527770306708": 152, "0063391125479737": 152, "006360": 14, "006392374888576145": 17, "006400": 15, "006568645592778921": 152, "006612077821046114": 152, "006677545399021065": 16, "006743854005870231": 17, "006800": 14, "0068541975270435635": 17, "0070": 152, "007283565733168": 152, "007356486366026932": 152, "00741acc0": 16, "00756032345816": 108, "007591910869623802": 19, "007777777778395056": 152, "00795168713418085": 19, "0080": 152, "008004610426723957": 152, "008025267011382514": 152, "00806919950991869": 152, "00813735": 14, "008233696222305298": 152, "0082930761066575": 152, "00830205250531435": 152, "008475089073181": 152, "008636128157377243": 152, "008640003204346": 152, "0088": 21, "008809642893568226": 145, "00884969377797024": 17, "0089258432388306": 152, "009": [111, 112], "0090": 152, "0092657830980087": 152, "00931412617366345": 17, "009382950059241718": 152, "0095133185386658": 152, "0095287438501144": 145, "009533638447234705": 145, "009662": 25, "009830": 19, "00997748374939": 152, "01": [14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 45, 100, 103, 107, 110, 112, 123, 128, 132, 135, 136, 150, 152], "010050335853248927": 152, "010081577114760876": 152, "01008585398667492": 152, "0101010100755026": 152, "01011066196727523": 16, "010744794691714028": 17, "011200": [14, 21], "0112442822962447": 35, "011248100661326789": 17, "011560071259737015": 152, "011562358220107061": 16, "011695269495248795": 152, "011743": 30, "01194334": 14, "011977991797623686": 17, "012048": 25, "012195": 30, "012386607937514782": 152, "01250313787700796": 17, "012528997457076856": 16, "012756952526979148": 152, "012959": 20, "013": 120, "01312994262040823": 152, "013202836861213048": 152, "013203505426645279": 152, "013333333333796271": 152, "013559697485632367": 152, "013620396947472472": 152, "013667368888855": 152, "013953080879420869": 152, "01406999584287405": 152, "014297901652753353": 152, "014444444443209914": 152, "014493": 25, "0145052969455719": 152, "014599558897316456": 152, "0146991021827692": 152, "014707": 30, "014792973524635432": 16, "01481068": 14, "014815865084528923": 152, "014847449427987967": 152, "014918585307896137": 152, "015": 107, "015165": 34, "01545220130427584": 35, "015463637164793908": 152, "01563472938407527": 16, "01574835695205985": 152, "015801263126963696": 152, "0158730158556815": 152, "016037708872722253": 152, "01643266061982747": 152, "016438758864791857": 152, "016495274379849434": 152, "016666666666203728": 152, "016816": 33, "016895": 33, "017217755317688": 152, "01723609397849675": 152, "017405643466831665": 152, "017433559522032738": 152, "017537753614771317": 19, "017544": 30, "017550497874617578": 152, "017670": 15, "01771484687924385": 152, "017766": [23, 25, 26, 27], "017770": 33, "017965496318325943": 16, "01802913252790635": 152, "018248": 31, "01824960671365261": 152, "0182683509407169": 152, "018339197296235295": 152, "0183959249407053": 152, "018634909763932228": 152, "018678518012166023": 152, "018686016335820517": 16, "01871933601796627": 152, "018888888888503125": 152, "01890910230576992": 152, "018917387394747708": 17, "01894244": 14, "019077003002166748": 152, "019143888726830482": 152, "01916022039949894": 152, "019347166642546654": 152, "019481932744383812": 152, "019782157614827156": 152, "019804658368229866": 152, "019806118682026863": 152, "019809621816311e": 108, "019880": 25, "019986823201179504": 152, "01it": [23, 107], "02": [14, 15, 22, 23, 28, 30, 31, 32, 33, 110, 111, 112, 152], "020155129954218864": 152, "020184030756354332": 152, "02019628696143627": 152, "020287929102778435": 152, "020313935354351997": 152, "02036337": 14, "020408": 33, "020490463474": 132, "020539406687021255": 152, "020595964044332504": 152, "02060607075691223": 152, "0207321961720783": 152, "02100101": [14, 15, 19, 21], "02100201": 19, "02100311": 14, "02100374549627304": 152, "02100601": 14, "02100801": 14, "02100851": [14, 15, 19, 21], "0210167169570923": 152, "02111111111080248": 152, "021120237186551094": 152, "02119298093020916": 152, "021272389449621617": 19, "021280916407704353": 152, "021316067016847247": 19, "021318": 30, "02133885601942893": 152, "02134801261126995": 152, "02141981518103": 152, "021457767114043236": 152, "02149142511188984": 152, "02169227972626686": 152, "021697456017136574": 152, "021834025159478188": 152, "022079596295952797": 152, "02217409573495388": 152, "022201931104063988": 152, "022236647084355354": 152, "022253897041082382": 152, "022261105477809906": 152, "02227860502898693": 152, "02233187196252402": 152, "02241339161992073": 152, "022453": 28, "022487830370664597": 152, "022489816357847303": 152, "022510839439928532": 152, "02255701646208763": 152, "0226049423217773": 152, "02260943448636681": 152, "022615865571424365": 152, "022687014192342758": 152, "022817134857178": 152, "022828377783298492": 152, "022918909788131714": 152, "022921955212950706": 152, "022962426766753197": 152, "023013164289295673": 152, "023077810183167458": 152, "02316347137093544": 152, "0231639385223": 152, "023214666172862053": 152, "02322317101061344": 152, "023243363946676254": 152, "023304933682084084": 152, "023332816548645496": 152, "023429": 34, "023488366399701": 152, "023508427664637566": 152, "02365320026874542": 152, "023677445948123932": 152, "02375788427889347": 152, "023782242089509964": 152, "0238032303750515": 152, "023804608383215964": 152, "02384454943239689": 152, "023845259100198746": 152, "023860113695263863": 152, "02389199184771213": 152, "024": [111, 112, 117], "02400804781354964": 152, "02401486597955227": 152, "024027807638049126": 152, "024034013971686363": 152, "024058369919657707": 152, "024081824347376823": 152, "024181541055440903": 152, "02420790456235409": 152, "02428392320871353": 152, "0244444444452932": 152, "02444641850888729": 152, "0244805496186018": 152, "02454484812915325": 152, "02457650564610958": 152, "02460562437772751": 152, "024725638329982758": 152, "02484716847538948": 152, "024903977289795876": 152, "024928677827119827": 152, "02492894046008587": 152, "02493913657963276": 152, "024973296327516437": 152, "025011882465332747": 152, "025206705555319786": 152, "025228777900338173": 152, "025230159983038902": 152, "02524220570921898": 152, "02526998706161976": 152, "025288190692663193": 152, "025354486890137196": 152, "025373382633551954": 152, "025386424735188484": 152, "025460125878453255": 152, "02547328919172287": 152, "025610920041799545": 152, "025642": 30, "025644585490226746": 152, "02566142504931324": 152, "025746019068962": 152, "025783058255910873": 152, "02582348883152008": 152, "025920337066054344": 152, "025927245616912842": 152, "02594492956995964": 152, "026018": 34, "026059428229928017": 152, "026072914712131023": 152, "026073369197547436": 152, "026153041049838066": 152, "026178": 33, "026188": 28, "026242190320044757": 152, "02626017779111862": 152, "026280250067218697": 35, "02633865411626175": 152, "02641656994819641": 152, "026466488419100643": 152, "02654256857931614": 152, "026647305116057396": 152, "026666666667592542": 152, "026684165000915527": 152, "026686497032642365": 152, "02672146074473858": 152, "026755": 25, "026795502159956852": 145, "026795591191855372": 145, "026850566267967224": 152, "026877814903855324": 152, "026973506435751915": 152, "027046818286180496": 152, "027050886303186417": 152, "0271761390897964": 152, "027197375893592834": 152, "027241162955760956": 152, "027269362611696123": 152, "02731814980506897": 152, "027319354936480522": 152, "027335839346051216": 152, "02735506788144294": 152, "027357084676623344": 152, "027406617300584912": 152, "02745734713971615": 152, "027459732769057155": 152, "027603846043348312": 152, "027608619537204504": 152, "027665": [23, 25, 26, 27], "027751151472330093": 152, "027780745178461075": 152, "0277860090136528": 152, "027872106507937942": 152, "027872290462255478": 152, "02792251281400827": 16, "02802048809826374": 152, "028032733127474785": 152, "02806585220969282": 152, "028169": 31, "028173299506306648": 152, "02820960246026516": 152, "028326774704166585": 152, "02842774987220764": 152, "028549600392580032": 152, "028627438470721245": 152, "028639836236834526": 152, "028658824041485786": 152, "02873232145793736": 152, "0287358143354586": 152, "028818044811487198": 152, "028845202177762985": 152, "02884882315993309": 152, "028888888887808717": 152, "028942884877324104": 152, "028995145112276077": 152, "029011488535021748": 152, "029026644304394722": 152, "02905316837131977": 152, "02907869778573513": 152, "029129577800631523": 152, "029139023562897312": 152, "029142240062355995": 152, "029163892567157745": 152, "0292171910405159": 152, "029225243255496025": 152, "029246959519878154": 152, "029274040833115578": 152, "029338866472244263": 152, "029340967535972595": 152, "029363089614303225": 14, "029365785916646": 152, "029437027871608734": 152, "029484260827302933": 152, "029630": 31, "02966911531984806": 152, "029726402834057808": 152, "029766265489161014": 152, "029785138120253882": 152, "029884984716773033": 152, "029916903004050255": 152, "029923668410629035": 152, "029941071485324454": 152, "029972150921821594": 152, "03": [15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 100, 112, 152, 180], "030025072395801544": 152, "03004241": 14, "03012196607887745": 152, "030123389098379347": 152, "030131986364722252": 152, "030200": [14, 15], "030228495597839355": 152, "030345": 30, "030352376401424408": 152, "030426261946558952": 152, "030493": 34, "030516": 31, "030516041442751884": 152, "030535": 30, "030551111325621605": 152, "030552612939532587": 152, "030564147979021072": 152, "03076649084687233": 152, "030864188447594643": 152, "03088119998574257": 152, "031085219234228134": 152, "031132448464632034": 152, "031142": [30, 31], "031166594645543": 152, "031186800450086594": 152, "0312153663442274": 152, "03131523355841637": 152, "03131694346666336": 152, "03131acc0": 17, "031389358546584846": 152, "031448664028519": 152, "031500": 112, "031501518096774817": 152, "03156481310725212": 152, "031568868551403284": 152, "0316469706594944": 152, "031746": 30, "031786": 30, "03186766803264618": 152, "0319025032222271": 152, "03197": 29, "0319740312759507": 152, "032018862664699554": 152, "03206848353147507": 152, "03223659098148346": 152, "032240718603134155": 152, "03229295266792178": 152, "03233479708433151": 152, "03239099182925808": 152, "03240770846605301": 152, "03240897646173835": 152, "032470062375068665": 152, "0325390866647164": 152, "03259826738194377": 16, "032640": [15, 21], "0326758299022913": 152, "032683": 30, "0327024": 152, "03280625864863396": 152, "032836": [30, 31, 32], "03286190703511238": 152, "032879263162612915": 152, "0328834131360054": 152, "03296476975083351": 152, "03297409042716026": 152, "033039854077990205": 152, "03306887298822403": 152, "03312114253640175": 152, "03322892263531685": 152, "03328896686434746": 152, "03329444641454352": 152, "03331481292843819": 152, "033356454223394394": 152, "033435314893722534": 152, "03352180868387222": 152, "033560678362846375": 152, "033568563591688874": 152, "033586286008358": 152, "033591731259473": 152, "03393064513802528": 152, "03395622838288546": 152, "03396281599998474": 152, "03412267193198204": 152, "03413750594481826": 152, "034152742475271225": 152, "03415900468826294": 152, "034208785742521286": 152, "034220": 14, "0342683307826519": 152, "03433660753071308": 152, "034375499933958054": 152, "03439800813794136": 152, "03440142671690969": 152, "034425731748342514": 152, "034443046897649765": 152, "03455743566155434": 152, "03465194166637957": 152, "03467543050646782": 152, "034866993991498695": 152, "034915": [23, 26, 27, 33], "035085": 30, "03519437834620476": 152, "03524043411016464": 152, "03524777293205261": 152, "03525979816913605": 152, "03527016192674637": 152, "03532205522060394": 152, "0353222293274311": 152, "035352912605204": 152, "03537106513977051": 152, "03553271293640137": 152, "03558255136013031": 152, "03560185059905052": 152, "035720": [14, 19, 21], "035866402089595795": 152, "0360838046297431": 152, "036092985421419144": 152, "03615150600671768": 152, "03624275326728821": 152, "0362650513648988": 152, "03629786572368363": 152, "0364886112511158": 152, "036522": 25, "03659551963210106": 152, "03666666666620372": 152, "03667616244336371": 152, "0367746576666832": 152, "036792658269405365": 152, "03695906326174736": 152, "036980945616960526": 152, "03702234849333763": 152, "03704646974802017": 152, "037085410207509995": 152, "03708771616220474": 152, "03715534880757332": 152, "037185147404670715": 152, "037264298647642136": 152, "037384": 30, "03739694920368493": 152, "03740504011511803": 152, "03744939017575551": 152, "037468": [31, 33], "037500": 25, "03761112979716725": 152, "037681630812585354": 152, "037783720856532456": 152, "037908248603343964": 152, "0379212737083434": 152, "037974949926137924": 152, "038024842739105225": 152, "0381862111389637": 152, "03821370052173734": 152, "03821662440896034": 152, "03824062645435333": 152, "03839759901165962": 152, "038398": 28, "03842049837112427": 152, "038427666574716565": 152, "03844364359974861": 152, "03862296789884567": 152, "0386896597014532": 152, "03873555362224579": 152, "03876843675971031": 152, "03908383771777153": 152, "03914311155676842": 152, "039243023842573166": 152, "03926002438804054": 152, "03927813754417002": 152, "039304": 24, "039339987812046374": 152, "03935941681265831": 152, "039440584182739": 152, "03948744013905525": 152, "03952961415052414": 152, "0395844394243032": 152, "03959364909679": 107, "0397439002990723": 152, "03974424544721842": 152, "039814376831055": 152, "039873": 30, "03989723877360423": 152, "03999999999930559": 152, "03b8b76ad005950d86fc5494546cd5435a47cbbd": 184, "04": [15, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 111, 112, 121, 123, 128, 130, 152, 184], "040": [111, 112], "040083497762680054": 152, "04015165230052339": 152, "04019220173358917": 152, "04020649939775467": 152, "040207725101047": 152, "040301863104104996": 152, "040338192135095596": 152, "04037995636463165": 152, "04037998989224434": 152, "04045604541897774": 152, "040502": 5, "040554215712472794": 152, "04059769585728645": 152, "040606487262994054": 152, "04062372690273656": 152, "040644481778144836": 152, "040741": 31, "04088243441656232": 152, "040907684969454": 152, "041033096611499786": 152, "041048262268304825": 152, "0410723001576519": 35, "041128822967099646": 152, "04115924602374434": 152, "041293028742074966": 152, "04134495183825493": 152, "041367638669908044": 152, "04136773571372032": 152, "04142872244119644": 152, "04160774126648903": 152, "04161144886165857": 152, "041638": 30, "041691072285175323": 152, "04180443454533815": 152, "04182005319744349": 152, "041860342708726725": 152, "04198075830936432": 152, "041999999999236134": 152, "0421593233011663": 152, "04218817502260208": 152, "04219204559922218": 152, "042206212878227234": 152, "042256352533198": 152, "04248927906155586": 152, "0425521619617939": 152, "042552653700113297": 152, "042555006747717": 152, "04282868843939569": 152, "042941": 30, "0429912454491495": 152, "04299420490860939": 152, "04308585688704625": 152, "0431044512324863": 152, "0431815385818481": 152, "04332808777689934": 152, "04337195058696024": 152, "043400": 112, "04347703978419304": 152, "04348974861204624": 152, "0435190349817276": 152, "043523017317056656": 152, "0435703825950624": 152, "043652": 23, "0437235832214355": 152, "04376556184142828": 152, "043880258593708275": 152, "043887220323085785": 152, "043929": [30, 31, 32], "043969": 30, "0440474362578243": 152, "044164396822452545": 152, "044276900589466095": 152, "0446071389131248": 152, "04467113250866532": 152, "044734448194503784": 152, "044760": 30, "04491093009710312": 152, "044969458132982254": 152, "045": 45, "04500359818339348": 152, "0452619935102012": 152, "04534463584423065": 152, "045420831647486": 152, "045456701517105": 152, "04555992891405496": 152, "04572408273816109": 152, "045795440673828125": 152, "04585271701216698": 152, "046022": [30, 31, 32], "04605297315865755": 152, "04606": 0, "04618659242987633": 152, "04619699716567993": 152, "046242620795965195": 152, "04624945670366287": 152, "04631739230826497": 152, "04635542135098983": 152, "046620383858680725": 152, "0466287637129426": 152, "04666666666620373": 152, "046844959259033": 152, "04695010185241699": 152, "046988748013973236": 152, "046a712": 177, "0471317321062088": 152, "04714265819638967": 152, "0471946001052856": 152, "047503143548965454": 152, "047546323388814926": 152, "04757720679044723": 152, "047584916590858485": 152, "047667736559903": 152, "047727540135383606": 152, "04774315282702446": 152, "047887738794088364": 152, "04791494831442833": 152, "048015411863000027": 152, "04805": [0, 99], "048109": [30, 31, 32], "04815902188420296": 152, "04842308908700943": 152, "04861912131309509": 152, "04869697988033295": 152, "0487590491771699": 152, "048796920694947676": 152, "04880514014512301": 152, "048889391124248505": 152, "048939090222120285": 152, "04913739860057831": 152, "04916006557067793": 152, "04944229": 14, "04944303259253502": 152, "0494534604589918": 152, "04950031088665128": 152, "04950055712210693": 152, "049778604507447": 152, "049841899424791336": 152, "04d": [127, 128], "04k": 136, "05": [10, 14, 15, 20, 21, 23, 24, 25, 26, 27, 30, 31, 32, 33, 108, 111, 112], "050000001652027934": 152, "050000002527070084": 152, "05000000283627202": 152, "05001222868822": 152, "05003134906291962": 152, "050040": [31, 33], "050143": 33, "050156839191913605": 152, "05027374318626243": 152, "05030542407184839": 152, "050360": 31, "05052750938504081": 152, "05055555552748148": 152, "050565505400300026": 152, "0506262369453907": 152, "05068816989660263": 152, "0507568078530312": 152, "05091230198740959": 152, "05105343088507652": 152, "0510625998179117": 152, "05109086260199547": 152, "05130905658006668": 152, "05131297558546066": 152, "05132152512669563": 152, "051404965808615": 107, "05140705183148384": 152, "05157728120684624": 152, "0516876": 14, "051863204687833786": 152, "05191": 20, "051910": [15, 19], "05201324075460434": 152, "05208738949149847": 152, "05211600113348184": 152, "0523207476362586": 152, "05246623436214254": 152, "0524930655956268": 152, "05270737037062645": 152, "05273476496545805": 152, "05276763825159934": 152, "05279702693223953": 152, "052807": 25, "05304856225848198": 152, "0531478464603423": 152, "0532445145272019": 152, "05335765704512596": 152, "05336632952094078": 152, "05343955382704735": 152, "053497942380003": 152, "0536433339118956": 152, "05369899049401283": 152, "05395232513546944": 152, "054": [111, 112], "054033324122428894": 152, "0541820205768704": 152, "05443309042602777": 152, "0545852929353714": 152, "05464784428477287": 152, "05478229746222496": 152, "05491440370678902": 152, "05498626958578825": 152, "055276": 28, "05537626892328262": 152, "055410385131836": 152, "0554541110992433": 152, "05555555555401248": 152, "055851222156576": 152, "05589492991566658": 152, "05605816841125488": 152, "05610727518796921": 152, "0561725080013276": 152, "056442486308515075": 152, "056498335860669616": 152, "05666666666620372": 152, "05681043490767479": 152, "05693256855011": 152, "056963336705747575": 152, "05730922520160675": 152, "05733166371": 152, "0574597492814064": 152, "057496074587106705": 152, "05758258327841759": 152, "057847213745116": 152, "057878735731085e": 108, "058177": 25, "058474055491387844": 152, "058518886566162": 152, "0585608153294": 152, "058706": 25, "05875986196674117": 152, "058775322056478924": 152, "05886959284543991": 152, "058919": 28, "058977754372689456": 152, "0590": 110, "059253980701517626": 152, "05933672775478992": 152, "059524": 31, "05999999999930558": 152, "06": [14, 15, 21, 23, 24, 28, 30, 31, 33, 34, 108, 110, 174, 181], "0600": 184, "0600609116256237": 152, "060093": 25, "0602086759498055": 152, "0602213962001406": 152, "0603746697306633": 152, "06049309560718636": 152, "06070328131318092": 152, "06072566285729408": 152, "0609850883483887": 152, "06104483656365321": 152, "0611329078674316": 152, "06120393336750567": 152, "061224": 33, "06129385158419609": 152, "0613703462812636": 152, "061376765367417": 152, "061396408081055": 152, "06160355731844902": 152, "06175": 0, "061836": 25, "06188205188243753": 152, "061896": 33, "06258307859733529": 30, "06273228777572512": 152, "0628127242821375": 152, "06283593": 22, "06285469895228743": 152, "06290167171715035": 152, "0629795470195091": 152, "063": 120, "063014969574606": 152, "06369": 35, "06374088437782353": 152, "06379114091396332": 152, "06384652107954025": 152, "064255": 30, "064286": [30, 31, 32], "06496669764682236": 152, "0649914529938123": 152, "06522314250469208": 152, "06546416910010913": 152, "06546416910128068": 152, "065532997859911e": 108, "065586157143116": 152, "06580013204365968": 152, "0658064484596252": 152, "066192412128051": 152, "06621104702854534": 152, "06624470394148856": 152, "06624612605006143": 152, "066570": [14, 15, 21], "06666666666689813": 152, "06671895980835": 152, "06674521416425705": 152, "06689acc0": 17, "067133665084839": 152, "06713514820217745": 152, "0674062106758356": 152, "0674881803803146": 152, "06765787499025464": 152, "067962": 33, "0679799139499664": 152, "06800140934064984": 152, "06803527064621448": 152, "0681": 51, "06814": 0, "068241": 33, "068247": 30, "068270": [14, 21], "0683930441737175": 152, "06870913652399192": 152, "068759411375146": 152, "06888888888919752": 152, "0690041290183774": 152, "069079": [30, 31], "06931471814989455": 152, "069550": 25, "06970649": 152, "06it": 23, "07": [14, 21, 22, 23, 24, 30, 31, 32, 33], "07005497813224792": 152, "0702972412109375": 152, "070304331514571": 152, "0703579567372798": 152, "0705": 51, "0706554651260376": 152, "07073431462049484": 152, "070774345681312": 152, "071053": 30, "0716267079114914": 152, "07163909580558539": 152, "071650528907776": 152, "0716905148356126": 152, "0717117115855217": 152, "0717879543080926": 152, "07214492559432983": 152, "07240752719538407": 152, "07241": 35, "072464": 31, "0726400837302208": 152, "07271983586251736": 152, "0727551": 14, "072848": 30, "073038898727946": 152, "07305517047643661": 152, "073345": 23, "07337620109319687": 152, "07352436": 14, "0735806226730347": 152, "07362334430217743": 152, "07364538814872504": 152, "073981": 128, "0741924165627901": 152, "07421420821920037": 152, "0743200851811303": 152, "074328": 30, "07485087784007191": 152, "07499999996833334": 152, "07528742959158059": 16, "075441": [30, 31, 32], "07553057372570038": 152, "0755555555547068": 152, "07565984372007947": 152, "075712": 30, "07601101696491241": 152, "07616382919974851": 152, "0762025992076": 152, "0766732692718506": 152, "076698": [23, 26, 27, 33], "07670099985772799": 152, "07671117782592773": 152, "07682": 0, "076924": 30, "07696104113489391": 152, "07696104113545482": 152, "07696104113551105": 152, "07707776129245758": 152, "07714912438359542": 152, "07718963869055703": 152, "07719137948006391": 152, "077381": [30, 31, 32], "07745150006893609": 152, "077500": 112, "077572684817844": 152, "07778486348171201": 152, "07785352234183011": 152, "07799616557442479": 152, "07816842701577136": 152, "0783161667403813": 152, "078522": 33, "07859469803599864": 152, "0787838399410248": 152, "07897601045720357": 152, "07899330457052": 152, "07902201265096664": 152, "079199": 30, "07952811568975449": 152, "07984513494496544": 152, "07990583777427673": 152, "08": [14, 15, 19, 21, 22, 23, 28, 30, 31, 32, 33, 94], "080": [111, 112], "08003168953582644": 152, "08016": 35, "08017025142908096": 152, "08020481467247009": 152, "0802469135719117": 152, "08055725886583803": 152, "0805715151131153": 152, "080851": [30, 31], "08109336085617543": 152, "08112683892250061": 152, "08211303852897013": 152, "08212855363470023": 152, "08222222222229938": 152, "08224359766491388": 152, "08237": 0, "0824157815953828": 152, "082498407363891": 152, "08279434137253297": 152, "08322348445653915": 152, "0832902544281549": 152, "08349631540477276": 152, "08358242362737656": 152, "0837298682696807": 152, "083737": 25, "08373983587039549": 152, "08384250849485397": 152, "084": 103, "0848464209397464": 152, "08486": 16, "08486acc0": 16, "085580": 25, "085714": [31, 33], "0858306884765625": 152, "08589823905593837": 152, "08622435480356216": 152, "086359": [31, 33], "0866086959839": 152, "08704tn12tp21train_loss0": 16, "0871577113866806": 152, "08725816011428833": 152, "087292": 30, "087374": 28, "08748222142457962": 152, "087583": [30, 31, 32], "0880317687988281": 152, "0882180836465625": 152, "088255": 25, "08831321989894252": 152, "0883911517599014": 152, "088608": 30, "08869124026872062": 152, "0887713264147822": 152, "08897302425204513": 152, "089": 112, "08923283219337463": 152, "08960569": 14, "089616": 23, "089678": 34, "089881": 30, "089989948272705": 152, "08epoch": 20, "09": [14, 15, 19, 22, 23, 24, 28, 30, 31, 33, 34, 111, 112, 114, 152, 175, 184], "090": [111, 112], "0900": [174, 175, 180, 184], "09002556798255278": 152, "090069": 28, "09027235209941864": 152, "09045128077268601": 152, "090534558147192": 152, "09055597260594368": 152, "09055873945737": 152, "09059121534228325": 152, "09068491533398629": 152, "09069322496652603": 152, "09069855883717537": 152, "09070029854774475": 152, "09071093946695327": 152, "09071410968899726": 152, "09071683958172798": 152, "09078982919454574": 152, "09079249650239944": 152, "0907941222190857": 152, "09080255255103112": 152, "0908067338168621": 152, "0908079169690609": 152, "09081626906991005": 152, "09081744477152824": 152, "09082573726773262": 152, "09082677140831948": 152, "09082993492484093": 152, "09083370342850686": 152, "09083639308810235": 152, "09083664193749427": 152, "09083719700574874": 152, "09083746895194053": 152, "09084171429276466": 152, "09084264189004898": 152, "09084642007946968": 152, "0908469520509243": 152, "09084771491587165": 152, "09084807336330414": 152, "0908483773469925": 152, "09085014089941978": 152, "09085262939333916": 152, "09085730984807014": 152, "090857744961977": 152, "09085912853479386": 152, "09086524546146393": 152, "09086695313453674": 152, "09087031185626984": 152, "090873122215271": 152, "090873484313488": 152, "09087421372532845": 152, "09087632820010186": 152, "09087948873639107": 152, "09088162183761597": 152, "09088353589177131": 152, "0908846378326416": 152, "09088497683405876": 152, "09088974744081497": 152, "0908934824168682": 152, "09089420288801194": 152, "09089943617582322": 152, "09097979786909288": 152, "09104066548170522": 152, "091042": 34, "09166838228702545": 152, "09188440488661437": 145, "09200627624264193": 152, "092051823536552": 152, "0921587586402892": 152, "09219684": 14, "092324829101562": 152, "09246942280151692": 152, "0927255153656006": 30, "0928826": 177, "0928990066051483": 152, "09301305944100022": 152, "09312676191329956": 152, "09320585189982214": 152, "0935552358627318": 152, "09380713850259781": 152, "094": 103, "094256": [28, 33], "09476642608642": 152, "09485439706542012": 152, "094891": 31, "094900": 112, "094924": [23, 25, 26, 27], "095": 119, "095663": [30, 31, 32], "09569137090713614": 152, "096": 117, "0963026087731123": 152, "09631062974767758": 152, "09641246907413006": 152, "096552": 31, "09687": 53, "09694586040870846": 152, "09718930795788765": 152, "0972980260848999": 152, "097304": 25, "097561": [31, 33], "09788931234235808": 152, "09800404": 14, "09812190169672579": 152, "0981799298690425": 152, "0986122886678875": 152, "0987323746085167": 152, "098829": 23, "0991808899374273": 145, "0991838201880455": 152, "09923006594181061": 152, "09936678409576416": 152, "09945592378764523": 145, "09971871227025986": 152, "09972630068659782": 152, "09973392114043236": 152, "09973965883255005": 152, "09975052047520876": 152, "099774": 33, "09977788031101227": 152, "09982802346348763": 152, "09983752146363259": 152, "09984949454665185": 152, "09989505112171174": 152, "09995957762002945": 152, "09997299909591675": 152, "09997679015000661": 152, "09997731372714043": 152, "09997882321476936": 152, "09998270869255066": 152, "09999998137354851": 152, "09999998435378074": 152, "09999998658895493": 152, "09999998882412911": 152, "09999999105930328": 152, "09999999180436134": 152, "09999999329447747": 152, "09999999403953552": 152, "09999999478459358": 152, "09999999552965164": 152, "09999999627470971": 152, "09999999635644484": 152, "09999999701976776": 152, "09999999776482582": 152, "09999999831161985": 152, "09999999850988388": 152, "09999999925494193": 152, "09999999938123459": 152, "0m": [17, 22, 30, 132, 135, 136, 141, 150], "0ma": [132, 135, 136, 150], "0mcc0": [16, 17, 22], "0x7f0abf7043a0": 30, "0x7f0abf86c1f0": 30, "0x7f0abf86c820": 30, "0x7f0abf86c8b0": 30, "0x7f0abf86cc10": 30, "0x7f0faefeb040": 15, "0x7f0faefeb160": 15, "0x7f0faefeb670": 15, "0x7f0faefebe50": 15, "0x7f1029331f70": 19, "0x7f28e2df51f0": 16, "0x7f29d1221ee0": 16, "0x7f29d1225310": 16, "0x7f29d12254c0": 16, "0x7f29d12260d0": 16, "0x7f2afb9328b0": 16, "0x7f2afb932ca0": 16, "0x7f2afb932e50": 16, "0x7f2afb939a60": 16, "0x7f2e20d95a60": 21, "0x7f4a921d7ca0": 33, "0x7f4a921e43a0": 33, "0x7f4a921e4af0": 34, "0x7f4a924ba1f0": 33, "0x7f5538032dc0": 20, "0x7f553803b1f0": 20, "0x7f553803bf70": 20, "0x7f6b4a296820": 23, "0x7faa65df1ee0": 19, "0x7fc2a666c820": 24, "0x7fc2a666c940": 24, "0x7fc2a666cb80": 24, "0x7fc2a666cd30": 24, "0x7fc2a666cf70": 24, "0x7fc2a666d550": 24, "0x7fd4706e7280": 28, "0x7fd4706e7670": 28, "0x7fd4706e8310": 28, "0\uc2dc\ubd80\ud130": 15, "1": [0, 1, 4, 6, 9, 10, 11, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 42, 51, 52, 53, 59, 79, 94, 97, 99, 100, 101, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 124, 125, 126, 132, 133, 135, 136, 137, 139, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 157, 161, 175, 176, 177, 180, 181, 182, 183, 184, 185, 186], "10": [0, 1, 6, 9, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 42, 43, 47, 51, 70, 94, 95, 96, 100, 101, 103, 104, 105, 107, 108, 110, 111, 112, 114, 115, 117, 119, 120, 122, 126, 128, 129, 132, 136, 137, 139, 141, 145, 147, 149, 150, 151, 152, 155, 161, 186], "100": [6, 17, 20, 23, 24, 30, 43, 51, 69, 88, 94, 95, 97, 98, 100, 101, 103, 104, 107, 108, 110, 111, 112, 114, 115, 122, 128, 130, 136, 142, 145, 149, 151, 152, 181], "1000": [15, 24, 30, 35, 94, 101, 107, 108, 111, 112, 120, 126, 127, 135, 152, 184], "10000": [112, 128], "100000": [30, 128], "1000000": [103, 105], "10000000": 103, "10000000074505806": 152, "10000000116725759": 152, "10000000149011612": 152, "10000000165202796": 152, "10000000223517418": 152, "10000000252707009": 152, "10000000283627201": 152, "10000000298023223": 152, "10000000359045096": 152, "1000000037252903": 152, "10000000447034836": 152, "10000000521540642": 152, "10000000596046447": 152, "10000000670552253": 152, "1000000074505806": 152, "10000000819563866": 152, "10000000820064922": 152, "10000000894069672": 152, "10000000968575477": 152, "10000001043081283": 152, "10000001266598701": 152, "10001244082020401": 152, "1000454425811768": 152, "1000bce700c": [111, 112], "10029054445525011": 152, "1003419572424118": 152, "1004": 0, "1004699": 103, "100644": [174, 175, 176, 177, 180, 181, 185], "1009": 135, "100x": 115, "100\ud638": 15, "101": [9, 14, 104, 111, 112], "1010": 104, "101183821270789": 152, "10120457": 14, "101289": [23, 26, 27, 33], "1013101627858306": 152, "10145181030060889": 152, "1014644532": 152, "1017326507876506": 152, "10176142491400242": 152, "102": [14, 22, 104, 108], "102048": 23, "1022": 152, "1023": 35, "102319": 28, "1024": [8, 9, 10, 45, 111, 145], "1024x1024": [9, 10, 88], "1024x1204": 10, "10254788": 14, "1026": 30, "1027": 152, "10274352580308914": 152, "1029": 104, "102985": 20, "10300765294167731": 152, "10306088653936361": 152, "1031": 101, "1033524638471561": 152, "10335524227573639": 152, "1036258339881897": 152, "10370859429506546": 152, "104": [28, 29, 95, 111, 112], "104004": 24, "1041": 16, "1045511960983276": 152, "10489286482334137": 152, "10490": 14, "105": [111, 112], "10500": 112, "10500000000000002": 152, "10536051565597443": 152, "1053605156572708": 152, "10544469070737": 107, "10548304048522066": 152, "10556810678833571": 152, "1056187907799229": 152, "10573": 129, "106": [111, 112], "1061245305061154": 152, "10622589196313859": 152, "10646723646540263": 152, "10646782095923937": 152, "10650250803827695": 152, "10655201971530914": 152, "1066": 30, "10666666666550928": 152, "1067636013031006": 152, "10694603919983": 152, "107": 95, "1070": 152, "107119": 28, "1071468107418276": 152, "10722655288680988": 152, "1074": 152, "10741": 9, "1076": 152, "10762037602072623": 152, "10762037602072624": 152, "1076842308044434": 152, "107685": 145, "10785636231303215": 152, "10792532227933407": 152, "10795782655477523": 152, "108": [95, 111, 112], "10802": 16, "108056": 20, "108198": 20, "10834079577106827": 152, "10859449952840805": 152, "108675": 21, "1088065505027771": 152, "109": [103, 112], "1090194": 19, "109033560752868": 152, "1090506": 19, "1090535": [15, 19], "1090566": [15, 19], "1090615": [15, 19], "1090653": 15, "1090654": 15, "1090655": 15, "1090656": 15, "1090657": 15, "1090658": 15, "109110": 103, "1092": [101, 107], "10959": 0, "109789": 20, "10_000": [111, 112], "10m": 130, "10mb": 100, "10min": 150, "10mw": 14, "10\ub144": [14, 16], "10\uc5ec\uac1c": 20, "10\uc6d4": [15, 19], "10\uc6d4\uc5d4": 15, "10\uc870\uc6d0\uc774": 19, "11": [1, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 88, 94, 100, 103, 104, 105, 111, 112, 114, 117, 119, 128, 136, 145, 149, 152, 161, 181, 186], "110": [111, 112, 113, 147], "11000": 112, "110000": 128, "11000000": 103, "11019136048853398": 152, "1103284968522937": 152, "11050952574565061": 152, "11054": [14, 16], "1106": 22, "110689": 14, "11086780652403831": 152, "11087922155857086": 152, "11093106865882874": 152, "110kb": 103, "111": 135, "11100999661663936": 152, "11101613159001103": 152, "11109846010804177": 152, "111111": [31, 33, 149], "111111111090535": 152, "1111111111049383": 152, "11112882122397423": 152, "11113375052809715": 152, "1111360877752304": 152, "11113841906189918": 152, "11113927066326142": 152, "11114718317985535": 152, "11115459278225899": 152, "11115589812397957": 152, "11116116121411324": 152, "1111651249229908": 152, "11117018386721611": 152, "11117456331849099": 152, "11117525771260262": 152, "111176498234272": 152, "11118221059441566": 152, "11118842512369156": 152, "11119341179728508": 152, "1111955966303746": 152, "11119996532797813": 152, "11120561137795448": 152, "11120680719614029": 152, "11121246218681335": 152, "11122014597058297": 152, "11122125610709191": 152, "11122472137212754": 152, "11122925654053688": 152, "11123602688312531": 152, "11124122738838196": 152, "11124403774738312": 152, "1112450510263443": 152, "1112453892827034": 152, "11124621704220772": 152, "11125476285815239": 152, "11126035824418068": 152, "1112654909491539": 152, "11128147840499877": 152, "11129455417394638": 152, "11129547506570817": 152, "11129894480109215": 152, "11130044609308243": 152, "11130479648709297": 152, "11132487207651139": 152, "11136268749833107": 152, "11138427332043647": 152, "111412935305373": 152, "11141293530537302": 152, "11147894263267517": 152, "11148354113101959": 152, "11148485541343689": 152, "1115": 152, "11150938868522645": 152, "11151184756308793": 152, "11153265833854675": 152, "11153553343618199": 152, "11162484937707866": 152, "1117858462035656": 152, "1118": 152, "112051": [31, 33], "1123": 152, "1123066107432047": 152, "112403": [30, 31], "1125": 152, "11258613327854435": 152, "112740": 33, "11289855823852121": 152, "113": [14, 108, 111, 112], "1130": 152, "11305": 0, "1131181314587593": 152, "1131498378701508": 152, "113286": 145, "1133245636868838": 152, "113375616073609": 152, "1137": 0, "11390028382623481": 152, "1139546632766724": 152, "11397136410118747": 152, "114": [30, 145], "11403226852417": 152, "11403467499327492": 152, "1141510665416718": 152, "11457271110266447": 152, "1145889222621919": 152, "11479310813952832": 152, "11479531228542328": 152, "114829": [30, 31, 32], "1149206195026636": 152, "11495007860163847": 152, "11499179378151894": 152, "11500": 112, "11524808398723353": 21, "115277": 28, "1153": 20, "11532": [0, 6], "1154": [20, 152], "11541": [0, 6], "1155": [0, 20], "1156": 20, "115685820579529": 152, "1157": 20, "115784": 21, "1158": 20, "116": [111, 112], "1160": 16, "116052": [30, 31, 32], "1162": 0, "11647273153066635": 152, "11648": 14, "11651808135211468": 152, "11670115184194098": 152, "11676363675255017": 152, "116800": 112, "11688710": 103, "1169": 14, "11692": 99, "117": [16, 103], "117091": 33, "117156": 30, "1172": 103, "117343": 23, "11745118766041761": 152, "117647": 33, "1177": 152, "11778303566220273": 152, "11778303566258155": 152, "1177830356663694": 152, "117794": [30, 31, 32], "1178646906898124": 152, "11790130382631658": 152, "118": [14, 108], "11807400994002819": 152, "11827787994978789": 152, "1183098679418264": 152, "11832280151689759": 152, "1184": 152, "1187": 23, "1188280272579738": 152, "1190": 23, "11903": 53, "11921977251768112": 152, "11929": 0, "1193269466817144": 152, "11934": 0, "11935449063389972": 152, "11942": 99, "1196": 23, "11964958906173706": 152, "1198": 23, "11983944773489327": 152, "1198775447601903": 152, "11b": 117, "11gb": 51, "11it": 23, "11th": [111, 112], "11\uc2dc": 14, "11\uc6d4": [15, 19], "11\uc77c": 141, "12": [0, 1, 9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 100, 111, 112, 113, 117, 119, 128, 136, 145, 150, 152, 161, 186], "120": [111, 112], "12000": 112, "120000": [30, 31, 128], "12000000": 103, "1200600191950798": 152, "1201": 23, "120119": 24, "1202": 23, "1204": 152, "1204772697554695": 152, "12054447084665298": 152, "120547": 30, "1206": 23, "1207": 23, "12075710296631": 152, "1208": 23, "12080522253006873": 152, "1209": 23, "12092": 8, "12095094119498716": 152, "120\uc6d0\uc758": 14, "121": [111, 112], "1211": 23, "12119": 16, "1215004357264235e": 108, "12162": 152, "1218401308467869": 152, "122": [103, 152], "1220": 152, "12248752611724914": 152, "122680844925344": 152, "12268777150029593": 152, "122763804824756": 152, "12283456255415204": 152, "123": [16, 20, 28, 150], "1231940608": 51, "1232157862403148": 152, "1233790211540655": 152, "1234": [101, 107, 108], "12345": [16, 20], "1235": 14, "12379411570727825": 152, "1238": 23, "124": [0, 103, 184], "12404205043696695": 152, "124668386247423": 152, "124735": 28, "12495710347546096": 152, "125": 103, "1250": 152, "12500": 112, "125000": [23, 25, 26, 27, 33], "1251": 16, "125100": 112, "12513122278003186": 152, "12525155174080282": 152, "125443935394287": 152, "125461": [30, 31, 32], "125470572564088": 152, "12559629707700676": 152, "12563702444193925": 152, "1257": 152, "1258461538435896": 152, "125968885421752": 152, "1259989069056579": 152, "12601786963641642": 152, "126036": 21, "12661959749425444": 152, "12661959749425447": 152, "126984": 33, "127": [103, 152], "12733350574271754": 152, "1274": 14, "12773477082244225": 152, "128": [14, 110, 111, 128, 150, 152], "1280": 9, "12805647044959995": 152, "1281": [0, 6], "12815": 25, "12840020135045052": 152, "128420652449131": 152, "128683": 20, "12868913731679366": 152, "1289": [0, 6], "1290": 14, "129101": 24, "129102": 24, "129103": 24, "129104": 24, "129105": 24, "129114331246837": 152, "12911488191024367": 152, "129140": 24, "1293100118637085": 152, "1293967353327041": 152, "12939673533270415": 152, "12968221306800842": 152, "1298573174048215": 152, "1299620866775513": 152, "12999999999861117": 152, "12b": [8, 51], "12gb": 51, "12k": 120, "12th": [111, 112], "12\ub144\ub798": 14, "12\uba85": 19, "12\uc6d4": [20, 21], "12\uc6d4\uae4c\uc9c0": 15, "12\uc77c": 141, "13": [0, 6, 14, 16, 17, 20, 21, 22, 23, 24, 28, 30, 31, 33, 35, 94, 103, 104, 111, 112, 128, 139, 150, 152, 155], "13000": 112, "130000": [128, 136], "13000000": 103, "1300905320340664": 152, "13014": 25, "13018": 25, "130361": 25, "130552": 145, "1305689513683319": 152, "13059370080526506": 152, "1307": 14, "1307074": 152, "13091368600726128": 152, "1309658679251207": 152, "131": 0, "1310": 14, "1313131313048466": 152, "13141210740238118": 152, "13170": 30, "13183": 25, "1319174081261988": 152, "132": [111, 112], "1320184853341844": 152, "13213661321516457": 152, "1323": 14, "13246155834246956": 152, "1324615583424696": 152, "1325481235208962": 152, "13267237772233784": 152, "1329829118": 14, "133": 0, "133255": 145, "133333333284741": 152, "1333530227472592": 152, "133499290822854": 152, "1336003900525302": 152, "13375353018989322": 152, "133837": 30, "133938": 24, "134": [0, 14, 16, 24], "1340019846351324": 152, "13402051515877247": 152, "13437245786190033": 152, "13441046": 103, "13449855148792267": 152, "13461": 99, "134921": 30, "1349883197180439": 152, "13498831971804393": 152, "13500": 112, "13506944700263662": 145, "1351874610643829": 152, "135217": [23, 26, 27, 33], "135226": [31, 33], "1352714304941603": 152, "13535699248313904": 152, "1354": 152, "13548263442620365": 152, "13561280071735382": 152, "13565862607035908": 152, "1359732747077942": 152, "136": [111, 112], "136097": 33, "13616": [14, 16, 20, 22], "13626v1": 0, "13628447167575358": 152, "1363": 103, "136319494247436": 152, "13632233440876007": 152, "136364": [31, 33], "13657896220684052": 152, "13661738585142094": 152, "1367816093": 152, "136832": 107, "1369": 8, "13699999999999998": 152, "13749557": 103, "13758843340302507": 21, "13777777777700623": 152, "1378050723416717": 152, "13799999999999998": 152, "137b": 98, "138": 152, "13809": 19, "1382298469543457": 152, "1384310316397912": 152, "13852907791733743": 152, "13852acc0": 16, "13862943620078907": 152, "1386294362007891": 152, "1388888888878087": 152, "1388972859829664": 152, "139": [23, 111, 112], "139000": 25, "13940305217600987": 152, "139480": 21, "139555": 33, "1397846799755621": 152, "139gwh\uc5d0\uc11c": 16, "13b": [51, 83, 98], "13th": [111, 112], "14": [0, 6, 9, 14, 16, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 42, 51, 88, 98, 103, 104, 111, 112, 120, 128, 133, 145, 150, 152, 184], "140": [0, 20], "14000": 112, "140000": 128, "14003336653113366": 152, "14061422869563103": 152, "1406386292203226": 152, "1406825812533498": 152, "1408": 17, "1409227941185236": 152, "1411447": 22, "141286": 25, "14129233918696021": 152, "14141440639117112": 152, "14153379789657064": 152, "1415460109710693": 30, "14165": 53, "14169538021087646": 152, "14175311097344043": 152, "1419625983771921": 152, "142": 14, "1420": 152, "142012": 31, "14201988305441238": 145, "1420887517385103": 152, "1423": 0, "1423875130712986": 152, "142442607879639": 152, "14265440707643529": 152, "14265440707643534": 152, "1428330622962676": 152, "142857": [26, 27, 33, 149], "143": [111, 112, 119], "14334851156873857": 152, "143526641437244": 152, "143695": 31, "1439800856751984": 19, "144": [113, 152], "1440933644771576": 152, "14425460236335147": 152, "14438456296920776": 152, "14451706111431123": 152, "1446": 24, "144712": 34, "1447671800851822": 152, "145": [14, 103, 152], "14500": 112, "145001": 23, "14501": 23, "1450238458686197": 145, "14511": 23, "145480": 103, "1456": 30, "146": [0, 105], "14605848491191864": 152, "1461": [103, 152], "14618251017493344": 152, "146271950006485": 152, "14648936986923217": 152, "1465": 0, "14652348": 14, "1468": 135, "14699623237570955": 152, "147": [111, 112], "14727157354354858": 152, "14733463600277902": 152, "14767602767328883": 152, "14769100063500679": 152, "1477519493550062": 152, "1479509949684144": 152, "148": 112, "1480": 135, "148148": [31, 33], "14824682586212107": 152, "148436403274538": 152, "14900000000000002": 152, "14916": [0, 6], "1492": [21, 152], "1493610416512177": 152, "14943984682775205": 152, "14944404510495848": 152, "14944404510495854": 152, "14953625": 22, "14987410993346564": 152, "1499894857406616": 152, "149kb": 114, "14gb": 51, "14th": [111, 112], "14x14": 88, "15": [0, 6, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 47, 51, 94, 98, 100, 103, 104, 110, 111, 112, 117, 119, 128, 136, 145, 149, 152, 155, 184], "150": [105, 111, 112, 120], "1500": 112, "15000": 112, "150000": 128, "15001": [0, 6], "15017744898796082": 152, "150223": 25, "1503982663154602": 152, "1508254329363505": 152, "151": 19, "151172319776523": 152, "1512319143641574": 152, "15124760381877422": 152, "1514": 23, "151474952697754": 152, "15148071944713593": 152, "1515486269045268": 145, "15163": 30, "151697635650635": 128, "151900": 112, "15196374676500757": 152, "15206043846975117": 152, "15212869114346": 152, "15242108698649745": 152, "1524210869864975": 152, "15254030227661133": 152, "152613": 34, "1526490034069866": 152, "1532": 0, "15321893766522407": 152, "15333333333240745": 152, "15341": 19, "15389785915613174": 152, "1539": [111, 112], "154": [111, 112], "1540": [111, 112], "15412284717444524": 152, "15412284717444538": 152, "1543": 0, "1547659635543823": 152, "155": [111, 112], "15500": 112, "15523123741149902": 152, "155331552028656": 152, "155797079205513": 152, "155838": 15, "15587535132395897": 152, "156": [22, 30], "15602947": 94, "15648258888424163": 152, "15648258888424169": 152, "1567": 16, "15673434886460502": 152, "1567399942720877": 152, "156780": 21, "157": [14, 120], "15709031459299314": 152, "15716274566948413": 152, "1572": 103, "1574074073806158": 152, "15769056713778093": 152, "15769056713778107": 152, "15771": 94, "15781": 25, "157895": 33, "157958984375": 152, "157th": [111, 112], "158": 24, "15803": 30, "1588389619937186": 152, "15883896199371866": 152, "158wduud": 16, "158wduudsync": 16, "159": [14, 152], "15908": 0, "15919": 0, "1593": 0, "159873457471698": 152, "15w": 112, "16": [0, 9, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 45, 51, 88, 103, 104, 105, 107, 108, 110, 111, 112, 113, 115, 136, 141, 143, 152, 175, 180], "160": [111, 112, 145], "1600": [111, 112], "16000": 112, "1600587368011475": 152, "1603544473648073": 152, "160582": [15, 19], "160583": [15, 19], "160584": [15, 19], "160585": [15, 19], "160586": [15, 19], "160587": [15, 19], "160682597425249": 152, "1607": 0, "1607390195131302": 152, "16078982": 14, "1610017": 152, "16112": 105, "1612120151519776": 152, "161248": 28, "1613579988479614": 152, "16138075318276104": 152, "1613907128572464": 152, "16158807": 14, "16175": 30, "1617922072094629": 152, "16194646654918554": 145, "162": 0, "1621559621911957": 152, "16218523657111322": 152, "16222103513433575": 152, "162235": 34, "16227": 25, "16263582197968346": 152, "162m": 103, "163": [14, 111, 112], "163235473632813": 152, "16333380341529846": 152, "163337": [23, 26, 27, 33], "16347259391720095": 152, "16353459524120556": 152, "1635345952412056": 152, "1636": 0, "1637": [111, 112], "1639": 101, "1639196932315827": 152, "163955656922057": 152, "16396880149841309": 152, "164": 30, "164078": 33, "16409189701080323": 152, "164179": 30, "1642": [111, 112], "164209136644416": 152, "1647925543989872": 152, "16486529111142117": 152, "16486529111142129": 152, "1648890905082226": 152, "165": [111, 112], "16500": 112, "165061561514934": 152, "1653": 14, "16545448899269105": 152, "1656944416877297": 152, "165961": [23, 25, 26, 27], "16637061934840555": 152, "1664350771921802": 152, "16646547615528107": 152, "166540891263221": 152, "16657824232760404": 152, "166667": [30, 31, 32], "1667372226715087": 152, "16681005880236627": 152, "166822": 33, "167": [16, 111, 112, 152], "167014": [30, 31, 32], "16762497072759863": 152, "1676352471113205": 152, "167743": 23, "16778857356312876": 152, "167826": [31, 33], "16785973124959508": 152, "168": 140, "16820714620311472": 19, "168405532836914": 152, "1684190336359297": 152, "16845434930938016": 152, "16879": 30, "168929786103597": 107, "1689504559035084": 152, "16895263698810598": 152, "16911812126636505": 152, "169238": 33, "1693682083627209": 152, "16950989984821221": 152, "16957532687520144": 152, "169595": 145, "1696420858601588": 152, "1698986291885376": 152, "1698990367823524": 152, "16989903679013044": 152, "16gb": 51, "16k": 105, "16min": 150, "16th": [111, 112], "16x": 88, "16x16": [0, 9, 116], "16\uc77c\uae4c\uc9c0": 20, "17": [0, 14, 16, 19, 20, 21, 23, 24, 28, 29, 30, 31, 32, 35, 51, 111, 112, 135, 136, 150, 152, 174, 175, 181], "17000": 112, "17005307972431183": 152, "1702": [111, 112], "1703": [111, 112], "170363187789917": 152, "170499539375307": 152, "1705422348446317": 152, "170billion": [111, 112], "1711": [111, 112], "1715": 0, "171642": 30, "171646059376813": 152, "1716517610327064": 152, "17172210053023365": 152, "171814935737186": 152, "171992": [30, 31, 32], "172": [14, 22, 24], "17203156054019927": 152, "1722": 31, "17222144025044": 152, "172414": 28, "1725": 0, "172619": 31, "172840": 33, "17291411757469177": 152, "173": 14, "17328171317695196": 152, "17329260855913162": 152, "1736": 152, "173666": 15, "17374768014997244": 152, "17386418557316": 152, "173913": 28, "174": 103, "1740421": 15, "174046516418457": 152, "17405880215656602": 152, "17405880215656605": 152, "17419189085101458": 152, "1741918908510146": 152, "1743314877152443": 152, "17435338714266152": 152, "1746": 14, "174603": [30, 31], "1747": [111, 112], "175": [16, 93], "17500": 112, "1752": 152, "1753449941255123": 145, "17555796836192408": 152, "17559212082902823": 152, "1756": [111, 112], "17570182084653996": 152, "1759595423936844": 152, "1759731325287265": 152, "175b": 98, "176": 14, "1760": [111, 112], "176087": [31, 33], "1761984825134277": 152, "1763": [111, 112], "17642224971204995": 152, "1764544": 22, "176471": 33, "1766937747568545": 152, "1767": [111, 112], "17674943804740906": 152, "17691": 30, "177": [103, 105, 152], "1770": [111, 112], "17719": 105, "177700": 112, "177724838256836": 152, "17777777777550618": 152, "177\uba85\uc758": 16, "178": 136, "17823": 105, "1783": [111, 112], "1784573495388031": 152, "17857569058736164": 152, "178878515958786": 152, "17892": 105, "178947": [31, 33], "179": 150, "1790": [111, 112], "17917594700983888": 152, "179317": 28, "1795732287232441": 145, "1795986601151526": 152, "179676280419033": 152, "179702": [30, 31, 32], "179741581835933": 152, "1798": [111, 112], "17994302767120876": 152, "1799878992578683": 21, "17kb": 114, "17m": 120, "17t09": 94, "17\uac1c": 15, "17\uc77c": 20, "18": [0, 6, 14, 15, 16, 20, 21, 23, 24, 28, 29, 30, 31, 33, 35, 51, 104, 111, 112, 117, 128, 130, 150, 152, 175, 180, 184], "180": [14, 111, 112, 152], "1800": 107, "18000": 112, "1801": 152, "1804": [0, 111, 112], "1805": 22, "18050": 112, "180569440788693": 152, "1808": [111, 112], "1808038353919983": 152, "1808829307556152": 152, "1809": [111, 112], "1809079928504717": 152, "181": [105, 111, 112], "1810": [0, 99, 111, 112], "1812": [111, 112], "1813": [111, 112], "18150741010904312": 152, "1816014": 15, "1816015": 15, "1816016": 15, "1816017": 15, "1816018": 15, "1816019": 15, "1817": [111, 112], "18184349636236827": 152, "1819": [111, 112], "182": [24, 30, 100], "1820": [111, 112], "18208635": 22, "1821878125947856": 152, "182338": [30, 31], "1825": [111, 112], "1826": [111, 112], "18260028518696703": 152, "18260028518696708": 152, "18271050453186": 152, "1828": 152, "18297020494937896": 14, "1829920572622323": 152, "183": 103, "1830": [111, 112], "18330565243959426": 152, "1833403348922729": 152, "1833910": [14, 21], "1835544238487878": 152, "1836": [111, 112], "183600": 112, "1836213392910842": 152, "18367815044046804": 152, "1838964819908142": 152, "18399974912e": 110, "1840": [111, 112], "18403090427713625": 152, "1842": [111, 112, 152], "1844": [111, 112], "1846": [111, 112], "1847": [111, 112], "1848": [111, 112], "1849": [111, 112], "185": [111, 112], "1850": [111, 112], "1851": [111, 112], "1851851851687243": 152, "1851851851779427": 152, "18527317950462321": 152, "1852731795046233": 152, "1852ebc": 174, "1855150594204762": 152, "185616": 25, "1856236656572445": 152, "18564963340759277": 152, "18592197238293587": 152, "18595886": 14, "186": [111, 112], "1860": [111, 112], "1861": [111, 112], "1864": [14, 111, 112], "1865": [111, 112], "1865225060661841": 152, "18653": 0, "1867": [111, 112], "18675": 19, "1868": [111, 112], "1869": 14, "1870": [111, 112], "187050": [31, 33], "18708438146379341": 152, "18708438146379353": 152, "1871": [111, 112], "1872": [111, 112], "1874": [111, 112], "1875": [111, 112], "18751066848635672": 152, "1876": [30, 31, 32], "1880": [111, 112], "188141": [23, 25, 26, 27], "1884039598180809": 152, "1884751": 14, "18859166279435158": 152, "1887": 14, "18870800407669353": 152, "1887080040766936": 152, "1887123200628493": 152, "188889": [30, 31, 32], "188892364501953": 152, "1889": [111, 112], "18890943971152108": 152, "188m": 103, "1890": [111, 112], "1890276476740837": 152, "18903659284114838": 152, "18904": 20, "1891": [111, 112], "1891543977169527": 152, "18927": 20, "18929": 20, "1893": 22, "18931": 105, "1896": [111, 112], "1897\ub144": 14, "18980654629698515": 152, "18980654629698537": 152, "18it": 24, "18th": [5, 111, 112, 129], "18\uc77c": 20, "18\uc870\uc6d0\uc774": 19, "19": [0, 14, 15, 16, 19, 20, 21, 23, 24, 28, 29, 30, 33, 100, 104, 110, 111, 112, 120, 128, 129, 152, 174], "190": [14, 121, 130], "1900": [14, 111, 112, 119], "19002137333154678": 152, "19004649233998394": 152, "19009": 105, "1901": [111, 112], "1902236282755808": 152, "1903": [111, 112], "19030399062256848": 152, "1904761904604435": 152, "1906": 0, "1907": 99, "19086722037431578": 152, "1909": 99, "191": 30, "1910": [99, 111, 112], "19106": 20, "1911": [111, 112], "1911078766376401": 152, "1913": [111, 112], "191378": 34, "1914": [14, 111, 112], "1915": [111, 112], "19151053100118282": 51, "19152449071407318": 152, "19153348461822214": 152, "1916": 51, "191633939743042": 152, "1919059753418": 152, "19198": 20, "192": 140, "1920": [111, 112], "1921": [111, 112], "1921483874320984": 152, "192296480531112": 152, "19242175789761945": 152, "19242175789761948": 152, "1925": [111, 112], "19258639": 22, "1926": [111, 112], "1928": [111, 112], "1929": [111, 112], "19295595935546": 108, "193": [14, 22, 152], "1930": [0, 119], "1931": 119, "19323829": 14, "1935215424746275": 152, "1936": [111, 112], "1937": [111, 112], "1938": [111, 112], "1939": [111, 112], "193974": 103, "1940": [111, 112], "1941": [111, 112], "19411": 51, "1943": [111, 112], "1945": [111, 112], "19457": 105, "1945817530155182": 152, "1946": 34, "19466acc0": 16, "1947": 34, "19470537423940926": 152, "194737": 31, "19478": [23, 25, 26, 27], "1948709785938263": 14, "1950": [49, 111, 112], "1951710104942322": 152, "1954": [0, 23, 111, 112, 156], "1955": [0, 5, 111, 112], "19555555557": 152, "1956": [111, 112], "1957": [0, 156], "19584": 16, "1960": [111, 112, 119], "1961": [111, 112], "1962": [111, 112], "19620483368635178": 14, "19628": 20, "1963": [111, 112], "1964": [111, 112], "1965": [34, 111, 112], "19650192408718997": 152, "19650308787822723": 152, "1966": [111, 112], "1967": 152, "1967119961977005": 152, "196754": 28, "1967\ub144": 15, "196m": 136, "1970": [0, 111, 112, 120, 145], "1970\ub144": 15, "1972": [111, 112], "197224577329997": 152, "1973": [5, 111, 112], "19735": [23, 25, 26, 27], "1974": [111, 112], "197402000427246": 152, "1975": [111, 112, 152], "1976": 120, "19767125672509347": 152, "1976712567250935": 152, "197674": 31, "1976\ub144": 15, "1977\ub144\uc5d4": 15, "1978583": 152, "197859": 28, "1979": [23, 111, 112], "198": [14, 16], "1980": [49, 111, 112], "19806": [23, 25, 26, 27], "1981": [111, 112], "1981\ub144": 15, "1982": [23, 24, 25, 26, 27, 31, 33, 51, 111, 112], "19823": 20, "1983": [23, 24, 25, 26, 27, 31, 33], "1984": [111, 112, 128], "198534": 19, "198538": 19, "198592": 19, "198596": 19, "198598": 15, "198599": 15, "1986": [111, 112], "198600": 15, "198601": 15, "198602": [15, 19], "198603": 15, "19868": 20, "1987": [23, 111, 112], "19888888888711426": 152, "1989": 28, "19890510874489944": 152, "1989105820655823": 152, "1989564895629883": 152, "1990": [30, 31, 32, 34, 111, 112], "19907079886438117": 152, "19907247605216172": 152, "1990\ub144\uc744": 21, "1992": [111, 112], "19926": 20, "1993": [30, 111, 112, 120, 150], "19939": 20, "1994": [111, 112, 120], "1995": 34, "1997": [28, 129], "19972720742225647": 152, "19976201755926012": 152, "199784937807312": 108, "1997\ub144": 15, "1998": [28, 31, 111, 112], "199893": 20, "1998\ub144": 15, "1999": [31, 32, 33, 34, 111, 112, 123, 151], "1999\ub144": [15, 20], "19mb": 51, "19th": [111, 112], "19\uc2dc": 141, "1b": [88, 98], "1e": [28, 30, 51, 112], "1f": [112, 128], "1f354j2g": 16, "1f354j2gsync": 16, "1gb": 51, "1gss34v9": 16, "1gss34v9sync": 16, "1h": 14, "1m": [17, 22, 30, 112, 130, 132, 135, 136, 141, 150], "1m0b7bee": 16, "1m0b7beesync": 16, "1m5majkn": 16, "1m5majknsync": 16, "1mb": [100, 103], "1min": [14, 150], "1mwandb": [17, 22, 30], "1r3nk1yw": 17, "1r3nk1ywsync": 17, "1s5a57gq": 16, "1s5a57gqsync": 16, "1st": [129, 136], "1sxdb0f": 17, "1sxdb0fssync": 17, "1t": 117, "1trwr7nn": 16, "1trwr7nnsync": 16, "1x0zsmyr": 16, "1x0zsmyrsync": 16, "1x1": 88, "1ym4z9wq": 16, "1ym4z9wqsync": 16, "1yqr3hin": 16, "1yqr3hinsync": 16, "1\ub144\uc5d0": 14, "1\uc2dc": 141, "1\uc2dc\uac04\ub9c8\ub2e4": 16, "1\uc6d4": 15, "1\uc6d4\ubd80\ud130": 15, "1\uc77c": [14, 15, 19], "1\uc77c\ubd80\ud130": [15, 19], "1\uc8708000\uc5b5\uc6d0\uc774": 19, "1\uc8fc\ub2f9": 14, "2": [0, 1, 4, 11, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 34, 35, 51, 59, 77, 78, 88, 94, 95, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 124, 125, 130, 132, 133, 135, 136, 137, 138, 139, 143, 145, 148, 149, 150, 151, 152, 153, 155, 157, 161, 174, 177, 180, 181, 182, 184, 186], "20": [0, 6, 9, 14, 15, 16, 19, 20, 21, 23, 25, 26, 27, 28, 30, 35, 87, 88, 101, 103, 104, 111, 112, 115, 132, 136, 141, 150, 152, 167, 175], "200": [6, 15, 24, 28, 51, 95, 111, 112, 133, 150, 152, 167, 170], "2000": [30, 32, 33, 105, 107, 108, 111, 112, 127, 129, 135], "20000": 128, "200000": 30, "2000000": 103, "20003": 25, "2000\ub144": 15, "2001": [111, 112], "2001\ub144": 20, "2002": [28, 111, 112, 119, 120], "2002883156967014": 152, "2003": [0, 111, 112, 122, 127, 152], "20039150988062224": 152, "2003\ub144": 14, "2004": [0, 5, 28, 103, 111, 112, 145], "20041acc0": 16, "2004\ub144": 15, "2005": [53, 111, 112, 128], "20050": 53, "200595378875732": 152, "2006": [0, 23, 111, 112, 145], "2007": [28, 111, 112, 120], "2008": [23, 28, 33, 111, 112], "200829": 20, "2008336848682828": 152, "2009": [33, 111, 112, 135, 152], "200905406979172": 152, "200m": 120, "200\ubc30": 20, "200\ud638\uc5d0": 15, "201": [101, 105, 111, 112, 145], "2010": [0, 33, 111, 112, 120], "2011": [28, 111, 112, 119, 121, 130, 135, 152], "2012": [36, 111, 112, 121], "2012\ub144": 15, "2013": [0, 111, 112, 128, 184], "201319": 20, "2014": [0, 5, 23, 24, 30, 110, 111, 112, 125], "201426": 33, "2015": [0, 24, 28, 30, 71, 101, 111, 112, 147], "20158361": 152, "2016": [0, 23, 53, 87, 101, 105, 106, 111, 112, 119, 120, 124], "201600": 20, "2017": [0, 6, 14, 49, 53, 97, 101, 104, 111, 112, 113, 116, 129], "20179854333400726": 152, "2018": [0, 6, 23, 33, 53, 95, 99, 101, 105, 106, 111, 112, 113, 119, 120, 129], "201831": 20, "20184": 112, "2018\ub144": [14, 15, 16, 20], "2019": [0, 6, 10, 94, 95, 97, 99, 101, 111, 112, 117, 119, 120, 129], "2019\ub144": 16, "2020": [0, 6, 14, 15, 19, 21, 53, 93, 95, 97, 99, 111, 112, 115, 116, 117, 119, 120, 136, 141], "20200101001103001": 21, "20200101001253001": 21, "20200101001855001": 21, "20200101040159002": 21, "20200101040200001": [14, 15, 21], "20200101040200002": [14, 15, 21], "20200101040201001": [14, 21], "20200101040202001": [15, 21], "20200101040206003": 21, "20200101060214001": 21, "20200101183234001": 21, "20200101184423001": 21, "20200101_20200115": 15, "20200102040158002": 19, "20200102080234001": 19, "20200103000814001": 19, "20200108092412001": 19, "20200108160505001": 14, "20200224163725001": 14, "20200320001516001": 14, "20200323170208001": 19, "20200326172754001": 14, "20200421102241001": 14, "20201101060124001": 15, "20201101082723001": 15, "20201101090150001": 15, "20201101090515001": 15, "20201101092641001": 15, "20201101113442001": [15, 19], "20201101125903001": [15, 19], "20201101130118001": [15, 19], "20201102114419001": 19, "20201231110236001": 21, "20201231111427001": 21, "20201231132917001": 21, "20201231140203001": 14, "20201231141813001": 14, "20201231164457001": [14, 21], "20201231171734001": 14, "20201231204324001": [14, 21], "202050316333771": 152, "2020a": 95, "2020b": 95, "2020\ub144": 16, "2020\ub144\uc740": 21, "2021": [0, 6, 14, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 53, 111, 112, 115, 116, 119, 120, 132, 135, 141], "20210101002609003": 14, "20210101002610001": 14, "20210101002615001": 14, "20210101040137001": 14, "20210101040138001": 14, "20211116142132001": 14, "20211123210051001": 14, "20211201094104001": 14, "20211209160337001": 14, "20211222141644001": 14, "20211231104409001": 14, "20211231112402001": 14, "20211231112403001": 14, "20211231115157001": 14, "20211231143447001": 14, "20211231150933001": 14, "20211231181802001": 14, "20211231182324001": 14, "20211231210909001": 14, "202195": 28, "2021\ub144": [14, 19], "2022": [0, 6, 9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 53, 95, 98, 112, 115, 116, 123, 132, 152, 181], "20220101002520005": [14, 21], "20220224155144001": 19, "20220228050135001": 19, "20220228093428001": [15, 19], "20220228103653001": [15, 19], "20220228154344001": [15, 19], "20220228184928001": 15, "20220228190438002": 15, "20220228193736001": 15, "20220228205136001": 15, "20220228223323001": 15, "20220301": [111, 112], "20220308000798": 123, "20220527101334001": 19, "20220527154429001": 19, "20220531091955001": 19, "20220531112630001": 19, "20220531150108001": 15, "20220531154303001": [15, 19], "20220701_020155": 30, "20220816001711": 123, "20220905_company50": 15, "20220906_071028": 17, "20220906_071142": 17, "20220906_071214": 17, "20220906_071333": 17, "20220906_071403": 17, "20220906_071523": 17, "20220906_071554": 17, "20220906_071712": 17, "20220906_071742": 17, "20220906_071900": 17, "20220919_090235": 16, "20220919_092838": 16, "20220919_092902": 16, "20220920_005201": 16, "20220920_010015": 16, "20220920_010205": 16, "20220920_010232": 16, "20220920_010421": 16, "20220920_010448": 16, "20220920_010633": 16, "20220920_010700": 16, "20220920_010846": 16, "20220920_010913": 16, "20220920_011101": 16, "20220920_021330": 16, "20220920_021512": 16, "20220920_022059": 16, "20220920_022233": 16, "20220920_022302": 16, "20220920_022431": 16, "20220920_022500": 16, "20220920_022632": 16, "20220920_022703": 16, "20220920_022833": 16, "20220920_022901": 16, "20220920_023029": 16, "20220920_024031": 16, "20220920_024240": 16, "20221001": 103, "20221215_115806": 22, "20221215_120145": 22, "20221216_003124": 22, "20221216_003453": 22, "2023": [0, 14, 45, 53, 84, 100, 112, 135, 136, 141, 174, 175, 180, 184], "2024": 104, "20244873": 14, "202692": 149, "2027769971690658": 152, "20281956968249237": 152, "20281956968249248": 152, "2030": 152, "2030\ub144": 16, "2030\uc744": 15, "20324": 20, "20325": 20, "20325291559000797": 152, "20326": 20, "20327": 20, "20327777777305223": 152, "20328": 20, "20333": 20, "20334": 20, "20335": 20, "20336": 20, "20337": 20, "2034": 150, "2034636748385512": 152, "20347139984369278": 152, "203739": 25, "20374327898025513": 152, "203924": 15, "20406588969959": 152, "20446": 105, "20447": 105, "2048": 9, "20483024": 152, "2049560397863388": 30, "2050\ub144\uc774\ub2e4": 21, "2056": 0, "20602956772264508": 152, "20622534751892": 152, "20629671216011047": 152, "20632": 14, "206367": 33, "206845": 21, "206995": 28, "207386240153904": 152, "207419": 25, "207547": 30, "20784": 152, "207940": 19, "208333": 33, "20854200422763824": 152, "20906424522399902": 152, "20915542462219794": 152, "209552": [30, 31, 32], "209571909913137": 152, "20newsgroup": 149, "20th": [111, 112], "20\ub144": 20, "21": [0, 6, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 100, 101, 103, 107, 108, 110, 111, 112, 114, 130, 136, 152], "21000": 111, "21000000000000002": 152, "2101934199945794": 152, "2102": 8, "2103": 9, "2105": 0, "210568908088681": 152, "21072103130978853": 152, "21077627": 152, "2108678847586545e": 108, "210945653270672": 152, "2109678855560513": 152, "211": 152, "21100983675569296": 152, "21118": 28, "2112": 9, "2113": 152, "211580514907837": 152, "21183": 105, "212": 14, "212170": 24, "21217251856446653": 19, "2125246165440904": 152, "2127181026670668": 152, "2129": 104, "212986089077653": 35, "213010": [30, 31, 32], "21341": 105, "21346006609706414": 152, "2135": 0, "2137": 14, "213700": 112, "213922": 28, "21400000000000002": 152, "2140641365107059": 152, "21452752351760865": 152, "2146502597464455": 152, "21479199138056074": 152, "2150": 152, "215196074379815": 152, "215686": 30, "215800": 112, "216": 24, "2163301201716118": 152, "2163301201716119": 152, "21656668186187744": 152, "2167186163365841": 152, "216783": [30, 31], "21728213826815287": 14, "21751579642295837": 152, "217525332521506e": 108, "21764491": 22, "2178465873003006": 152, "2179": [20, 22], "2180174231529235": 152, "21807907607263988": 145, "2182841300964355": 152, "2183526396751403": 152, "21852376175624544": 152, "21875141391323671": 152, "219": [31, 33], "2190274": 14, "219403": [30, 31, 32], "2195909172296524": 152, "21it": 103, "21min": 150, "21st": [111, 112], "22": [0, 6, 9, 14, 15, 16, 19, 20, 23, 28, 30, 31, 32, 33, 35, 103, 111, 112, 128, 136, 150, 152], "220": [111, 112, 117, 122], "2200": 105, "2201": 53, "220126": 30, "22015353503574592": 21, "2202": 0, "2205": [0, 105], "22052617371082306": 152, "2206": 0, "2207": 0, "2207817789982073": 152, "2208": [0, 6], "22083134949207306": 152, "2208441019058227": 152, "22086668": 22, "2209": [0, 6], "2210555225610733": 152, "22110844002351862": 21, "22142546": 14, "221891": 28, "221892": 28, "222": [19, 111, 112, 128], "22205013036727905": 152, "222222": 33, "2223": 35, "222329": [23, 25, 26, 27], "222721": [31, 33], "222771860531334": 152, "222928": [23, 25, 26, 27], "223181": 21, "2232bf3": 183, "22353": 16, "2238002725221477": 152, "223855": 149, "22386": 152, "224": [111, 112], "224036483432627": 107, "224238872528076": 30, "2242692696241041": 152, "2244161333617765": 152, "224525048": 103, "2245705448013361": 21, "22467442005872726": 152, "22468823567808915": 152, "2247240034286678": 152, "22482402838833196": 152, "2249209702014923": 152, "224x224": 9, "225": 152, "2256082773208616": 152, "225806": 28, "225879836082458": 152, "226": 19, "226201621008416": 152, "2263261437416078": 152, "226467": 23, "22646935797399945": 152, "226677": 25, "227077": 19, "2272521961226583": 152, "2273": 14, "22738339269375524": 152, "22741": 105, "22745": 105, "2274680429034763": 152, "2275": 14, "2275139331817626": 152, "22767148911952972": 152, "227756137638969": 152, "228": 112, "228070": [31, 33], "2281": 103, "228681125865242": 152, "228714": 25, "22875212784856558": 152, "2288841644922892": 152, "2293009676418639": 29, "229571372270584": 152, "22974988263514307": 152, "2298": 23, "22gb": 51, "22it": 103, "22nd": [0, 111, 112], "22xgmnw8": 22, "22xgmnw8sync": 22, "22\uc77c": [14, 20], "23": [0, 14, 15, 16, 20, 23, 28, 30, 94, 100, 111, 112, 117, 135, 136, 141, 145, 150, 152, 184], "230": [15, 17, 20, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 111, 112, 152], "230078": 23, "2301": 0, "23018273615527657": 152, "2304922645497653": 152, "2305": 53, "230519461631775": 152, "2308": 53, "231": [111, 112], "231485": 23, "23162247641012074": 152, "23194885086268185": 152, "232": [14, 20], "2321656532999542": 152, "2325001955032349": 152, "23292849957942963": 152, "232k": 114, "2330": 14, "2330093636364418": 152, "233062": 23, "23333306312561": 152, "2333679087460041": 152, "2334528881435593": 152, "2335412502288818": 152, "233715": 25, "2338264191316234": 152, "2339521853385075": 152, "234047": 28, "23411971915790059": 152, "23427294194698334": 152, "234318804740906": 152, "234340": 25, "234429": 28, "234434127807617": 152, "2344785405840311": 152, "234567901196464": 152, "234650719165802": 152, "234776": 23, "2349082961678505": 152, "235": 21, "235069": 24, "235554731218934": 152, "2355661774882012": 152, "2359296": 51, "235955": 30, "236": 110, "23679817765951156": 152, "23692641034722328": 152, "23776455167163577": 152, "238": [111, 112], "23802": 152, "2380435297265649": 152, "238197326660156": 152, "2382670289940303": 152, "238576": 149, "23889190826607307": 152, "238902": 34, "238952159881592": 152, "239": [22, 108], "2390": 30, "2391": 30, "2392": 30, "23927003145217896": 152, "2393": 30, "2393397092819214": 152, "2394": 30, "2394mib": 112, "2395": 30, "239583": [30, 31], "23980206837877632": 152, "239959": 28, "23rd": [111, 112], "23\uc2dc": 141, "24": [9, 14, 15, 16, 17, 21, 22, 23, 28, 30, 31, 33, 35, 85, 103, 111, 112, 113, 117, 136, 145, 152], "240": 103, "2400": 152, "24045217": 14, "240481845103053": 152, "2404918": 145, "2405412077903748": 152, "24066539108753204": 152, "2408658489817811": 152, "24086584898178115": 152, "24092480540275574": 152, "241245746612549": 152, "241290": [31, 33], "24153346777929982": 152, "2416311651468277": 152, "2416791915893555": 152, "2417418599128722": 152, "24206": 0, "242064": 128, "24221": 0, "242317545413971": 152, "242745341360569": 152, "243": [111, 112], "243070": [31, 33], "24317131489515303": 152, "243324": 33, "243343": [31, 33], "24354935751654835": 152, "243671": 21, "243672": 21, "243673": 21, "243674": 21, "243675": 21, "244": [111, 112], "2441218301929142": 152, "24425282842966542": 152, "2442528284296655": 152, "244442932288125": 152, "2445598989725113": 152, "2447265088558197": 152, "2448540449142456": 152, "24508911790326238": 152, "245335590839386": 152, "245509": [31, 33], "246029": 28, "24603603780269623": 152, "2463554620742798": 152, "2468165174126625": 152, "247": [103, 111, 112, 119], "247149721569528": 152, "24714972156952805": 152, "2472682": 14, "2477": 135, "2477717101573944": 152, "24786447": 152, "24800": 23, "248177": 33, "2484613592937987": 152, "24863": 94, "2488": 14, "24899999999999997": 152, "249": 184, "24900000000000003": 152, "24931146192053955": 152, "249377": [23, 25, 26, 27], "24949350953102112": 152, "2499561309814453": 152, "24gb": 51, "24mb": 103, "24th": [111, 112], "25": [14, 15, 16, 19, 22, 23, 24, 25, 26, 27, 28, 30, 31, 35, 47, 94, 95, 98, 111, 112, 117, 120, 128, 129, 136, 142, 152], "250": [9, 111, 112], "2500": 112, "25000": 110, "250000": [30, 31, 33, 149], "250046": 20, "2505337163909442": 152, "250626658245578": 152, "250735392794013": 152, "25080054998397827": 152, "25091810534198355": 152, "250m": 8, "251": [14, 23, 103], "25133133": 14, "251404": 14, "251764": 33, "25201512277126314": 152, "2521924495697023": 152, "25219999875725335": 152, "2521999987572534": 152, "2522": 30, "25237317085266": 152, "25252525251887564": 152, "2525869905948639": 152, "25280910134315493": 152, "25286320050557454": 152, "253": 152, "253649": 20, "2537673862402816": 152, "2540597200393677": 152, "254098796844483": 152, "25424020821444454": 152, "25457": 105, "25461": 105, "254611086845398": 152, "25463688023094283": 14, "25475": 105, "2548": 16, "2548acc0": 16, "2552475929260254": 152, "256": [8, 14, 16, 17, 19, 22, 30, 88, 117], "2561096668243408": 152, "2561513797552215": 152, "2562444779607984": 152, "25635379552841187": 152, "2565449684858322": 152, "25664": 16, "256899498630729": 152, "25697005": 14, "256x256": [9, 10], "2570201081641083": 152, "257080": 28, "25730": 136, "25743132426534937": 152, "2574427025423358": 152, "2575892210006714": 152, "2577278188119332": 152, "25782379508018494": 152, "258": [121, 130], "258090591430664": 152, "2581": 105, "2581733147753403": 152, "25819794668091667": 152, "2583255767822266": 152, "2584400296211242": 152, "2584603667259215": 152, "258500": 112, "258536": 21, "258537": 21, "2585714322398417": 152, "258632": 103, "2590": 30, "25913405418395996": 152, "259259": 30, "2592729784548283": 152, "25942555218935015": 152, "259526": 33, "259527": 145, "259843": 28, "25992": 136, "25999999999999995": 152, "25h": 135, "25hbuild": 135, "25hrequir": [132, 135, 136, 150], "25ldone": 135, "25min": 14, "25th": [111, 112], "25\uc77c": [14, 19], "26": [10, 14, 15, 16, 21, 23, 24, 25, 26, 27, 28, 30, 31, 33, 85, 95, 100, 107, 111, 112, 128, 142, 145, 152, 174], "260": [111, 112], "2601": 103, "260452628135681": 152, "26048": 136, "260563": 31, "2607381343841553": 30, "2607411935925484": 152, "2607489824295044": 152, "26096": 30, "26100": 136, "26130": 136, "261365": 34, "261628": 30, "261657238006592": 128, "26177132": 145, "262141": [30, 31], "26224": 105, "26241374015808105": 152, "2626262625994085": 152, "262964129447937": 152, "263": [14, 152], "263141": 23, "2635118961334229": 152, "2641089407861668": 145, "26436833": 152, "264435": 31, "264450388285885": 152, "2646642609779317": 14, "264700": 112, "26487721796664926": 152, "26491374": 152, "265": 14, "26517586410045624": 152, "2654": 51, "26574485265980285": 152, "26576": 150, "26592340022325517": 152, "26599999999999996": 152, "266217577457428": 152, "2663285652796427": 14, "2668755257019132": 152, "26687552570191325": 152, "267111": 21, "2673": 152, "26747798919677734": 152, "267557430267334": 152, "267766": [23, 25, 26, 27], "267790": 14, "26809704303741455": 152, "268116643244866": 107, "2682366371154785": 152, "268511325444344": 152, "269231": [31, 33], "269355": 19, "26945594184191995": 145, "269513": 34, "269841269819602": 152, "26\uc77c": 16, "27": [10, 14, 15, 16, 17, 21, 22, 23, 28, 30, 31, 32, 35, 51, 69, 111, 112, 117, 145, 152], "270": 152, "270096": 23, "270118": 33, "2709275364875794": 152, "2709827545409401": 152, "2715209622206862": 152, "2715209622206863": 152, "271877": 21, "27219223976135254": 152, "2724": [20, 22], "2724171280860901": 152, "272474583729167": 152, "272716283135944": 152, "27308953884575": 152, "2734027441797985": 152, "2735632185": 152, "2738": 112, "273856472969055": 152, "274": [111, 112], "274252": 105, "274359": 19, "2744368456982516": 152, "274446924376207": 155, "274910": 145, "2756188680003915": 152, "27564658059061264": 152, "276": 14, "276040": 20, "2760459780693054": 152, "27618899941444397": 152, "2762430664151907": 152, "276408004760743": 152, "27650429494678974": 152, "27655373497141733": 152, "277": 30, "277136898040773": 152, "2771944399682726": 152, "2772588723025781": 152, "2773457169532776": 152, "277665": [23, 25, 26, 27], "277778": 31, "2777975a2334c2396ccb9faf98ab149824ec465b": 184, "278": [111, 112], "278030": 145, "2780546369890838": 152, "2780742120763763e": 152, "2781986892223358": 152, "27821696095948567": 152, "278689": 28, "279": [111, 112, 152], "2793": 0, "27944541030519776": 152, "279606819152832": 152, "279688": 30, "27975747734308243": 152, "28": [14, 15, 16, 17, 19, 20, 22, 23, 24, 28, 29, 30, 31, 33, 35, 111, 112, 114, 123, 152], "280": [52, 111, 112], "2802": 24, "2803": 0, "280368": 25, "28047922": 14, "280516": [30, 31], "2807204246521": 152, "280933845461242": 152, "280b": 98, "281": 24, "281398": 14, "2817": 24, "281742": 34, "28175778368280996": 152, "2817714214324951": 152, "2818": 24, "2819": 24, "282": 19, "2820": 24, "2820512820238879": 152, "2821": 24, "282110285758972": 152, "282835324932625": 152, "2829674184322357": 152, "2831": 112, "283419132232666": 152, "283658": [26, 27, 33], "283784": 33, "2840523043982159": 152, "284129": 28, "2844853401184082": 152, "2845817714929582": 152, "285": [24, 111, 112], "2850": 24, "2850092927096146": 152, "2850300274976867": 152, "2851": 24, "2851081848144532": 152, "2852": 24, "2853": 24, "2853970527648926": 152, "2854": [24, 30], "285564": [31, 33], "285714": 28, "285999862353007": 14, "286": [16, 24, 30], "2861169584095478": 152, "28614394288966066": 152, "28614394288966083": 152, "286240578111675": 152, "28673261404037476": 152, "286880": 33, "2868936721207613": 152, "287": [24, 30], "28705792129039764": 152, "28712310772271554": 152, "2874221801757812": 152, "2876820724414198": 152, "2877488086620967": 152, "2877505226455023": 152, "28775052264550244": 152, "287804": 19, "287821763753891": 152, "28789310455322265": 152, "288": [24, 30], "2883289317289988": 14, "2885": 103, "288551": 33, "288624": [26, 27, 33], "288802": 33, "289": 152, "289473260111279": 152, "2895": 152, "28970395103096963": 152, "28987571597099304": 152, "28it": 23, "28\uc77c": 15, "29": [14, 21, 22, 23, 24, 26, 27, 30, 31, 32, 33, 111, 112, 117, 120, 128, 145, 150, 152], "290": [23, 25, 26, 27, 111, 112], "290000": 25, "29000000000000004": 152, "2900974750518799": 152, "29022714495658875": 152, "2903820521198213": 152, "2906177127978444": 152, "291": 0, "29130387": 14, "2915966510772705": 30, "29187180995941164": 152, "2918782234191895": 128, "2919665389931534": 152, "29211614": 152, "2927805900573732": 152, "293520": 31, "293573": 19, "2936119906": 152, "29369887570285214": 152, "293700": 112, "2937325588117043": 152, "293935": 25, "2939641773700714": 152, "294": 103, "2941": 105, "2957142441467513": 152, "295765495300293": 152, "29584785221336524": 152, "295981720050152": 152, "296": 152, "2960053444307032": 152, "29600534443070325": 152, "2960137814283371": 14, "29665989984447755": 152, "2967510416892118e": 108, "297": 132, "2972231205811517": 152, "2974543133079955": 152, "29756946355149305": 152, "297673": 33, "2978416590213351": 152, "2978416590213352": 152, "2978954613208771": 152, "298": [30, 132], "29808357678767705": 152, "2981277704238892": 152, "2988475929530144": 152, "29894404822132653": 152, "29911605285273657": 152, "2993130683898926": 152, "2994259119033815": 152, "29996280868848163": 152, "29c": 112, "29it": 24, "29\uc77c": [14, 21], "2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec": [101, 103, 107, 108], "2a59bqsm": 16, "2a59bqsmsync": 16, "2a74d89": 183, "2bclip": 9, "2ceyf1n4": 16, "2ceyf1n4sync": 16, "2d": [6, 126], "2e": 45, "2e7jflgg": 17, "2e7jflggsync": 17, "2f": [25, 31], "2fa": [77, 78], "2h04jfx6": 22, "2h04jfx6sync": 22, "2k": [132, 135, 136, 150], "2min": 150, "2m\uc758": 141, "2ngg0tpm": 16, "2obg8t98": 17, "2oivm1t2": 16, "2oivm1t2sync": 16, "2s63fdzf": 16, "2s63fdzfsync": 16, "2vv0hewt": 17, "2vv0hewtsync": 17, "2x": [88, 115, 117], "2yq3mw4j": 16, "2yq3mw4jsync": 16, "2zt1qpx2": 16, "2zt1qpx2sync": 16, "2\u00b2\u2075": 117, "2\uacf5\uc7a5": 20, "2\ub144": 20, "2\ub300": 15, "2\ub9cc": 20, "2\ubd84\uae30\uc5d0": 16, "2\uc2dc": 141, "2\uc6d4": 15, "2\uc6d4\ubd80\ud130": 15, "2\ucc28\uc804\uc9c0": 20, "3": [0, 1, 5, 8, 9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 42, 47, 49, 51, 55, 61, 74, 83, 92, 93, 97, 98, 100, 101, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 120, 121, 122, 132, 133, 135, 136, 139, 143, 145, 146, 149, 150, 151, 152, 161, 174, 175, 180, 181, 184, 186], "30": [0, 3, 6, 14, 16, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 70, 87, 96, 100, 103, 111, 112, 129, 139, 145, 150, 152, 161], "300": [9, 111, 112, 150], "3000": [112, 127], "30000": [103, 110, 112, 128], "3000000": 103, "300007": 23, "3000326329631926": 152, "30006176233291626": 152, "300k": 120, "300m": 9, "300w": 112, "300\ud638": 15, "301": 103, "301071643829346": 152, "30110509278196973": 152, "3012711354385487": 152, "3019773": 145, "3027957253985933": 152, "30285680294036865": 152, "3028968002392749": 19, "302897": 19, "303": [111, 112], "3035161207119624": 152, "3037643601664413": 152, "303969": 25, "303\uc5b5\uc6d0\uc744": 14, "304293155670166": 152, "305": 120, "30500775774319966": 14, "3050496578216553": 152, "30523637334505715": 152, "305328941345215": 152, "3054954707622528": 152, "305556": 30, "3058826974593103": 152, "30588778853416443": 152, "3059754371643066": 152, "306": [0, 14, 28, 34], "3061930537223816": 152, "3062569569796324": 152, "3063109305169847": 152, "3065742522854": 152, "3066": [30, 31, 32], "3066542577943232": 29, "307": [28, 111, 112], "3072": 112, "3075068242847919": 152, "307692": 33, "30779310458650194": 152, "3078935027122498": 152, "30799426429340176": 152, "308": 28, "3080440490": 152, "3081002600491047": 152, "30811312794685364": 152, "3081607738509774": 152, "308204": 28, "30842970315780904": 152, "308485984802246": 152, "308928": 33, "3089823722839355": 152, "309": 28, "309001147774482": 152, "30900114777448207": 152, "3091985285282135": 152, "3093050652080112": 152, "30939303582741157": 152, "309474611282349": 152, "309476": 33, "309712243080139": 152, "30_000": 112, "30e0ccb": 183, "30k": 146, "30min": 14, "30tb": 117, "30th": [23, 111, 112], "30\ub144": 21, "30\ubd84": 14, "31": [14, 22, 23, 24, 30, 31, 32, 34, 111, 112, 132, 135, 136, 140, 141, 150, 152, 184], "310": 28, "31062971577048304": 152, "311": 28, "31138": 30, "311434030532837": 30, "3115": 0, "3119921805544": 152, "312158226966858": 152, "3124418258666992": 152, "3125058130824736": 152, "3125091246325367": 152, "3126": 14, "3126117847152092": 152, "3128114342689514": 152, "3128788981690175": 152, "313": 152, "31315051799433097": 152, "31341073": 152, "31365885996615045": 152, "3136588599661505": 152, "3136667526430554": 152, "314": [103, 111, 112], "3143009778112173": 152, "3143158": 14, "314413": 33, "314837": 145, "3149481895897124": 152, "314956903457642": 152, "31518845558166503": 152, "3152145147323608": 152, "31562480330467224": 152, "315789473664974": 152, "3160255074501037": 152, "316108": 19, "316640100991759": 152, "31665071715186865": 152, "317": 22, "317378": 128, "317392498254776": 152, "317460": [30, 31, 32], "317580962181091": 152, "318096989863972": 152, "318610280752182": 152, "318708": 25, "31882762478330307": 152, "3188276247833031": 152, "3191691594567949": 145, "3196": 22, "319663143157959": 152, "31979130793668337": 152, "3197913079366835": 152, "31m100": 132, "31m12": 136, "31m17": 135, "31m27": 132, "31m4": 135, "31m54": 150, "31\uc77c": [14, 20], "32": [0, 8, 9, 14, 16, 17, 19, 22, 28, 30, 45, 51, 103, 111, 112, 132, 135, 136, 141, 150], "32000": 103, "32006070017814636": 152, "320284903049469": 152, "3204577164651875": 152, "3204577164651876": 152, "320464": 19, "3205361928480367": 152, "321096407409169": 152, "32126699541178017": 152, "32146450877189636": 152, "321642255783081": 152, "32200417": 152, "32208251953125": 152, "322135237242685": 152, "3222507753641843": 152, "322421": 128, "3225314312924941": 152, "3226379733532667": 152, "32292348": 14, "32296014": 14, "32307078506564724": 152, "32323366": 152, "32332706451416016": 152, "32402369379997253": 152, "32440507411956787": 152, "3245970745918638": 145, "324700": 25, "3247616750": 14, "325226652622223": 152, "3254g": 16, "32550658281478617": 152, "32555586099624634": 152, "325581": 33, "32564": 16, "32564acc0": 16, "326": [108, 119], "326329428785377": 152, "32647931506198496": 145, "3269": 108, "326970": 149, "327": [103, 111, 112], "327033519744873": 30, "32708": 14, "3272883892059326": 152, "327325": 33, "3275638867650108": 145, "3276653647422791": 152, "32767": 152, "3279976915096982": 152, "328208327293396": 152, "32832280118185425": 152, "3284517904122671": 152, "3284977972507477": 152, "3285024154428924": 152, "3285040669655546": 152, "3295": 22, "3299575706066555": 152, "3299575706066556": 152, "32gb": 51, "32k": 105, "32m1": 132, "32m298": 132, "32m461": 136, "32m52": 135, "32m636": 135, "32m9": 150, "32x32": 9, "33": [14, 15, 23, 24, 25, 26, 27, 30, 33, 35, 94, 103, 115, 128, 145, 150], "330156": 21, "33036327": 22, "330709": [31, 33], "33076155450609": 152, "331": [103, 111, 112], "33127416269768944": 29, "332": 152, "3320080794477474": 152, "33214378356933594": 152, "33243343234062195": 152, "332493": 33, "332501": 28, "33317976239575325": 152, "3331964910030365": 152, "333333": [30, 33], "3333333333185187": 152, "3333333333333333": 108, "33338644554217656": 152, "3335316630287303": 152, "3336375951766968": 152, "333913": 149, "334075": 145, "3343541645341449": 152, "33436": 20, "334601": 33, "3346821069717407": 152, "3347507417201996": 152, "3348137766122818": 152, "3349212914705276": 152, "33493686": 14, "334940": 25, "335": [111, 112], "335063934326172": 30, "335245": 33, "3353415497716667": 152, "3353415497716672": 152, "33574057": 14, "33578805923463": 152, "336": 9, "3360": 108, "336600": 112, "3367249697446823": 152, "33679577708244324": 152, "33695": 152, "3369654417037964": 152, "336px": 9, "336x336": 9, "33701446652412415": 152, "3370403753386603": 152, "337079": 30, "3371551722288132": 152, "3373492727159626": 152, "3376509308815003": 152, "3378403186798096": 152, "3379381071100026": 145, "338": [111, 112], "33805098533630373": 152, "33813833362526363": 152, "33828441947698595": 152, "33854187": 14, "338881254196167": 152, "338889": [30, 31, 33], "339": 14, "3390489612188604": 152, "3392370343208313": 152, "33925": 107, "33999999999999997": 152, "33b": 83, "33mentelecheia": [17, 22, 30], "33mwarn": 22, "34": [0, 14, 20, 21, 22, 24, 33, 111, 112, 132, 135, 136, 141, 150], "340": 9, "340121": 30, "34047603607177734": 152, "34076554398569797": 152, "340982913970947": 152, "341": 24, "34112692": 14, "34122953414917": 152, "34148": 20, "34197703417804504": 152, "342000": 25, "342065739466084": 152, "3421005010604858": 152, "34213744625449183": 152, "34244710206985474": 152, "3426904241243998": 152, "342701804637909": 152, "3428099542940226": 152, "342919707298279": 152, "343": [14, 152], "34311446903531895": 16, "3434767007827757": 152, "3435245777160014": 152, "3435245777160023": 152, "34372544288635254": 152, "343837": [31, 33], "34388906210660936": 152, "3440860214933326": 152, "3440898985369131": 152, "3441504937079218": 152, "3442993678090223": 152, "34469854469854466": 35, "344843": 103, "344844": 103, "34486544132232666": 152, "3453836627304554": 152, "34551202019469607": 152, "3457771937052409": 152, "34588676674498453": 152, "346": 14, "34609341621398926": 152, "346154": 33, "34623068273067475": 152, "346372310677454": 152, "34645339846611023": 152, "3465757022785438": 145, "3465827856780583": 145, "3465828747099568": 145, "347": 15, "3473098207303265": 152, "34796334778269133": 152, "348": 14, "348135626366958": 152, "3484": 103, "34844744205474854": 152, "348837": 30, "3489603996276855": 152, "3493381023406983": 152, "349479913711548": 30, "3496905752250248": 145, "349789": 33, "34979259967803955": 152, "349943590164184": 152, "3499656090752427": 145, "34b": 117, "34it": 23, "34k": 103, "34m": [17, 22, 30], "35": [0, 14, 16, 20, 21, 22, 24, 28, 30, 31, 32, 33, 34, 111, 112, 117, 120, 150, 152], "350": [24, 105], "3500": 112, "35029977937018786": 152, "35036173462867737": 152, "350831": [31, 33], "35086887776851655": 152, "351": 103, "35133889416853586": 152, "351351351341206": 152, "351438074447317": 152, "35168678990791136": 152, "3516867899079114": 152, "3517324017228247": 152, "3519227033342969": 145, "35195610448718073": 152, "35200": 103, "352100": 112, "3522205935672775": 152, "3526109635829926": 152, "352829": 33, "35304332": 14, "353139877319336": 152, "353173": 33, "35347050428390503": 152, "353698372840881": 152, "3542680740356445": 152, "3544959825168774": 19, "3547240469054427": 152, "3548059927092658": 152, "355": [14, 128], "3552114872225542": 152, "355417": [23, 25, 26, 27, 33], "3555277672078874": 152, "3557": 30, "35570975244045255": 152, "355847175203072": 152, "3558471752030721": 152, "356": 128, "3561165131571915": 145, "35636063549253677": 152, "3563797414302826": 152, "356613": [30, 31, 32], "3566843113861978": 152, "3568": 30, "35685782028959667": 152, "357": 152, "357664": 31, "357745": 30, "358087": 33, "3589421510696411": 152, "359": [111, 112], "35903206546025535": 145, "359375": 33, "35945": 152, "359515190124512": 152, "35952309105131364": 152, "35959198474884035": 152, "3597119006845686": 152, "359891652097845": 152, "35gb": 51, "35lxag5u": 17, "35lxag5usync": 17, "36": [0, 6, 15, 19, 30, 31, 32, 33, 35, 97, 103, 111, 112, 135, 150], "3607129294011328": 152, "3609868586063385": 152, "36101144552230835": 14, "36161744594573975": 152, "361705": 25, "3618507874508699": 152, "3619428873062134": 152, "36196450125426055": 152, "362": [111, 112], "362140": 33, "3624002845095718": 152, "362400284509572": 152, "3624297085720154": 152, "3631428241729737": 152, "36342382": 152, "3635103702545166": 152, "3636": [101, 107, 108], "363636": 33, "36375135481357573": 152, "36392": 16, "363974618911743": 152, "364": 14, "3643739732810193": 152, "364447": 28, "36449912190437317": 152, "3645357459783554": 152, "36455040506811603": 152, "3650163412094116": 152, "36521188616752626": 152, "3652218150352202": 152, "36558184027671814": 152, "3656056709587574": 152, "3656192421913147": 152, "365789": 34, "3659698486328125": 152, "366": [14, 16], "36605697870254517": 152, "36646339164839853": 152, "3664802716837989": 152, "366501808166504": 152, "367": [16, 152], "367011500419014": 152, "367028": [31, 33], "3673328459262848": 152, "3679927587509155": 152, "368": 16, "3680855777528551": 152, "368122": 34, "3683128794034322": 152, "368441152572633": 152, "3687988817691803": 152, "3688957737551795": 152, "369": [16, 20, 103], "3694": [30, 31, 32], "3698277353097963": 152, "3698390002038444": 152, "36983900020384447": 152, "3698685281806522": 152, "36it": 23, "36m": [100, 104], "36m0": [132, 135, 136, 150], "36mb": 136, "36min": 14, "36o0ldih": 16, "36o0ldihsync": 16, "36th": [111, 112], "36\ub9cc\uba85": [14, 16], "37": [0, 6, 14, 15, 19, 22, 28, 30, 31, 32, 111, 112, 142, 145], "370": 16, "3700122098128001": 152, "3701383246947222": 152, "37013832469472235": 152, "37045379281044005": 152, "37084027417004106": 152, "371": 16, "3710936218500137": 152, "37123751640319824": 152, "37124642729759216": 152, "3712513309499346": 152, "3712513309499348": 152, "371429": 33, "3717052936553955": 152, "3719": 25, "3721025586128235": 152, "37295582954090467": 152, "373": 103, "3731122314929962": 152, "37316074293080925": 152, "3733553886413574": 30, "37337837686991365": 145, "373465908815218": 152, "373670": 22, "373675": 25, "373858": 25, "3738812698258294": 152, "374244": [31, 33], "3743484366": 152, "3744139075279236": 152, "374700": 112, "3747661471366883": 152, "37483677003118726": 152, "3748432844877243": 152, "37495": 21, "374973249435424": 152, "3751106262207031": 152, "3753472553359138": 152, "375461806191338": 152, "37554": 20, "37595123052597046": 152, "375999981840818": 152, "375m": 103, "3762440251916417": 152, "376811": 31, "37728322446346285": 152, "3776": 25, "377622": [30, 31], "3777039244822744": 152, "377871535718441": 152, "378": 103, "3780543494180079": 152, "378238": 28, "3783985793590546": 152, "3785300427012973": 152, "3785381019115448": 152, "378788": 33, "378911566734314": 152, "37897453": 14, "37927": 16, "37927acc0": 16, "3795117437839508": 152, "379622534248564": 152, "379629": 31, "37u4j5w8": 22, "38": [14, 15, 20, 29, 30, 33, 111, 112, 128, 179], "380": [103, 111, 112], "380187131961186": 152, "380282": 31, "380702": 128, "380952": 33, "381": [103, 111, 112], "38110026717185974": 152, "381295": 33, "381300": 30, "38130316138267517": 152, "38168871533125637": 152, "38170992": 103, "3822804285420312": 152, "382299": [23, 33], "3824710249900818": 152, "3825223781996303": 152, "3826148182153702": 152, "382623314857483": 152, "3826446420616574": 152, "382657": 23, "382716": 31, "3827680640750461": 152, "383": [111, 112], "383234": 33, "383309006690979": 152, "3833363808691502": 152, "3837": 30, "383765": 33, "384": [30, 113], "38405901193618774": 152, "3842": 108, "3842966556549072": 30, "3844850063323975": 152, "38452149331569674": 152, "384615": [31, 33], "3846781253814697": 152, "384912": 34, "385": 14, "3850690140078465": 152, "3852004334330559": 152, "385281375197048": 152, "385310": 19, "38542279601097107": 152, "38552218191325666": 152, "385724": 19, "38578488296932645": 152, "3859741806983947": 152, "3862943611186682": 152, "386536": 25, "386676873022225": 107, "38686257": 103, "386983186006546": 152, "387": [111, 112], "387025356292725": 152, "3875945382648044": 152, "387800": 28, "387810": 19, "387900710105896": 152, "388298433356816": 152, "3885018050670626": 152, "3885394036769867": 152, "3887": 30, "38872024416923523": 152, "38887887398401894": 152, "3888888888567388": 152, "388889": 33, "389381": 33, "3893874883651733": 30, "38939291536808013": 152, "389438509941101": 152, "39": [10, 14, 17, 20, 21, 22, 30, 33, 35, 111, 112, 128, 132, 135, 136, 141, 150, 152], "3900874853134155": 152, "39013231322169306": 152, "39027324233514565": 152, "3904047669635879": 152, "390883": 33, "3908944098485841": 152, "3914314246426026": 152, "391977071762085": 30, "3921151995658874": 152, "3921919425328573": 152, "3922": 105, "3922528200679355": 152, "3923": 105, "39233422146903146": 152, "39261747068829006": 152, "39262569": 14, "3927939838833279": 152, "3928699791431427": 152, "3929948170979816": 152, "3932976722717285": 30, "3934319317340851": 152, "39356791619211434": 152, "39377264669165013": 152, "393870": 19, "394514090485043": 152, "39463675022125244": 152, "394920063018799": 152, "3952705932988061": 152, "39533209800720215": 152, "3953467755295613": 152, "395349": 33, "3954794108867645": 152, "395555": [26, 27, 33], "39561948031187055": 152, "395788433154424": 152, "3958378553390502": 152, "3962100613862276": 152, "39698004722595215": 152, "3970118880271911": 152, "3972": 30, "3972317576408386": 30, "3972695622179243": 152, "397472381591797": 152, "3976234495639801": 152, "39764": 132, "3977": 108, "397855": 30, "397952": 23, "3980284184217453": 152, "3981026129370882": 152, "3981595748000675": 152, "39835565818680657": 152, "398488": 20, "3986912210782369": 152, "3987556591183646": 16, "39895099401474": 152, "3989551968872547": 152, "399": [0, 30], "3991887867450714": 152, "3993108928203584": 152, "3993554711341858": 152, "399375": 25, "3994131624698639": 152, "39it": 23, "3a6e16220649c10b4cd5b3ca2aa3ac50b9e5b24f322be56bbed0737c3feefaaa": 135, "3aj4gdmk": 16, "3aj4gdmksync": 16, "3b": [51, 117], "3b106lwn": 16, "3bpaphe7": 16, "3bpaphe7sync": 16, "3bx0elnp": 17, "3bx0elnpsync": 17, "3d": [0, 3, 8, 120, 148, 150], "3d_studio": 149, "3f340121f0986bf8": 112, "3fyvrvgf": 30, "3gb": 51, "3jgaq9xx": 16, "3jgaq9xxsync": 16, "3kb": 100, "3m": 141, "3mb": 103, "3min": [14, 22, 150], "3q97kspe": 22, "3rd": 129, "3upm5zw": 16, "3upm5zwesync": 16, "3w3bkjug": 16, "3w3bkjugsync": 16, "3x3": [10, 88], "3\uac1c": 14, "3\uacf5": 20, "3\ub2e8\uacc4\ub85c": 19, "3\ubd84\uae30": 21, "3\uc6d4": [19, 141], "3\uc870500\uc5b5\uc6d0\uc73c\ub85c": 21, "3\uc870\uc6d0\ub300\uc5d0": 21, "4": [0, 1, 6, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 51, 53, 59, 79, 83, 86, 87, 97, 98, 100, 101, 108, 111, 112, 113, 114, 115, 116, 117, 122, 132, 133, 135, 136, 139, 141, 143, 145, 149, 150, 151, 152, 161, 174, 175, 176, 180, 181, 184, 186], "40": [14, 15, 16, 17, 19, 20, 21, 22, 29, 35, 79, 103, 111, 112, 139, 151, 152, 167], "400": [9, 26, 27, 111, 112], "4000": [112, 127], "40000": 128, "4000000": 103, "4003549336881114": 152, "4003549336881116": 152, "4005433334244622": 152, "400621": 25, "4009397059679031": 152, "40094903": 152, "400million": [111, 112], "400x": 88, "400\ud638\uc5d4": 15, "4010718471474118": 152, "40120257437229156": 152, "4021126025252872": 152, "4021384835243225": 152, "40265536": 14, "40278589725494385": 152, "403": [111, 112, 152], "4033030778169632": 152, "4035642951726913": 152, "403571": [30, 31], "4036736488342285": 152, "4040002981821695": 152, "4040156900882721": 152, "404229": 149, "4044821739196777": 152, "40465158224105835": 152, "40471704192459584": 152, "4048138054696502": 152, "4048138054696506": 152, "4049933248096043": 152, "4051099667946498": 152, "4051308393478394": 152, "405797": 33, "4058368131518364": 152, "405919623374939": 152, "406": [16, 105], "4061099": 94, "40612800121307374": 152, "406149": 149, "4062464237213135": 152, "40634281262755395": 152, "4064190685749054": 152, "40643646253479854": 152, "40655995971626707": 152, "4067401882674959": 152, "406873881816864": 152, "407": [103, 110, 112], "40712885856628": 152, "40721428394317627": 152, "4073": 103, "407407": 33, "4074074078": 152, "408": 0, "408242": [30, 31], "40851979123221505": 152, "408884": 25, "408889": 31, "4089191257953644": 152, "4092903137207031": 152, "40978858404689367": 152, "4098752948972914": 152, "4098756572162499": 152, "4098756572162503": 152, "40\ubd84": 141, "40\uc8fc\ub144": 15, "41": [14, 15, 19, 20, 111, 112], "410": [111, 112], "4100": 30, "4100873610433413": 152, "41012402772903445": 152, "410384": 23, "41051129": 152, "411": [17, 111, 112], "411004638671875": 152, "4111373096704483": 152, "4112602941691875": 152, "4116775261031257": 152, "41183939278125764": 152, "41185176": 14, "4119377543528875": 152, "4121724492973752": 152, "412215": [31, 33], "4124165214598179": 152, "4125315": 145, "41257696": 103, "4127258360385895": 14, "41280580": 103, "412947": [30, 31], "4129498998324075": 152, "4129695691956162": 152, "41296956919561634": 152, "4129734568297863": 152, "413279": 30, "41351083368062974": 152, "413581609725952": 152, "4138374083571964": 152, "41399666402075025": 152, "414": [23, 25, 103], "414474": 33, "41461974952117087": 152, "41476214": 14, "415": [23, 24, 25, 26, 27, 28, 31, 33], "41501474380493164": 152, "4150846584": 108, "415362": [23, 25, 26, 27], "415459543466568": 152, "41551544395307993": 152, "415961": [23, 25, 26, 27], "4160135120153427": 152, "416100": 112, "4163795210421085": 152, "416620707511902": 152, "4166274363483794": 152, "4172645108567344": 152, "417581510543823": 152, "4178920825322469": 152, "41815333664417265": 152, "41826743086179097": 152, "41831708": 14, "41851362850930957": 152, "418568": 34, "419": 30, "4192": [103, 105], "41927905082701": 152, "4195118091144356": 16, "4195900823409209": 14, "41982099413871765": 152, "419857": [31, 33], "41k": 136, "42": [8, 14, 20, 30, 33, 35, 103, 111, 112, 136], "420": [111, 112], "4202008843421936": 152, "42043137550354004": 152, "42045146226882935": 152, "420680743983702": 152, "420690": 33, "420939": [23, 25, 26, 27], "421": 30, "4212134650598962": 152, "42121727665782804": 152, "4213864803314209": 152, "4214225709438324": 152, "422": [105, 111, 112], "4222222221898273": 152, "42227031141519544": 152, "4223848611116409": 152, "422535": 23, "42268345": 152, "42272013458940716": 152, "423": 103, "4230997562408447": 152, "4232210506374636": 152, "42326092951827576": 152, "423400950431824": 152, "4234406484497918": 152, "4234808087348938": 152, "4235381631689017": 152, "423538163168902": 152, "4236492501364814": 152, "4237": 110, "42373811536365086": 152, "4240686010569334": 152, "424300": 112, "4244162026935911": 152, "4244162026935918": 152, "4248759551503945": 152, "42487595515039467": 152, "425000": 25, "4250685731569926": 152, "425499": 19, "425627151255806": 152, "426230": 28, "426261": 25, "427": [23, 105], "4277962": 152, "428": [0, 14, 103], "428054": 23, "4285337212423949": 152, "428571": [30, 33], "42867404222488403": 152, "4286973774433136": 152, "4288": 105, "4293242484331131": 152, "4296712492948265": 152, "429940": 25, "43": [14, 20, 22, 24, 35, 111, 112, 115, 128, 136, 152, 179], "430223838157124": 152, "430280049641927": 152, "430436897277833": 152, "43046212": 14, "430772896633587": 152, "430983": 30, "431": [24, 111, 112], "431002": 30, "4310186803340912": 152, "4311": 108, "4311494575606452": 152, "431169271469116": 152, "4313059644566642": 152, "43137869": 103, "43142897": 103, "4322194457054138": 152, "43249382376670836": 152, "432632": 24, "43278515": 14, "432800473204122": 152, "43283358": 152, "4329821487267812": 152, "43306236075249366": 152, "4330623607524941": 152, "4331acc0": 16, "433401": [31, 33], "433544445037843": 152, "43378524780273436": 152, "4340397599847348": 152, "4344255328178406": 152, "43455282": 14, "4346828691661358": 152, "43473703985412915": 152, "435": [0, 108, 111, 112], "4352289259433746": 152, "4354722201824188": 152, "4355814456939697": 152, "435728073120117": 152, "435897": 30, "4366700": 145, "437": 14, "43703860640525816": 152, "437147": [26, 27, 33], "4375795140862465": 152, "43763422667980195": 152, "437892961502075": 152, "4379139787207047": 152, "43815643": 152, "4383622705936432": 152, "438971": 128, "439": 14, "4390567261732707": 152, "439142453324124": 152, "4393458787279667": 152, "4393939393939394": 35, "439508193554606": 152, "4396458": 152, "4397713": 145, "4398733735084535": 152, "43987542390823364": 152, "43it": 23, "44": [6, 14, 21, 28, 29, 33, 35, 98, 103, 111, 112, 135, 152], "440": 23, "4402464628219604": 152, "440559": 23, "44068923592567444": 152, "440m": 114, "441048": [31, 33], "44132310152053833": 152, "4414571046829223": 152, "4415394": 145, "44182train_loss0": 16, "44183275227507113": 152, "442": [111, 112], "44212474822998": 152, "442171192169189": 152, "442327070236207": 152, "44272010181254395": 152, "4428694": 145, "44289947897195814": 152, "4432090878486634": 152, "4432110205292702": 152, "44326648849528": 108, "4437849283218385": 152, "4438908696174622": 152, "4439284801483154": 152, "443945384025575": 152, "444": [111, 112], "4440085932612419": 152, "44401636720738": 152, "4440664765834577": 152, "44434": 17, "444409430027008": 152, "444444": [30, 31, 33], "444444444320989": 152, "44444444443950626": 152, "4446329014792689": 16, "4447674": 152, "445079586075412": 152, "4453229010105133": 152, "4454398795410999": 152, "44544156491756437": 152, "44572acc0": 16, "44621886669153665": 152, "446\ub9cc": 14, "4475": 108, "448": [121, 130], "4480247225281728": 152, "448127388954163": 152, "4481358230113983": 152, "448412187894186": 152, "4489587392133696": 152, "44914649901267": 145, "4493477040020368": 152, "4493477040020373": 152, "44940024614334106": 152, "449900817871094": 152, "449915270805356": 152, "45": [14, 15, 20, 24, 30, 33, 35, 107, 111, 112, 119, 120, 122, 136, 152, 174], "4500": 112, "450000374764204": 152, "4500\uc5b5\uc6d0\uc5d0": 20, "4506096941108505": 152, "45086624": 103, "45087203": 103, "4509164703468697": 145, "451": [111, 112], "4511": 103, "451196633776029": 152, "45179317759142984": 152, "4518": 30, "451961803479181": 152, "451961803479182": 152, "452": 30, "45200169": 14, "4520202020110353": 152, "45229148864746094": 152, "452699175145891": 152, "45332501977682116": 152, "4535639047622682": 152, "4536": 103, "453f5bc": [174, 176, 177, 179], "453f5bcf1cfe7616ded061ca2b1cf1e910351824": [174, 175], "454": 103, "45409396290779114": 152, "4542298316955566": 152, "45446985446985444": 35, "45448160244462393": 152, "454545": 33, "45504247943560283": 152, "4551342276028461": 152, "45518324": 152, "455663": 25, "455730713128055": 152, "456012099981308": 152, "4561": 30, "456199": [23, 33], "456348": 23, "45656153485178946": 152, "45673076672987506": 110, "456747": 33, "456k": 100, "457": [111, 112], "457221": 19, "457412910461425": 152, "458333": 33, "458417229904026": 152, "458484387397766": 152, "4585": 108, "45877": 14, "4589559988355822": 16, "459": [111, 112], "4590431611053646": 152, "4592802584171295": 152, "459355": 33, "45938059820069205": 152, "4595166444778442": 152, "45972611324043794": 145, "459748269058764": 152, "459793": 103, "45it": 24, "46": [14, 25, 29, 33, 35, 111, 112, 128, 184], "46030": 103, "460480": 103, "4607523679733276": 152, "460900": 112, "461": 136, "461368560791016": 152, "4615187886617018": 152, "461538": [30, 33], "4615578651428223": 152, "4616": 152, "46163train_loss0": 16, "461669683456421": 152, "46167train_loss0": 16, "462396": 19, "462459": 127, "462811": 127, "4629502296447754": 152, "4631067621441408": 16, "463171": 19, "4632687270641327": 152, "4634987852639622": 152, "463683": 127, "4636900547983257": 14, "46394": 16, "46394acc0": 16, "464567": 33, "46470": 19, "46471": 19, "46475": 19, "46477": 19, "46478": 19, "4648455142974854": 152, "4648907739423103": 152, "4650069460272789": 152, "4650723061795412": 152, "4650723061795419": 152, "465864181518555": 152, "46617349055078294": 152, "466667": 33, "466801": 127, "466k": 114, "467": 152, "46723321235772747": 19, "46726287": 103, "46726298": 103, "4674039426777098": 152, "46882564": 152, "4688612878322601": 152, "468966903707212": 152, "4691283585240593": 14, "469300": 34, "46934685": 152, "46940648555755615": 152, "46946394741535186": 152, "4699": 103, "46mb": 104, "46\uc870\uc6d0\ub300\ub85c": 19, "47": [14, 15, 16, 19, 30, 31, 35, 51, 112, 114, 128, 136], "47000362923358285": 152, "4702285533016523": 16, "4705633774399757": 152, "47071945667266846": 152, "470860": 25, "4709807678063713": 152, "471": 0, "47115384615384615": 29, "471545": 33, "471698": 30, "4717846617102623": 152, "47215969661434976": 35, "472329": [23, 25, 26, 27], "47249train_loss0": 16, "472539": 25, "472998": 19, "473": 112, "4734817637337579": 152, "4736030129460684": 152, "47376230359077454": 152, "47384417057037354": 14, "474": 14, "4742779970169066": 152, "474656": [23, 26, 27, 33], "474820": 33, "47492": 14, "475418": 25, "47543461829176115": 14, "47551360925038655": 152, "47579583078622817": 152, "475884": 25, "4760036665014923": 152, "47610455825924874": 152, "476190": 30, "476552414894104": 152, "476596": 33, "476814": [26, 27, 33], "4770257814062966": 152, "4770597591996193": 152, "4770723730325699": 152, "477493": [31, 33], "47778acc0": 17, "4778187870979309": 152, "4781847609413994": 152, "47851452": 152, "4785268584887186": 152, "47856080532073975": 152, "479": 14, "4790469151291808": 22, "479205131530762": 152, "4793075716122985": 152, "4798": 24, "47998train_loss0": 16, "4799913730886247": 152, "48": [14, 20, 21, 22, 23, 33, 35, 101, 107, 110, 111, 112, 136, 152], "4801769256591797": 152, "48035172671079635": 152, "4804173162407261": 152, "4804653570495008": 152, "480899": 34, "4816522326806949": 145, "481953": 33, "48196596": 103, "48196650": 103, "4820239801682076": 152, "48242614923472477": 152, "4825298238545656": 152, "48266232311725615": 152, "48268745514815": 155, "482846216572118": 152, "4828462165721186": 152, "4828745499253273": 152, "483": 152, "4832791": 152, "4833": 108, "4837201237678528": 152, "4837617874145508": 152, "4839033007621765": 152, "484": [14, 16, 53], "4841044306755067": 152, "4842275597155094": 152, "4843333332497222": 152, "48480454087257385": 152, "484906649778778": 152, "485": 14, "48553305864334106": 152, "48568335771560667": 152, "486": 152, "4864306248476107": 152, "4865640806034207": 152, "48694471889678254": 152, "4869715571403503": 152, "48717684911357034": 152, "487200": 112, "48731302552753025": 152, "4875531804415069": 152, "4876408100128176": 152, "4878202319145202": 152, "48795462530517447": 152, "488": 14, "4880732536315917": 152, "488254": 127, "4883527679034347": 152, "48875993937253953": 152, "489": [30, 31, 32, 53], "489119": 30, "48919835686683655": 152, "489818": 28, "4899999999999998": 132, "48t": 20, "49": [14, 15, 16, 28, 33, 94, 103, 128, 152], "49076725275249233": 22, "4909617304801941": 152, "491": 105, "4910168096423149": 152, "49140mib": 112, "4914559665787048": 152, "4914559665787055": 152, "4916548767501645": 152, "4917181432247162": 152, "4918918490409851": 152, "492": 14, "493": 21, "493088": 28, "49328284449875354": 152, "4937671720981598": 152, "494": 111, "4945665955543518": 152, "4947402609719171": 152, "4950372223947054": 14, "4954831686284807": 152, "4955023588736858": 152, "495761942863464": 152, "49591032415628433": 152, "496": [111, 112], "49621543": 103, "49621655": 103, "496300": 112, "496824312210083": 152, "497": 120, "4971213": 145, "49714879393577577": 152, "497177": [23, 25, 26, 27], "49732834100723267": 152, "497915780544281": 152, "4982015788555145": 152, "4987923622131347": 152, "499": 184, "499377": [23, 25, 26, 27], "49960836470127107": 152, "4996921420097351": 152, "4998456843197346": 152, "49999310076236725": 152, "49it": 24, "49m": [132, 135, 136, 141, 150], "49m23": [132, 135, 136, 141, 150], "49mnotic": [132, 135, 136, 141, 150], "49mpip": [132, 135, 136, 141, 150], "49\ubd84\uacbd\uc5d0": 141, "4b4edc1": 180, "4b4edc115e87629b853fc5084931350348909663": 180, "4f": 110, "4fa39c8": [176, 177, 179, 180], "4fb2ed8": [180, 181], "4gb": 51, "4m": 141, "4min": 22, "4th": [111, 112, 128, 129], "4x": [9, 117], "4\uc2dc": 20, "4\uc6d4\uae4c\uc9c0": 19, "4\ucc28": 14, "5": [0, 1, 9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 47, 79, 83, 94, 97, 98, 100, 101, 104, 105, 106, 108, 111, 112, 114, 117, 122, 124, 128, 132, 133, 136, 139, 141, 142, 145, 149, 150, 152, 155, 161, 174, 175, 177, 180, 181, 182, 184, 186], "50": [6, 9, 14, 15, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 37, 87, 88, 94, 97, 100, 103, 105, 108, 111, 112, 115, 120, 126, 128, 136, 142, 150, 152, 180, 184], "500": [3, 100, 110, 112, 136, 167, 184], "5000": [112, 127, 136], "50000": [103, 128], "500000": 25, "5000000": 103, "500013296804193": 152, "5002365076418617": 152, "5003574252128602": 152, "5005275414844204": 152, "500527541484421": 152, "50078015327453": 152, "5008124589920044": 152, "5009278669953346": 152, "500km": 141, "500\uc5b5\uc6d0\uc5d0": 20, "500\ud638": 15, "5010495139285922": 152, "501081607511474": 152, "5011142507195473": 152, "502": [111, 112], "50212365": 95, "502124309539795": 152, "50256": 100, "50257": 111, "5026": 103, "5026300244861179": 152, "50299999993": 152, "5030347108840942": 152, "503096": 31, "5032047": 152, "5036019414663313": 152, "504": 107, "5040773967745518": 152, "5042677521705627": 152, "5044889359683212": 152, "504613733026627": 152, "5049610137939453": 152, "5055979818105698": 152, "5057655387454565": 152, "5058705645390194": 152, "506": 24, "5060144066810608": 152, "506538450345397": 152, "5066773494084676": 14, "506885": [31, 33], "507": 105, "507101": 25, "507366928259525": 152, "5079365079314689": 152, "5083285570144653": 152, "508752492070198": 152, "5088331699371338": 152, "5088414877653122": 152, "5090053081512451": 152, "509185202916463": 152, "5096372005012301": 152, "5096396565437318": 152, "509806": [30, 31], "509990119934082": 152, "50it": 23, "50\uc5ec": 141, "51": [14, 15, 16, 21, 22, 28, 30, 33, 35, 128, 136], "510": [111, 112], "5102350264787674": 152, "510292598605156": 152, "51032940": 103, "51033150": 103, "5105727970600128": 152, "5107786150136963": 152, "5108256237575629": 152, "510870265960694": 152, "5109133243560791": 152, "5109996477762858": 152, "511": [0, 29, 112], "5117599874734878": 152, "512": [8, 9, 14, 16, 17, 19, 21, 30, 51, 110, 112, 114, 115], "5121": 17, "5122612968087197": 152, "5123818334583414": 22, "51238train_loss0": 22, "5128358319401741": 152, "513354111031174": 152, "5134019255638123": 152, "513688063621521": 152, "5139": 152, "514085": 33, "51426acc0": 16, "5144984575880421": 145, "5146351165241665": 152, "5148299932479858": 152, "514854": 21, "5148541733920216": 21, "515099125438266": 152, "5151218771934509": 152, "5151515151132535": 152, "5152": [0, 6], "5154653616249562": 152, "5159353629304713": 152, "5159353629304715": 152, "5160080606117845": 152, "5161": [0, 6], "5162451863288879": 152, "51649958": 14, "5168040946125985": 152, "5169796407222748": 152, "51699698": 14, "5173569798469544": 152, "517410898208619": 152, "5177711397409439": 152, "518": [14, 111, 112], "5182306855916977": 152, "518519": 31, "5187976956367493": 152, "5193201501853764": 152, "519595": 28, "519921213326355": 152, "51aafd": 21, "51it": 30, "51z": 94, "52": [14, 20, 22, 28, 30, 33, 103, 135, 136], "520": [111, 112], "5203056308598093e": 152, "5204781480063937": 145, "5205207884311676": 152, "520790159702301": 152, "5211324095726013": 152, "5211626291275024": 152, "521296923625839": 152, "521429": [30, 31, 32], "5216344833374": 152, "522": 21, "522379159927368": 152, "522638": 34, "5229": 30, "522965590300311": 152, "523": 16, "5232": 105, "5234188318252564": 152, "52346754": 14, "5237525105476379": 152, "5238095237835223": 152, "523898": 25, "5243439616039047": 152, "524343961603905": 152, "5244248604016497": 152, "5245177417993545": 152, "52461838722229": 152, "52469102": 103, "52470264": 103, "5248393416404724": 152, "525": [111, 112, 152], "5250355693505371": 145, "525151567988925": 152, "5251638889312744": 152, "5256941318511963": 152, "525729": 34, "5260767102241516": 152, "5262686189508873": 152, "5262686189508876": 152, "5264039039611816": 152, "5266369490971852": 152, "5266369490971856": 152, "526721": 152, "5269137233495712": 152, "527": 14, "5272161457273695": 152, "527260013181598": 152, "5273105978965758": 152, "527514": 34, "5275579690933228": 152, "5277079284191132": 152, "5280389": 152, "5281": 0, "5283": 105, "528441429138184": 152, "528532": [23, 25, 26, 27], "5289": 14, "529": [53, 152], "529236": [31, 33], "5295765637523598": 152, "5297322273254395": 152, "529771": 16, "52gb": 51, "53": [14, 22, 24, 28, 30, 33, 103, 108, 111, 112, 174], "530": [93, 112], "5302295088768005": 152, "530694967508316": 152, "5307975": 152, "53091334684587": 152, "5311867952346803": 152, "531340": [31, 33], "531536": 128, "5316045413682643": 152, "5319959935158121": 152, "5321281790733337": 152, "5323186298211415": 152, "53267826826777": 108, "5326852523605549": 152, "532685252360555": 152, "533": 17, "5334630190756529": 152, "5334633": 145, "533753": 34, "5338767528533935": 152, "533890": 33, "53430": 135, "5347955226898193": 152, "535612565287408": 152, "536": 105, "5360476672649384": 152, "5361560556566348": 135, "536394": 95, "5364161756303575": 152, "536606056036479": 152, "5367234945297241": 152, "5368331864793847": 152, "536893": 16, "5369794368743896": 152, "537": 103, "5373274594545364": 152, "5375698208808899": 14, "5379707217216492": 152, "538": 30, "5381382368505001": 152, "5382207289094766": 152, "538284": 34, "5383680820465088": 152, "538462": [30, 31, 33], "53867435": 14, "539": 107, "5391488671302795": 152, "5391562134027481": 152, "5393182039260864": 152, "5394160777330399": 152, "539497": [30, 31, 32], "53971634": 103, "53972222": 103, "5399529510350565": 152, "54": [14, 20, 21, 28, 33, 94, 103, 107, 111, 112, 135, 174], "540": 93, "5402519106864929": 152, "5405859769669961": 152, "54073486328125": 152, "540b": 98, "541044": 16, "541075611114502": 152, "541123934836883": 152, "5415724128422639": 152, "541761589050293": 152, "5419433057308197": 152, "5420901507139206": 152, "5421510398387909": 152, "542485": 16, "542485316149969": 16, "542900": 112, "543": [111, 112, 145], "5434947": 152, "5435505": 152, "5438662767410278": 152, "544": 14, "5440375487491753": 152, "5441355347633362": 152, "545": 20, "5451": 105, "5454545454545454": 35, "545455": 33, "5455716252326965": 152, "545708": 128, "5459191679954529": 152, "5463879113428052": 152, "5463879113428056": 152, "5469": 105, "5469532": 152, "547": 105, "547535": [25, 28], "547619": [30, 31], "548": 103, "548355": [31, 33], "548855": 25, "548975944519043": 152, "5497331604361534": 152, "54fa40f": [177, 179, 180], "54it": 23, "54th": 0, "55": [14, 21, 22, 94, 107, 111, 112, 135, 152, 184], "5500": 112, "5503150254487992": 152, "5509150475263596": 152, "551013136": 103, "5512014642357826": 152, "5514543205499649": 152, "551981115341187": 152, "552": 19, "5522102773189544": 152, "5522374004125595": 152, "5524925": [177, 179, 180], "5525827613141802": 152, "5532432510658585": 152, "5533533722162247": 152, "55349142": 103, "55349925": 103, "5537001609802246": 152, "553kb": 100, "5543202757835388": 152, "5553434246116215": 152, "555367": 16, "555486556628476": 22, "55549global_step546lr0": 22, "5555555554864204": 152, "5555555555382716": 152, "5555555555452675": 152, "555556": [30, 31], "555858987569809": 152, "556": [30, 31, 32], "55624": 17, "5564370689820499": 152, "556589663028717": 152, "557": 105, "557279497385025": 152, "5574072420597076": 152, "557561": 14, "5576": 103, "5579301101135489": 152, "558": [103, 105], "5580196784602272": 152, "5581017136573792": 152, "5583333332497221": 152, "558351": 33, "558923": 14, "558927": 19, "5589282512664795": 152, "559": 103, "5593037558926477": 152, "5595276564359665": 152, "559653": 33, "5597643057419147": 152, "559828281402588": 152, "559892": 21, "5599215030670166": 152, "5599398672580719": 152, "55eval_loss0": 16, "55k": 136, "56": [0, 14, 20, 21, 22, 24, 28, 119, 135, 136, 140, 152], "560198": 33, "560365": 24, "5603938579559327": 152, "560866": 128, "5612490766722223": 22, "561801": 25, "562": 14, "562641906738282": 152, "5631718": 22, "5632155805826187": 152, "564": 152, "5640980223814647": 152, "564110": [31, 33], "5642764568328857": 152, "5644107758998871": 152, "56441368063523": 152, "5645034700632096": 152, "5646324700779385": 152, "5649130344390869": 152, "565": [111, 112], "565062618255617": 152, "5658087696202627": 152, "566": 152, "5661": 103, "5664587616920471": 152, "5668640611007268": 152, "5672577619552612": 152, "567363": 25, "5674934085458517": 152, "5676436835382548": 152, "5677988529205322": 152, "5678": 33, "5680274128913879": 152, "568219244480133": 152, "5683780044317246": 152, "568400": 112, "568863": 23, "5692125529050827": 152, "56gb": 51, "57": [0, 14, 16, 22, 26, 27, 28, 33, 100, 136], "570": 114, "570048": 33, "570948": [23, 25, 26, 27, 33], "571": [14, 152], "5710591435432434": 152, "5710992306470871": 152, "571429": [31, 33], "5716313332319259": 152, "57164252": 14, "571946": 23, "5719722": 152, "5720635890960692": 152, "572295": [28, 33], "5725445315241814": 152, "5730520486831665": 152, "5734125177065531": 14, "57356196641922": 152, "5736709266901017": 152, "573951": 23, "5744902908802032": 152, "574614330098895": 152, "574704": 24, "57484370470047": 152, "574969": 14, "575033": 14, "575039": 14, "57536414488468": 152, "5755005634088165": 152, "576": 20, "57634037733078": 152, "5763556361198425": 152, "5766310691833496": 152, "5768337538468736e": 152, "5768337677246613e": 152, "5769483402371407": 152, "5770901381969452": 152, "577428936958313": 152, "577716016769409": 152, "5777320265769958": 152, "577781380712986": 152, "577867": 25, "5779075": 14, "577968": 25, "5779788494110107": 152, "578": [111, 112], "5785669237375259": 152, "578618": 34, "5786906272172928": 152, "578860592842102": 152, "5791655408011542": 152, "579313": 25, "5795": 105, "5796": 16, "579674": [31, 33], "5796759605407715": 152, "57it": 94, "57\ubd84\uacbd\uc5d0\ub294": 141, "58": [23, 25, 26, 27, 33, 53, 111, 112], "580046021938324": 152, "5803": 14, "5804461449384689": 152, "580488": 16, "5806098580360413": 152, "5806891532275694": 152, "580752494931221": 152, "581": 20, "58103942871094": 152, "5812047616908983": 152, "58121748691968": 152, "5813835948705673": 152, "58142": 30, "5815661487686965": 152, "5820300175084008": 152, "5820991456508636": 152, "582206": [31, 33], "5826810441083398": 152, "583": 14, "5830207": 152, "583333": 33, "5835189384228876": 152, "5842362410492368": 152, "58426094": 152, "5844497149251596": 152, "5844844531181247": 22, "5845632533232371": 152, "58469": 19, "58470": 19, "5849519714713096": 152, "58601504691836": 152, "5870785329076978": 152, "58709": 24, "587413": [30, 31, 32], "5877866648873042": 152, "5877866649030966": 152, "5881895881895881": 35, "588553": 20, "5886256409357892": 152, "5889425377361477": 152, "589": [111, 112], "589239579596395": 152, "5893126898341708": 152, "5894590816212744": 152, "589626": 152, "59": [14, 21, 22, 28, 30, 33, 35, 111, 112, 120, 128, 145], "590": [17, 105], "590156": 128, "590201": 30, "5902392476797104": 152, "5904256105422974": 152, "5904481410980225": 152, "5904821053147316": 152, "591": [23, 103], "591088530421257": 152, "5913944244384766": 152, "591490375995636": 152, "5916098952293396": 152, "5916839916839918": 35, "59204630851745": 152, "5926": 105, "5926167368888855": 152, "593": 120, "593023756146431": 152, "5931995581448133": 145, "5933": [0, 6], "593594": 149, "5936046262814404": 152, "594": [111, 112], "5940357313858171": 35, "5940763026475906": 152, "5942": [0, 6], "59450996": 152, "594681": 33, "594924": [23, 25, 26, 27], "5951818227767944": 152, "595236301422119": 152, "596": 105, "5964958867020723": 35, "596500": 112, "5969623416662216": 152, "597": 103, "5970727115869522": 152, "5971336365555293": 152, "5972": 103, "5972039008306133": 152, "5980050881703696": 152, "59833586": 14, "599": 17, "5997474747474748": 35, "5997911095619202": 152, "5999829795625473": 152, "5999999999795558": 152, "5b": [9, 51], "5billion": [111, 112], "5d99c3aa2cd1b79db65583bd456136cd9fbbcc4": 184, "5g": 14, "5gb": 51, "5th": [23, 111, 112], "5x": [88, 115], "5\ub144\uac04": 19, "5\uc5b8": 140, "5\uc6d4": 15, "5\uc6d4\uc5d4": [14, 15, 16], "6": [0, 1, 6, 9, 14, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 51, 85, 88, 94, 97, 101, 103, 104, 106, 108, 111, 112, 114, 117, 127, 128, 132, 135, 136, 139, 145, 149, 150, 152, 161, 184, 185, 186], "60": [16, 20, 22, 25, 26, 27, 28, 29, 33, 35, 47, 70, 94, 96, 111, 112, 117, 128, 129, 135, 151, 152, 161], "600": [80, 111, 112, 115], "6000": 112, "60000": 128, "6000000": 103, "60023": 108, "6002833247184753": 152, "6004": 16, "6004041439294816": 152, "6005045566293928": 152, "60077": 152, "6009999999": 152, "600million": [111, 112], "600\ud638": 15, "600\ud638\ub97c": 15, "600\ud638\uc5d0": 15, "6010507076978684": 152, "6011057376861573": 152, "601244": 16, "601322603225707": 152, "6013480097055435": 152, "6014356017112732": 152, "6014894707978905": 152, "6015325670498084": 35, "601659": 33, "601905071735382": 152, "601953": 34, "6024388074874878": 152, "602978": 33, "6035295695066452": 152, "6037357442080975": 152, "604": 152, "604038265559883": 152, "60404": 152, "6040872625385721": 152, "6044882446527481": 152, "6045406103134154": 152, "6046907782554627": 152, "6047012209892273": 152, "6048533856868744": 152, "6051172554492951": 152, "6054804116487503": 152, "6056559213265249": 145, "6060932964086533": 152, "607": [103, 105], "6070075160927243": 152, "60709da": 183, "6076949115341027": 152, "6079433553160218": 152, "607943355316022": 152, "6079999999150001": 152, "608": 103, "6087498277425766": 152, "609": 152, "609109103679657": 152, "609438": 34, "6096499741077424": 152, "60it": [20, 23], "61": [19, 22, 25, 28, 29, 30, 33, 135, 152], "610": 107, "6100264191627502": 152, "6103616148233414": 152, "6107279777526857": 152, "61077201": 14, "6109052265588026": 35, "611": 14, "611111": 30, "61125920481152": 152, "6113076812691158": 152, "6113331038327985": 152, "6116340756416321": 152, "6116812": 152, "611814": 33, "611842": 33, "6118693023920059": 152, "612057495117187": 152, "612063941028383": 152, "61211": 24, "61222103497842": 152, "6122414320707321": 152, "6123547405004501": 152, "6135365962982178": 152, "6136944791990455": 152, "61374": 103, "613909": 34, "613999999915": 152, "6142416": 14, "6143026351928711": 152, "6145224": 152, "615": 152, "6151176895973893": 35, "6152072912602486": 152, "615207291260249": 152, "615226": 25, "615385": [26, 27, 31, 33], "615502": 28, "6157705187797546": 152, "6158387660980225": 152, "615917": 30, "6159706115722656": 152, "615\ub9cc": 14, "616": [6, 14], "6160316441204637": 145, "6161861394167182": 152, "616191": 33, "6163566360309041": 152, "6163956195116043": 152, "6165847301483156": 152, "616803": 25, "616857": 25, "6169759377837181": 152, "617": 107, "617283950607758": 152, "617461": 128, "6175571918487549": 152, "6177343167893081": 152, "6178307306435373": 152, "6179495543241501": 152, "617981": 34, "6180178427067431": 16, "618018": 16, "618385820918613": 152, "6185740262269974": 152, "6187533557415008": 152, "618890": 149, "6189156651496888": 152, "619035180409749": 152, "6192097634077072": 152, "619234496642365": 152, "6193571090698242": 152, "6194979637861252": 152, "62": [14, 16, 28, 29, 35, 51, 111, 112, 135, 136, 184], "6202": 16, "6207689881324768": 152, "6211654329045517": 152, "6211654329045535": 152, "6211802777111816": 135, "6212121212121212": 35, "6213171839714051": 152, "6215577125549316": 152, "621722": [31, 33], "621732091903686": 152, "6218": 14, "62188": 152, "6219": 14, "6219531387090683": 152, "622": 14, "62214136": 22, "6222955": 152, "622478": 28, "6226463794708252": 152, "622821": 28, "623": [103, 152], "6232512129677668": 152, "62350": 14, "6235321164131165": 152, "623534759879209e": 108, "6239841527409024": 152, "6241": 108, "624865765838529": 145, "625000": [31, 33], "6251657009124756": 152, "6251761059453366": 29, "625310": 28, "625587": 152, "625640649927987": 152, "6261020600795746": 152, "626347541809082": 128, "6266018450260162": 152, "627": 14, "62717399597168": 152, "6278219133615494": 152, "6282": 103, "628229808807372": 152, "628378": 33, "6288093000650405": 152, "629": 107, "629476198554039": 152, "6296296296115227": 152, "62it": 101, "63": [9, 14, 22, 28, 29, 119, 135, 145, 152], "6300692686554132": 152, "6300975859165192": 152, "630240973830223": 152, "6302479207515717": 152, "6306056916713715": 152, "6306196133295695": 152, "6306696415194301": 14, "631": [14, 103], "631021115928547": 152, "6310879856348037": 152, "6312766671180725": 152, "6316824167966842": 152, "6318665146827698": 152, "6319933338297739": 152, "632": [9, 14], "6320065855979919": 152, "6320095574554566": 152, "63207": 28, "63225589900849": 152, "6327709509266746": 152, "633": 103, "63322": 105, "633373832702638": 152, "6333910822868347": 152, "6335693955421448": 152, "6338666": 152, "634": [111, 112], "634419396519661": 152, "6346445910731934": 152, "6346445910731939": 152, "634724": 152, "6348272562026978": 14, "6348734751343728": 152, "635": 135, "635204005241394": 152, "635240": 34, "63527436653773": 152, "635549034012687": 152, "6356056213378907": 152, "635912299156189": 152, "636": [111, 112, 135], "6362178372900401": 152, "6363498419523239": 152, "636364": 33, "636558": 23, "6368729309905782": 35, "637": [111, 112], "6370809895484615": 152, "6371696591377258": 152, "6371875941753388": 152, "637304": [23, 25, 26, 27], "6374659019661213": 16, "637466": 16, "6375426169484854": 152, "6379999999500001": 152, "6380366259151035": 152, "638435": 28, "6384710669517517": 152, "638696": 19, "6396074990431467": 152, "639968752861023": 152, "63g": 100, "63mb": 136, "64": [0, 8, 14, 16, 22, 35, 53, 101, 110, 111, 112, 117, 135], "640": [19, 20], "6401087": 22, "640138": 33, "6404455900192261": 152, "6405402686860826": 152, "640747": 33, "6407616078853607": 152, "6410084575414657": 152, "6410277843475343": 152, "6410729912131234": 152, "6410962343215942": 152, "6412571244580745": 152, "6414405763149261": 152, "642276": 33, "642412": 25, "6424735730344598": 14, "643": 14, "643159": 23, "643411": 28, "643467": 25, "643486": 14, "643487": 14, "643488": 14, "643489": 14, "643490": 14, "6434971481561661": 152, "6437": 108, "643700": 112, "644": 20, "644089": 14, "6441273166075167": 132, "6444204216480794": 152, "64492": 105, "645867": 111, "646": [111, 112], "646188926696777": 152, "6467330462218057": 145, "647": [111, 112], "6470509966214498": 152, "647059": [30, 33], "6470937132835388": 152, "64711train_loss0": 16, "6472298730578687": 152, "6475066512823104": 152, "6483241111040116": 152, "6483639587055553": 14, "6484619776407877": 152, "648607": 14, "6486195921897888": 152, "6490831957923042": 152, "64b": 98, "64gb": 51, "64it": 23, "64x64": [9, 10, 88], "65": [14, 22, 29, 35, 53, 101, 111, 112, 132, 135, 141, 152], "650": [9, 111, 112], "6500": 112, "65007954279483": 35, "6501025140285492": 152, "650206": 33, "6503": 112, "6503607503607504": 35, "6503789352872539": 152, "6504347576035394": 152, "6506289839744568": 152, "65080326795578": 152, "650808334350586": 152, "6511220229996575": 152, "651163": 33, "6511701941490173": 152, "6512066079510583": 152, "6514": [30, 31, 32], "6514423076923077": 29, "6515151515151515": 35, "6516749501228333": 152, "6519516706466675": 152, "65217": 22, "6522184759378433": 152, "6524575412273407": 152, "65272802": 14, "6528063505887985": 152, "653300": 112, "6533805131912231": 152, "653463": [24, 30], "653464": [24, 30], "653465": [24, 30], "653466": [24, 30], "653467": [24, 30], "653468": 30, "653502": 24, "6535684954036366": 14, "6538003087043762": 152, "654": 30, "654203474521637": 152, "6542543949045063": 152, "6549134254455566": 152, "6549388404418197": 152, "6549664517243703": 152, "655029296875": 152, "655548": 14, "6560884118080139": 14, "6563803288671706": 152, "656716": 30, "656886": 16, "6570854714462421": 135, "6575677396177281": 21, "657568": 21, "657814": 25, "6580655585685583": 135, "658124": 25, "658565005660057": 152, "658637": 14, "6594241172075271": 152, "6596688153346381": 152, "65b": 83, "65billion": [111, 112], "65it": 24, "65mb": 114, "66": [0, 14, 16, 22, 35, 51, 101, 111, 112, 135, 136], "6600303232669831": 152, "6600911617279053": 152, "66027516": 152, "6602881044149399": 152, "6603913962841034": 152, "6604177474975585": 152, "6609686613082886": 14, "661336047859807": 152, "661544": 25, "661764144897461": 152, "661946": 34, "6619628310203552": 152, "662069": 33, "662247": 95, "662407511472702": 152, "6626d56": [174, 176, 177, 179], "6626d56233bdf14ea2f9741588523c2a6d5c483d": [174, 175], "662704": 28, "66277": 105, "6632340461015701": 152, "6634315013885498": 152, "66354718208313": 152, "6637576699256897": 152, "6637577414512634": 152, "664": 135, "664210915565491": 152, "6643118752373589": 152, "6644162535667419": 152, "664599246033868": 152, "6648780703544617": 152, "665": [111, 112], "665009011942105": 155, "665362": [23, 25, 26, 27], "6657542082998488": 152, "6657921642065048": 152, "6658364466583645": 16, "6659291565418244": 152, "665962": 25, "6659841272566054": 152, "6660489351224613": 152, "666050275001261": 152, "6661734580993652": 152, "6663359231022626": 152, "6666666666516203": 152, "6666666666666666": 16, "666667": [33, 149], "666896": 28, "6669036716222765": 152, "667129993438721": 152, "6675231665372848": 152, "6675720485773954": 14, "6676555216312409": 152, "667660": 23, "667920": [30, 31, 32], "668": 16, "668090": 14, "668761": 14, "668762": 14, "668763": 14, "668764": 14, "668765": 14, "668766": 14, "668767": 14, "668768": 14, "668769": 14, "668770": 14, "6689490675926208": 152, "669206157186698": 152, "6696984320878983": 152, "67": [0, 14, 16, 22, 30, 35, 101, 111, 112], "670": 16, "6701412068472968": 152, "6701883879830325": 152, "6710249781608582": 152, "67116572068": 107, "671351": 23, "6719021423435378": 152, "672": [29, 51], "672131": 33, "6724554291746573": 14, "6727087252669864": 152, "672840": 31, "672965435185822": 35, "673": [14, 107], "673107": 25, "673938": [23, 26, 27, 33], "6741435077455309": 152, "6741549015045166": 152, "6748478": 152, "674951": 34, "674959808588028": 152, "6749999999": 152, "6749999999074999": 152, "675": [30, 31, 107, 152], "67537acc0": 17, "675995961825053": 152, "6764449241372277": 145, "6765992105007171": 152, "6766": 103, "6767237674030993": 152, "6767676767676769": 16, "676806": 33, "6769340634346008": 152, "677083": 33, "6772064924240112": 152, "677306281195746": 152, "677398823599758": 152, "6775986671447753": 152, "67766global_step549lr0": 16, "6779175245241125": 152, "6779964208602904": 152, "678051": 25, "6783880680137142": 135, "6788614100880093": 152, "67927313": 14, "6793989837169647": 152, "6796886920928955": 152, "679706026453727": 35, "67th": [111, 112], "68": [14, 16, 22, 29, 30, 100, 111, 112, 135, 136, 152], "680": 22, "680045485496521": 152, "680219697952271": 152, "680398739212089": 152, "6804": [23, 25], "6805806457996368": 152, "6806197047233582": 152, "68063global_step549lr0": 16, "680778": [23, 25, 26, 27, 33], "682016827000512": 152, "6820690483526008": 152, "6825235188007355": 152, "6826499429616061": 14, "6826923076923077": 29, "6830": 23, "6833051443099976": 152, "6842105263022469": 152, "6846902370452881": 152, "685": [105, 111, 112], "685006892681122": 152, "6851790109009271": 152, "6858244955539703": 152, "6858331813414893": 152, "686": [103, 152], "6861237555742263": 152, "6868418": 0, "687408": 23, "687473406288814": 152, "6875664088461134": 152, "6876316348711649": 152, "687737911939621": 152, "68788004": 14, "688141": [23, 25, 26, 27], "689": [111, 112], "68913eval_loss0": 16, "6893860750728183": 152, "6893939393939394": 35, "689394": 33, "6894": 30, "6894622564315795": 152, "6895470358751884": 14, "689755380153656": 152, "68978acc0": 22, "69": [14, 29, 35, 105, 135], "690": [103, 107, 111, 112], "6900": [17, 19], "690210": [23, 25, 26, 27], "6904528617858887": 152, "6908267736434937": 152, "6908912089135911": 152, "690992": 23, "691": [16, 17], "6918159127235413": 152, "6918225136640888": 145, "691886854171752": 152, "692": 152, "692289924621582": 152, "692308": [30, 33], "6925550699234009": 152, "692587971687317": 30, "693141": 23, "693147180560723": 152, "6933852344751358": 152, "6937022149562836": 152, "69395eval_loss0": 16, "694": 22, "6944896761916455": 14, "694544792175293": 152, "694598": 14, "694599": 14, "694600486755371": 152, "6948964387178421": 152, "6950854659080505": 152, "6951278984546662": 152, "6953143775463104": 152, "695652": [26, 27, 33], "695952582359315": 152, "696": 22, "6960519154866537": 152, "6964739632869893": 22, "6965884747288964": 152, "6966831141048008": 152, "696977050953278": 152, "697": [22, 105], "697141504287719": 152, "6973669797182083": 152, "6974779167686911": 152, "6979990694257948": 152, "698": 103, "69807eval_loss0": 16, "6984683573246002": 152, "69876eval_loss0": 16, "699376": 25, "699400": 112, "6996152639389037": 152, "6997313087533348": 145, "6997373965051439": 152, "6999426712671027e": 112, "699993": 23, "69c99c1f20b21cfc214b07dc630afcc52a23a3a4": 184, "6a4834d": 183, "6billion": [111, 112], "6f": [127, 128, 135], "6m": 6, "6mb": 105, "6min": 14, "6th": 9, "6\uc6d4": 15, "7": [1, 10, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 43, 45, 51, 53, 69, 97, 98, 100, 101, 103, 104, 105, 108, 110, 111, 112, 113, 120, 128, 132, 136, 141, 145, 149, 150, 152, 161, 184, 186], "70": [14, 19, 22, 29, 52, 95, 103, 111, 112, 119, 145, 152], "700": [9, 80, 111, 112], "7000": 112, "70000": 128, "7000000": 103, "7002859115600586": 152, "7004050612449646": 152, "7013998627662659": 152, "70146global_step546lr0": 16, "7015290180842082": 152, "7015772461891174": 152, "701703": 25, "702": 152, "7020963006549411": 152, "702137": 149, "7021779139836629": 152, "7029999999000001": 152, "703": 152, "703344": 128, "7033872485160828": 152, "7034077525138855": 152, "703704": [28, 33], "703916822627378": 152, "704": 110, "7043274402618408": 152, "7045339941978455": 152, "7045623505630207": 152, "704906948407491": 152, "70495eval_loss0": 16, "7050536228550806": 152, "7053548276424408": 152, "7054342985153198": 152, "705539": 23, "70578fn11fp16global_step48mcc0": 16, "705882": [31, 33], "706": 107, "7062499708599514": 152, "706383": 33, "706422758102417": 152, "706954562664032": 152, "7070525884628296": 152, "707182431221009": 152, "7075881520907084": 152, "707927669262908": 152, "7079999999": 152, "7082306557231479": 152, "70836926": 14, "7084757924079895": 152, "7087128102779389": 152, "708752137868833": 152, "7090": 110, "7090898901224136": 152, "7094447016716003": 152, "709791": 34, "70b": 98, "71": [14, 22, 35, 95, 111, 112, 135, 136], "7100220680236816": 152, "7107454538345337": 152, "710816662841373": 152, "711029": 25, "7111220359802246": 152, "7112665004200405": 152, "711332082748413": 152, "7114471904726491": 152, "71160579": 22, "7119239542219374": 152, "712": 16, "7121212121212122": 35, "712603521347046": 152, "7127739984882842": 14, "71288acc0": 22, "71346global_step610lr0": 16, "713495": 34, "7135660039054023": 152, "7139965176582337": 152, "7139999999": 152, "714": 152, "7141295931091425": 152, "7141295931091431": 152, "714368814892239": 152, "7145481109619141": 152, "714690089225769": 152, "715696952078077": 152, "715895": 145, "716": 128, "7161286473274231": 152, "7162305646472507": 152, "71639": 17, "7167915105819702": 152, "7169607857863108": 152, "7170875298093867": 152, "717370119690895": 152, "7174402475357056": 152, "717613": 21, "7176932009588028": 152, "7178064083191105": 152, "7182757245169745": 152, "7183065354824066": 152, "718453": 14, "71868": 105, "719": [111, 112], "719424": 33, "7194733553462558": 152, "7199262201786041": 152, "72": [14, 22, 35, 111, 112, 135], "7202261": 180, "720238": 30, "7202866797702516": 152, "7204073071479797": 152, "72059global_step549lr0": 16, "720808560318417": 152, "72096train_loss0": 17, "72143075466156": 152, "7219855189323425": 152, "72240": 24, "7225010902553423": 135, "7227683544158936": 152, "7229824145634969": 152, "72317train_loss0": 17, "7232087903552585": 152, "723238": 103, "723309": 25, "723513": 34, "7236059308052063": 152, "723911": 24, "724138": [28, 33], "7243074602550931": 152, "7246161": 145, "7247352600097656": 152, "7249999999": 152, "7254211902618408": 152, "7254809141159058": 152, "726": 152, "7261502756012811": 152, "726335525512695": 152, "7268": 103, "727": 24, "7271": 25, "7271665891011556": 152, "7272209480976366": 152, "72731train_loss0": 17, "7275664448738097": 152, "7282691597938538": 152, "7283771634101868": 152, "7286302831437853": 152, "728865": 34, "7289518859651354": 152, "729008": 28, "729900": 112, "72mb": 136, "73": [16, 19, 22, 24, 28, 30, 111, 112, 135], "730000": 25, "731": [16, 17], "731034": 25, "73189train_loss0": 17, "732": [23, 35], "7321758026569418": 152, "7324": 105, "7327": 35, "733": 152, "733351707458496": 152, "7333948813470017": 22, "73341733": 22, "7334885597229": 152, "73375train_loss0": 17, "73376": 105, "7337837298711141": 152, "7339953780174255": 152, "734": [111, 112], "73421train_loss0": 16, "7345global_step549lr0": 16, "7352332243367302": 152, "7353357390220683": 14, "7354151606559753": 152, "7357237325774298": 152, "736": [111, 112], "7361850976943969": 152, "7365705847740174": 152, "736786593331231": 152, "736842": 33, "7368649337026808": 152, "7369999999000001": 152, "73779global_step650lr0": 16, "73782097697258": 152, "738": 30, "7384": 14, "7384365010732551": 22, "73844train_loss0": 22, "7389515042304993": 152, "739": 152, "7390028595924378": 152, "7392514573203193": 152, "739726": 33, "739937": 34, "73fbeaf": 175, "73it": 23, "74": [14, 16, 22, 30, 35, 103, 111, 112, 136, 152], "7400881057268722": 22, "7402534365717239": 152, "740259716245863": 152, "7403112888336185": 152, "7403956360287136": 152, "7404359757900238": 152, "7408284081353083": 152, "74135train_loss0": 16, "741397101149303": 22, "741414487361908": 152, "742": 152, "74201012": 22, "742234440291489": 152, "7424242424242424": 35, "7426078796386719": 152, "7430278062820435": 152, "7431858331334158": 152, "743327": 28, "743425109308362e": 152, "7436153888702393": 152, "7437359650929769": 152, "744": [111, 112], "7442686306105719": 152, "744459581375122": 152, "7445871914581467": 22, "74467025670524": 152, "7447236180904523": 22, "7448662141188256": 152, "74502105": 152, "7450411319732666": 152, "7450666628395886": 152, "745236": 34, "7452939433210036": 14, "7454": 14, "74558687210083": 152, "745588": 33, "7456": 35, "74614": 15, "746253": 34, "7466441154479981": 152, "746772848367693": 152, "7468354430379747": 14, "7469874143600463": 152, "747177": [23, 25, 26, 27], "74724train_loss0": 16, "7482755780220032": 152, "7488": 51, "749077": [30, 31, 32], "7492063492063492": 14, "749298248506891": 14, "7493083596229553": 152, "749388": 23, "749894": [23, 25, 26, 27], "74efc42": [174, 176, 177, 179], "74efc42f1": 174, "74efc42f190870df59f42e1013c8bcb766d119b9": [174, 175], "74it": 136, "75": [0, 14, 16, 23, 25, 30, 31, 32, 35, 103, 105, 111, 112], "750": [111, 112, 117, 184], "7500": 112, "7503141760826111": 152, "750612": 23, "7507988410070539": 22, "7508global_step560lr0": 22, "751225": 34, "7515979970202726": 14, "7523576293806506": 152, "752381": 33, "7525374889373779": 152, "7529": 35, "753": 152, "75302train_loss0": 16, "7531645569620253": 14, "7533559920550403": 152, "7535561919212341": 152, "7535566773749426": 22, "75356eval_loss0": 22, "753678321838379": 152, "75403train_loss0": 16, "7541576802730561": 152, "754637752793726": 152, "7549334557136301": 22, "755": 110, "7556502297443957": 152, "756": [21, 23], "7560356259346008": 152, "7561087608337402": 152, "756882642582059": 152, "756947": 25, "757": 14, "7570669054985046": 152, "75735104": 14, "7574": [0, 6], "757506": 24, "7576857016752074": 152, "7578847774437496": 22, "758": 24, "75823683": 14, "7583": [0, 6], "7586309909820557": 152, "7587": 53, "759": [111, 112], "75912": 15, "7592": 104, "759814174969991": 152, "76": [9, 14, 16, 22, 110, 111, 112], "760": [111, 112], "7601279616355896": 14, "76074743270874": 112, "7609699527422588": 152, "76133126": 14, "7614807307720184": 152, "761785608553607": 152, "762": 21, "76264271736145": 152, "7631global_step456lr0": 17, "764055218641406": 152, "76427eval_loss0": 17, "7649813916948106": 152, "765": 152, "7650192379951477": 152, "765698": 34, "7660671982418458": 14, "7668444594100311": 14, "7671eval_loss0": 17, "767606": 33, "768": [14, 15, 110, 111, 112], "768240": 28, "768800": 112, "7688843831944374": 22, "7691373178155086": 152, "7691373178155088": 152, "76936eval_loss0": 17, "76945686340332": 152, "76it": 24, "77": [14, 16, 22, 24, 30, 103, 105], "770": [111, 112, 117], "7702807784080505": 152, "77039eval_loss0": 16, "771287155151366": 152, "7713922262191772": 152, "7715571337276035": 152, "771775144744973": 14, "7724587930573358": 152, "77292global_step650lr0": 16, "7731204032897949": 14, "773810": 33, "773874": 103, "774047705334313": 14, "7742315477284243": 14, "7743260264396667": 152, "774326799710591": 152, "77445eval_loss0": 17, "7749561309814452": 152, "7749583721160889": 14, "775": [111, 112], "7757685352622061": 22, "7758243685876923": 152, "7759999999074999": 152, "776027750968933": 152, "77644eval_loss0": 16, "776516477637529": 22, "7766585350036621": 152, "77671eval_loss0": 17, "777": 51, "7773478090763093": 152, "7777777777432102": 152, "777802": 25, "7779": 103, "778532": [23, 25, 26, 27], "7788461538461539": 29, "7788773775100708": 152, "7798994974874371": 22, "7799eval_loss0": 22, "77gb": 51, "78": [14, 16, 22, 30, 35, 95, 111, 112, 136], "780": 152, "780089": 34, "780387353897094": 152, "78077936": 14, "7808": 103, "7812200784683228": 152, "78147eval_loss0": 16, "78172128538039": 152, "7823833227157593": 152, "7825global_step456lr0": 17, "783": 152, "783068783068783": 14, "7835": 16, "783784": 33, "7838737487792968": 152, "7839088670144436": 152, "783973473707835": 152, "7841405712333676": 152, "785": 103, "785336": [14, 21], "785425448417662": 152, "78543353": 14, "786": [51, 103], "7863431660657688": 152, "78634918": 14, "7866509199609911": 152, "78679global_step456lr0": 17, "787": [111, 112], "78751eval_loss0": 16, "7875376955323292": 152, "7875376955323294": 152, "787820911407472": 152, "788": 152, "7881527801250634": 14, "78852eval_loss0": 16, "788555": 25, "7892586641434904": 16, "789669513702393": 152, "78it": 23, "79": [14, 16, 22, 30, 112], "790": [111, 112], "7900076427042646": 152, "7901608188947041": 152, "7903929410806272": 152, "79063701800694e": 108, "7906828334396937": 16, "7908996045589447": 152, "790970": 128, "791655": 128, "791667": 33, "7917594692248326": 152, "792": 23, "7923396890705874": 16, "7923858074358401": 152, "7924955818388195": 152, "7925": 14, "794034": 14, "79414225": 14, "7942999": 152, "79475519657135": 152, "79481234550476": 152, "7948817253112793": 152, "794895172119141": 152, "7951": 14, "795524288275124": 152, "795838020247469": 14, "79634953": 14, "796858215332032": 152, "7968761801719666": 152, "797343": 34, "7973950795947902": 14, "79745eval_loss0": 16, "797537386417389": 152, "7978774722624216": 14, "7978934049606323": 152, "79864global_step456lr0": 17, "798841881752014": 152, "799": 103, "79cde8905e45a47f": [101, 107, 108], "7b": [51, 83, 98], "7b1": 51, "7ffd228": [181, 182], "7m7e05hu": 16, "7m7e05husync": 16, "7min": 150, "7\uc6d4\ubd80\ud130": 20, "7\uc77c": 20, "8": [1, 6, 9, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 51, 61, 69, 83, 88, 98, 99, 100, 101, 103, 105, 108, 110, 111, 112, 113, 114, 115, 124, 132, 135, 136, 141, 145, 149, 150, 152, 161, 184, 186], "80": [14, 16, 17, 22, 29, 30, 35, 83, 111, 112, 115, 120, 132, 145, 150, 152], "800": [51, 111, 112, 136], "8000": 112, "80000": 128, "800000": 30, "8000000": 103, "800041675567627": 152, "8005030751228333": 152, "80069train_loss0": 16, "8009085059165955": 152, "801": 0, "80128765": 14, "80148global_step650lr0": 16, "80164global_step456lr0": 17, "802091729640961": 152, "802290514152911": 152, "8025983892937552": 152, "8025984580504936": 35, "8027013989387362": 14, "8027322625961777": 152, "802841540755959": 16, "802891": 108, "803030303030303": 35, "8035576939582825": 152, "803606": 28, "8036339667108323": 152, "803800": 112, "8041651871469286": 152, "8041757582507306": 14, "8042060041106648": 14, "8045366795366795": 14, "8046839102325267": 14, "8049886621315193": 14, "805": 28, "805270916317296": 152, "8053802145851983": 152, "805790901184082": 152, "805954927572994": 14, "8067716627733474": 14, "8069455133544075": 152, "807": 14, "8070857387586171": 145, "8073120721209749": 35, "8075026869773865": 152, "8075116052276107": 14, "807693099975586": 152, "807850": 19, "8080": [17, 20, 61], "8084240469908484": 14, "809008": 23, "809384": 30, "8094637852091993": 14, "8096889436244965": 152, "80990493381229": 152, "80gb": 51, "81": [14, 16, 22, 30, 135], "8106017713175628": 14, "810671669674209": 152, "8109302162168566": 152, "8109302162251897": 152, "811": [111, 112], "8117618": 152, "8122045384513007": 152, "812558126449585": 152, "812592": 23, "8128131628036499": 152, "813314": 28, "813571095466614": 152, "8136528134346008": 152, "8138297478357951": 152, "81464global_step650lr0": 16, "8148148151": 152, "8148745715618133": 152, "814890384674072": 152, "8153495192527771": 152, "8154245281843358": 152, "8155": 103, "8156261616282993": 152, "815864": 33, "8160": 112, "8160318732261658": 152, "8165262017090233": 152, "817": 152, "817172": 34, "817219": 152, "8174244178666009": 152, "817425860464573": 152, "817477707696492": 152, "8179838974696024": 14, "8180068135261536": 152, "8181499573919508": 152, "81818402": 14, "8182960730456528": 152, "81832": 103, "8192": [8, 145], "8194134831428528": 152, "8197667598724365": 152, "819876": 28, "8199644976192051": 152, "82": [14, 16, 22, 28, 35, 111, 112], "820743430985345": 152, "821": [111, 112], "821036100387573": 152, "821884269184537": 152, "822197030576038": 152, "8224291814698114": 152, "8229714737584194": 152, "8231304507724357": 14, "8232758620689655": 14, "82328": 152, "823284888087085": 152, "823479084407582": 14, "824": [111, 112], "824231719970703": 152, "8243044892946879": 152, "8245844": 152, "825088196727965": 152, "82520e7875fc69": 110, "82527global_step650lr0": 16, "825504": 21, "8255044887345607": 21, "8255860805511475": 152, "8257068116299219": 152, "8257713248638838": 14, "8259999998999998": 152, "8265": 14, "8269158482551573": 152, "827": 23, "8270976185798645": 152, "8275042325607501": 152, "82756757736206": 152, "8275765712628258": 14, "828204870223999": 152, "828649": 23, "82866eval_loss0": 16, "8291": 14, "8293424091943761": 152, "83": [14, 16, 22, 23, 24, 30, 121, 130, 135], "8304114023844401": 152, "8306878306878307": 14, "8310660719871521": 152, "831461": 33, "8316201654065506": 14, "831760479344262": 152, "8321995464852607": 14, "8324528217315674": 152, "8329554043839759": 14, "8330308529945554": 14, "833248193": 152, "833444407582283": 152, "833746569962225": 152, "834": 14, "834000": 25, "8340578079223633": 152, "8344671201814059": 14, "8346521258354187": 152, "8346863150596618": 152, "835": 152, "835000": 33, "8351849488988791": 14, "8351891378637732": 14, "8352229780801209": 14, "836478": 33, "8366067935289703": 152, "8370756314020869": 14, "837860183047866": 152, "839": [23, 111, 112], "8396104574203491": 152, "839826829122668": 152, "8398320378929996": 152, "839832037893": 152, "83it": [20, 30], "84": [14, 16, 22, 30, 111, 112, 117, 119], "840": [111, 112], "8405752408315796": 152, "841389800608158": 152, "8416612963899948": 14, "8416924252477069": 14, "8418636918067932": 152, "8419096206765615": 14, "8420461010091653": 14, "842105": 33, "84284": 22, "8428568844583993": 14, "8431163771644155": 152, "8431163771644157": 152, "84325": 28, "843464023537106": 152, "843712": 28, "8446215139442231": 14, "8448275862068966": 14, "845041184955173": 152, "845083717375899": 14, "84513521194458": 152, "8452358961105346": 152, "8453894654909769": 152, "8456896551724138": 16, "846154": 33, "846369": [30, 31, 32], "8465215619765862": 16, "84662264585495": 152, "847029685974121": 152, "8471301983903201": 14, "8471407045467768": 152, "8472237527370453": 152, "847674": 23, "8481564521789551": 152, "849": [111, 112], "8490943908691406": 152, "8492333903150788": 16, "8496030672556825": 152, "84gb": 51, "85": [14, 16, 22, 23, 30, 111, 112, 115], "850": [111, 112], "8500": 112, "8501870264609654": 152, "8501989907520767": 14, "8509526835547553": 152, "851": 17, "8517777272479437": 14, "8518518518232738": 152, "8520880222320557": 152, "8528951346874237": 152, "8539513349533081": 152, "854": [103, 110], "85427": 17, "854999": 23, "8551825504170523": 152, "8555574890591362": 152, "856754672889186": 152, "8568254854944017": 152, "8570949314037963": 152, "8571844696998596": 152, "8576761537128025": 152, "8582547346750895": 152, "858469": 100, "858684": 30, "8589930772781371": 152, "859194891827816": 152, "85934401": 14, "8595886193597174": 14, "8598122": 14, "85\ub144": 15, "86": [14, 16, 20, 22, 111, 112, 150], "860287052386768": 152, "8611091058190008": 152, "8613271713256836": 152, "8615469124582079": 152, "8617703727076175": 152, "8617703727076176": 152, "8617791864607067": 152, "8618583679199219": 152, "8620413064956665": 152, "8622870445251465": 152, "862912118434906": 152, "863": 51, "8631192445755005": 152, "8631575107574463": 152, "8633557140827179": 152, "8633925139904022": 152, "863442": 23, "864": 14, "8641168276468912": 152, "8644108938029865": 14, "8644522918595208": 152, "86489": 24, "8649173259735108": 152, "865800": 112, "866727590560913": 152, "8671932220458984": 152, "8675100591447619": 152, "8678891599178314": 152, "8680202687611864": 152, "8683999688876635": 152, "8684459182951185": 152, "8691527287165324": 152, "8691604139030074": 152, "87": [14, 16, 22, 111, 112, 121, 130], "870": [0, 14, 152], "8707619605792893": 152, "8707838190926446": 152, "870980441570282": 152, "871009826660156": 152, "871084690093994": 152, "8713": [20, 22], "871394": 34, "871484327316284": 152, "871793395280838": 152, "87184global_step790lr0": 16, "872": 103, "87225178": 95, "8728516340255738": 152, "872867226600647": 152, "8731648921966553": 152, "873382854368536": 152, "873748779296875": 152, "8740266468789842": 152, "87408849234339e": 152, "8743": 14, "874766953786214": 152, "874kb": 100, "875": 184, "8754242658615112": 152, "8754687373542778": 152, "8755013942718506": 152, "8755223027370869": 152, "8756595693460896": 152, "875851555821591": 152, "8764177560806274": 152, "8765435218811035": 152, "877": 152, "877087": 34, "87733449406094": 152, "878": 152, "878004424663513": 152, "8785028352814224": 152, "8786590695381165": 152, "8787878787878788": 35, "879450798034668": 152, "879700": 112, "8799245460269352": 152, "88": [14, 16, 22, 23, 88, 117], "880208917458852": 152, "8803811073303223": 152, "880466": 33, "8805878221988678": 152, "8807709": 22, "880851": 30, "88103": 105, "8818578124046326": 152, "88197": 24, "882": 0, "882071053981781": 152, "882104041841295": 152, "88246488571167": 152, "8836": 103, "8836533972493942": 152, "8838164329528808": 152, "88382": 20, "8839708745479584": 152, "88407": 20, "88413": 20, "88439": 20, "884681761264801": 152, "884779371155633": 152, "8848589893698096": 152, "885008454322815": 152, "8855": 152, "88550": 20, "8856943421893649": 152, "885801887512207": 152, "8858444094657898": 152, "8865294039249421": 152, "886792": 28, "8869431614875793": 152, "887": 0, "887304": [23, 25, 26, 27], "8874885131087566": 152, "888": 152, "888152563256316": 155, "888158": 30, "8882899284362793": 152, "888783973455429": 152, "8888888888790125": 152, "8888888888823795": 152, "8888888888827162": 152, "889": 103, "889160": 149, "8892569541931152": 30, "8896758079528808": 152, "889790": 34, "88it": 110, "89": [14, 16, 17, 35, 103, 108, 111, 112, 135], "890": 152, "890000": 25, "8905021548271179": 152, "8905305203853535": 152, "8911628544330596": 152, "8912580755021837": 152, "8913208246231079": 152, "8918190002441406": 152, "8919851157400344": 152, "892": [51, 111, 112], "8920": 108, "8924511830012004": 152, "893": [23, 25, 26, 27], "893048": 149, "8930710017681122": 152, "8931920528411865": 152, "893358": 25, "893755": 34, "8938221335411072": 152, "893900990486145": 30, "8939241734827547": 35, "8944442338413663": 152, "89454": 20, "89486acc0": 17, "895": [23, 25, 26, 27], "895180702209473": 128, "8953": 22, "8955254554748535": 152, "8955683052539826": 152, "8957698961367982": 30, "8958088377661515": 30, "8960176991150443": 30, "8960376670584083": 22, "8960786700248718": 152, "896372185813056": 152, "896465": 14, "8964992761611938": 152, "896727": 128, "896856880187988": 152, "897": 51, "8972178141276042": 152, "897441": 34, "8977bc2": 185, "898551": 28, "898655": 30, "8989042401313782": 152, "899151": 25, "8993445038795471": 152, "8995069801807404": 152, "899846577644348": 152, "8999915237636707e": 152, "899k": 100, "89d6ac597a40e29": [101, 107, 108], "8aa13df": 175, "8aa13df1fa53b03617c8b86752d442068c0ce56a": 175, "8b": 98, "8billion": [111, 112], "8gb": 51, "8k": 105, "8mb": [51, 114], "8min": 14, "8th": [111, 112], "8x8": 9, "8\uac1c": [15, 19], "8\uac1c\uc0ac\uac00": [15, 19], "8\uc6d4": 15, "8\uc6d4\uc5d0": 14, "8\uc8703000\uc5b5\uc6d0\ub300\ub85c": 19, "9": [0, 1, 6, 14, 16, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 51, 95, 99, 101, 103, 105, 106, 108, 111, 112, 117, 119, 128, 132, 135, 136, 145, 149, 150, 152, 161, 180, 184, 186], "90": [14, 17, 30, 110, 111, 112, 136, 150, 151, 152], "900": [101, 111, 112], "9000": 112, "90000": 128, "9000000": 103, "900003040065772e": 152, "9000521475110517": 152, "900067400932311": 152, "90013": 16, "9006467580795288": 152, "9011274512865044": 152, "901128": 34, "9013971149921417": 152, "901506": 25, "9017829835414887": 152, "9018328309059143": 152, "9020455718040467": 152, "902053": 30, "9023345887660981": 152, "9027936637401581": 152, "9028993308544159": 152, "903": 0, "9030599276224772": 152, "903959184885025": 152, "904638576448713": 152, "9047776937484742": 152, "905062073469162": 152, "9051498711109162": 152, "9054386794567109": 152, "905730802064189e": 108, "9058874368667602": 152, "905983": 28, "9061625897884369": 152, "9061688786978715": 152, "906697412331899": 152, "906922808788813": 152, "907007": 24, "9071476677119651": 152, "9072303771972656": 152, "90740": 20, "9074244916439056": 152, "907718539237976": 152, "90773559": 14, "9077460765838623": 152, "9077514350414276": 152, "9079844713211059": 152, "9079863071441651": 152, "908": [16, 103], "9081074988842013": 152, "908365": 25, "9083827204174466": 152, "9084170997142792": 152, "9084529221057892": 152, "9084756791591644": 152, "9086": 16, "9086551727646448": 29, "9086619794368744": 152, "9087440133094787": 152, "908799512368887e": 152, "908976": 34, "90918": 20, "9092812064780683": 152, "9093945089752844": 152, "9094338595867157": 152, "9098460018634796": 152, "90f23ec": 177, "90k": 88, "90m": [132, 135, 136, 150], "91": [14, 17, 22, 30, 150, 152], "9101777918673029": 21, "910178": 21, "9101901948451996": 152, "9103051900863648": 152, "9104019999504089": 152, "9104682432280646": 152, "9105643033981323": 152, "9105921447277069": 152, "9106474757194519": 152, "9106616199016571": 152, "9106798052787781": 152, "9106871962547303": 152, "9107547461986542": 152, "9107627511024475": 152, "910851": 34, "9109231293201446": 152, "91106196641922": 152, "9110627174377441": 152, "9110994279384613": 152, "9111285269260406": 152, "9111976206302643": 152, "9112907469272613": 152, "9114029586315155": 152, "9114533245563508": 152, "9114806866952789": 14, "9115502536296844": 152, "9116369605064392": 152, "9116515040397644": 152, "9118037780125937": 152, "9118721087773641": 152, "9118741154670715": 152, "911925446987152": 152, "9119442880153656": 152, "9119841039180756": 152, "9120813608169556": 152, "9120863258838654": 152, "9121033608913421": 152, "9121947288513184": 152, "9122909307479858": 152, "9123625040054322": 152, "9123888492584229": 152, "9125157237052918": 152, "9126778662204742": 152, "9129321826829": 152, "9129396239916484": 152, "9133953988552094": 152, "9134948909282684": 152, "9135325968265533": 152, "9136266094420601": 14, "9141834139823913": 152, "9142145872116089": 152, "9143188178539277": 152, "9146278921763101": 152, "9148176729679107": 152, "914996188879013": 152, "915027": 25, "91504776": 14, "91516358": 14, "9152511358261108": 152, "9159986495971679": 152, "91612019971099": 152, "91635215": 152, "9164608538150787": 152, "9164952185418871": 152, "9165": 105, "9166006147861481": 152, "9168468117713928": 152, "9169389188289643": 152, "916973489522934": 152, "917": 0, "9172113299369812": 152, "9174473414104023": 152, "917453050613403": 152, "9177050948143005": 152, "9177692532539368": 152, "918256985219584": 152, "9189544194716004": 152, "919250": 95, "919475555419922": 152, "9197418034076691": 152, "9197915196418762": 152, "91be346ce97972f5": 103, "92": [14, 17, 21, 22, 30, 51, 97, 111, 112, 130], "9200849056243896": 152, "9201": 110, "92010298371315": 152, "920215": 25, "9202969610691071": 152, "92046": 24, "92047": 24, "9204763114452362": 152, "92048": 24, "92049": 24, "92050": 24, "92051": 24, "920939": [23, 25, 26, 27], "9209719644652472": 152, "921": 24, "92140168": 14, "9214084148406982": 152, "9223": 103, "9223617800281911": 152, "9223808370094702": 152, "9223808370094703": 152, "923": 24, "92311429977417": 152, "9233746528625488": 152, "9234955966472626": 152, "9235683441162109": 152, "9235726594924927": 152, "9237553596496582": 152, "9238462153413554": 152, "9238621056079864": 152, "9241811692714691": 152, "9243027687072753": 152, "9244933878967375": 152, "9246693849563599": 152, "925548": 14, "9255641990237766": 152, "9256532788276672": 152, "925821": 28, "9259259259116369": 152, "9259259259181319": 152, "9259259259187814": 152, "92594481": 14, "9259529941013552": 17, "9259544157948747": 152, "926": [14, 20, 152], "9261069238185883": 152, "926681931813558": 152, "9267397880554199": 152, "9269208124816014": 14, "927": 103, "9271989339005193": 152, "9272": 110, "9281115879828327": 14, "928241": 14, "928571": 30, "929": 152, "92mb": 103, "93": [0, 14, 16, 17, 29, 111, 112, 128], "930": [22, 152], "9300058656023976": 152, "9302503347396851": 152, "930793991416309": 14, "9309146285057068": 152, "931201514160114e": 108, "9313304721030042": 14, "9315055": 152, "931628999164661": 152, "9317025850216545": 152, "932": 110, "9320395422644892": 152, "9329399141630901": 14, "932944": 33, "9329968214035034": 152, "9332154810428619": 152, "9333105725176685": 152, "933551393706223": 112, "933635026216507": 152, "9338362574577331": 152, "9338732779026031": 152, "9343199729919434": 152, "9343347639484979": 14, "934763948497854": 14, "935": 152, "9351759076118469": 152, "9353445768356323": 152, "9355605125427247": 152, "9357312977313995": 152, "935814490942164": 14, "9358580072292853e": 152, "9359890752368503": 152, "9361532661649914": 152, "9361587982832618": 14, "9366410970687866": 152, "9366952789699571": 14, "9369237124919891": 152, "937": 184, "937135538789961": 152, "937251": 25, "9372662842273712": 152, "937361064931399": 152, "937481838464737": 152, "937500": [30, 31, 32], "937843376827051": 152, "9378823009649313": 152, "938": [111, 112], "938048362731934": 152, "93838484131265": 108, "9384097099304199": 152, "93872": 20, "9388108253479004": 152, "9392126202583313": 152, "9392213821411133": 152, "9393776824034334": 14, "939386063134093": 152, "9394": 25, "939766138792038": 152, "93it": 23, "94": [14, 17, 30], "940210": [23, 25, 26, 27], "9403512413688508": 14, "9404": 51, "9404210229503303": 17, "9409192383289338": 152, "9409907221794128": 152, "9410110116004944": 152, "9414067029953003": 152, "942301": 14, "9429188728332519": 152, "943": 119, "9435745537281036": 152, "943827": 33, "944": [16, 19], "944037276506424": 152, "944045": 19, "9442847371101379": 152, "9444616088410577": 152, "9446840107440948": 152, "9447168111801147": 152, "945039": 28, "9452589069885053": 152, "9456190446093845": 152, "9458022725617946": 152, "9460621774196625": 152, "946215808391571": 152, "946848": [23, 26, 27, 33], "947": 14, "94701087474823": 152, "947089947075267": 152, "9474806981643329": 30, "947885513305664": 152, "9481481481391936": 152, "948905": 30, "9489622076240566": 152, "9491150442477876": 30, "9492060959339141": 152, "9493901491165161": 152, "9495910765330818": 30, "9496804177761078": 152, "94\ub144": 15, "95": [14, 17, 20, 30, 88, 97, 103, 111, 112], "9500": 112, "9500268008973863": 152, "950174129340383": 152, "9502161026000977": 152, "9502478659152984": 152, "950515135257185": 152, "9512531757354736": 152, "951733589172363": 152, "9522316236050686": 145, "9522718071937561": 152, "952373": 33, "952513": 33, "9525385618209838": 152, "952751": 21, "9527512959359385": 21, "9529073238372803": 152, "952\ub9cc": 14, "9533914708501714": 16, "9547281682491302": 152, "9548657298088074": 152, "9549902737140655": 152, "955": 20, "955035": 30, "955290111180942": 108, "9553639352321625": 152, "9561408758163452": 152, "9561534903362163": 152, "95617": 105, "9568761706352233": 152, "957": 105, "9570511102676391": 152, "957790600982717": 152, "957808": 30, "958100": 112, "9583303928375244": 152, "9586255116896196": 14, "9586986899375916": 30, "9587222039699554": 152, "9588610708713532": 152, "959061336517334": 152, "9597": 25, "959949502845605": 152, "9599951684474946": 152, "96": [14, 17, 19, 22, 30, 35, 111, 112, 135], "960": [0, 14], "960401701927185": 152, "960415": 28, "960746": 30, "9607468128204346": 152, "960805": 30, "9613dda": 180, "9616746664047241": 152, "9618860918242997": 152, "96235901": 22, "962483372280577": 152, "963042879104613": 152, "96359983086586": 152, "9637438952922821": 152, "96388427810584": 152, "964": [111, 112], "9645551145076752": 152, "9645883781616761": 14, "9648597265277666": 152, "964c673": [182, 185], "9657190799713135": 152, "9661835748675581": 152, "9664158940315246": 152, "966483163833619": 152, "96653938": 14, "966953155729506": 152, "967106": 30, "9675707817077637": 152, "967620": 30, "967770": 30, "967973": 30, "968": 184, "968215875053943": 152, "9689162568358742": 14, "968976": 25, "969": 152, "969531393051147": 152, "96gb": 51, "96it": 108, "97": [17, 30, 111, 112, 135], "970": 6, "9702214002609253": 152, "970297": 33, "970326895536801": 152, "97071016": 152, "970902": 14, "9712950348854065": 152, "9719110247106496": 16, "972": 152, "972270": 23, "972928": [23, 25, 26, 27], "9730925319655515": 152, "9735818028450012": 152, "9740810260175872": 152, "9747179567813873": 152, "97506": 21, "9756801762639395": 152, "975768095254898": 152, "9758998453617096": 152, "97593": 20, "976": [111, 112], "97624731": 14, "97627": 20, "97650": 20, "97667": 20, "977142": [23, 26, 27, 33], "9774350543228523": 152, "97756": 20, "977634889": 14, "9778721332550049": 152, "97797042": 14, "9780619010239433": 152, "9782684757568221": 152, "9783030668907": 37, "978488": 21, "9784880492636585": 21, "9786549585511946": 152, "9786576999558343": 152, "9787092269858242": 152, "978836": 23, "979": 152, "979167127609253": 152, "9793456785422703": 35, "9793609": [175, 176, 177, 179], "97936099145d29e1067f42a856e9aa3a41c7b50f": 175, "97gb": 51, "98": [14, 17, 30, 111, 112], "980": [0, 111, 112], "980159": 30, "980204629898072": 152, "980392": 30, "981": [111, 112], "983945485121674": 152, "984": [111, 112, 184], "9841269840876163": 152, "9853566560115524": 14, "9873750627040863": 152, "988107": 25, "9893611453220097": 152, "989784550666809": 152, "99": [14, 103, 105, 111, 112, 117, 128], "990155601501463": 152, "990185": 14, "9904": 103, "991": [28, 111, 112], "992": 184, "992185453036204": 152, "99268501437722": 152, "993": 152, "99320948": 95, "9938374519348144": 152, "9947576940059661": 152, "995413": 33, "9955683946609497": 152, "9956230812602573": 152, "996": 184, "99621": 20, "9969701210657758": 152, "9970690608024597": 152, "9972156604131": 152, "9976812325252717": 152, "998": 184, "998075495427734": 152, "9982102600171": 152, "999": [101, 184], "999072253704071": 152, "999200": 112, "9995": [103, 105], "99957": 105, "9996923130945297": 152, "9996923130945299": 152, "999894": [23, 25, 26, 27], "999999": 30, "9999990000010001": 30, "99acea4a740b4cc36e4a93a238c7de11b0ce341d65b7d37168b3b90fd64721d2": 94, "9min": 150, "9th": [111, 112], "9\ubd84": 141, "9\uc2dc\uae4c\uc9c0": 15, "9\uc6d4": 14, "9\uc6d4\uc5d4": 15, "9\ud488\uc0ac": 140, "A": [0, 1, 4, 6, 7, 8, 9, 37, 42, 45, 46, 50, 51, 52, 54, 55, 59, 60, 61, 62, 64, 65, 71, 73, 74, 78, 80, 81, 82, 86, 87, 90, 93, 95, 97, 99, 100, 105, 108, 109, 111, 112, 113, 114, 119, 120, 121, 122, 124, 126, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 147, 148, 150, 151, 152, 154, 156, 158, 159, 160, 163, 164, 165, 167, 172, 177, 181, 182, 183], "AT": [111, 112], "And": [24, 30, 95, 100, 108, 112, 116, 136, 139, 174, 177, 184], "As": [1, 2, 5, 6, 8, 9, 23, 26, 27, 38, 41, 50, 52, 53, 55, 56, 59, 60, 77, 80, 81, 83, 88, 89, 91, 93, 97, 98, 99, 100, 110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 128, 130, 132, 139, 140, 143, 144, 148, 150, 151, 155, 163, 171, 172, 173, 177], "At": [10, 11, 36, 49, 50, 52, 56, 86, 96, 97, 111, 112, 114, 115, 116, 117, 119, 142, 145, 148, 172], "BE": [111, 112], "Be": [30, 85, 89, 178], "But": [5, 117, 126, 130, 139, 143, 144, 146, 150, 152, 173, 174, 175, 176, 180, 181, 182, 183], "By": [2, 4, 6, 7, 8, 9, 10, 11, 12, 30, 37, 45, 46, 50, 52, 53, 54, 59, 60, 63, 64, 65, 66, 67, 68, 71, 74, 76, 77, 79, 80, 81, 82, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 105, 106, 109, 111, 112, 113, 114, 115, 116, 128, 129, 130, 132, 133, 134, 136, 137, 138, 145, 146, 147, 148, 149, 150, 151, 155, 157, 159, 160, 161, 167, 171, 172, 178, 181, 182], "For": [2, 4, 8, 9, 12, 30, 35, 38, 41, 42, 43, 45, 46, 49, 52, 59, 60, 64, 69, 71, 73, 76, 77, 79, 80, 81, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 124, 125, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 150, 151, 152, 156, 157, 159, 170, 174, 176, 177, 178, 180, 181], "IN": 144, "IT": [14, 64, 65, 71, 111, 112, 159, 160], "If": [14, 30, 45, 46, 54, 68, 76, 77, 81, 84, 92, 93, 97, 100, 101, 105, 107, 108, 109, 111, 112, 114, 115, 123, 125, 126, 130, 133, 140, 143, 144, 145, 147, 152, 157, 173, 174, 175, 176, 177, 178, 180, 181, 183, 184, 185], "In": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 29, 35, 36, 38, 41, 42, 45, 46, 50, 52, 53, 54, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 76, 77, 80, 81, 82, 83, 84, 86, 88, 89, 90, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 167, 168, 171, 172, 173, 174, 176, 177, 179, 180, 181, 183, 184, 185], "Into": 6, "It": [3, 5, 6, 8, 9, 10, 12, 24, 30, 36, 37, 42, 45, 46, 47, 50, 52, 53, 54, 56, 59, 60, 61, 64, 66, 67, 68, 69, 71, 72, 73, 76, 77, 82, 83, 85, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 162, 164, 166, 167, 169, 171, 172, 175, 177, 178, 181, 183], "Its": [41, 53, 111, 112, 172, 181], "NO": [51, 136, 181], "NOS": [111, 112], "NOT": [14, 16, 17, 22, 30, 105, 110], "No": [14, 15, 16, 17, 19, 21, 24, 29, 35, 43, 69, 71, 74, 84, 88, 97, 99, 100, 105, 111, 112, 151, 166, 167, 173, 177], "Not": [8, 9, 69, 79, 111, 112, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "ONE": [136, 152], "OR": 183, "Of": [97, 111, 112, 144], "On": [0, 6, 9, 29, 30, 35, 42, 43, 50, 59, 60, 62, 76, 97, 111, 112, 115, 116, 119, 126, 136, 144, 151, 152, 156, 158, 172, 173, 174, 176, 178, 181, 183], "One": [5, 40, 46, 49, 50, 52, 59, 71, 90, 97, 105, 111, 112, 115, 116, 118, 119, 130, 133, 137, 138, 139, 143, 147, 153, 157, 177], "Or": [69, 124, 139], "Such": [38, 46, 49, 59, 111, 112], "THE": 173, "That": [60, 97, 101, 108, 111, 112, 130, 175, 177], "The": [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 17, 28, 30, 32, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 137, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 165, 167, 168, 169, 173, 175, 176, 178, 180, 181, 183, 186], "Their": [46, 49, 50, 52, 53, 59, 89, 98, 111, 112, 116], "Then": [9, 72, 76, 80, 88, 96, 97, 99, 100, 105, 107, 108, 111, 112, 125, 128, 129, 133, 144, 149, 153, 155, 178, 180], "There": [3, 12, 17, 50, 64, 65, 66, 70, 71, 72, 77, 91, 92, 93, 102, 104, 106, 109, 111, 112, 114, 115, 117, 120, 121, 126, 130, 131, 133, 134, 135, 137, 141, 143, 145, 146, 148, 154, 155, 156, 159, 160, 172, 173, 174, 175, 178, 179], "These": [5, 6, 7, 8, 9, 11, 12, 13, 38, 40, 41, 42, 45, 46, 49, 50, 52, 53, 55, 56, 57, 58, 59, 62, 64, 65, 66, 71, 74, 76, 77, 82, 86, 88, 89, 90, 91, 93, 95, 97, 98, 100, 103, 106, 110, 111, 112, 113, 115, 116, 117, 120, 121, 122, 124, 126, 127, 128, 130, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 150, 154, 155, 156, 159, 160, 164, 165, 171, 172, 176, 179], "To": [1, 6, 8, 9, 10, 14, 17, 22, 30, 45, 46, 49, 55, 59, 60, 61, 63, 64, 67, 68, 69, 71, 72, 76, 77, 78, 80, 81, 82, 83, 88, 89, 93, 94, 95, 96, 97, 98, 100, 102, 103, 105, 108, 109, 110, 111, 112, 113, 114, 116, 120, 121, 123, 126, 130, 132, 133, 135, 136, 137, 139, 141, 142, 147, 148, 150, 151, 152, 156, 157, 159, 165, 167, 174, 176, 177, 180, 181, 182, 183, 185], "Will": [25, 111, 112, 116], "With": [1, 6, 9, 12, 13, 45, 49, 50, 51, 59, 64, 65, 66, 76, 81, 82, 90, 97, 106, 110, 111, 112, 116, 117, 128, 130, 133, 139, 141, 155, 159, 160, 161, 166, 167, 172, 181, 185, 186], "_": [8, 24, 84, 97, 99, 105, 107, 108, 119, 124, 126, 128, 133, 139, 143, 145, 147, 149], "_20220911": [14, 21], "_20221229": 14, "___": 113, "___________________________________________________": [14, 16, 22, 29, 30, 35, 135], "__call__": [30, 112], "__dict__": [111, 112], "__file__": 181, "__init__": [127, 128, 152], "__version__": [15, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 152], "__worker_lfs__": 20, "_annot": 20, "_ax": 23, "_blank": 152, "_category_pr": 21, "_column": 30, "_config": [14, 20, 22], "_confusion_matrix": [14, 22], "_copier_conf": 69, "_cv": 14, "_data": 34, "_date": 23, "_derj_9r": [100, 101, 103, 108, 114, 132, 135, 136, 141, 150], "_diff_prev": 23, "_diff_year": 23, "_equinox_iii": 149, "_export": [14, 20], "_finbert": 30, "_format": 23, "_func_": [15, 17, 26], "_i": 125, "_j": 125, "_keys_": 28, "_m": 147, "_method_": [16, 17, 30], "_name": 34, "_of_00020": 112, "_parms_": 28, "_partial_": [15, 17, 24], "_pipeline_": [15, 16, 19, 21, 24, 30], "_polarity_pr": 21, "_pred": [14, 20, 22], "_similar": 148, "_split": 17, "_t5": 30, "_t_sne": 28, "_target_": [15, 17, 24], "_token": 145, "_tone": 31, "_w_2": 143, "a100": [51, 83], "a319": [111, 112], "a320": [111, 112], "a321": [111, 112], "a57fa0037aa12ddd2821b0233a9d917cf821e415": 184, "a600": 142, "a6000": 112, "a7mqtfdv": 17, "a7mqtfdvsync": 17, "a936190": 184, "a93619043f8d34fc902c9968898a2690b4e504d1": 184, "a_data": 152, "a_i": 148, "a_ib_i": 148, "aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559": [111, 112], "aaa": 140, "aac": 131, "aakash": 0, "aardvark": [111, 112, 156], "aaron": [111, 112], "ab": [0, 6, 8, 9, 53, 101], "ab11": 183, "ab323ba": 183, "ab3578d6": 179, "ab3579d6": 179, "aba": [111, 112], "abandon": [49, 111, 112], "abbeel": [0, 6], "abbrevi": [6, 102, 111, 112, 139, 180], "abc": [111, 112, 115], "abcabc123\u1100\u1161\u1102\u1161\u1103\u1161": 104, "abcabc123\uac00\ub098\ub2e4": 104, "abh": [111, 112], "abil": [0, 5, 6, 8, 9, 10, 41, 42, 44, 46, 49, 50, 52, 53, 54, 55, 59, 81, 85, 86, 90, 92, 93, 100, 109, 111, 112, 113, 116, 126, 130, 134, 138, 154, 156, 163, 171, 173], "abjad": [111, 112], "abl": [4, 10, 14, 16, 17, 22, 37, 42, 47, 68, 70, 87, 90, 91, 92, 96, 100, 107, 108, 110, 111, 112, 114, 116, 117, 120, 129, 130, 137, 139, 140, 144, 146, 150, 161, 172, 176, 180], "abnorm": [111, 112], "abolish": [111, 112], "abolit": [111, 112], "abort": [111, 112, 177], "about": [6, 8, 12, 35, 37, 49, 50, 51, 52, 55, 59, 63, 67, 71, 76, 77, 83, 85, 88, 89, 94, 97, 98, 100, 105, 111, 112, 116, 117, 119, 121, 123, 126, 127, 130, 134, 136, 138, 139, 144, 146, 147, 150, 151, 152, 154, 156, 167, 171, 172, 173, 175, 177, 178, 179, 185], "abov": [10, 14, 51, 55, 67, 80, 89, 98, 104, 105, 110, 111, 112, 113, 117, 125, 128, 130, 141, 143, 144, 158, 174], "abraham": [111, 112], "abridg": 49, "absenc": 130, "absolut": [10, 100, 111, 112, 181], "absorb": [111, 112], "absorpt": [111, 112], "abspath": 181, "abstain": 20, "abstention": [111, 112], "abstract": [11, 49, 50, 59, 60, 74, 89, 98, 114, 115, 120, 130, 139, 164, 172], "absurd": 17, "abund": [6, 130], "ac": [0, 101, 111, 112], "ac80a2f": [177, 179, 180], "academ": [83, 85, 89, 111, 112, 168], "academi": [85, 133], "academia": [49, 111, 112], "acc": [14, 16, 17, 20, 22], "acc0": 16, "acc_stat": [111, 112], "acceler": [59, 85, 88, 97, 110, 111, 112, 152], "accent": [112, 142], "accept": [111, 112, 114, 166, 169, 172, 175], "access": [5, 6, 8, 12, 38, 42, 45, 46, 50, 52, 59, 60, 64, 68, 71, 72, 73, 74, 76, 77, 78, 82, 83, 84, 85, 88, 91, 93, 96, 98, 110, 111, 112, 121, 129, 130, 159, 166, 176, 185], "accessor": 0, "accommod": [12, 111, 112, 163, 166, 171, 172], "accompan": 108, "accompani": [83, 93, 108, 111, 112, 178], "accomplish": [1, 112, 114, 116, 130], "accord": [6, 8, 42, 46, 49, 59, 89, 97, 107, 111, 112, 113, 119, 130, 133, 142, 149, 151, 152, 156], "accordingli": [57, 88, 113, 137], "account": [8, 10, 67, 68, 74, 75, 76, 77, 80, 81, 92, 99, 105, 111, 112, 116, 120, 130, 137, 151, 154, 167, 171, 172, 176, 178], "accredit": [111, 112], "accumul": [6, 45], "accur": [6, 7, 9, 10, 12, 40, 42, 49, 53, 55, 57, 59, 71, 73, 85, 88, 90, 93, 97, 98, 100, 111, 112, 122, 130, 131, 132, 134, 137, 141, 146, 148, 150, 151, 167, 172], "accuraci": [6, 7, 12, 14, 16, 20, 22, 25, 29, 30, 35, 38, 41, 42, 45, 50, 51, 55, 57, 59, 71, 74, 84, 90, 91, 92, 93, 105, 109, 110, 115, 116, 121, 128, 130, 131, 132, 135, 136, 137, 144, 150, 165], "accuracy_scor": 135, "accus": [111, 112, 140], "acd2b4820c0b62bd7294ddb900c498fdab6ba657": 184, "achiev": [1, 6, 10, 41, 42, 44, 49, 50, 51, 52, 55, 59, 63, 64, 65, 71, 77, 88, 91, 92, 93, 98, 102, 105, 111, 112, 113, 115, 116, 117, 128, 130, 133, 134, 136, 137, 138, 146, 147, 150, 151, 157, 159, 160, 171, 172], "acic": [111, 112], "acid": [111, 112], "ack": 101, "acknowledg": [52, 85, 98, 111, 112], "acl": 0, "aclanthologi": 0, "acm": [0, 6, 53, 89], "acquaint": 80, "acqui": 101, "acquir": [6, 42, 50, 98, 111, 112, 114, 152], "acquisit": [93, 130, 139], "acrobat": 6, "acronym": [9, 158], "across": [6, 10, 11, 12, 38, 39, 46, 48, 51, 52, 53, 55, 56, 59, 61, 62, 64, 65, 66, 71, 76, 77, 85, 88, 89, 91, 93, 95, 98, 99, 100, 111, 112, 113, 114, 115, 116, 117, 120, 127, 128, 130, 133, 134, 149, 150, 151, 154, 158, 159, 160, 171, 172], "act": [12, 40, 42, 44, 50, 52, 56, 59, 100, 111, 112, 126, 130, 172], "action": [6, 12, 40, 42, 44, 53, 54, 57, 64, 65, 75, 111, 112, 115, 116, 119, 130, 137, 142, 159, 160, 164, 167, 170], "activ": [1, 6, 12, 18, 37, 42, 44, 52, 69, 71, 77, 82, 88, 97, 100, 111, 112, 114, 116, 117, 119, 126, 127, 128, 130, 133, 140, 163, 164, 166, 169, 170, 171, 172], "activation_function1": 128, "activist": [111, 112, 120, 152], "actor": [6, 78, 149], "actual": [10, 45, 52, 64, 66, 88, 97, 103, 105, 111, 112, 128, 136, 143, 147, 150, 159, 164, 166, 169, 171, 172, 185], "ad": [6, 8, 9, 10, 14, 15, 20, 22, 28, 50, 52, 76, 81, 88, 101, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 126, 127, 130, 132, 133, 139, 140, 145, 146, 150, 152, 166, 172, 174, 175, 177, 178, 181, 183, 185], "adalora": [51, 52], "adalora_linear": 52, "adam": [0, 109, 111, 112, 127, 128], "adamik": 7, "adamw": [88, 110, 112], "adapt": [1, 6, 7, 9, 10, 42, 45, 46, 49, 52, 54, 55, 56, 57, 65, 71, 77, 78, 83, 84, 88, 89, 91, 97, 98, 100, 109, 111, 112, 113, 116, 117, 122, 130, 134, 141, 151, 160, 163, 165, 166, 169, 171, 172], "adaption_prompt": 52, "add": [9, 25, 26, 27, 52, 55, 60, 61, 67, 68, 69, 76, 79, 80, 97, 99, 100, 104, 106, 108, 110, 114, 115, 116, 117, 132, 133, 139, 140, 145, 146, 149, 152, 155, 157, 166, 167, 172, 173, 175, 176, 177, 178, 179, 180, 182, 185], "add_available_latest": [23, 31], "add_corpu": 152, "add_decisions_to_calendar": 23, "add_dictionari": 141, "add_doc": 152, "add_dummy_prefix": [103, 105], "add_prefix_spac": 111, "add_special_token": 104, "add_unconventionals_to_calendar": 23, "addict": 136, "addit": [4, 5, 6, 7, 8, 9, 10, 12, 36, 42, 46, 50, 51, 60, 64, 65, 66, 71, 76, 77, 88, 91, 92, 93, 97, 98, 100, 104, 105, 111, 112, 113, 115, 116, 117, 120, 122, 123, 125, 130, 133, 136, 138, 140, 143, 151, 159, 160, 171, 176, 177, 178, 180], "addition": [1, 6, 9, 12, 46, 49, 52, 66, 71, 77, 88, 93, 103, 105, 111, 112, 114, 115, 123, 130, 137, 166, 169, 172], "address": [1, 6, 12, 37, 38, 47, 49, 50, 52, 53, 55, 57, 59, 60, 63, 67, 74, 77, 78, 81, 82, 83, 85, 88, 89, 93, 95, 97, 98, 102, 106, 111, 112, 115, 116, 117, 130, 133, 136, 137, 138, 145, 147, 151, 157, 158, 165, 170, 171, 172, 173], "addus": [80, 81], "adept": [42, 46, 54, 91], "adequ": [38, 71, 83, 95, 111, 112], "aderholt": [111, 112], "adhd": [111, 112], "adher": [1, 6, 43, 46, 69, 77, 89, 111, 112, 121, 165, 166, 167, 171], "adhes": [111, 112], "adi": [111, 112, 124], "adin": 107, "aditya": 0, "adj": 144, "adjac": [114, 138, 151], "adject": [111, 112, 138, 139, 140, 144], "adjust": [0, 9, 12, 42, 46, 50, 52, 55, 74, 88, 95, 97, 98, 106, 109, 111, 112, 137, 144, 155, 171, 172], "adm": 9, "administ": [111, 112], "administr": [76, 81, 82, 93, 111, 112, 119], "admir": [111, 112], "admiss": [111, 112], "admit": [111, 112], "ado": [111, 112], "adob": 169, "adolesc": [111, 112], "adopt": [12, 41, 49, 50, 55, 63, 64, 65, 74, 77, 85, 98, 111, 112, 120, 159, 160, 170, 171], "adp": 144, "adtran": [111, 112], "adult": [111, 112, 136, 139], "adulthood": [111, 112], "adv": 144, "advanc": [0, 1, 2, 5, 6, 8, 9, 11, 12, 37, 38, 41, 42, 44, 45, 46, 47, 49, 52, 55, 57, 59, 60, 72, 73, 77, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 98, 109, 111, 112, 116, 122, 126, 129, 130, 133, 139, 151, 152, 154, 156, 161, 165, 186], "advantag": [5, 6, 9, 46, 49, 50, 51, 52, 54, 57, 73, 96, 98, 109, 111, 112, 115, 116, 120, 129, 132, 134, 138, 147, 151, 154, 166, 172], "advent": [12, 13, 42, 44, 57, 86, 97, 111, 112], "adventur": [111, 112], "adverb": [138, 140, 144], "advers": 59, "adversari": [5, 6, 9, 11, 59, 77, 85, 130], "advertis": [8, 11, 111, 112, 119, 130], "advic": [30, 85, 118], "advis": 42, "advisori": 49, "advoc": [50, 111, 112], "ae": [77, 78, 111, 112], "aerat": 142, "aeroplex": [111, 112], "aerosol": [111, 112], "aerospac": [111, 112], "aeschylu": [111, 112], "aesthet": [2, 7, 111, 112], "af": [95, 101], "affair": [111, 112, 167], "affect": [9, 10, 59, 67, 68, 71, 106, 109, 111, 112, 115, 119, 120, 130, 132, 133, 137, 157, 174], "affel": 99, "affero": 181, "affili": [111, 112, 120, 121, 136], "affin": [111, 112], "affix": 140, "afford": [6, 111, 112], "afforest": [111, 112], "afn": 135, "afraid": 130, "african": [111, 112], "afrikaan": 95, "after": [3, 6, 8, 10, 17, 45, 52, 60, 67, 68, 82, 87, 88, 95, 97, 98, 99, 101, 104, 105, 108, 109, 110, 111, 112, 113, 115, 117, 119, 120, 123, 126, 128, 136, 138, 139, 140, 144, 145, 150, 151, 152, 153, 154, 166, 171, 172, 174, 175, 177, 178, 182, 183, 184], "aftermath": 63, "afternoon": [24, 111, 112], "afterthought": 63, "afterward": [111, 112, 142], "ag": [1, 12, 66, 70, 77, 78, 80, 81, 88, 90, 97, 98, 101, 111, 112, 148], "again": [100, 106, 111, 112, 114, 115, 145, 174, 177, 181], "against": [6, 9, 50, 53, 54, 57, 59, 77, 95, 111, 112, 128, 130], "age1": [111, 112], "age1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx": 76, "age_kei": 76, "agenc": [59, 111, 112], "agenda": [111, 112], "agent": [0, 1, 47, 54, 72, 98, 111, 112, 130], "agentless": [64, 159], "agg_func": 17, "agglom": 148, "aggrav": [111, 112, 136], "aggreg": [53, 119, 121, 134, 138], "aggregate_info": 17, "aggregate_scor": 30, "aggress": [111, 112], "agi": [1, 100], "agil": [1, 46, 64, 65, 159, 160, 161, 165, 167, 169, 170], "agnost": [12, 73, 105], "ago": [111, 112, 130], "agrarian": [111, 112], "agre": 167, "agreement": [69, 77, 121], "agricultur": [88, 111, 112], "ah": 101, "ahead": [45, 50, 77, 101, 128, 152, 175, 182, 185], "ahm": [0, 72], "ai": [1, 3, 5, 6, 8, 14, 16, 17, 22, 40, 41, 46, 47, 55, 58, 71, 78, 83, 85, 88, 90, 93, 96, 97, 98, 101, 116, 122, 130, 134, 139, 141, 154, 166, 168, 169, 170, 185], "aid": [12, 50, 53, 55, 59, 98, 111, 112, 136, 144, 172], "aidan": 0, "aie": [45, 176, 177, 178, 180, 181, 182, 183, 184, 185], "aim": [6, 11, 12, 36, 37, 38, 41, 42, 44, 46, 48, 49, 50, 52, 53, 54, 55, 57, 59, 63, 64, 65, 75, 76, 77, 80, 83, 85, 88, 89, 93, 95, 100, 102, 105, 106, 111, 112, 115, 116, 130, 138, 147, 148, 150, 151, 156, 159, 160, 163, 165, 167, 168, 170, 171, 172, 186], "ainer": 107, "ainsworth": [111, 112], "air": [111, 112, 133], "airbu": [111, 112], "aircraft": [111, 112], "airflow": [56, 71], "airless": [111, 112], "airlin": [111, 112], "airmen": [111, 112], "airplan": 117, "airport": [111, 112], "aiva": 2, "ajunew": 15, "ak": 101, "aka": [111, 112, 179], "akbari": [0, 116], "akin": [46, 53, 156], "al": [0, 6, 7, 52, 53, 71, 84, 95, 97, 98, 99, 101, 105, 106, 107, 111, 112, 113, 115, 116, 117, 119, 120, 124, 125, 127, 128, 129, 145, 147], "al15qitl": 0, "alabahmu": [111, 112], "alabama": [111, 112], "alabamian": [111, 112], "alabamo": [111, 112], "alabamu": [111, 112], "alain": 0, "alan": [23, 30, 31, 186], "alat": 56, "albama": [111, 112], "albanian": 95, "albedo": [111, 112], "albert": [109, 117], "alcohol": [111, 112, 156], "alebamon": [111, 112], "alec": 120, "aleph": [111, 112], "alert": [65, 71, 160], "alex_delvecchio": 149, "alexa": [49, 130], "alexand": [0, 6, 111, 112], "alexandra": 0, "alexei": [0, 6], "alfredo": [111, 112], "algebra": [111, 112, 151], "algorithm": [1, 2, 5, 6, 7, 12, 35, 38, 39, 40, 49, 50, 53, 54, 55, 59, 71, 73, 76, 77, 78, 80, 84, 88, 91, 93, 97, 102, 103, 104, 105, 107, 108, 120, 122, 125, 126, 129, 130, 136, 137, 140, 141, 147, 151, 152, 153, 154, 156, 166, 167, 169, 170], "algorithmia": 71, "ali": [101, 107], "alibam": [111, 112], "alibama": [111, 112], "alibamu": [111, 112], "alic": 120, "alien": [111, 112], "align": [1, 6, 9, 10, 42, 46, 50, 53, 54, 55, 59, 63, 89, 93, 97, 105, 120, 122, 125, 128, 130, 164, 167, 170, 172], "alik": [49, 63], "all": [0, 3, 6, 8, 9, 10, 23, 36, 41, 43, 45, 46, 50, 51, 52, 53, 55, 61, 63, 64, 66, 70, 71, 72, 73, 75, 76, 80, 81, 82, 88, 89, 93, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 130, 133, 136, 137, 138, 140, 141, 142, 145, 146, 147, 149, 150, 151, 153, 154, 155, 157, 159, 166, 167, 168, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 183, 184, 185, 186], "all_coherence_scor": 149, "all_word": 101, "alleg": [111, 112], "allegedli": [111, 112], "allegro": 71, "allei": [111, 112], "alleng": 108, "allergi": [111, 112], "allevi": [41, 50, 167], "alli": [111, 112], "allibam": [111, 112], "alloc": [50, 51, 55, 74, 132, 138, 148, 152, 166, 167, 169, 172], "allomorph": 139, "allow": [2, 6, 8, 9, 11, 12, 38, 40, 42, 46, 49, 50, 51, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 76, 77, 78, 80, 81, 84, 85, 88, 89, 91, 93, 95, 96, 97, 98, 100, 102, 103, 105, 106, 109, 111, 112, 113, 116, 121, 122, 124, 126, 129, 131, 132, 134, 136, 137, 138, 142, 144, 145, 147, 148, 151, 152, 155, 158, 159, 160, 163, 164, 166, 167, 171, 172, 174, 176, 178, 181], "allow_whitespace_only_piec": [103, 105], "allyn": 129, "almost": [90, 111, 112, 114], "alo": [0, 6], "alon": [6, 10, 88, 111, 112, 116, 137, 139], "along": [9, 36, 45, 52, 72, 73, 106, 110, 111, 112, 114, 116, 126, 136, 144, 150, 155, 173, 180], "alongsid": [111, 112], "alpha": [32, 52, 105, 111, 112, 133, 152], "alphabet": [103, 105, 108, 111, 112, 139], "alpin": [60, 61], "alreadi": [17, 49, 51, 59, 76, 97, 100, 109, 111, 112, 132, 133, 135, 136, 141, 142, 150, 155, 176, 180, 181, 183, 185], "also": [1, 2, 5, 6, 8, 9, 10, 11, 12, 24, 38, 41, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 64, 66, 69, 70, 71, 72, 73, 77, 78, 80, 83, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 102, 103, 104, 105, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 127, 128, 130, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 146, 148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 163, 165, 167, 171, 172, 173, 174, 175, 177, 178, 180, 181, 185, 186], "alston": [111, 112], "alt": [117, 150], "altaic": 140, "alter": [46, 50, 54, 77, 85, 111, 112, 139, 172], "altern": [1, 6, 8, 9, 13, 37, 40, 45, 46, 52, 60, 76, 97, 111, 112, 120, 128, 131, 132, 133, 138, 139, 147, 151, 165], "alternate_sign": 143, "although": [9, 50, 52, 53, 66, 69, 88, 111, 112, 113, 124, 147, 151, 154, 182], "alti": 101, "altogeth": 175, "altruist": [111, 112], "aluminum": 152, "alwai": [25, 64, 65, 66, 71, 79, 97, 104, 106, 107, 108, 110, 111, 112, 118, 130, 132, 136, 143, 147, 150, 159, 160, 171, 172, 178, 185], "am": [95, 97, 101, 120, 130, 132, 137, 139, 146, 174, 175, 176, 177, 180, 181, 182, 185], "amalgam": 42, "amateur": [6, 130], "amaz": 136, "amazon": [38, 49, 59, 121, 152], "ambigu": [55, 57, 91, 105, 131, 134, 144, 165], "amen": [41, 136], "amend": [111, 112, 183], "amer": 101, "america": [111, 112], "american": [0, 83, 101, 111, 112, 120, 122], "amhar": 95, "ami": 0, "amid": 152, "amit": [0, 6, 59], "amodei": 99, "among": [40, 42, 52, 60, 64, 75, 83, 86, 97, 98, 101, 105, 111, 112, 120, 122, 144, 147, 149, 151, 159, 164, 167, 171, 172], "amorph": [111, 112], "amort": 115, "amount": [2, 8, 10, 12, 46, 52, 53, 71, 77, 91, 92, 93, 95, 98, 100, 109, 111, 112, 113, 116, 117, 121, 124, 126, 128, 130, 132, 133, 134, 139, 144, 145, 156], "amp": [14, 20, 108], "amper": 2, "amphibian": [111, 112], "ampicillin": 142, "ampl": 52, "amplif": 109, "amplifi": [53, 92, 130], "amtrak": [111, 112], "amus": [111, 112], "an": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 24, 37, 38, 41, 42, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 185], "anachron": 98, "anali": 101, "analog": [46, 53, 59, 98, 115], "analogi": [116, 125, 156], "analys": [31, 111, 112, 130, 135], "analysi": [0, 1, 6, 9, 37, 38, 39, 40, 41, 47, 49, 50, 53, 55, 59, 65, 71, 73, 75, 88, 89, 93, 95, 96, 98, 100, 109, 111, 112, 113, 119, 120, 121, 122, 123, 126, 129, 130, 132, 138, 141, 143, 145, 148, 150, 153, 154, 156, 160, 167, 171, 172], "analyst": [101, 111, 112, 119, 120, 128], "analyt": [1, 37, 39, 53, 65, 98, 146, 160, 163, 165, 167, 170, 172], "analyz": [1, 2, 5, 8, 9, 12, 23, 37, 38, 41, 49, 57, 65, 87, 89, 90, 91, 97, 98, 111, 112, 116, 118, 120, 121, 123, 126, 130, 132, 134, 137, 138, 140, 141, 143, 147, 148, 151, 154, 160, 165, 166], "anarch": [111, 112], "anarcha": [111, 112], "anarchi": [111, 112], "anarchism": [111, 112], "anarchist": [111, 112], "anarcho": [111, 112], "anarkhia": [111, 112], "anc": 101, "ancestor": [111, 112, 180], "ancestri": [111, 112], "anchor": 59, "ancient": [1, 111, 112], "ancillari": 74, "andiron": [111, 112], "andrea": 0, "andreessen": 56, "andrew": [111, 112], "android": [120, 169], "anecdot": [111, 112], "anew": 46, "ang": 108, "angel": 119, "anger": [108, 111, 112, 134], "angjoo": [0, 6], "angl": [8, 9, 111, 112, 126, 147, 148, 157], "anglo": [111, 112], "angri": [3, 130], "angular": [111, 112, 124], "ani": [3, 6, 9, 10, 12, 38, 51, 56, 59, 60, 61, 64, 65, 73, 79, 88, 89, 91, 95, 97, 98, 99, 100, 102, 104, 105, 106, 110, 111, 112, 114, 115, 116, 117, 120, 121, 126, 128, 130, 132, 133, 135, 136, 139, 143, 145, 150, 152, 153, 156, 159, 160, 166, 167, 170, 172, 174, 181, 185], "anim": [5, 6, 8, 100, 111, 112, 117, 137, 143, 149], "ann": [41, 101], "annals_cirp": 149, "anniston": [111, 112], "annot": [14, 16, 17, 19, 20, 32, 55, 59, 88, 93, 122, 128, 130, 136, 137, 146], "annot_arg": 32, "annot_id": 20, "annotation_ag": [14, 16, 17, 19], "announ": 101, "announc": [12, 23, 93, 101, 111, 112], "annual": [0, 111, 112, 122, 123, 152], "annul": [111, 112], "anomali": [12, 77, 111, 112], "anonym": [38, 93, 111, 112], "anoth": [5, 7, 9, 10, 14, 16, 17, 22, 40, 49, 50, 51, 52, 59, 64, 65, 66, 67, 71, 73, 81, 84, 90, 97, 98, 100, 104, 105, 106, 110, 111, 112, 113, 116, 126, 130, 131, 132, 133, 134, 137, 139, 140, 143, 145, 147, 150, 152, 155, 156, 157, 159, 160, 171, 175, 176, 177, 179, 180, 183], "ansibl": [65, 160], "ansuz": [111, 112], "answer": [42, 51, 53, 57, 59, 69, 86, 89, 92, 93, 98, 100, 109, 113, 114, 115, 116, 122, 131, 136, 154], "answer_text": 100, "answers_fil": 69, "ant": 101, "antarct": [111, 112], "antarctica": [111, 112], "antebellum": [111, 112], "anthrop": 59, "anthropogen": [111, 112], "anthropologi": [111, 112], "anthropologist": [111, 112], "anti": [111, 112], "anticip": [50, 52, 111, 112, 113], "anticipatori": 85, "anticonvuls": [111, 112], "antidepress": [111, 112], "antigon": [111, 112], "antipathet": [111, 112], "antipod": 147, "antipsychot": [111, 112], "antiqu": [111, 112], "antithet": [111, 112], "antonym": [137, 156], "antspeak": 115, "anxieti": [111, 112], "anyon": [6, 77, 136, 150, 183], "anyth": [1, 7, 87, 111, 112, 114, 155, 182], "anywher": [111, 112, 181], "aonach": 180, "ap": [101, 105, 145], "apach": [38, 71, 88], "apache_beam": 112, "apart": [71, 111, 112, 116, 143], "api": [12, 20, 42, 45, 46, 56, 59, 60, 61, 64, 71, 72, 73, 77, 85, 89, 100, 112, 123, 135, 159], "api_kei": [100, 123], "apk": 60, "apm": 171, "apocalypt": [111, 112], "apologi": 130, "aporia": 59, "app": [1, 5, 17, 47, 58, 61, 77, 91, 102, 106, 107, 108, 130], "appalachian": [111, 112], "appar": [111, 112, 183], "apparatu": [111, 112], "apparel": [111, 112], "appeal": [52, 111, 112], "appear": [6, 9, 57, 97, 108, 111, 112, 114, 117, 120, 128, 130, 131, 132, 133, 136, 137, 139, 147, 150, 151, 156, 157, 158, 176, 177, 178, 182], "appel": [111, 112], "append": [23, 25, 26, 27, 31, 32, 50, 77, 97, 101, 106, 108, 115, 127, 128, 133, 135], "appl": [49, 51, 59, 102, 105, 107, 108, 127, 130, 133, 139, 145], "appli": [6, 7, 8, 9, 12, 14, 15, 16, 19, 20, 21, 24, 28, 30, 33, 34, 36, 37, 38, 41, 46, 49, 50, 52, 54, 55, 57, 59, 64, 66, 71, 77, 81, 87, 88, 95, 96, 97, 98, 99, 100, 104, 105, 108, 110, 111, 112, 113, 115, 116, 117, 119, 126, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 143, 147, 148, 150, 151, 155, 156, 157, 159, 161, 164, 167, 171, 172, 177, 180, 181], "applic": [0, 1, 5, 6, 7, 8, 11, 37, 38, 42, 44, 45, 46, 47, 48, 51, 52, 54, 56, 58, 60, 61, 62, 64, 65, 66, 70, 71, 73, 74, 78, 82, 83, 85, 86, 88, 89, 91, 93, 94, 96, 97, 100, 102, 105, 109, 111, 112, 116, 120, 121, 122, 126, 129, 132, 133, 140, 144, 145, 147, 148, 154, 155, 159, 160, 162, 163, 169, 170, 171, 172, 186], "apply_to": [15, 30], "apply_worker_lf": 20, "appoint": 49, "apport": [111, 112], "appreci": [80, 97, 111, 112], "approach": [0, 6, 7, 8, 9, 10, 11, 23, 38, 40, 41, 42, 49, 52, 53, 54, 55, 56, 57, 59, 63, 64, 66, 67, 69, 80, 83, 84, 89, 92, 93, 95, 96, 97, 99, 100, 102, 105, 106, 109, 111, 112, 115, 116, 117, 118, 119, 120, 121, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 146, 147, 148, 150, 151, 154, 156, 157, 159, 163, 164, 165, 166, 169, 171, 172, 175, 185, 186], "appropri": [6, 9, 14, 22, 45, 46, 49, 52, 53, 55, 60, 66, 71, 72, 76, 80, 81, 82, 89, 91, 94, 100, 109, 111, 112, 116, 130, 137, 140, 151, 156, 177, 184], "approv": [67, 68, 111, 112, 121, 166, 167], "approx": [99, 113, 132, 133, 151], "approxim": [7, 8, 9, 52, 95, 105, 111, 112, 119, 128, 132, 133, 138, 151, 156], "apr": 9, "april": [9, 111, 112, 117, 152], "apt": [60, 64, 79, 80, 81, 111, 159], "aqua": [111, 112], "aquacultur": [111, 112], "aquat": 3, "ar": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 22, 24, 30, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 76, 77, 78, 79, 80, 81, 83, 86, 88, 89, 90, 91, 92, 93, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 164, 165, 166, 167, 169, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 183, 185], "arab": [95, 130], "arai": [111, 112], "arbitrari": [6, 111, 112, 117, 130, 157, 184], "arc": [111, 112, 121], "arcelormitt": [111, 112], "archaeolog": [111, 112], "archiei": [111, 112], "architect": [42, 49], "architectur": [1, 5, 6, 7, 9, 11, 12, 14, 16, 17, 22, 38, 42, 46, 47, 48, 55, 58, 59, 64, 71, 84, 86, 87, 88, 93, 97, 98, 109, 110, 111, 112, 127, 130, 138, 154, 159, 166, 168, 169, 172], "archiv": [15, 60, 72, 111, 112, 121], "arctic": [111, 112], "ard": 101, "area": [1, 7, 8, 12, 49, 50, 52, 54, 59, 63, 71, 77, 84, 88, 89, 93, 98, 111, 112, 120, 134, 167, 171, 172, 177, 178, 179, 181], "aren": [97, 166, 174, 185], "arg": [15, 20, 24, 30, 110, 111, 112], "argentin": [111, 112], "argentina": [111, 112], "argilla": 136, "argmax": [97, 106, 110, 128], "argo": [64, 159], "argsort": 150, "argu": [111, 112, 130], "arguabl": [89, 97], "argument": [17, 30, 89, 104, 110, 111, 112, 128, 130, 150, 152, 184], "argumentum": 150, "ari": [97, 101], "arial": 28, "arima": 12, "aripiprazol": [111, 112], "aris": [2, 8, 9, 10, 38, 50, 55, 59, 64, 89, 111, 112, 120, 130, 137, 159, 163], "arisen": 50, "aristotl": 1, "arithmet": [9, 49, 57, 98, 100, 113, 147], "ariz": 59, "arizona": 136, "arkansa": [111, 112], "arket": 107, "arkho": [111, 112], "arm": [49, 64, 101, 111, 112, 159], "armadillo": 22, "armand": 0, "armenian": [95, 111, 112], "armi": [111, 112], "arn": 107, "arni": 107, "arnin": 107, "aros": [111, 112], "around": [9, 12, 41, 51, 52, 56, 72, 83, 88, 96, 105, 111, 112, 115, 116, 117, 119, 126, 128, 130, 143, 157, 171, 176, 178], "arpa": 95, "arrai": [12, 49, 50, 59, 73, 103, 105, 111, 112, 126, 128, 132, 150, 152, 158], "arrang": [8, 57, 116], "arrest": [111, 112], "arriv": [53, 71, 100, 108], "arrow": [101, 107, 108, 110, 112], "arsen": [111, 112], "art": [1, 6, 8, 10, 11, 46, 50, 57, 85, 88, 93, 98, 108, 109, 111, 112, 113, 115, 117, 130, 134, 138, 168], "arthur": 59, "articl": [12, 30, 37, 40, 46, 49, 54, 83, 84, 89, 90, 92, 93, 97, 98, 103, 111, 112, 115, 117, 118, 119, 121, 122, 130, 134, 137, 147, 148, 151], "articlesperform": 122, "articless": 84, "articul": [111, 112, 163, 167], "artifact": [6, 9, 10, 16, 17, 22, 71, 111, 112, 115], "artifici": [1, 2, 3, 5, 6, 8, 11, 41, 44, 49, 52, 54, 59, 77, 78, 83, 87, 88, 89, 90, 91, 93, 97, 100, 111, 112, 122, 129, 130], "artist": [5, 7, 111, 112, 149], "artistri": 2, "artner": 107, "artwork": [2, 5], "arxiv": [0, 6, 8, 9, 53, 99], "as_target_token": 30, "asana": 167, "asarrai": 150, "ascet": [111, 112], "ascii": 98, "asd": [111, 112], "ase": 101, "ases": 101, "ashish": 0, "ashkenazi": [111, 112], "ashraq": [101, 107, 108], "ashraq___parquet": [101, 107, 108], "asian": 152, "asid": [111, 112, 116, 181], "ask": [9, 30, 64, 100, 111, 112, 116, 136, 152, 155, 159, 178, 180], "asleep": [111, 112], "aspect": [2, 7, 9, 42, 45, 49, 50, 53, 54, 55, 57, 59, 60, 62, 65, 71, 74, 76, 77, 80, 89, 93, 95, 96, 98, 100, 106, 111, 112, 113, 116, 122, 126, 129, 133, 134, 136, 138, 139, 140, 151, 156, 160, 166, 169, 170, 171, 172], "asperg": [111, 112], "ass": 101, "assail": [111, 112], "assassin": [111, 112], "assembl": 119, "assembli": [58, 111, 112, 164, 169], "assert": [152, 172], "assess": [9, 38, 46, 53, 63, 71, 74, 85, 89, 111, 112, 120, 137, 147, 165, 166, 169, 171], "assessor": [111, 112], "asset": [24, 30, 44, 77, 101, 118, 119, 128, 145, 152], "assign": [9, 37, 59, 70, 75, 90, 111, 112, 113, 114, 115, 119, 120, 126, 127, 131, 132, 133, 134, 136, 137, 140, 144, 151, 152, 154, 158, 161, 167, 171], "assimil": 46, "assist": [2, 5, 38, 42, 48, 50, 53, 59, 88, 89, 91, 98, 111, 112, 131, 143], "assistantag": 42, "associ": [0, 1, 8, 9, 10, 12, 49, 50, 52, 59, 63, 71, 74, 76, 77, 86, 92, 93, 98, 100, 105, 106, 107, 111, 112, 116, 119, 120, 122, 126, 127, 129, 134, 135, 136, 137, 139, 143, 147, 150, 151, 154, 155, 157, 169, 171], "assum": [40, 67, 72, 84, 97, 105, 130, 132, 133, 138, 151, 157, 176, 178, 181], "assumpt": [89, 111, 112, 145, 147, 151, 156, 157, 172], "assur": [12, 55, 166, 169, 170, 171, 172], "asterisk": 54, "asteroid": [111, 112], "astroblem": [111, 112], "astronom": [111, 112], "astronomi": [111, 112], "astyp": [25, 31], "asuncion": 152, "asx": 152, "asymmetr": [76, 77, 78, 152], "asymmetri": [111, 112], "ata": 101, "ate": [101, 140], "ates": 101, "atheism": 150, "atheist": 150, "athenian": [111, 112], "athlet": [59, 111, 112, 130], "ati": 101, "ating": 101, "ation": 101, "ativ": 101, "atkin": [111, 112], "atlanta": [111, 112], "atlassian": [65, 160], "atmospher": [3, 111, 112], "atom": [3, 53], "atop": 128, "atp": [111, 112], "attach": [77, 111, 112, 123, 140], "attack": [9, 52, 63, 77, 111, 112, 119], "attain": [6, 52, 92, 111, 112, 117], "attempt": [111, 112, 134, 151, 167, 175, 177], "attend": [6, 10, 52, 87, 88, 111, 112, 116, 117], "attent": [0, 1, 6, 8, 9, 10, 11, 12, 46, 53, 55, 59, 88, 89, 92, 96, 98, 100, 104, 111, 112, 115, 117, 130, 138, 154, 181], "attention_mask": [100, 104, 110, 112], "attention_probs_dropout_prob": 112, "attitud": [111, 112, 118, 136], "attngan": 11, "attornei": [111, 112], "attract": [5, 111, 112, 151], "attribut": [2, 9, 42, 43, 44, 59, 93, 98, 100, 104, 111, 112, 134, 140, 150, 165], "attun": 135, "atur": 101, "atyp": [111, 112], "au": 101, "auburn": [111, 112], "aud400": 152, "aud450": 152, "audienc": [98, 111, 112, 134, 167], "audio": [0, 9, 50, 59, 72, 116, 121, 150], "audit": [12, 64, 119, 120, 123, 159], "auditor": [111, 112], "aug": 152, "augment": [1, 2, 9, 10, 42, 46, 47, 50, 52, 88, 93, 100, 105, 120, 130, 131], "august": [0, 101, 111, 112], "augusta": 5, "auprc": 14, "auroc": 14, "aurora": 3, "austral": [111, 112], "australia": [0, 152], "authent": [1, 45, 46, 64, 70, 76, 78, 80, 82, 159], "author": [6, 9, 10, 77, 78, 84, 95, 111, 112, 115, 116, 117, 120, 174, 175, 180, 184], "authoris": 176, "authoritarian": [111, 112], "authorized_kei": [80, 81], "authorship": [2, 93], "autism": [111, 112], "autismu": [111, 112], "autist": [111, 112], "auto": [16, 17, 19, 24, 28, 42, 73, 74, 97, 98, 100, 101, 103, 108, 110, 111, 112, 114, 128, 136, 175, 177], "auto_pip_depend": 73, "autocomplet": [98, 130], "autocrat": [111, 112], "autoencod": [6, 11, 126], "autogen": [1, 47], "autogpt": [42, 44], "autoimmun": [111, 112], "autom": [6, 12, 38, 42, 44, 53, 55, 56, 60, 63, 64, 65, 66, 69, 75, 85, 93, 121, 130, 159, 160, 165, 166, 167, 169, 170, 171], "automag": 175, "automak": 152, "automat": [6, 7, 8, 30, 59, 64, 71, 73, 74, 88, 98, 104, 111, 112, 130, 134, 136, 138, 140, 141, 145, 159, 165, 174, 177, 178, 182], "automl": [1, 35, 36, 37], "automobil": [111, 112], "automodel": 114, "automodelforseq2seqlm": 51, "automot": [50, 111, 112], "autonom": [42, 44, 50, 53, 54, 59, 111, 112], "autonomi": [42, 44, 57, 111, 112], "autonotebook": [100, 101, 103, 108, 110, 111, 112, 114, 136], "autopilot": 6, "autoregress": [0, 6, 8, 9, 109, 111, 115, 117, 130], "autosc": 55, "autoscrap": [1, 44, 47], "autotoken": [104, 111, 112, 114], "autotrain": [1, 46, 47], "autotrain_project_nam": 45, "autreat": [111, 112], "aut\u00f3": [111, 112], "aux": [60, 144], "auxiliari": [8, 9, 46, 88, 100, 111, 112], "av": 145, "avail": [6, 8, 9, 12, 23, 24, 30, 36, 37, 38, 42, 46, 50, 52, 53, 59, 60, 61, 64, 65, 66, 69, 71, 76, 79, 83, 88, 89, 93, 95, 100, 104, 110, 111, 112, 114, 115, 117, 119, 120, 121, 125, 127, 130, 132, 133, 135, 136, 139, 141, 148, 150, 159, 160, 167, 169, 172, 185], "avatar": 6, "avenu": [2, 40, 52, 89], "averag": [26, 27, 84, 101, 111, 112, 113, 114, 115, 117, 119, 120, 124, 128, 132, 133, 135, 144, 145, 147, 152, 154], "average_coher": 152, "aveyron": [111, 112], "avg": [14, 16, 22, 29, 30, 35, 135, 136], "avid": 22, "avoc": [111, 112], "avoid": [6, 10, 17, 30, 49, 51, 54, 55, 89, 95, 97, 100, 102, 106, 111, 112, 116, 132, 133, 145, 181], "avx": 152, "avx2": [14, 22, 100, 152], "aw": [59, 64, 71, 159, 167, 169], "awai": [111, 112, 115, 136], "await": 178, "awaken": [111, 112], "awar": [7, 10, 12, 30, 55, 57, 63, 89, 91, 109, 111, 112, 114, 120, 130, 135, 154, 157], "awesom": 97, "ax": [23, 24, 25, 26, 27, 31, 32, 149], "ax2": [25, 32], "axessubplot": 15, "axi": [14, 31, 110, 111, 112, 136, 152, 155], "axial": 116, "axno": [23, 24, 25], "axvspan": 32, "ayb": [111, 112], "ayp": [111, 112], "ayq": 0, "az": 95, "aza": [111, 112], "azerbaijani": 95, "azur": [59, 64, 85, 159], "a\uac70\ub798\uc18c": 20, "b": [9, 16, 17, 22, 51, 53, 55, 67, 68, 74, 78, 88, 97, 101, 108, 111, 112, 114, 115, 117, 119, 120, 124, 147, 148, 151, 152, 174, 175, 177, 178, 180, 182], "b101602": [177, 179, 180], "b1osgjx9": 135, "b305c5107a17618f2938a067d5ffcbb556909d82398762089": 135, "b41f869": 183, "b4befef": 175, "b63f764": 174, "b86f514977d51ee81aaea6b10573b8fd9bfd0a38": 184, "b943bed": [176, 177, 179], "b_": [119, 120, 145], "b_i": 148, "ba": [99, 101], "bab2min": 0, "babbl": [111, 112], "babel": 6, "babi": 139, "back": [5, 8, 9, 28, 46, 53, 59, 64, 71, 72, 80, 88, 101, 110, 111, 112, 119, 120, 127, 132, 133, 136, 144, 148, 152, 159, 174, 175, 177, 178, 180], "backbon": [6, 48, 51], "backend": [15, 20, 24, 30, 60, 69, 77, 79, 167, 181], "backend_pdf": 181, "backend_token": 104, "background": [47, 54, 89, 111, 112, 116, 130, 134], "backlash": 120, "backlog": [171, 172], "backpropag": [8, 88], "backtrack": 53, "backup": 173, "backward": [30, 88, 112, 116, 127, 128, 145], "bacon": [129, 158], "bacteria": [6, 142], "bad": [95, 117, 136, 175, 181, 184], "bag": [1, 111, 112, 126, 129, 138, 139, 145, 146, 150, 154, 156, 158], "bah\u00e1\u02bc\u00ed": [111, 112], "bai": [111, 112], "bake": 100, "baker": [0, 111, 112, 119], "bakeri": 139, "bakunin": [111, 112], "bakuninist": [111, 112], "balanc": [23, 25, 26, 27, 28, 41, 42, 45, 46, 52, 53, 55, 77, 88, 92, 93, 97, 102, 106, 111, 112, 115, 116, 133, 136, 167], "balanced_diff": [23, 25, 26, 27, 28, 29, 33, 35], "baldwin": [111, 112], "ballerina": 6, "ballot": 119, "bamboo": [65, 160], "ban": [101, 111, 112], "banana": [127, 133], "banc": 101, "band": [111, 112], "bang": [111, 112], "bangla": 95, "bank": [1, 36, 37, 43, 99, 101, 111, 112, 120, 130, 137, 152], "banker": 43, "bankhead": [111, 112], "bap": 130, "bapeul": 130, "baptist": [0, 111, 112], "bar": [85, 101, 111, 112, 114, 128, 136, 149, 150, 155, 156], "barachia": [111, 112], "barb": [111, 112], "barbasol": [111, 112], "barber": [111, 112], "barcelona": [111, 112], "bard": [42, 49, 93], "bare": [75, 185], "bare_dir": 185, "bare_repo": 185, "barh": 155, "barret": 0, "barri": 0, "barrier": [6, 98, 115], "barsetshir": 174, "bart": [95, 97, 100], "barth": 0, "barto": 53, "barua": 0, "base": [0, 1, 4, 5, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 38, 42, 44, 46, 49, 51, 53, 54, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 81, 83, 84, 86, 88, 89, 91, 92, 93, 95, 97, 98, 99, 100, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 166, 167, 169, 170, 171, 172, 173, 179], "base_dir": 30, "basebal": [96, 111, 112, 129], "baselin": [1, 36, 37, 51, 71, 169], "basenam": 181, "basesentimentanalys": 30, "basesnorkel": 20, "bash": [45, 79, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "bashag": 79, "basi": [60, 83, 88, 111, 112, 139, 153, 155, 167], "basic": [1, 4, 37, 46, 67, 75, 76, 80, 87, 92, 107, 108, 111, 112, 116, 118, 129, 130, 134, 139, 140, 144, 153, 157], "basicconfig": [23, 25, 26, 27, 28, 30, 35], "basqu": 95, "basra": [111, 112], "bass": 137, "bassett": [111, 112], "batch": [10, 15, 20, 21, 24, 30, 45, 55, 71, 88, 110, 111, 112, 128], "batch_dir": 20, "batch_siz": [45, 111, 127, 128], "batcher": [15, 16, 17, 20, 24, 30], "batr": [111, 112], "battalion": [111, 112], "battl": [111, 112, 115], "bay": [105, 134, 137, 138], "bayou": [111, 112], "bazaar": 185, "bbd16": 0, "bc": [111, 112], "bd": 147, "bdrf": [111, 112], "bdvj03": 0, "beach": [111, 112], "beacon": [177, 179, 180], "beam_output": 97, "bean": [156, 158], "bear": 156, "bearish": 128, "beat": [101, 117, 152], "beaufort": [111, 112], "beauti": [3, 140, 158], "beautifulsoup": [12, 43, 93, 121, 123], "beautifulsoup4": 123, "becam": [111, 112], "becaus": [8, 9, 10, 24, 28, 41, 53, 60, 71, 88, 90, 92, 95, 97, 99, 108, 110, 111, 112, 113, 114, 115, 116, 128, 130, 132, 136, 140, 142, 143, 145, 147, 152, 153, 172, 175, 176, 177, 178], "becom": [5, 9, 12, 41, 46, 50, 52, 53, 59, 62, 63, 64, 73, 77, 84, 88, 90, 91, 93, 97, 98, 99, 102, 106, 111, 112, 115, 116, 122, 126, 128, 130, 134, 138, 139, 140, 142, 145, 146, 152, 159, 163, 166, 172, 181], "bed": [111, 112], "bedford": [111, 112], "bedrock": [111, 112], "been": [2, 5, 6, 8, 9, 10, 11, 12, 13, 17, 41, 42, 45, 49, 53, 54, 63, 76, 77, 83, 85, 86, 90, 93, 97, 98, 99, 100, 103, 104, 106, 110, 111, 112, 115, 116, 117, 118, 120, 121, 128, 130, 133, 135, 136, 138, 141, 142, 147, 150, 151, 152, 153, 166, 171, 174, 176, 178, 180, 183, 184], "beer": 156, "befor": [7, 9, 16, 17, 22, 45, 51, 63, 64, 72, 76, 81, 82, 88, 89, 93, 97, 99, 100, 101, 104, 105, 108, 110, 111, 112, 114, 116, 117, 120, 126, 128, 132, 133, 136, 138, 139, 140, 142, 146, 147, 148, 150, 152, 154, 159, 171, 172, 174, 175, 177, 178, 181, 183], "beforehand": [105, 148], "began": [55, 111, 112, 121], "begin": [8, 24, 45, 46, 51, 52, 59, 96, 104, 108, 111, 112, 116, 125, 128, 129, 130, 136, 139, 157, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185], "begun": 56, "behalf": 42, "behav": [10, 59, 92], "behavior": [6, 12, 30, 40, 44, 46, 51, 57, 59, 61, 62, 83, 85, 91, 100, 111, 112, 114, 116, 118, 144], "behaviour": [111, 112], "behind": [9, 89, 92, 97, 98, 105, 111, 112, 116, 133, 134, 147, 150, 151, 170, 171, 185], "beigebook": 30, "being": [1, 2, 6, 8, 11, 12, 41, 42, 49, 50, 51, 52, 56, 62, 64, 71, 77, 82, 86, 88, 90, 91, 97, 111, 112, 113, 115, 116, 117, 128, 130, 132, 136, 139, 147, 149, 152, 156, 158, 159, 171, 177, 178], "beings": 130, "belarusian": 95, "belief": [41, 97, 111, 112], "believ": [24, 30, 96, 97, 111, 112, 115, 129, 130, 150], "bell": 142, "bellman": 53, "bellsouth": [111, 112], "belong": [9, 88, 116, 130, 138, 144, 150, 151], "below": [12, 42, 51, 52, 95, 111, 112, 120, 152, 173, 174], "belt": [111, 112], "beman": 155, "ben": [23, 177, 180], "benann": 10, "bench": [111, 112], "benchmark": [6, 49, 53, 59, 85, 89, 98, 99, 122, 134, 172], "bend": [111, 112], "beneath": [111, 112], "benefici": [12, 46, 52, 55, 89, 92, 103, 105, 106, 111, 112, 117, 120, 126, 143, 148, 172], "benefit": [7, 9, 49, 50, 53, 59, 60, 63, 66, 76, 83, 88, 98, 111, 112, 115, 116, 130, 150, 154, 167], "bengio": [0, 53, 127, 128], "bengio03a": 0, "benjamin": [111, 112], "bento": 72, "bentoml": [1, 70, 74], "benz": [111, 112], "ber": 101, "berkelei": [6, 83], "berlin": 0, "bermano": [0, 6], "bernank": 23, "berneri": [111, 112], "bernoulli": 132, "berri": 114, "bert": [0, 1, 9, 12, 45, 47, 53, 55, 95, 96, 98, 104, 108, 109, 110, 112, 116, 117, 126, 130, 138, 146], "bert_base_uncas": [110, 112], "bertasiu": [0, 116], "bertconfig": 112, "bertformaskedlm": [110, 112], "bertforpretrain": [14, 16, 17, 22, 110], "bertforsequenceclassif": [14, 16, 17, 22, 110], "bertin": [0, 95], "bertmodel": [112, 114], "bertnorm": 103, "bertrand": [111, 112], "berttoken": 114, "berttokenizerfast": 110, "bertviz": 114, "bertwordpiecetoken": 112, "besb": 72, "besid": [9, 111, 112], "best": [9, 24, 29, 30, 35, 45, 53, 66, 68, 70, 71, 76, 89, 91, 92, 97, 101, 103, 105, 107, 111, 112, 115, 116, 117, 122, 130, 138, 145, 146, 147, 151, 152, 155, 166, 167, 172, 182], "best_count": 101, "best_estim": [29, 35], "best_model": [14, 19, 22], "best_model_dir": 19, "best_pair": [101, 108], "best_score_at_start": [107, 108], "best_segment": [107, 108], "besta": 53, "bestow": 42, "bet": [101, 145], "beta": [5, 8, 93, 130], "beta_": 151, "beta_k": 151, "bethg": [0, 6], "better": [9, 12, 28, 38, 41, 42, 46, 49, 50, 52, 53, 54, 55, 57, 62, 63, 64, 65, 71, 76, 77, 79, 80, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 100, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 125, 128, 130, 132, 133, 136, 137, 138, 143, 147, 148, 150, 151, 155, 157, 159, 160, 166, 172, 173, 183], "between": [2, 6, 7, 8, 9, 10, 11, 23, 36, 38, 42, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 59, 62, 63, 64, 65, 66, 71, 73, 74, 76, 77, 78, 82, 84, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 106, 111, 112, 113, 114, 116, 117, 119, 120, 122, 124, 125, 126, 127, 129, 130, 132, 133, 135, 136, 137, 138, 139, 143, 144, 145, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 159, 160, 171, 172, 177, 180, 181, 183, 185], "beverag": [111, 112], "bewild": [111, 112], "beyer": 0, "beyond": [2, 42, 46, 49, 50, 52, 54, 55, 57, 71, 88, 91, 116, 120, 126, 139, 171], "bf5c643": 180, "bg": [95, 120], "bgjm16": 0, "bgk": 0, "bgm": 149, "bhk": 0, "bhm": [111, 112], "bi": [99, 101, 111, 112], "bia": [12, 14, 16, 17, 22, 45, 47, 49, 50, 53, 55, 59, 74, 83, 85, 92, 93, 95, 110, 111, 112, 117, 126, 127, 128, 130, 132, 157], "bias": [16, 17, 22, 30, 50, 53, 55, 59, 70, 71, 74, 86, 90, 92, 93, 95, 98, 109, 120, 130, 137, 143], "bibl": [111, 112], "biblic": [111, 112], "bibliographi": 1, "bicamer": [111, 112], "bicub": 9, "bicycl": 59, "bid": [111, 112], "bidirect": [0, 1, 52, 96, 98, 99, 111, 112, 116, 130, 154], "bidirection": 112, "biederman": 97, "big": [3, 12, 13, 21, 38, 39, 41, 101, 106, 111, 112, 119, 121, 128, 136, 139, 150, 163, 176, 177, 180, 181], "bigger": [107, 108, 111, 112, 117], "biggest": [108, 139, 152], "bigram": [119, 120, 133, 138, 143, 149], "bigram_model": 133, "bigramassocmeasur": 149, "bigramcollocationfind": 149, "bigscienc": 51, "bike": 59, "bil": 101, "bilinear": [9, 136], "bill": [111, 112, 120, 144], "billion": [9, 45, 49, 52, 78, 93, 111, 112, 115, 117, 122, 130, 152], "bin": [0, 6, 15, 24, 26, 42, 60, 79, 95, 100, 112, 114, 124, 152], "binari": [14, 22, 53, 60, 84, 88, 99, 100, 111, 112, 119, 126, 128, 136, 154, 157], "bind": [8, 9], "bingl": 155, "bio": 101, "biodivers": [111, 112], "biographi": [111, 112], "bioinformat": 150, "biolog": [111, 112], "biologi": 85, "biologist": 88, "biom": [111, 112], "biomed": 93, "biometr": 78, "bipartit": 9, "birch": 0, "bird": [3, 111, 112, 129, 130], "birmingham": [111, 112], "birth": [111, 112], "bisect": [1, 161, 186], "bisect_dir": 184, "bisectdemo": 184, "bisexu": [111, 112], "bist": 117, "bit": [3, 8, 101, 132, 178], "bitbucket": [65, 76, 160], "bitcoin": 77, "bite": [111, 112], "bitstream": 28, "bitter": [111, 112], "bl": 101, "black": [40, 41, 111, 112], "blain": [111, 112], "blair": [111, 112], "blame": [111, 112], "blank": [8, 81, 117, 136], "blanket": [10, 111, 112], "blast": [111, 112], "blazer": [111, 112], "ble": 101, "bleed": [111, 112], "blei": 152, "blend": [6, 42, 44, 55, 111, 112, 168], "blendsearch": [35, 42], "bless": 120, "bleu": [55, 109], "bleuler": [111, 112], "blind": [111, 112], "blindism": [111, 112], "blo": 101, "blob": 9, "bloc": [111, 112], "block": [8, 9, 10, 59, 88, 111, 112, 116, 117, 133, 154], "block_siz": [45, 111], "blockchain": 12, "blog": [8, 9, 12, 51, 52, 53, 93, 99, 101, 134], "blogger": 120, "blogpost": 51, "bloom": [0, 97, 120], "bloomz": 51, "blue": [32, 111, 112, 113, 114, 155, 158], "blueprint": [45, 167, 169, 172], "blur": [9, 56], "blurri": 8, "bm25": 55, "bmo": 128, "bn": 95, "bo": 101, "board": [0, 53, 111, 112, 121], "boardseq": 94, "boast": [85, 111, 112], "bob": [111, 112], "bobbl": 155, "bodi": [0, 89, 111, 112, 156], "bodmin": 178, "bohemian": [111, 112], "boi": [111, 112, 120], "boil": 126, "boilerpl": 69, "bojanowski": [0, 124], "bok": [120, 137], "boll": [111, 112], "bolshev": [111, 112], "bolshevik": [111, 112], "bolster": [49, 59], "bommasani": 0, "bon": [101, 107], "bonanno": [111, 112], "bond": [101, 111, 112], "bone": [111, 112], "bonsai": 6, "bonu": 140, "bonum": 140, "boo": 101, "book": [14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 49, 93, 95, 96, 97, 100, 101, 111, 112, 117, 128, 130, 139, 145, 152, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "bookcorpu": 109, "boom": [12, 184], "boost": [12, 73, 128], "bootstrap": [53, 64, 66, 69, 159], "boqe": 0, "border": [111, 112], "bore": 97, "borgeaud": 0, "borgu": [111, 112], "borisdayma": 8, "born": [111, 112], "borrow": [100, 111, 112, 120, 128], "bos_id": [103, 105], "bos_piec": [103, 105], "bos_token_id": 111, "bosma": 0, "boston": 119, "bot": [49, 72, 121], "botch": [111, 112], "botchan": 105, "both": [0, 6, 7, 8, 9, 10, 40, 41, 49, 50, 52, 53, 54, 55, 57, 59, 64, 69, 71, 72, 73, 76, 77, 79, 88, 89, 91, 92, 95, 96, 97, 98, 99, 100, 105, 110, 111, 112, 114, 115, 116, 120, 126, 129, 130, 136, 138, 142, 144, 145, 147, 149, 150, 151, 154, 155, 156, 158, 159, 163, 164, 167, 170, 172, 175, 176, 177, 180, 183, 184], "bottl": 156, "bottleneck": [12, 59], "bottom": [8, 128, 148], "bought": [114, 128], "bound": [10, 88, 139, 151], "boundari": [2, 5, 7, 46, 52, 88, 95, 111, 112, 114, 130, 139, 140, 142, 153, 167], "bourgeoi": [111, 112], "bow": [138, 153], "bowl": [111, 112], "box": [24, 30, 40, 41, 51, 62, 73, 84, 88, 115, 139, 177], "boycott": [111, 112], "boyd": [111, 112], "bp": 152, "bpe": [1, 8, 96, 99, 102, 111, 115], "bpe_gpt_token": 103, "bpe_token": 103, "bpe_tokenizer_path": 103, "bpetrain": [103, 111], "br": 101, "bracket": [117, 124], "bradlei": [111, 112], "brain": [10, 49, 100, 111, 112, 116, 130], "brainard": 24, "brainstorm": 167, "branch": [0, 1, 53, 64, 111, 112, 130, 132, 133, 159, 161, 173, 174, 176, 179, 181, 183, 184, 185, 186], "branching_threshold": 145, "branchingentropytoken": 145, "brand": 134, "brandon": 0, "brassier": [111, 112], "brave": [1, 4], "brazil": [111, 112], "brdf": [111, 112], "brea": 101, "breach": [12, 63, 64, 77, 159], "breadth": [42, 97], "break": [8, 30, 53, 55, 63, 65, 71, 79, 91, 95, 98, 100, 101, 102, 103, 105, 106, 108, 111, 112, 116, 130, 136, 139, 140, 142, 143, 144, 145, 146, 153, 160, 167, 171, 184], "break_output": 184, "breakdown": [43, 111, 112, 116, 153, 169], "breakfast": 158, "breakm": 184, "breakthrough": [6, 8, 116], "brecht": 181, "brett": [111, 112], "brew": 79, "brian": [0, 6], "bridg": [44, 54, 56, 59, 63, 65, 73, 100, 111, 112, 160], "bridgeport": [111, 112], "brief": [9, 52, 100, 110, 141], "briefli": [130, 167, 170], "bright": [111, 112], "brighton": [111, 112], "brill": 0, "brillig": 183, "bring": [6, 10, 42, 98, 111, 112, 183], "britain": [111, 112], "british": [111, 112], "brittl": [8, 85], "bro": 101, "broad": [6, 46, 48, 49, 50, 52, 54, 59, 92, 111, 112, 113, 130, 157], "broadband": [111, 112], "broaden": [50, 52, 54, 55, 59, 120], "broader": [50, 53, 70, 71, 85, 88, 89, 97, 111, 112, 116, 134, 137, 164], "broadli": [74, 77, 111, 112, 126, 152], "broke": 130, "broken": [97, 104, 117, 130, 139, 140, 144, 146, 184], "brokerag": 128, "bromin": [111, 112], "brook": [111, 112, 133], "brooklei": [111, 112], "broth": 142, "brother": [111, 112, 119], "brought": [50, 83, 111, 112], "brown": [53, 111, 112, 115, 132, 142, 144, 155, 158], "brows": [69, 85], "browser": [88, 121, 176, 177], "bryant": [111, 112], "br\u00e9gier": [111, 112], "bs4": 123, "bsr": 9, "bu": [101, 111, 112], "bubbl": [111, 112], "bucket": [124, 143], "buddharaksa": [111, 112], "buddhism": [111, 112], "buddhist": [111, 112], "budget": [42, 49, 51, 111, 112, 168, 169, 172], "buffer": 145, "buford": [111, 112], "bug": [68, 73, 89, 98, 166, 169, 173, 178, 180, 184], "buggi": 184, "bui": [101, 128, 152], "build": [1, 3, 6, 9, 12, 17, 18, 37, 46, 49, 54, 59, 64, 65, 70, 71, 72, 73, 75, 85, 97, 98, 106, 111, 112, 113, 122, 126, 129, 130, 133, 134, 135, 139, 146, 147, 151, 159, 160, 171, 172, 177, 183], "buildctl": 60, "builder": 136, "buildkit_host": 60, "buildkitd": 60, "built": [6, 20, 28, 46, 53, 60, 61, 62, 64, 65, 66, 71, 73, 74, 77, 78, 88, 105, 111, 112, 116, 121, 135, 137, 144, 159, 160, 166, 169, 181, 183], "builtin": 15, "bulgarian": [95, 115], "bulk": [111, 112], "bull": 128, "bullet": 139, "bump": 108, "bunch": [150, 181, 184], "bundl": [69, 121], "burden": [50, 52, 111, 112], "bureau": [0, 111, 112], "bureaucrat": [111, 112, 120], "burgeon": [38, 59], "burgess": [0, 120], "burial": [111, 112], "burlap": [111, 112], "burmes": 95, "burn": [111, 112, 152], "burn_in": 152, "buse": 167, "bushi": 100, "busi": [12, 45, 59, 63, 64, 65, 71, 77, 111, 112, 121, 123, 134, 152, 159, 160, 165, 169, 171, 172], "busiest": [111, 112], "butter": 46, "butterfli": 16, "button": [67, 68, 72, 76, 82, 111, 112, 121, 177, 178], "bwt21": 0, "by3oe75k": 16, "by3oe75ksync": 16, "bypass": [46, 82, 111, 112], "byrn": [111, 112], "byt5": [0, 1, 96, 116], "byte": [0, 1, 9, 96, 99, 101, 105, 111, 116, 146], "byte_fallback": [103, 105], "bytelevel": 111, "bytepair": 101, "bzr": 185, "c": [0, 10, 49, 51, 67, 69, 74, 78, 80, 88, 95, 97, 99, 101, 104, 105, 108, 111, 112, 115, 116, 119, 128, 132, 133, 139, 142, 145, 147, 151, 152, 155, 157, 169, 174, 181], "c3": 135, "c4": 95, "c608fbcd461a99d00c2d71d26c64bd6fb26c6c71": 184, "c626438": 100, "c_": [128, 147, 149], "c_i": 119, "c_j": 119, "c_npmi": 152, "c_uci": [149, 152], "c_v": [147, 149, 152], "ca": [78, 95, 101], "cabinet": [111, 112], "cac": 152, "cach": [14, 15, 16, 17, 19, 20, 21, 22, 24, 29, 30, 42, 55, 56, 60, 61, 94, 100, 101, 103, 107, 108, 110, 111, 112, 114, 128, 132, 135, 136, 141, 145, 150, 152, 185], "cache_dir": 17, "cached_dev_electra_256_10_2": [14, 22], "cached_dev_electra_256_2_2": 14, "cached_dev_electra_256_3_2": [14, 22], "cached_dev_electra_512_2_2": 14, "cached_path": [15, 16, 17, 19, 20, 21, 22, 24, 29, 30, 128, 145, 152], "cached_path_cache_root": [15, 16, 17, 19, 20, 21, 22, 29], "cached_train_electra_256_10_2": [14, 22], "cached_train_electra_256_2_2": 14, "cached_train_electra_256_3_2": [14, 22], "cached_train_electra_512_2_2": 14, "cacl2": 142, "cadair": [180, 181], "cadr": [111, 112], "cafe": [5, 130], "cahaba": [111, 112], "cahokia": [111, 112], "cai": [0, 6], "cairngorm": [177, 180], "cake": 100, "calcium": [111, 112], "calcul": [9, 20, 23, 24, 28, 52, 88, 94, 95, 97, 107, 108, 111, 112, 113, 114, 116, 117, 119, 127, 128, 133, 137, 139, 145, 148, 149, 150, 152, 157, 158], "calendar": 31, "calib": [111, 112], "calibr": 85, "california": 6, "call": [5, 6, 8, 9, 10, 16, 17, 19, 21, 24, 29, 30, 38, 53, 56, 59, 60, 62, 64, 72, 77, 83, 88, 95, 97, 99, 100, 101, 103, 104, 105, 111, 112, 113, 114, 116, 117, 119, 120, 124, 126, 128, 132, 136, 137, 140, 145, 146, 148, 151, 152, 153, 157, 159, 167, 170, 173, 175, 176, 178, 183], "calvert": [111, 112], "cambodia": [111, 112], "came": [5, 105, 111, 112, 152], "camel": 83, "camelcas": 145, "camelid": [1, 86, 87], "camellia": [111, 112], "camera": [6, 9], "camil": [111, 112], "camillo": [111, 112], "camouflag": [111, 112], "camp": 108, "campa": 108, "campai": 108, "campaig": 108, "campaign": [0, 108, 111, 112], "campbel": [111, 112], "campu": [111, 112], "campus": [111, 112], "can": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 30, 35, 38, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 164, 165, 166, 167, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "canad": 101, "canada": [111, 112], "canadian": [101, 111, 112, 130], "candid": [0, 8, 30, 59, 84, 97, 108, 111, 112, 116, 120, 134], "candidate_label": 100, "canebrak": [111, 112], "cannot": [9, 14, 40, 41, 42, 57, 105, 111, 112, 120, 124, 143, 152, 153], "canon": 104, "canopi": [111, 112], "canyon": [111, 112], "cap": [59, 101, 111, 112], "capabl": [2, 5, 6, 7, 8, 9, 38, 42, 44, 45, 46, 49, 50, 52, 54, 55, 56, 57, 59, 64, 69, 71, 73, 74, 77, 83, 85, 86, 88, 91, 93, 100, 105, 112, 113, 116, 122, 130, 136, 139, 146, 154, 159], "capac": [1, 42, 49, 50, 57, 59, 100, 111, 112, 126, 163], "capit": [56, 84, 100, 101, 111, 112, 115, 119, 136, 139], "capita": [111, 112], "capitalist": [111, 112], "capitol": [111, 112], "cappuccino": 147, "capshaw": [111, 112], "caption": [8, 9, 122, 130], "captiv": [100, 126], "captur": [1, 4, 8, 9, 10, 12, 46, 49, 50, 52, 55, 59, 64, 86, 88, 91, 92, 98, 106, 109, 113, 114, 116, 120, 123, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 143, 147, 148, 150, 151, 153, 154, 157, 159, 172], "capybara": 8, "car": [46, 97, 101, 111, 112, 133, 137, 149, 152], "carbon": [111, 112], "carbonel": [0, 99], "card": [12, 40, 77, 78, 83], "cardin": 10, "care": [12, 50, 53, 55, 71, 89, 98, 101, 110, 111, 112, 136, 146, 174, 176], "career": [97, 111, 112, 130], "carefulli": [6, 45, 46, 53, 57, 97, 98, 100, 115, 117, 150, 171, 172], "caregiv": [111, 112], "caret": [111, 112], "cargo": 79, "carl": 130, "carlo": [53, 151], "carnivalesqu": [111, 112], "carol": 183, "carolin": [0, 6, 111, 112], "carollian": 183, "carpentri": 185, "carr": [111, 112], "carri": [1, 77, 111, 112, 114, 116, 121, 138, 139, 146, 150], "carrier": 152, "carv": 59, "case": [0, 8, 9, 40, 42, 45, 46, 48, 49, 52, 55, 58, 59, 64, 65, 67, 74, 76, 81, 83, 88, 89, 97, 98, 100, 105, 108, 111, 112, 113, 114, 115, 116, 117, 128, 130, 132, 133, 136, 137, 139, 140, 142, 145, 147, 150, 151, 152, 154, 157, 159, 160, 165, 167, 169, 178, 180, 183], "casein": [111, 112], "cash": [111, 112, 152], "casino": [111, 112], "cassoulet": 156, "cast": [10, 111, 112], "casualti": 152, "cat": [100, 113, 117, 126, 132, 139, 147, 149, 153, 174, 175, 176, 177, 180], "cat18": 0, "cat_preds_df": 19, "catalan": [95, 111, 112], "catalinac": [0, 120], "catalog": [111, 112], "catalyz": 50, "catastroph": 51, "catch": [64, 65, 139, 140, 159, 160], "categor": [6, 12, 74, 77, 89, 97, 98, 99, 111, 112, 130, 134, 137], "categori": [1, 9, 15, 18, 37, 42, 56, 59, 65, 74, 89, 98, 111, 112, 116, 126, 130, 133, 135, 137, 140, 143, 144, 150, 151, 160, 167], "categoris": [111, 112], "category_data": 21, "category_pr": 21, "category_preds_df": [19, 21], "category_record": 19, "cater": [52, 151], "catfish": [111, 112], "cathedr": [111, 112], "cathol": [111, 112], "catholic": [111, 112], "cattl": [111, 112], "caught": [111, 112], "caus": [9, 10, 64, 65, 92, 93, 97, 111, 112, 117, 120, 130, 143, 159, 160, 177, 184], "causal": [9, 98, 109, 111, 117], "causal_language_model": 51, "caution": [97, 147], "cavalri": [111, 112], "cave": [111, 112], "caveat": 143, "cavern": [111, 112], "caviti": [111, 112], "cb": [12, 13, 111, 112], "cbow": [124, 154], "cbow_model": 128, "cbow_test": 128, "cbspeeches_list": 43, "cc": [14, 22, 95, 100, 103, 105, 144], "cc360cb": [177, 179, 180], "ccnet": 95, "cconj": 144, "cd": [56, 64, 66, 68, 70, 71, 75, 79, 80, 81, 159, 170, 178, 185], "cd27": 183, "cdc": [111, 112], "cdd": [111, 112], "cdn": [9, 55], "cdot": [8, 84, 105, 106, 119, 126, 147, 148, 157], "ce": [101, 111, 112], "ce8bddc": 177, "ceas": [111, 112], "ceb": 95, "cebuano": 95, "cede": [111, 112], "cel": 150, "celebr": [111, 112], "cell": [29, 35, 88, 103, 111, 112, 136], "cen": 101, "censor": 120, "censorship": [82, 120], "censu": [111, 112], "census": [111, 112], "cent": 152, "center": [3, 23, 47, 56, 77, 111, 112, 119, 141, 144, 152], "centervil": [111, 112], "cento": [60, 75, 81], "centr": [111, 112], "central": [1, 10, 36, 37, 38, 43, 49, 61, 63, 65, 66, 93, 95, 98, 111, 112, 116, 120, 137, 147, 154, 160], "centralbank_analysi": 36, "centric": [55, 56, 171], "centroid": 148, "centuri": [5, 111, 112, 150], "ceo": [59, 101, 111, 112], "cere": [111, 112], "ceremoni": [111, 112], "cert": 72, "certain": [8, 10, 44, 46, 49, 50, 53, 55, 59, 71, 88, 90, 92, 93, 97, 102, 104, 106, 111, 112, 116, 117, 130, 132, 138, 140, 142, 150, 151, 157, 172, 181], "certainli": 139, "certainti": 132, "certfil": 72, "certif": [59, 77, 78, 82], "certifi": 166, "cf": 97, "cfa": [111, 112], "cfg": [14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 128, 145, 152], "cgze19": [0, 6], "ch": [101, 152], "cha": 101, "chain": [12, 42, 49, 56, 59, 74, 78, 98, 105, 132, 151], "chainforg": 57, "chair": [24, 30, 32, 130], "chairman": [24, 30], "chairperson": 32, "chalco": 152, "challeng": [1, 2, 6, 8, 9, 10, 37, 39, 42, 52, 59, 70, 74, 75, 76, 78, 83, 85, 86, 90, 95, 97, 98, 102, 106, 108, 111, 112, 115, 116, 126, 129, 130, 132, 137, 138, 140, 143, 151, 153, 156, 164, 165, 167, 170, 172], "cham": 129, "chamber": [111, 112], "champion": [53, 111, 112, 171], "championship": [111, 112, 130], "chan": [0, 6], "chanc": [97, 98, 115, 143, 147, 155, 157], "chang": [0, 1, 8, 9, 10, 12, 14, 23, 25, 28, 42, 44, 46, 50, 52, 56, 64, 65, 66, 71, 74, 76, 80, 85, 97, 103, 104, 106, 107, 108, 110, 111, 112, 119, 120, 128, 130, 132, 137, 139, 140, 144, 151, 152, 155, 159, 160, 163, 164, 165, 166, 169, 171, 172, 173, 179, 182, 183, 184, 185], "changeset": 181, "chanh": [111, 112], "channel": [9, 10, 76, 88, 116, 169], "chao": [111, 112, 166], "chaotic": 166, "chapter": [37, 71], "char": [101, 103, 105], "charact": [0, 95, 101, 103, 104, 105, 106, 107, 111, 112, 115, 122, 136, 139, 142, 143, 145, 146, 154, 174], "character": [93, 98, 111, 112, 115, 148, 151, 169, 171, 172], "character_coverag": [103, 105], "character_freq": [107, 108], "characterawar": 115, "characteris": [111, 112], "characterist": [12, 53, 71, 83, 93, 97, 105, 111, 112, 115, 120, 130, 132, 136, 146, 166], "charcoal": [111, 112], "charg": [111, 112, 139, 176], "charge_": 139, "charl": 34, "charli": 116, "chart": [23, 42, 64, 89, 111, 112, 159, 170], "chase": [59, 100], "chat": [42, 111, 112], "chataigni": [111, 112], "chatbot": [1, 46, 53, 57, 59, 70, 74, 83, 96, 98, 122], "chatdev": 42, "chatgpt": [42, 46, 53, 83, 85, 92, 96], "chaudhari": 0, "chdir": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "che": 101, "cheaha": [111, 112], "cheap": 180, "check": [1, 36, 37, 41, 43, 55, 60, 97, 98, 99, 110, 111, 112, 114, 120, 136, 144, 172, 173, 177, 185], "checklist": [111, 112], "checkout": [67, 68, 173, 175, 178, 180, 182, 183, 184, 185], "checkpoint": [14, 16, 17, 22, 38, 51, 97, 100, 110, 112], "cheer": 133, "cheetah": 6, "chef": [46, 64, 65, 159, 160], "chelat": [111, 112], "chelsea": 0, "chemistri": 150, "chen": [0, 99], "cheng": [0, 6], "cher": [111, 112], "cheroke": [111, 112], "cherri": 180, "chess": 42, "chezmoi": 66, "chi": [101, 108, 111, 112], "chic": 108, "chicago": [111, 112, 119, 139], "chickasaw": [111, 112], "chico": 108, "chief": [111, 112], "chiefli": [111, 112], "chil": 108, "child": [99, 111, 112, 128, 139], "childersburg": [111, 112], "childhood": [111, 112], "children": [111, 112, 136, 139, 150], "chile": 108, "chilton": [111, 112], "chin": [101, 108], "china": [101, 108, 111, 112, 120, 152], "chine": 108, "chines": [0, 49, 93, 95, 102, 105, 108, 120, 139, 140, 145, 152], "chip": [108, 128], "chipo": 108, "chipot": 108, "chipotl": 108, "chitchat": 42, "chmod": 80, "chocol": 145, "choctaw": [111, 112], "choi": [0, 6], "choic": [21, 30, 46, 52, 59, 60, 64, 76, 93, 97, 100, 102, 105, 111, 112, 125, 126, 128, 132, 133, 136, 137, 138, 144, 146, 147, 151, 156, 159, 166, 167, 170, 171, 172, 173, 174], "choices_nam": 21, "chomskyan": 139, "choos": [21, 53, 60, 62, 64, 68, 69, 75, 82, 93, 97, 102, 105, 106, 109, 110, 111, 112, 117, 129, 130, 131, 133, 140, 147, 151, 154, 156, 159, 167, 170, 174, 176, 181], "chop": 150, "chosen": [8, 10, 45, 77, 97, 109, 133, 144, 151, 167, 170, 171, 172], "chown": 80, "cho\ub294": 14, "chracter": 115, "chri": [111, 112], "christ": [111, 112], "christian": [0, 111, 112], "christiano": 34, "christoph": 0, "chroma": 59, "chromedriv": 121, "chromosom": [111, 112], "chronic": [111, 112], "chronicl": 119, "chronolog": [111, 112, 121], "chu": [45, 176, 177, 178, 180, 181, 182, 183, 184, 185], "chua": [111, 112], "chuan": [0, 6], "chuang": 0, "chunj": 0, "chunk": [15, 76, 143], "chunk_data": [14, 21], "chunk_df": 15, "chunk_id": [14, 15, 19, 21, 24], "chunk_siz": [15, 24], "church": [111, 112, 152], "ci": [56, 64, 66, 70, 71, 75, 101, 112, 159, 170, 171, 173, 177, 185], "cia": 119, "ciao": 97, "cicl": 129, "cinema": 149, "ciphertext": [77, 78], "circa": 150, "circl": [12, 111, 112], "circleci": [64, 65, 159, 160], "circuit": [111, 112], "circular": 145, "circularli": [111, 112], "circumfix": 139, "circumst": [111, 112, 120, 171], "circumv": 46, "citat": [89, 120], "cite": [89, 111, 112, 152], "citi": [3, 97, 100, 111, 112, 136, 143], "citizen": [111, 112], "civil": [111, 112], "civilis": [111, 112], "ci\ub97c": 20, "cjhutto": 135, "cjwbw": [5, 130], "ck": 101, "cl": [101, 103, 104, 108, 110, 111, 112, 114], "cla": 21, "claim": [77, 111, 112, 116, 120, 152], "clan": [111, 112], "clarif": 67, "clarifi": 55, "clariti": [55, 89, 100, 167, 172], "clark": [99, 111, 112, 115], "clash": [111, 112], "class": [8, 9, 10, 14, 15, 20, 21, 22, 28, 33, 43, 45, 46, 51, 60, 70, 73, 75, 87, 88, 100, 104, 110, 111, 112, 114, 116, 127, 128, 136, 138, 139, 140, 147, 150, 151, 152, 182], "class_data_dir": 51, "class_dir": 51, "class_prompt": 51, "classes_": 136, "classic": [8, 40, 46, 77, 111, 112], "classif": [1, 12, 14, 16, 18, 19, 20, 21, 22, 29, 30, 35, 37, 46, 50, 57, 59, 75, 80, 84, 88, 96, 97, 98, 99, 100, 109, 110, 111, 112, 116, 117, 120, 122, 124, 126, 129, 130, 134, 135, 137, 138, 143, 146, 148, 151, 153, 156], "classifi": [1, 6, 9, 16, 17, 18, 37, 46, 84, 85, 90, 98, 99, 100, 110, 111, 112, 114, 116, 117, 128, 130, 134, 140, 144, 147], "classification_model": [14, 22], "classification_report": [135, 136], "classification_t5": 30, "classification_util": [14, 22], "classlabel": 110, "classroom": 185, "claud": 59, "claw": 100, "cld3": 95, "clean": [3, 45, 71, 89, 93, 95, 110, 111, 112, 122, 138, 142, 155, 174, 183], "clean_text": 112, "cleaner": 183, "cleans": [56, 117], "cleanup": [177, 182], "clear": [5, 9, 16, 43, 45, 52, 53, 55, 63, 64, 68, 89, 100, 111, 112, 114, 136, 139, 140, 148, 149, 159, 165, 166, 167, 171, 172, 183], "clearer": [111, 112], "clearli": [89, 97, 116, 133, 163, 165, 167, 172], "clf": 150, "cli": [60, 61, 79, 80, 81], "click": [67, 68, 76, 82, 88, 96, 110, 112, 121, 132, 135, 141, 176, 177, 178], "client": [24, 31, 32, 33, 34, 60, 76, 77, 78, 166, 169, 172], "clientel": 59, "climat": [111, 112], "climatologi": [111, 112], "climb": [6, 100], "clingston": [111, 112], "clinic": [111, 112, 130], "clinician": [111, 112], "clip": [6, 8, 10, 72, 88, 111, 112], "clipboard": [176, 177], "clitic": 139, "clm": [1, 96, 109], "clo": 101, "clone": [76, 80, 177, 184], "close": [0, 2, 5, 6, 8, 9, 46, 49, 59, 89, 90, 92, 101, 111, 112, 114, 115, 117, 118, 126, 128, 130, 132, 133, 136, 139, 147, 152, 156, 172], "closer": [55, 88, 97, 106, 111, 112, 126, 128], "closest": [111, 112, 148], "cloth": [111, 112], "cloud": [12, 38, 55, 56, 60, 62, 64, 65, 66, 70, 72, 77, 78, 80, 81, 111, 112, 136, 152, 159, 160, 167, 169, 176], "cloudform": [64, 159], "cls_token": [111, 112], "clue": [55, 130, 136], "cluster": [60, 62, 64, 65, 74, 75, 80, 95, 98, 119, 126, 150, 151, 159, 160], "cm": [136, 149, 152], "cm_uci": 149, "cm_umass": 149, "cmap": [25, 31], "cmd": [15, 60, 61, 79, 173], "cmu": 83, "cncf": [60, 62], "cnooc": 152, "cnt": [111, 112], "cnvrg": 71, "cny2": 152, "cny8": 152, "co": [2, 59, 95, 100, 101, 111, 112, 136, 138, 143, 147, 148, 151, 154, 155, 157, 171], "coal": [111, 112, 119], "coalit": [111, 112], "coars": 144, "coast": [111, 112], "coastal": [111, 112], "coastlin": [111, 112], "coattail": [111, 112], "cocain": [111, 112], "coco": [10, 88], "code": [4, 6, 8, 9, 19, 42, 44, 45, 52, 59, 61, 64, 67, 68, 69, 71, 72, 73, 74, 77, 78, 80, 85, 95, 97, 98, 100, 110, 111, 112, 115, 119, 120, 121, 124, 130, 133, 136, 141, 143, 150, 152, 155, 159, 161, 164, 166, 167, 169, 171, 172, 173, 175, 178, 179, 180, 183, 186], "code_execution_config": 42, "code_info": [14, 15, 21], "code_info_avail": [14, 15, 19, 21], "codeag": 76, "codebas": [65, 96, 160, 166, 171], "codebook": 8, "codenam": 98, "coder": 177, "codifi": [111, 112], "coe": [111, 112], "coeffici": [111, 112], "coequal": [111, 112], "coerc": [111, 112], "coercion": [111, 112], "coerciv": [111, 112], "coexist": [111, 112, 115], "coffe": [9, 147], "cog": [5, 130], "cognit": [42, 97, 100, 111, 112, 130, 137], "cogview2": [5, 130], "coh": 152, "cohen": [0, 5, 6], "coher": [0, 1, 6, 9, 46, 48, 49, 53, 55, 59, 86, 89, 91, 92, 93, 97, 98, 99, 111, 112, 129, 130, 131, 148, 151, 166], "coherence_per_top": [149, 152], "coherence_per_topic_uci": 149, "coherence_per_topic_umass": 149, "coherencemodel": 149, "coin": [111, 112, 132], "coincid": [111, 112], "col": [14, 15, 16, 21, 26, 30, 31, 33, 34], "colab": [6, 9, 15, 17, 21, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 97, 110, 111, 112, 123, 152, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "colab_workspac": 123, "cold": [59, 111, 112, 137, 183], "colder": [111, 112], "cole": 0, "colin": [0, 111, 112], "collabor": [1, 6, 12, 38, 42, 44, 46, 59, 63, 64, 65, 66, 68, 71, 75, 80, 81, 82, 83, 130, 150, 159, 160, 161, 169, 171, 172, 173, 180, 183, 185, 186], "collar": [111, 112], "collat": 112, "colleagu": [89, 112, 178, 183, 185], "collect": [1, 6, 7, 9, 12, 38, 42, 43, 49, 59, 65, 71, 88, 90, 95, 98, 100, 101, 107, 108, 109, 111, 112, 115, 117, 122, 129, 130, 132, 133, 135, 136, 137, 138, 147, 148, 150, 151, 152, 155, 157, 158, 160, 171], "collectiv": [111, 112], "collectivis": [111, 112], "collectivist": [111, 112], "collector": [111, 112], "colleg": [111, 112, 130], "colloc": 149, "colloqui": [130, 175], "colmenarejo": 0, "colon": [111, 112], "coloni": [3, 111, 112], "colonist": [111, 112], "color": [8, 21, 32, 59, 111, 112, 113, 114, 116, 150, 155], "coloss": [52, 95], "colour": [111, 112], "colsample_bylevel": 35, "colsample_bytre": [29, 35], "columbu": [111, 112], "column": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 52, 59, 107, 108, 110, 113, 114, 116, 119, 125, 126, 136, 145, 149, 150, 151, 157, 158], "column_info": [17, 22, 28, 33], "com": [1, 5, 8, 9, 15, 24, 30, 53, 61, 64, 67, 68, 69, 70, 76, 79, 80, 81, 82, 83, 94, 97, 101, 112, 119, 120, 128, 130, 132, 135, 136, 141, 145, 150, 152, 159, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185], "combat": 152, "combin": [5, 6, 7, 8, 9, 10, 12, 14, 40, 41, 51, 52, 53, 54, 55, 56, 59, 64, 65, 71, 72, 77, 78, 88, 89, 91, 92, 95, 97, 99, 105, 106, 109, 111, 112, 113, 114, 116, 117, 121, 130, 132, 135, 136, 138, 139, 140, 142, 147, 149, 151, 152, 154, 159, 160, 161, 162, 166, 171, 172, 175, 177, 183], "come": [3, 5, 9, 46, 49, 50, 52, 53, 59, 61, 64, 89, 92, 93, 97, 98, 101, 110, 111, 112, 116, 119, 120, 121, 126, 128, 130, 136, 139, 140, 152, 154, 157, 159, 181, 183], "comet": [111, 112], "comfi": 16, "comfort": [42, 80, 142], "comma": [111, 112], "command": [42, 45, 46, 51, 57, 64, 69, 72, 73, 76, 79, 80, 81, 100, 103, 105, 111, 112, 114, 124, 130, 141, 159, 173, 174, 176, 178, 181, 183, 185], "commenc": 172, "commensur": 46, "comment": [46, 67, 111, 112, 121, 134, 152, 178, 184], "commentari": 101, "commerc": [12, 59, 119, 130], "commerci": [83, 111, 112, 150, 152], "commiss": [111, 112], "commission": [111, 112], "commit": [52, 64, 76, 80, 81, 111, 112, 159, 171, 173, 175, 179, 180, 181, 182, 183, 184, 185], "committe": [30, 111, 112, 120], "commmit": 181, "common": [5, 8, 42, 46, 55, 57, 64, 65, 76, 77, 80, 88, 90, 93, 95, 97, 100, 104, 105, 106, 109, 110, 111, 112, 120, 122, 125, 126, 128, 130, 132, 133, 135, 136, 137, 138, 139, 144, 147, 148, 150, 153, 157, 158, 159, 160, 180, 183], "commonli": [1, 50, 64, 77, 78, 88, 104, 109, 111, 112, 119, 122, 139, 142, 143, 154, 159, 172], "commonmark": 181, "commonplac": [111, 112], "commun": [11, 36, 52, 53, 59, 60, 63, 64, 65, 69, 76, 77, 78, 82, 83, 87, 89, 91, 98, 101, 111, 112, 117, 120, 130, 131, 137, 159, 160, 163, 169, 171, 172], "communard": [111, 112], "communist": [111, 112], "comp": 150, "compa": 108, "compac": 108, "compact": [8, 108, 111, 112, 126], "compan": [101, 107, 108], "companhia": [111, 112], "compani": [42, 46, 56, 59, 71, 93, 97, 101, 107, 108, 111, 112, 119, 121, 132, 134, 145, 152, 156], "companion": 130, "company_by_nam": 123, "companyseq": 94, "compar": [6, 9, 55, 56, 57, 60, 62, 67, 69, 76, 77, 78, 83, 84, 85, 88, 89, 90, 95, 97, 108, 109, 111, 112, 113, 115, 116, 117, 122, 126, 128, 130, 131, 132, 133, 138, 142, 143, 147, 148, 149, 150, 158, 171, 172, 173, 178, 180], "comparison": [8, 9, 51, 54, 55, 64, 89, 97, 105, 111, 112, 159], "compass": 108, "compat": [30, 51, 59, 60, 62, 79, 104, 105, 111, 112, 113], "compel": [6, 42, 111, 112, 126, 130, 136, 167, 168], "compet": [5, 93, 119, 130], "competit": [8, 65, 83, 93, 111, 112, 115, 117, 119, 120, 160], "competitor": 119, "compil": [7, 14, 22, 100, 101, 111, 112, 122, 152, 166, 181], "complaint": [51, 136], "complement": 66, "complementari": 117, "complet": [6, 7, 8, 12, 14, 22, 30, 42, 47, 52, 60, 62, 67, 70, 71, 83, 87, 89, 90, 95, 96, 98, 100, 110, 111, 112, 113, 129, 132, 163, 166, 167, 171, 172], "complex": [5, 6, 7, 8, 9, 11, 12, 40, 41, 42, 44, 46, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 71, 76, 88, 89, 91, 92, 93, 97, 98, 100, 101, 102, 104, 105, 106, 111, 112, 113, 114, 115, 116, 121, 126, 128, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 144, 145, 148, 150, 151, 156, 161, 164, 166, 167, 169, 171, 172], "compli": [74, 77, 111, 112, 165], "complianc": [59, 64, 71, 93, 111, 112, 159, 169], "compliant": [59, 60, 62], "complic": [6, 111, 112, 130, 140], "compon": [7, 8, 9, 10, 12, 42, 52, 55, 56, 57, 58, 59, 62, 64, 65, 66, 68, 69, 71, 73, 77, 78, 80, 81, 88, 89, 93, 100, 102, 110, 111, 112, 113, 116, 126, 127, 130, 138, 139, 140, 147, 148, 150, 151, 158, 159, 160, 164, 168, 169], "components_": 150, "compos": [9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 60, 62, 71, 88, 108, 111, 112, 113, 116, 128, 130, 145, 147, 152, 154, 172], "compose_worker_lf": 20, "composit": [2, 8, 59, 104, 105, 111, 112, 143], "composition": 0, "compound": [49, 93, 111, 112, 135, 139, 140, 145], "comprehend": [49, 52, 93, 111, 112, 113, 114, 126, 139, 142, 172], "comprehens": [1, 6, 10, 12, 37, 38, 42, 45, 46, 47, 48, 50, 52, 54, 55, 58, 59, 62, 71, 73, 75, 76, 77, 78, 82, 88, 91, 98, 99, 100, 111, 112, 115, 116, 121, 130, 151, 165, 167, 169, 171, 186], "compress": [6, 8, 9, 103, 106, 115, 126, 150], "compris": [9, 46, 52, 111, 112, 113, 117, 164], "comprnfb": 34, "compromis": [12, 38, 50, 55, 77, 95, 116], "compuls": [111, 112], "compulsori": [111, 112], "comput": [0, 5, 6, 7, 8, 9, 11, 12, 13, 38, 42, 44, 45, 46, 52, 53, 54, 55, 59, 60, 62, 73, 74, 76, 78, 83, 86, 88, 89, 91, 93, 94, 97, 98, 99, 102, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 128, 129, 130, 131, 132, 133, 136, 137, 139, 140, 142, 143, 145, 146, 147, 150, 151, 153, 154, 155, 157, 176, 178, 185], "computation": [46, 77, 97, 101, 126, 128, 130, 133, 134, 136, 138, 146, 151], "compute_environ": 51, "compute_loss": [107, 108], "compute_metr": 110, "compute_pair_scor": 108, "compute_scor": [107, 108], "compvi": 51, "com\ub85c": 140, "con": [14, 16, 101], "concat": 52, "concat_data": [14, 16, 17], "concaten": [6, 9, 10, 14, 15, 20, 21, 52, 101, 111, 113, 116, 149, 154], "concatenated_exampl": 111, "concentr": [1, 50, 59, 111, 112, 116, 120, 151], "concept": [1, 9, 10, 11, 37, 38, 42, 46, 49, 53, 54, 55, 57, 59, 67, 70, 75, 77, 78, 80, 82, 87, 88, 96, 100, 105, 106, 109, 111, 112, 114, 116, 118, 126, 129, 130, 132, 137, 142, 143, 147, 149, 155, 156, 157, 158, 161, 162, 167, 171, 172, 186], "conceptu": [52, 59, 98, 137, 166], "concern": [1, 12, 47, 50, 53, 55, 59, 60, 71, 74, 77, 86, 92, 93, 97, 98, 109, 111, 112, 121, 129, 130, 152, 156], "concert": [98, 149], "concis": [9, 49, 55, 57, 64, 89, 98, 116, 159, 167, 170], "conclud": [107, 111, 112, 142], "conclus": [37, 62, 69, 73, 78, 97, 111, 112, 126, 128, 130, 134, 150], "concret": [49, 106], "concurr": [55, 111, 112], "conda": [28, 30, 42, 69], "condens": [49, 111, 112, 126, 147, 148, 167], "condit": [6, 8, 9, 12, 46, 50, 55, 59, 97, 105, 111, 112, 117, 132, 144, 145, 172], "condition": 138, "conditional_gener": 51, "conduc": 59, "conduct": [6, 12, 55, 100, 111, 112, 116, 161, 167, 169, 172], "cone": 139, "conecuh": [111, 112], "confcal": [23, 24, 25, 26, 27, 31], "confect": 46, "confeder": [111, 112], "confederaci": [111, 112], "confer": [0, 6, 36, 89, 111, 112, 119, 120, 129], "confid": [8, 12, 88, 95, 111, 112], "confidenti": [74, 76, 77, 78], "config": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 51, 76, 80, 81, 111, 112, 114, 128, 145, 149, 150, 152, 173, 174, 183], "config_fil": 51, "config_group": [16, 19, 21, 23, 26, 28, 29, 30, 33, 35], "config_list": 42, "config_list_from_json": 42, "configmap": 80, "configur": [45, 60, 61, 62, 69, 72, 73, 75, 76, 77, 81, 89, 110, 111, 112, 117], "confin": 55, "confirm": [24, 30, 67, 68, 71, 77, 111, 112, 117, 174, 178], "confirmmeasur": 152, "conflict": [20, 68, 111, 112, 165, 180], "conflicted_fil": 177, "confluenc": [49, 111, 112, 169], "conform": 120, "confound": 0, "confront": [38, 57, 111, 112], "confus": [93, 111, 112, 136, 173], "confusion_matrix": [14, 16, 17, 22, 135, 136], "conglomer": [111, 112], "congratul": 112, "congreg": [111, 112], "congress": [111, 112, 119, 137], "congression": [111, 112], "congressmen": [111, 112], "conifer": [111, 112], "conjug": 130, "conjunct": [119, 120, 144], "conll": 122, "conneau": 95, "connect": [1, 9, 46, 52, 54, 64, 70, 76, 77, 78, 80, 88, 89, 111, 112, 116, 117, 126, 127, 128, 151, 159, 176, 177, 180], "connot": [111, 112, 156], "cono": 101, "conscienc": [111, 112], "consciou": 97, "conscious": [111, 112, 130], "consecut": [101, 106, 117, 172], "consensu": [111, 112, 128, 152], "consent": [93, 111, 112], "consequ": [1, 59, 98, 100, 111, 112, 116, 140, 178], "conserv": [50, 97, 111, 112, 120], "consid": [9, 12, 24, 25, 30, 35, 41, 46, 51, 52, 55, 63, 64, 65, 66, 69, 77, 88, 89, 93, 97, 98, 100, 103, 105, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 125, 126, 130, 132, 133, 136, 137, 138, 139, 140, 143, 144, 147, 149, 150, 151, 153, 154, 156, 158, 159, 160, 166, 167, 170, 171, 178], "consider": [10, 50, 52, 55, 70, 74, 86, 89, 93, 98, 109, 111, 112, 130, 146], "consist": [6, 8, 9, 38, 49, 52, 55, 56, 61, 62, 64, 65, 66, 76, 88, 89, 91, 93, 97, 99, 102, 105, 106, 111, 112, 113, 116, 117, 119, 120, 121, 122, 126, 130, 137, 139, 142, 143, 147, 149, 154, 157, 159, 160, 163, 165, 167, 171], "consol": 105, "consoli": 37, "consolid": [75, 111, 112], "conson": [111, 112], "constant": [0, 46, 51, 55, 71, 88, 111, 112, 130, 133, 145, 147, 172], "constantli": [111, 112, 130], "constel": [111, 112], "constitu": 130, "constitut": [72, 111, 112, 119, 140], "constrain": [8, 46, 49, 50, 59, 60, 62, 92, 95, 150], "constraint": [6, 9, 50, 52, 62, 71, 83, 89, 97, 100, 111, 112, 121, 150, 151, 164, 166, 167, 170, 171, 172], "construct": [6, 12, 46, 53, 57, 83, 98, 111, 112, 119, 120, 137, 139, 146, 152, 154, 167, 171], "consult": [85, 165, 166], "consum": [6, 12, 40, 46, 52, 59, 93, 101, 111, 112, 118, 144, 152, 172], "consumer": [111, 112], "consumpt": [34, 45, 50, 77, 86, 98, 111, 112, 172], "cont": 101, "contact": [6, 111, 112], "contain": [8, 9, 11, 24, 38, 45, 55, 56, 62, 64, 65, 67, 73, 80, 81, 89, 91, 93, 94, 95, 97, 98, 104, 105, 110, 111, 112, 114, 116, 117, 119, 120, 121, 122, 124, 126, 128, 130, 133, 134, 136, 137, 139, 145, 146, 147, 150, 152, 153, 155, 156, 158, 159, 160, 171, 173, 174, 175, 177, 178, 182, 183], "container": [1, 38, 55, 60, 61, 64, 70, 73, 75, 80, 159, 169], "containerd": [1, 62, 64, 70, 81, 159], "contempl": [1, 97], "contemporari": [44, 111, 112], "contend": 69, "content": [1, 2, 6, 8, 11, 12, 14, 21, 24, 43, 49, 51, 55, 57, 59, 60, 76, 77, 81, 82, 85, 86, 88, 92, 93, 94, 95, 98, 100, 111, 112, 115, 116, 117, 120, 121, 122, 123, 130, 136, 139, 147, 148, 151, 167, 173, 174, 175, 177, 179, 180, 181, 182, 183, 184, 185], "content_typ": [24, 30], "contest": 130, "context": [1, 6, 7, 8, 9, 12, 30, 37, 38, 41, 45, 46, 47, 50, 52, 54, 57, 59, 60, 69, 76, 77, 85, 86, 89, 91, 92, 93, 97, 98, 99, 100, 102, 107, 109, 111, 112, 113, 114, 116, 122, 124, 125, 126, 127, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 147, 148, 153, 154, 155, 156, 167, 170, 171], "context_s": 128, "context_vector": 128, "context_word": 155, "contextu": [11, 46, 49, 50, 53, 55, 57, 59, 86, 91, 97, 98, 100, 109, 113, 126, 130, 131, 138, 148], "contigu": [120, 138, 143], "contin": 101, "continent": [111, 112], "conting": [167, 170], "continu": [2, 5, 8, 9, 11, 30, 42, 46, 50, 51, 52, 53, 55, 59, 63, 64, 70, 77, 78, 79, 80, 83, 85, 91, 93, 98, 101, 106, 107, 108, 111, 112, 116, 122, 126, 130, 132, 133, 139, 140, 148, 152, 154, 159, 163, 166, 169, 172, 177, 183], "contour": 7, "contourpi": 136, "contrac": 101, "contract": [77, 111, 112, 128, 130, 139, 142, 171], "contradict": [55, 111, 112], "contradictori": [55, 111, 112], "contrail": [111, 112], "contrari": [111, 112, 150], "contrast": [6, 8, 10, 12, 13, 52, 53, 71, 95, 97, 100, 111, 112, 114, 116, 126, 136, 148, 150, 171, 172], "contribut": [6, 9, 42, 49, 50, 52, 55, 57, 59, 67, 68, 75, 77, 84, 89, 93, 98, 111, 112, 113, 115, 116, 117, 130, 141, 146, 150, 151, 152, 178], "contributor": 181, "control": [0, 1, 3, 45, 49, 52, 55, 57, 59, 64, 71, 74, 75, 77, 78, 80, 81, 89, 97, 105, 106, 111, 112, 120, 121, 152, 159, 161, 167, 169, 172, 174, 176, 181, 185], "controversi": [5, 111, 112], "convei": [1, 120, 130, 167], "conveni": [49, 76, 104, 110], "convent": [41, 46, 54, 56, 111, 112, 126, 130, 173], "converg": [28, 50, 53, 54, 56, 64, 116, 159, 181, 183], "convers": [1, 44, 46, 49, 59, 83, 92, 93, 96, 98, 105, 110, 119, 122, 126, 145, 165, 171, 178], "convert": [7, 8, 9, 10, 14, 22, 55, 59, 73, 77, 78, 88, 97, 100, 102, 104, 105, 108, 111, 112, 115, 116, 117, 119, 121, 123, 128, 130, 132, 133, 136, 138, 142, 146, 148, 155, 158], "convert_ids_to_token": 114, "convert_to_humanbyt": 17, "convert_tokens_to_id": 104, "convict": [111, 112], "convinc": [57, 85, 111, 112, 168], "convolut": [9, 10, 50, 88, 116, 172], "coo": 15, "cook": 46, "cooki": 140, "cool": [111, 112, 180], "cooler": [111, 112], "cooper": [111, 112], "coordin": [111, 112, 126, 166, 171, 172], "coosa": [111, 112], "cope": [111, 112], "copi": [14, 16, 21, 23, 24, 25, 26, 27, 30, 31, 32, 34, 61, 66, 67, 68, 76, 79, 98, 101, 107, 108, 111, 112, 120, 171, 173, 176, 177, 178, 179, 180, 185], "copilot": [49, 130], "copiou": [111, 112], "copper": 152, "coptic": [111, 112], "copyright": [93, 121, 181], "cor": 101, "cordonni": 0, "core": [3, 6, 11, 14, 15, 21, 22, 42, 44, 46, 57, 58, 59, 60, 62, 66, 68, 77, 80, 86, 93, 100, 101, 103, 104, 105, 111, 112, 113, 115, 116, 126, 137, 148, 156, 171, 172, 174], "corefer": 130, "coreweav": 59, "corn": [111, 112, 156], "cornel": 122, "corner": [67, 68, 111, 112], "cornerston": [6, 50, 52, 105, 165], "corp": 101, "corpor": [101, 111, 112, 119, 130, 152], "corpora": [49, 93, 98, 99, 122, 135, 146, 148, 149, 156, 157], "corporati": 107, "corporatio": 107, "corpu": [1, 6, 12, 18, 32, 36, 37, 45, 86, 92, 93, 95, 97, 103, 105, 106, 107, 108, 109, 113, 120, 124, 125, 126, 128, 132, 135, 136, 138, 139, 142, 143, 144, 145, 146, 147, 149, 150, 151, 153, 154, 155, 156, 157, 158], "corpus_cfg": 15, "corpustext": 135, "corr": [25, 31, 119, 120], "corr_column": [25, 31], "corr_data": [25, 31], "corr_data1": 25, "corr_data2": 25, "corrado": 0, "correct": [6, 8, 9, 20, 30, 42, 49, 53, 55, 59, 64, 66, 77, 93, 95, 96, 98, 99, 104, 111, 123, 130, 131, 139, 140, 141, 143, 144, 145, 159, 165, 175, 185], "correct_ct": 128, "correctli": [45, 64, 76, 91, 99, 115, 119, 130, 136, 140, 159, 171], "correl": [1, 6, 36, 37, 38, 93, 95, 111, 112, 119, 152], "correspond": [5, 6, 9, 10, 11, 46, 51, 52, 55, 88, 104, 110, 111, 112, 114, 115, 117, 121, 126, 136, 138, 139, 141, 144, 147, 150, 151, 153, 154, 155, 156, 158, 172, 181], "correspondingli": [111, 112], "corrupt": [9, 99, 111, 112, 115, 150], "corsican": 95, "cortic": [111, 112], "cosin": [9, 10, 55, 116, 119, 152], "cosmic": 16, "cosmo": 16, "cost": [9, 10, 12, 35, 45, 46, 50, 52, 55, 59, 63, 65, 71, 90, 97, 105, 109, 111, 112, 115, 117, 120, 127, 128, 146, 152, 160, 164, 166, 167, 170, 172], "costli": [6, 93, 120, 172], "cot": 100, "cot_prompt": 100, "cotton": [111, 112], "couch": 9, "cough": 92, "could": [5, 9, 10, 12, 14, 40, 41, 42, 46, 49, 50, 52, 53, 54, 59, 64, 77, 88, 89, 92, 95, 97, 102, 104, 105, 106, 111, 112, 115, 116, 117, 120, 127, 130, 136, 137, 138, 139, 143, 147, 152, 156, 159, 165, 167, 170, 173, 174, 175, 176, 177], "couldn": 177, "council": [111, 112], "count": [14, 15, 17, 21, 22, 100, 103, 105, 106, 115, 116, 119, 120, 126, 133, 136, 145, 146, 147, 150, 151, 153, 155, 156, 157, 158], "counter": [111, 112, 118, 120, 132, 133, 139], "counteract": 6, "countercultur": [111, 112], "counterpart": [83, 111, 112, 115], "counti": [111, 112], "countin": 145, "countplot": [24, 25, 136], "countri": [0, 3, 88, 111, 112, 152], "countryexposure_": 119, "countryrisk_": 119, "countrysentiment_": 119, "countvector": [126, 143, 150], "coupl": 6, "courag": 171, "cours": [43, 49, 52, 72, 111, 112, 117, 130, 139, 173, 176, 178], "coursera": 49, "court": [93, 111, 112, 152], "courtlisten": 93, "covari": 151, "cover": [9, 12, 37, 54, 60, 70, 71, 75, 81, 85, 88, 89, 93, 96, 103, 105, 111, 112, 115, 119, 120, 129, 130, 133, 150, 165, 168, 170, 186], "coverag": [20, 94, 103, 105, 111, 112, 119, 121, 128], "covid": [111, 112], "cowen": 128, "cozi": 9, "cp": [34, 152], "cp38": [136, 150], "cpi": [12, 34], "cpi_diff_prev": [25, 26, 27, 28], "cpi_diff_year": [25, 26, 27, 28], "cpiaucsl": 34, "cpu": [6, 14, 22, 51, 88, 100, 112, 150], "cpu_feature_guard": [14, 22, 100], "cr": 101, "craft": [2, 9, 46, 50, 57, 89, 92, 98, 100, 166], "craftsperson": 46, "craiyon": [5, 130], "crash": 184, "crass": [111, 112], "crater": [111, 112], "crawl": [1, 95, 122, 129, 130], "crawler": [93, 121], "crayfish": [111, 112], "cream": [139, 145], "creat": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 23, 25, 36, 37, 42, 43, 45, 47, 49, 50, 52, 53, 54, 56, 57, 59, 62, 64, 65, 66, 71, 72, 73, 75, 76, 78, 79, 82, 83, 85, 86, 88, 89, 90, 93, 94, 95, 97, 100, 107, 110, 115, 116, 121, 123, 126, 132, 133, 135, 136, 137, 139, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 162, 167, 169, 171, 173, 174, 177, 180, 181, 182, 183, 185], "create_ngram_model": 133, "create_project": 21, "create_records_from_cv_pr": [16, 17, 19], "creation": [1, 6, 42, 46, 50, 53, 55, 59, 62, 63, 88, 98, 111, 112, 121, 147, 153, 164, 165, 166, 169], "creativ": [5, 8, 9, 11, 42, 53, 55, 85, 86, 88, 97, 98, 111, 112, 119, 132, 166], "creator": [2, 5, 9, 88, 130, 137], "creatur": [3, 100], "credenti": [64, 76, 77, 78, 81, 82, 111, 112, 159], "credibl": [55, 130], "credit": [12, 36, 38, 40, 59, 111, 112, 120], "credoai": 59, "creek": [111, 112], "creep": [166, 172], "crenshaw": [111, 112], "crescent": [111, 112], "crespo": 0, "crf": 144, "cri": 60, "crime": [3, 111, 112], "crimin": [111, 112], "crimson": [32, 111, 112], "crise": [12, 40, 119], "crisi": 152, "criteria": [0, 43, 93, 111, 112, 140, 145, 166, 167, 169], "criterion": [84, 127, 128, 145], "critic": [0, 7, 10, 14, 22, 37, 42, 46, 47, 50, 52, 55, 59, 60, 63, 71, 74, 77, 85, 87, 89, 93, 98, 100, 111, 112, 113, 116, 122, 130, 131, 139, 163, 165, 169, 172], "criticis": [111, 112], "critiqu": [4, 87, 89, 111, 112], "critu": 150, "crop": [6, 9, 12, 88, 111, 112], "cross": [1, 8, 10, 18, 37, 55, 57, 65, 69, 88, 93, 95, 99, 109, 111, 112, 116, 119, 122, 127, 128, 160, 185], "cross_val_predict": [14, 16, 17], "crossentropyloss": [127, 128], "crossov": [111, 112], "crouch": 130, "crow": [111, 112], "crowdfund": 120, "crowdsourc": 51, "crucial": [5, 6, 7, 8, 10, 12, 38, 40, 41, 45, 46, 50, 52, 53, 54, 55, 59, 64, 71, 73, 76, 77, 78, 80, 88, 89, 92, 93, 95, 98, 102, 105, 106, 111, 112, 116, 122, 131, 132, 133, 134, 136, 137, 138, 140, 142, 143, 144, 146, 147, 148, 151, 157, 159, 165, 166, 167, 172], "crush": [111, 112], "crutch": 10, "cruz": [111, 112], "cryptocurr": 77, "cryptograph": [38, 76, 77, 78], "cryptographi": [76, 77, 78], "cryptosystem": 78, "crystal": 152, "crystallin": [111, 112], "css": [121, 169], "csv": [23, 45, 73], "ct": [71, 101], "ctmodel": 152, "ctor": 101, "ctrl": [97, 99], "ctype": 24, "cu": 101, "cu118": 45, "cuda": [45, 51, 112], "cuda_device_ord": [15, 17, 24, 31, 32, 33, 34, 152], "cuda_visible_devic": [15, 17, 24, 31, 32, 33, 34, 152], "cue": [111, 112], "cui": 0, "cuisin": 46, "culinari": 46, "culmin": 12, "cultiv": [111, 112], "cultur": [63, 64, 65, 93, 98, 111, 112, 130, 132, 134, 137, 142, 159, 160, 171], "cumberland": [111, 112], "cumbersom": 123, "cumbria": [176, 177], "cumul": [54, 92, 97, 111, 112], "cup": [111, 112], "curat": [46, 55, 56, 57, 93, 98], "cure": [111, 112], "curi": [0, 6], "curiou": 182, "curl": [60, 80], "curli": 117, "curr_sv": 52, "currenc": [111, 112, 119, 152], "current": [9, 17, 22, 30, 36, 49, 54, 55, 60, 61, 63, 71, 76, 77, 78, 88, 89, 93, 97, 111, 112, 120, 127, 128, 129, 130, 132, 151, 152, 163, 165, 167, 173, 174, 175, 180, 184], "current_ngram": 133, "current_word": 133, "curriculum": 6, "curs": [49, 126, 133, 143, 148], "cursiv": [111, 112], "curtail": 50, "curv": [77, 78, 111, 112], "curvatur": [0, 84], "custom": [7, 8, 9, 41, 42, 45, 50, 52, 53, 59, 60, 61, 62, 64, 65, 66, 71, 74, 77, 82, 88, 91, 92, 93, 98, 111, 112, 121, 130, 134, 137, 138, 148, 152, 159, 160, 164, 165, 166, 171, 172], "custom_inventori": [64, 159], "customis": 178, "customiz": [42, 60, 105], "cut": [25, 26, 27, 28, 29, 33, 35, 42, 46, 98, 101, 111, 112, 118, 128, 148], "cute": 147, "cv": [14, 16, 17, 158, 173, 177, 185], "cv_matrix": 158, "cv_pred": [16, 17], "cv_preds_inv": 14, "cv_preds_new": 16, "cv_preds_top": 14, "cvf": [0, 6], "cw": [111, 112], "cxhxw": 88, "cy": [95, 101], "cyber": [49, 77], "cybersecur": 85, "cycl": [1, 6, 14, 42, 60, 63, 71, 161, 162, 171, 172], "cycler": 136, "cyclic": [120, 171, 172], "cynic": [111, 112], "cyril": [111, 112], "czech": 95, "d": [0, 14, 16, 17, 22, 24, 37, 53, 59, 67, 74, 79, 80, 84, 99, 100, 101, 105, 106, 108, 111, 112, 113, 115, 119, 124, 128, 129, 136, 139, 140, 142, 146, 147, 150, 151, 152, 157, 175, 180, 181, 182], "d14": 0, "d2b4434": [176, 177, 179, 180], "d55c9d": 21, "d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0": 110, "d6ed38f9b76acdb2c76ae773f15031c42b9fbdb": 184, "d_": [8, 120], "d_w": 147, "da": [95, 101, 123], "dad": 171, "daemon": [60, 61], "dai": [0, 12, 23, 31, 65, 83, 88, 99, 101, 111, 112, 120, 128, 136, 152, 160, 171], "daili": [23, 46, 91, 111, 112, 130, 171], "daily_treasury_yield_curv": 23, "daisyworld": [111, 112], "dakota": [111, 112], "dali": 5, "dall": [1, 4, 11, 59, 130], "dalla": [111, 112, 119], "dalle2": 9, "damag": [10, 111, 112], "damp": 108, "dan": 0, "danawa": 94, "danc": [0, 183], "dancer": 6, "dang": 108, "danger": [108, 175, 185], "dani": 0, "daniel": [0, 6], "danish": 95, "dark": [3, 16, 111, 112], "darkblu": 32, "darken": [111, 112], "darker": [111, 112], "darkest": [111, 112], "darktrac": 49, "dart": [1, 122, 129], "dart_api_kei": 123, "dartmoor": 178, "dash": 182, "dashboard": 82, "data": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 16, 17, 18, 22, 28, 29, 30, 33, 34, 36, 39, 42, 43, 45, 46, 47, 49, 50, 53, 54, 57, 58, 60, 61, 63, 64, 65, 70, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 91, 92, 96, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 113, 115, 116, 117, 118, 119, 120, 122, 124, 126, 127, 129, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 151, 152, 153, 156, 158, 159, 160, 164, 165, 167, 169, 170, 185], "data_col": [33, 112], "data_column": 17, "data_dir": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 123, 152], "data_fil": [14, 16, 17, 19, 20, 21, 22, 24, 28, 30, 33, 45], "data_files_modifi": [17, 22, 28], "data_inv": 14, "data_inval_cv": 14, "data_kei": [14, 15, 21], "data_path": [45, 181], "data_pol_merg": 14, "data_sourc": [14, 15, 21], "data_topic_cv": 14, "databas": [6, 12, 38, 46, 56, 57, 78, 89, 93, 116, 120, 121, 130, 137], "databrick": [56, 59], "datacollatorforlanguagemodel": [111, 112], "datadog": [64, 65, 159, 160], "dataflow": 164, "datafram": [14, 15, 20, 21, 22, 23, 24, 28, 30, 73, 123, 136, 149], "dataframe_to_predict": 21, "dataframeinput": 73, "dataiku": 71, "dataload": 111, "datano": [24, 25], "datarobot": 71, "dataset": [1, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 25, 26, 28, 29, 30, 33, 35, 36, 37, 46, 49, 51, 52, 53, 59, 73, 74, 75, 84, 88, 89, 90, 96, 98, 106, 109, 113, 116, 119, 120, 121, 125, 128, 129, 130, 132, 134, 135, 138, 139, 147, 149, 150, 155], "dataset_build": [16, 20], "datasetdict": [94, 136], "datasetinfo": 17, "date": [5, 15, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 55, 66, 68, 78, 89, 93, 111, 112, 119, 123, 130, 132, 133, 142, 150, 155, 174, 175, 176, 180, 181, 184, 185], "datetim": [17, 22, 28, 32], "datetime64": 28, "dateutil": [136, 141], "daunt": 93, "davi": [0, 111, 112], "david": [0, 96, 111, 112, 129], "davinci": [83, 100], "davydov": 0, "dax": 152, "db": [15, 19, 64, 159], "db1": [64, 159], "dbeorlf123": 15, "dbk": 0, "dbow": 154, "dbscan": [138, 148], "dcl21": 0, "dclt18": 0, "dc\uc5d0\uc11c": 20, "ddim": 9, "de": [0, 51, 77, 78, 95, 101, 111, 112], "de73": 183, "de82": 183, "deactiv": [42, 97], "dead": 99, "deadlin": 170, "deadlock": 17, "deal": [9, 38, 49, 50, 53, 56, 57, 63, 89, 93, 101, 111, 112, 116, 126, 133, 136, 138, 139, 143, 147, 152, 156, 171, 177], "deali": [111, 112], "dean": [0, 155], "death": [111, 112], "deb": 80, "debat": [111, 112], "debian": 79, "debit": 40, "debt": [0, 101, 115, 152], "debug": [1, 42, 58, 98, 161, 166, 167, 172, 186], "debut": 130, "decad": [6, 49, 111, 112, 120, 130], "decai": [45, 88, 110], "decatur": [111, 112], "decemb": [111, 112, 152], "decenni": [111, 112], "decent": [136, 149], "decentr": [38, 76, 77], "decentralis": [111, 112], "decid": [6, 10, 36, 52, 57, 97, 105, 106, 111, 112, 128, 136, 144, 145, 146, 175, 177], "decidu": [111, 112], "decimet": [111, 112], "deciph": [0, 102], "decis": [1, 9, 12, 24, 27, 30, 36, 37, 39, 44, 49, 50, 53, 54, 57, 59, 63, 64, 76, 85, 91, 94, 98, 106, 111, 112, 118, 119, 120, 130, 138, 159, 178], "decker": [111, 112], "decl": 101, "declar": [64, 65, 66, 101, 111, 112, 159, 160], "declin": [111, 112, 119, 120, 151, 152], "decod": [1, 7, 12, 95, 96, 98, 99, 100, 110, 111, 115, 130, 139], "decompos": [55, 57, 132, 150, 151, 163], "decomposit": [42, 52, 104, 132, 165], "deconstruct": 114, "decoupl": 115, "decreas": [8, 95, 97, 106, 111, 112, 145], "decri": 155, "decrypt": [76, 77, 78, 79], "dedic": [6, 64, 71, 159], "deduct": [111, 112], "dedupl": [55, 95, 117, 128], "deed": [111, 112], "deem": [77, 126], "deep": [0, 1, 6, 11, 12, 14, 17, 22, 40, 41, 46, 50, 53, 54, 59, 71, 73, 85, 86, 87, 88, 91, 93, 97, 98, 99, 102, 111, 112, 113, 116, 118, 128, 130, 131, 134, 136, 137, 154, 170], "deepart": 2, "deepcopi": [107, 108], "deepdeep": 17, "deepdream": 2, "deepen": [111, 112], "deeper": [9, 52, 55, 73, 89, 106, 112, 113, 130], "deepercut": 6, "deeplabcut": 0, "deepli": [45, 54, 111, 112], "deepmind": 53, "deepnlp": 45, "deepspeed_config": 51, "def": [20, 26, 32, 34, 52, 73, 100, 101, 107, 108, 110, 111, 112, 115, 124, 127, 128, 132, 133, 135, 136, 145, 150, 152, 181], "default": [0, 12, 14, 17, 19, 24, 28, 49, 60, 64, 66, 69, 79, 80, 81, 82, 88, 100, 112, 120, 124, 150, 152, 159, 175, 177, 180, 181, 182], "defaultdict": [101, 107, 108, 132, 133, 155], "defeat": [53, 111, 112, 136], "defect": [65, 111, 112, 160, 172], "defenc": [111, 112], "defend": [111, 112], "defens": 119, "defi": [111, 112], "defiantli": [111, 112], "defici": 164, "deficit": [111, 112, 119, 137], "defin": [0, 1, 6, 7, 8, 16, 17, 19, 21, 29, 50, 52, 57, 61, 62, 63, 64, 66, 69, 71, 72, 73, 75, 84, 95, 97, 98, 99, 103, 106, 107, 108, 110, 114, 116, 120, 127, 130, 132, 133, 135, 136, 140, 143, 145, 147, 150, 154, 155, 157, 158, 159, 164, 167, 168, 170, 171, 172], "definit": [72, 78, 111, 112, 119, 139, 144, 157, 166, 171, 174, 175, 176, 180, 182], "deflat": 34, "deforest": [111, 112], "degrad": [9, 117, 172], "degre": [42, 111, 112, 116, 130, 140, 147, 172], "dehghani": 0, "dejavu": 28, "del": [111, 112], "delai": [6, 63, 111, 112, 164, 172], "deleg": [111, 112], "delegitimis": [111, 112], "delet": [19, 79, 81, 99, 111, 112, 115, 174, 175, 176, 177, 180, 181, 182], "delete_project": 21, "delhi": [111, 112, 129], "deliber": [0, 59, 64, 159], "delic": [46, 116], "delin": [52, 56, 111, 112], "deliv": [64, 65, 71, 80, 111, 112, 116, 159, 160, 170, 171, 172], "deliver": [47, 172], "deliveri": [55, 64, 80, 159, 164, 171, 172], "delug": 16, "delus": 81, "delusion": 150, "delv": [2, 39, 44, 49, 50, 54, 59, 89, 100, 106, 111, 112, 142, 167, 169, 172, 186], "demand": [10, 12, 46, 50, 52, 53, 55, 59, 64, 65, 93, 98, 111, 112, 122, 152, 159, 160, 169, 171, 172], "demo": [6, 51, 83], "democraci": [111, 112, 150], "democrat": [0, 50, 52, 59, 71, 83, 111, 112, 120, 150], "demograph": [111, 112, 120], "demonstr": [6, 8, 42, 49, 50, 51, 53, 73, 83, 85, 89, 93, 97, 98, 100, 101, 111, 112, 113, 115, 116, 120, 130, 150, 172], "demopoli": [111, 112], "den": 101, "dendrogram": 148, "deng": 0, "deni": 185, "denim": 16, "denni": [0, 111, 112], "dennison": 0, "denois": [6, 9, 10, 98, 99, 117], "denomin": [111, 112, 143], "denormalizer_spec": [103, 105], "denot": [8, 53, 54, 95, 111, 112, 119, 126, 133, 137, 140, 145, 147, 151], "dens": [14, 16, 17, 22, 88, 110, 117, 127, 128, 138, 154], "dense_predict": [14, 16, 17, 22], "denser": [126, 158], "densif": 55, "densiti": [55, 111, 112, 148], "dental": [111, 112], "dentistri": [111, 112], "dep": 144, "depart": [111, 112, 171], "depend": [8, 9, 10, 40, 41, 42, 45, 46, 49, 52, 53, 61, 62, 64, 69, 71, 72, 73, 75, 86, 88, 89, 93, 97, 98, 99, 100, 102, 103, 105, 106, 109, 111, 112, 113, 114, 115, 116, 128, 130, 132, 133, 136, 137, 138, 139, 140, 142, 145, 146, 147, 150, 151, 154, 156, 157, 159, 164, 171, 172, 174, 175, 176, 182], "depict": [3, 42, 59, 111, 112], "deploi": [1, 41, 45, 46, 55, 57, 59, 61, 62, 64, 65, 70, 71, 73, 74, 75, 80, 85, 86, 92, 97, 98, 109, 130, 159, 160, 166, 172, 176], "deploy": [49, 50, 53, 55, 60, 62, 63, 64, 65, 70, 71, 72, 75, 80, 83, 85, 92, 98, 159, 160, 161, 169, 170, 171, 172], "deposit": 99, "deprec": [22, 30, 110, 112], "depress": [111, 112], "depriv": [111, 112], "depth": [0, 9, 12, 41, 47, 50, 55, 68, 70, 87, 96, 111, 112, 115, 153, 165, 167, 169, 172], "der": [0, 101, 147], "derail": 167, "derang": 150, "derek": 0, "deri": [0, 6], "deriv": [12, 14, 52, 59, 95, 105, 111, 112, 113, 115, 128, 136, 137, 139, 142, 147, 157, 171], "descart": [111, 112], "descend": [101, 111, 112, 124], "descent": [111, 112, 151], "describ": [6, 8, 9, 10, 25, 49, 60, 64, 68, 81, 88, 89, 96, 111, 112, 116, 130, 139, 151, 153, 159, 164, 165, 167, 170], "descript": [5, 6, 8, 9, 10, 11, 12, 17, 59, 67, 68, 71, 82, 88, 93, 100, 111, 112, 119, 120, 130, 145, 167, 171, 173, 176], "desegreg": [111, 112], "desert": [111, 112], "deserv": 136, "deshuffl": 117, "desiderata": 130, "design": [1, 5, 6, 7, 9, 10, 11, 41, 42, 43, 46, 50, 52, 53, 59, 60, 62, 71, 73, 74, 76, 77, 80, 85, 88, 89, 90, 91, 93, 95, 97, 98, 100, 103, 105, 111, 112, 113, 114, 115, 116, 117, 122, 123, 130, 136, 138, 151, 163, 165, 167, 169, 171, 172], "desir": [8, 42, 44, 46, 52, 55, 57, 64, 66, 76, 81, 92, 95, 97, 100, 106, 108, 116, 121, 130, 133, 147, 148, 151, 159, 165, 172], "desktop": [61, 169], "desoto": [111, 112], "despit": [5, 9, 10, 38, 49, 50, 53, 55, 59, 86, 91, 101, 109, 111, 112, 115, 126, 130, 132, 139, 151, 153, 172], "destigmat": [111, 112], "destin": [66, 67, 69, 111, 112], "destroi": [10, 111, 112], "destruct": [111, 112], "det": 144, "detach": [77, 128, 177], "detail": [5, 6, 7, 12, 30, 42, 45, 52, 53, 55, 57, 67, 76, 77, 83, 89, 96, 99, 100, 104, 107, 111, 112, 116, 119, 129, 130, 144, 152, 166, 167, 170, 172, 177, 182], "detect": [0, 6, 12, 14, 17, 21, 24, 31, 32, 33, 34, 38, 46, 49, 50, 55, 59, 64, 65, 74, 77, 78, 95, 98, 99, 111, 112, 116, 120, 122, 130, 134, 138, 140, 147, 159, 160, 172], "detectgpt": [0, 1, 86, 87, 90], "detector": [0, 6], "determin": [7, 9, 10, 36, 42, 52, 55, 64, 89, 91, 97, 100, 102, 104, 106, 110, 111, 112, 113, 114, 116, 117, 130, 132, 134, 135, 136, 137, 138, 139, 140, 144, 145, 147, 157, 159, 172], "determinist": [6, 9, 97, 124, 143], "deterr": 120, "detoken": 105, "detox": [111, 112], "detriment": [97, 117], "dev": [14, 17, 20, 22, 28, 33, 65, 71, 135, 160, 181], "dev50": 17, "dev57": [16, 19, 20, 22], "dev58": 21, "dev67": 14, "dev7": 152, "dev_siz": [14, 16, 20], "devast": [111, 112], "develop": [1, 2, 5, 6, 9, 11, 12, 41, 42, 46, 47, 49, 50, 52, 53, 54, 55, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 76, 77, 78, 83, 84, 85, 86, 87, 88, 91, 92, 93, 96, 97, 98, 109, 111, 112, 113, 116, 119, 120, 121, 122, 130, 131, 132, 136, 137, 138, 141, 143, 151, 152, 154, 156, 159, 160, 161, 162, 163, 165, 167, 168, 169, 170, 173, 176, 178, 180, 186], "development": [49, 111, 112], "deviat": [23, 28, 95, 112, 132], "devic": [49, 50, 51, 71, 73, 76, 77, 78, 82, 111, 112, 120], "devis": 10, "devlin": [0, 95, 99, 112, 113], "devoid": [59, 165], "devop": [1, 56, 70, 73, 80, 161, 169], "devot": 119, "devsecop": [1, 65, 70], "devset": 132, "df": [38, 73, 136], "df618e0": 183, "dfd": 165, "dfedtar": 23, "dfedtaru": 23, "dff": 23, "dff_30": 23, "dg": 107, "dhariwa": 10, "dharma": [111, 112], "dhn": [111, 112], "di": [5, 101, 130, 139, 145], "diabet": [111, 112], "diacrit": [111, 112], "diagnos": [109, 111, 112, 156], "diagnosi": [49, 92, 111, 112], "diagnost": [49, 50, 111, 112], "diagon": 150, "diagram": [113, 164, 165, 167, 169, 170, 174, 175, 176], "dialect": [49, 93, 98, 111, 112, 130], "dialog": [79, 97, 122, 130], "dialogu": [42, 46, 53, 91, 97, 98, 122, 131], "diam": 101, "diamet": [111, 112], "dic": 141, "dice": [88, 152], "dichotomi": [111, 112], "dick": 139, "dict": [14, 15, 17, 20, 21, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "dict_kei": 101, "dictat": [111, 112], "dictatorship": [111, 112], "dictionari": [30, 31, 43, 55, 104, 108, 110, 111, 112, 120, 124, 126, 135, 139, 144, 145, 146, 149, 156, 165], "did": [97, 107, 108, 110, 111, 112, 116, 117, 130, 173, 183], "didn": [9, 20, 51, 88, 175], "diego": 83, "diet": [111, 112], "dietmar": 0, "diff": [9, 23, 174, 175, 177, 180, 185], "differ": [4, 5, 6, 7, 9, 10, 12, 37, 41, 42, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 62, 64, 66, 71, 72, 73, 74, 76, 77, 78, 82, 84, 88, 89, 91, 93, 95, 97, 98, 99, 100, 102, 103, 104, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 128, 130, 131, 133, 134, 136, 137, 138, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 156, 157, 159, 164, 166, 169, 172, 173, 174, 177, 180, 183, 185], "differenti": [0, 6, 84, 93, 111, 112, 136], "differential_privacy_clipping_threshold": [103, 105], "differential_privacy_noise_level": [103, 105], "difficult": [12, 26, 27, 92, 93, 99, 100, 109, 111, 112, 114, 121, 126, 134, 137, 140, 147, 148, 151, 166, 172], "difficulti": [6, 111, 112, 116, 130, 172, 185], "diffus": [0, 5, 52, 111, 112, 130], "dig": 101, "digit": [6, 12, 14, 55, 59, 63, 76, 78, 89, 93, 98, 111, 112, 130, 148], "digraph": [111, 112], "dilemma": [50, 126], "dillard": [111, 112], "dilut": [111, 112], "dim": [52, 111, 112], "dimc": 59, "dimens": [2, 9, 38, 41, 49, 52, 55, 59, 88, 92, 113, 116, 119, 126, 128, 138, 146, 147, 148, 154, 156, 157], "dimension": [6, 9, 41, 49, 55, 56, 59, 99, 113, 115, 120, 126, 127, 133, 136, 147, 150, 151, 153, 154, 156, 157], "diminish": [50, 88, 111, 112], "din": 124, "diner": [111, 112], "ding": 101, "dioxid": [111, 112], "dip": 152, "diphthong": [111, 112], "dir": [15, 19, 61, 139, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "direct": [9, 46, 49, 52, 55, 56, 89, 98, 99, 100, 105, 111, 112, 113, 114, 128, 145, 157, 171], "directli": [6, 53, 55, 57, 59, 60, 66, 69, 103, 104, 105, 111, 112, 115, 116, 120, 121, 123, 130, 138, 144, 152, 156, 174], "director": [133, 149], "directori": [14, 60, 61, 64, 66, 80, 110, 111, 112, 123, 135, 159, 173, 174, 175, 176, 177, 178, 179, 180, 182, 184, 185], "dirglielo": 139, "dirichlet": [138, 148, 152], "dirk": 0, "dirnam": 181, "dirti": [23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 111, 112, 117], "disabl": [17, 60, 110, 111, 112], "disadvantag": [49, 147, 172], "disagr": [111, 112], "disagre": [111, 112], "disambigu": [130, 131, 137, 142, 153, 157], "disappear": [111, 112], "disappoint": 136, "disast": [12, 111, 112], "disc": [111, 112], "discard": [14, 16, 21, 55, 97, 117, 146, 153, 174, 176, 181], "discern": [55, 93, 147], "disciplin": [71, 111, 112, 120, 162, 163, 166, 171, 172], "disclos": 52, "disco": [5, 111, 112, 130], "disconnect": 71, "discours": [130, 136, 140, 174, 175, 176, 177, 179], "discov": [53, 97, 98, 100, 116, 130, 138, 148, 150, 151, 152], "discoveri": [0, 2, 49, 97, 120, 130, 151], "discrep": [64, 84, 155, 157, 159], "discret": [9, 42, 52, 126, 148, 156, 164], "discrimin": [14, 16, 17, 22, 99, 111, 112, 137, 138], "discriminator_predict": [14, 16, 17, 22], "discriminatori": 130, "discuss": [2, 4, 12, 55, 57, 63, 72, 76, 77, 79, 80, 84, 87, 89, 96, 97, 106, 111, 112, 113, 119, 120, 123, 130, 140, 150, 155, 158, 165, 167, 170, 172], "diseas": [49, 92, 111, 112], "disenfranchis": [111, 112], "disentangl": 134, "disfranchis": [111, 112], "disgrac": 139, "disgracefulli": 139, "dish": [46, 156], "disinform": [85, 90, 98], "disintegr": [111, 112], "disjoint": 73, "disk": [79, 110, 111, 112, 177], "dislik": 145, "dismal": [111, 112], "dismember": [111, 112], "dismiss": [111, 112], "disobei": [111, 112], "disord": [111, 112], "disp": 112, "dispar": [111, 112], "dispers": [114, 119], "displaci": 144, "displai": [43, 61, 72, 81, 91, 111, 112, 113, 121, 142, 145, 149, 150, 152, 155, 178], "dispos": [111, 112], "disproportion": 59, "disproven": [111, 112], "disput": [111, 112], "disregard": 138, "disrupt": [0, 77, 111, 112, 114], "dissect": [42, 56], "dissemin": [59, 111, 112], "dissimilar": 147, "dist": [110, 111, 112], "distanc": [111, 112, 126, 148], "distant": [116, 128], "distict": 114, "distil": 74, "distilbert": [99, 108], "distinct": [7, 10, 46, 50, 71, 77, 111, 112, 113, 114, 116, 119, 121, 126, 130, 137, 139, 145, 147, 156, 171, 172], "distinctli": [111, 112], "distinguish": [9, 42, 52, 90, 99, 106, 111, 112, 115, 126, 128, 140], "distort": 8, "distress": [111, 112], "distri": 101, "distribut": [0, 6, 8, 12, 38, 40, 46, 51, 54, 55, 59, 60, 62, 65, 72, 73, 74, 75, 76, 78, 80, 83, 95, 97, 99, 111, 112, 113, 116, 120, 127, 128, 130, 132, 133, 136, 138, 139, 146, 147, 148, 151, 152, 154, 155, 158, 160, 176], "distributed_typ": 51, "district": [111, 112], "disturb": [111, 112], "ditto": 150, "div": 43, "dive": [55, 73, 101, 110, 111, 113, 135, 138, 170], "diverg": [7, 8, 57, 111, 112, 151, 183], "divers": [0, 7, 8, 9, 10, 11, 38, 40, 42, 45, 46, 49, 50, 52, 53, 54, 55, 59, 83, 88, 93, 97, 98, 100, 109, 111, 112, 116, 121, 122, 130, 144], "diversifi": [12, 13, 83, 105, 111, 112, 116], "divi": 101, "divid": [10, 56, 75, 108, 109, 111, 112, 114, 116, 119, 132, 137, 138, 139, 140, 142, 143, 147, 151, 157, 163, 164, 167, 171, 172], "dividen": 101, "dividend": [101, 152], "divin": [111, 112], "divis": [111, 112, 140, 167], "dixi": [111, 112], "django": 167, "dlc": 6, "dlcrnet": 6, "dlerror": 14, "dlopen": 14, "dlrpv": 0, "dlt": 77, "dm": 154, "dmrmodel": 152, "dn": 80, "dna": [111, 112], "dnn": 97, "do": [5, 6, 9, 24, 30, 42, 53, 59, 69, 77, 79, 88, 97, 99, 100, 101, 102, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 128, 132, 133, 136, 139, 142, 147, 150, 151, 152, 157, 158, 164, 165, 167, 169, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185], "do_lower_cas": 114, "do_sampl": [97, 111], "doc": [16, 17, 22, 30, 35, 61, 80, 135, 136, 144, 152], "doc_inst": 152, "doc_length": 152, "doc_topic_dist": 152, "docker": [1, 42, 55, 60, 62, 64, 65, 70, 72, 75, 159, 160, 169], "dockerd": 61, "dockerfil": [1, 66, 70], "doctor": [111, 112, 136, 156], "doctrin": [111, 112], "document": [15, 24, 30, 36, 42, 46, 47, 49, 55, 64, 73, 76, 77, 93, 95, 98, 111, 112, 119, 120, 121, 125, 126, 130, 134, 137, 138, 144, 146, 147, 150, 151, 153, 155, 156, 157, 158, 159, 164, 165, 166, 167, 169, 171, 172, 178, 182], "document_al": 123, "documentlist": 43, "doe": [6, 9, 10, 46, 50, 52, 55, 77, 81, 90, 97, 99, 100, 105, 106, 111, 112, 113, 115, 116, 121, 125, 126, 138, 139, 140, 143, 148, 150, 151, 154, 156, 157, 158, 171, 172, 174, 180, 183], "doesn": [9, 52, 84, 85, 92, 97, 105, 112, 116, 132, 133, 136, 139, 140, 157, 177], "dog": [51, 97, 111, 112, 113, 115, 116, 126, 137, 142, 143, 144, 147, 149, 153, 158], "dogecoin": 101, "doha": 0, "doi": 0, "dollar": [130, 152], "domain": [6, 8, 11, 17, 38, 39, 40, 42, 45, 46, 53, 54, 55, 57, 59, 65, 74, 84, 85, 86, 88, 89, 91, 98, 100, 109, 116, 117, 121, 122, 130, 134, 137, 138, 141, 144, 145, 160, 163, 166, 169], "domest": [111, 112, 119], "domin": [59, 111, 112, 114, 116, 120, 138, 139], "don": [3, 23, 24, 59, 64, 72, 76, 93, 97, 112, 113, 115, 126, 128, 130, 136, 139, 142, 146, 152, 153, 155, 159, 174, 175, 176, 177, 178, 181, 185], "donald": 0, "donat": [111, 112, 119], "done": [8, 52, 64, 71, 79, 92, 99, 103, 104, 105, 108, 109, 111, 112, 116, 126, 132, 159, 171, 172, 176, 178, 183], "dong": [0, 116], "door": 144, "doppler": [1, 66, 70], "dosovitskii": [0, 116], "dot": [9, 52, 66, 70, 113, 116, 125, 126, 147, 180], "dotdrop": [1, 66, 70], "dotenv": 123, "dotenv_path": 123, "dotfil": [1, 64, 70, 159], "dothan": [111, 112], "doubl": [9, 53, 111, 112, 134, 180], "doubli": [0, 116], "doubt": 183, "dow": 101, "down": [6, 8, 9, 14, 16, 17, 22, 53, 60, 61, 63, 65, 89, 91, 97, 100, 101, 102, 103, 104, 105, 106, 110, 111, 112, 113, 115, 116, 117, 126, 128, 130, 139, 140, 143, 144, 146, 152, 153, 160, 167, 169, 177], "downcast_bf16": 51, "downg": 107, "downgr": 107, "downgra": 107, "downgrad": [101, 107], "download": [15, 20, 45, 59, 60, 61, 72, 77, 95, 100, 103, 104, 111, 114, 121, 124, 125, 128, 132, 133, 135, 136, 139, 142, 144, 150, 155], "downscal": 88, "downstream": [49, 99, 109, 110, 111, 112, 113, 114, 117, 126, 146], "downtim": [65, 160], "downtown": [111, 112], "downturn": 12, "downward": 171, "downweight": 125, "dozen": 140, "dozier": [111, 112], "dpg": 94, "dpg\ub294": 94, "dqn": 53, "dr": [104, 136], "draft": [42, 59, 89, 120, 167], "dragon": 16, "dragonfli": [111, 112], "dramat": [59, 95, 115, 119], "draw": [1, 4, 37, 46, 53, 89, 97, 111, 112, 116, 130, 136, 140], "drawback": [97, 116, 119, 151], "drawbench": 10, "drawn": [116, 147], "dream": 17, "dreambooth": 51, "dreamlik": 2, "dress": [111, 112], "drew": [111, 112], "dri": 101, "drift": [59, 64, 65, 74, 119, 159, 160], "drill": 128, "drink": 156, "drive": [50, 52, 54, 55, 65, 66, 89, 93, 97, 111, 112, 116, 122, 123, 139, 160, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "drive_dir": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "driven": [0, 9, 16, 37, 42, 44, 52, 54, 63, 69, 71, 93, 103, 105, 130, 166, 169], "driver": [111, 112], "drone": 12, "drool": [111, 112], "drop": [9, 10, 14, 15, 21, 88, 105, 111, 112, 117, 119, 130, 146, 152], "drop_dupl": 15, "drop_index": [15, 16, 20, 24], "dropbox": 66, "dropdown": 112, "droplet": [111, 112], "dropna": [31, 34], "dropout": [112, 140], "drosophila": 6, "drought": 12, "droz": 5, "drug": [49, 111, 112], "drunk": 156, "dry": [111, 112], "ds_cfg": [16, 17, 22, 30], "ds_inval": 14, "ds_pol": 14, "ds_tp": 14, "ds_tp_merg": 14, "ds_tp_predict": 14, "ds_tp_valid": 14, "ds_zero3_cpu": 51, "dsa": 78, "dsl": [65, 160], "dsm": [111, 112], "dso_load": 14, "dsp": [111, 112], "dt": [32, 144], "dtmodel": 152, "dtype": [14, 15, 21, 25, 28, 110, 112, 128, 150], "du": [101, 117], "dual": 85, "ducharm": 0, "duck": 130, "dudlei": [24, 30], "due": [5, 6, 8, 9, 38, 46, 49, 50, 52, 59, 62, 64, 69, 71, 77, 83, 84, 97, 98, 111, 112, 116, 128, 130, 132, 133, 134, 137, 138, 140, 141, 142, 143, 144, 147, 148, 151, 152, 153, 156, 159, 164, 167, 172], "duel": 53, "duke": 119, "dummi": [9, 126], "dump": [111, 112], "duolingo": 85, "dup": 101, "duplic": [52, 98, 111, 112, 117, 181], "durabl": 152, "durat": [29, 35, 50, 52, 111, 112, 121, 167, 171], "dure": [5, 7, 8, 9, 10, 46, 50, 51, 52, 53, 54, 77, 78, 88, 89, 97, 98, 100, 106, 109, 110, 111, 112, 113, 115, 116, 117, 119, 133, 136, 140, 142, 145, 150, 151, 152, 171, 172], "dust": [111, 112], "dustri": 107, "dutch": 95, "duti": [111, 112], "dvae": 8, "dvc": 70, "dw2008\uc744": 14, "dwindl": 55, "dx": 14, "dy": 101, "dyer": 99, "dynam": [0, 2, 12, 14, 38, 40, 41, 46, 49, 50, 52, 54, 55, 57, 59, 71, 74, 88, 89, 91, 97, 99, 111, 112, 141, 152, 167, 171, 172], "dynamo_backend": 51, "dysfunct": [111, 112], "dysmorph": [111, 112], "dysphoria": [111, 112], "dysregul": [111, 112], "e": [0, 1, 4, 11, 12, 14, 16, 17, 19, 21, 22, 45, 53, 55, 59, 60, 64, 65, 67, 74, 75, 78, 79, 82, 84, 88, 93, 95, 97, 99, 100, 101, 102, 105, 106, 107, 108, 110, 111, 112, 114, 115, 117, 119, 120, 123, 126, 128, 130, 132, 133, 137, 138, 139, 142, 143, 145, 146, 147, 148, 152, 153, 156, 159, 160, 167, 170, 171, 174, 175, 177, 180, 181, 183], "e2": 5, "e4bb8ea": 175, "e5451fd": [177, 179, 180], "e61909": [0, 6], "e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf": 136, "ea15": 183, "eac": [111, 112], "each": [5, 6, 8, 9, 10, 12, 20, 23, 36, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 55, 59, 60, 65, 71, 72, 73, 75, 76, 77, 80, 81, 83, 88, 93, 94, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 164, 166, 169, 170, 172, 174, 179, 180, 181, 182], "ead": 124, "eagach": 180, "eager": 16, "ear": 101, "earli": [12, 40, 49, 57, 63, 64, 65, 111, 112, 139, 159, 160, 166, 171, 172], "earlier": [9, 45, 53, 81, 88, 113, 114, 116, 152, 155, 172, 176, 178, 183], "earliest": [111, 112, 172], "early_stop": 97, "earn": [101, 111, 112, 119, 120, 128, 152], "earnest": 16, "earni": 107, "earnin": 107, "earth": [83, 88, 111, 112], "earthshin": [111, 112], "earthworm": [111, 112], "eas": [6, 55, 65, 66, 76, 160], "easi": [59, 62, 64, 66, 69, 71, 72, 74, 79, 97, 102, 110, 111, 112, 123, 132, 136, 140, 146, 156, 159, 176, 180, 181], "easier": [8, 9, 64, 65, 66, 73, 74, 83, 91, 98, 99, 111, 112, 113, 121, 130, 137, 150, 151, 159, 160, 163, 166, 172], "easili": [6, 8, 51, 66, 71, 72, 73, 112, 124, 145, 147, 150, 152, 172], "east": [111, 112], "eastern": [111, 112], "eat": [100, 102, 111, 112, 126, 130, 132, 139], "ebner": 0, "ebook": 117, "ec": [141, 142], "ecc": [77, 78, 112], "ecdsa": 78, "echo": [79, 80, 111, 112, 173, 176, 177, 185], "echolal": [111, 112], "echolalia": [111, 112], "echota": [111, 112], "eckert": 129, "eclect": [111, 112], "ecolog": [111, 112], "ecologi": 6, "econ_col": [33, 34, 35], "econ_data": [23, 25, 26, 27, 34], "econ_data2": [23, 25, 26, 27], "econ_data_pivot": 34, "econ_ind": 23, "econ_news_code_info_20220905": 15, "econ_news_code_info_available_20220905": [15, 19], "econ_news_code_info_available_20220911": 21, "econ_news_code_info_available_20221229": 14, "econ_news_filt": 19, "econ_news_filtered_202201229": 14, "econ_news_filtered_20220905": [15, 19], "econ_news_filtered_20220911": 21, "econ_news_kr": [1, 14, 18, 19, 21, 37], "econ_news_kr_chunk": [15, 21], "econ_news_kr_chunks_": [14, 21], "econ_news_kr_chunks_2020_code_20220911": 21, "econ_news_kr_chunks_2020_code_20221229": 14, "econ_news_kr_chunks_2022_code_20220911": 21, "econ_news_kr_chunks_2022_code_20221229": 14, "econ_seri": 23, "econ_train_larg": [26, 27, 28], "econ_train_smal": [26, 27, 28, 33], "econo": 101, "econom": [0, 1, 36, 38, 39, 85, 111, 112, 118, 120, 137, 165], "econometr": 41, "economi": [0, 12, 13, 97, 101, 111, 112, 119, 137], "economist": 119, "ecor": [111, 112], "ecosystem": [1, 6, 47, 58, 59, 60, 62], "ed": [101, 129, 139], "ed25519": 76, "eda": [1, 36, 37, 71, 93, 96], "edg": [46, 50, 53, 59, 60, 71, 73, 98, 111, 112, 118, 152], "edit": [0, 9, 64, 79, 88, 89, 159, 173, 174, 175, 178, 183], "editor": [173, 175], "edmundson": [111, 112], "edouard": 0, "edu": [129, 150], "eduardo": 0, "educ": [7, 8, 42, 48, 63, 92, 111, 112, 129, 176], "edward": [111, 112], "edx": 49, "ee": [107, 111, 112], "ee24636": 183, "eec": 0, "ef": [141, 142], "ef5": [111, 112], "effect": [0, 1, 6, 9, 10, 12, 25, 26, 27, 37, 38, 39, 40, 41, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 59, 64, 65, 68, 70, 71, 73, 74, 75, 77, 78, 80, 81, 84, 86, 89, 90, 91, 92, 93, 95, 97, 98, 100, 102, 104, 106, 111, 112, 116, 117, 120, 122, 126, 130, 131, 136, 137, 138, 139, 141, 143, 146, 147, 148, 150, 151, 152, 153, 155, 156, 157, 159, 160, 163, 165, 166, 167, 171, 172, 186], "effector": 44, "efficaci": [42, 49, 50, 55, 59, 111, 112], "effici": [0, 1, 6, 8, 10, 12, 38, 40, 46, 47, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 71, 73, 74, 76, 80, 81, 88, 91, 93, 95, 96, 97, 98, 100, 105, 106, 111, 112, 115, 116, 124, 126, 130, 131, 132, 133, 138, 140, 143, 145, 148, 150, 151, 154, 155, 159, 160, 161, 162, 163, 165, 166, 170, 171, 172], "efficientnet": [6, 9], "effort": [42, 53, 65, 77, 88, 89, 97, 98, 111, 112, 116, 121, 130, 138, 160, 166, 171, 172], "effortlessli": 50, "efro": [0, 6], "eg": 150, "egalitarian": [111, 112], "egg": [111, 112, 132, 158], "egyptian": [111, 112], "eh": 107, "ehr": 77, "ei": 101, "eibi": [111, 112], "eichenbaum": 34, "eigenvalu": 126, "eigh": [177, 180], "eight": [36, 98, 111, 112, 128], "eighteen": 130, "eighteenth": [111, 112], "eighth": [0, 111, 112], "either": [9, 17, 30, 79, 81, 88, 91, 95, 96, 111, 112, 116, 121, 123, 130, 132, 137], "ej": 69, "ekonelectra": [14, 16, 17, 19, 21, 22], "ekonf": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 128, 145, 152], "ekonlpi": 142, "ekorpkit": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 128, 145], "ekorpkit_config_dir": [15, 17, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "ekorpkit_data_dir": [15, 17, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "ekorpkit_data_root": [16, 19, 20, 22], "ekorpkit_log_level": [15, 17, 24, 31, 32, 33, 34, 152], "ekorpkit_project": [15, 17, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "ekorpkit_project_dir": 17, "ekorpkit_workspace_root": [15, 17, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "el": [30, 95, 101], "elabor": [49, 53, 57, 111, 112, 165, 167], "elantra": [111, 112], "elaps": [15, 20, 24, 28, 30], "elast": 55, "elasticsearch": [64, 65, 159, 160], "elbaz": 121, "elect": [0, 30, 111, 112, 119, 120], "elector": [111, 112, 120], "electr": [99, 111, 112], "electra": [14, 22], "electraforsequenceclassif": [14, 16, 17, 22], "electromagnet": [111, 112], "electron": [49, 77, 111, 112, 123, 130, 152], "eleg": 126, "elegantli": 126, "element": [5, 9, 43, 45, 50, 52, 54, 57, 72, 88, 93, 97, 110, 111, 112, 113, 116, 121, 128, 129, 140, 141, 145, 146, 151, 157, 166, 171, 172], "elementari": [111, 112], "elementwis": [113, 114], "elev": [42, 50, 53, 111, 112, 119], "eleven": [111, 112], "elgam": [77, 78], "eli": [0, 6], "elicit": [53, 57], "elif": [0, 6], "elig": [111, 112], "elimin": [6, 8, 52, 84, 88, 97, 105, 111, 112, 120, 126, 163, 172], "elit": [111, 112], "elk": [64, 65, 159, 160], "ellipt": [77, 78], "elmo": [99, 126, 138], "elmor": [111, 112], "els": [14, 23, 25, 26, 27, 32, 100, 101, 108, 114, 123, 135, 145, 152, 156, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185], "elsewher": 152, "elucid": [41, 54, 59, 172], "elva": [111, 112], "em": [103, 105, 106, 151], "ema": 107, "emac": 174, "email": [42, 46, 49, 76, 77, 78, 121, 178], "emancip": [111, 112], "emb": [55, 128], "embed": [1, 6, 8, 9, 10, 46, 52, 59, 71, 88, 96, 102, 109, 110, 111, 112, 113, 114, 115, 116, 124, 127, 129, 130, 132, 139, 148, 169], "embedding_dim": 128, "embedding_s": [127, 128], "embodi": [44, 46, 111, 112, 116], "embrac": [46, 63, 89, 111, 112, 171], "emdedding_dim": 128, "emerald": [111, 112], "emerg": [0, 39, 42, 45, 46, 49, 52, 54, 56, 59, 74, 77, 83, 85, 86, 93, 100, 111, 112, 116, 120, 139, 144, 148, 151, 172], "emi": 107, "emigr": [111, 112], "emilio": 0, "emiss": [111, 112], "emma": [111, 112], "emnlp": 0, "emoji": 115, "emot": [3, 91, 111, 112, 118, 130, 134], "emoticon": 135, "emp": [20, 25, 26, 27, 28], "emp_diff_prev": [25, 26, 27, 28, 29, 33, 35], "emp_diff_year": [25, 26, 27, 28], "emperor": [111, 112], "emphas": [48, 50, 55, 59, 60, 63, 64, 65, 66, 87, 92, 111, 112, 156, 159, 160, 171, 172], "emphasi": [44, 50, 57, 59, 111, 112, 168, 171, 172], "emphasis": [111, 112], "empir": [0, 84, 92, 100, 111, 112], "emploi": [7, 9, 12, 38, 41, 42, 46, 49, 50, 55, 57, 59, 64, 77, 89, 95, 98, 111, 112, 133, 136, 137, 138, 139, 147, 148, 150, 151, 159, 162, 169, 170, 186], "employ": [12, 13, 38, 111, 112, 119, 120, 152], "employ_diff_prev": 25, "employe": [77, 111, 112, 134], "employm": 108, "empow": [59, 113, 130], "empti": [9, 64, 108, 145, 152, 159, 173, 185], "emptyset": 97, "emul": 46, "en": [95, 100, 101, 103, 105, 108, 110, 111, 112, 114, 130, 135, 136, 142, 144, 145], "en_core_web_sm": 144, "en_mc4": 95, "enabl": [2, 5, 6, 7, 8, 9, 11, 12, 14, 22, 41, 42, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 71, 72, 73, 76, 77, 78, 80, 82, 83, 86, 88, 89, 91, 92, 93, 95, 97, 98, 100, 105, 109, 111, 112, 113, 114, 116, 118, 119, 121, 122, 126, 130, 138, 148, 159, 160, 166, 171, 172, 186], "enable_differential_privaci": [103, 105], "enable_sampl": 105, "enact": [111, 112], "enc": 101, "encapsul": [10, 42, 44, 50, 59, 64, 116, 126, 136, 159, 167], "encod": [1, 7, 8, 30, 52, 89, 95, 96, 97, 98, 99, 100, 104, 105, 111, 112, 114, 115, 124, 126, 130, 142, 146, 153, 154, 156], "encode_as_piec": 103, "encode_word": [101, 107, 108], "encoded_input": 104, "encoded_word": [101, 107, 108], "encompass": [46, 49, 50, 65, 89, 98, 160, 164, 167, 172, 186], "encount": [3, 7, 9, 45, 88, 89, 97, 111, 112, 116, 133, 139, 143, 173], "encourag": [6, 8, 10, 37, 63, 64, 65, 83, 85, 88, 97, 159, 160, 171], "encrypt": [1, 12, 38, 64, 66, 70, 74, 76, 78, 79, 82, 159], "encyclopedia": [93, 111, 112], "end": [3, 4, 8, 32, 34, 37, 46, 49, 51, 55, 67, 68, 74, 75, 77, 80, 91, 96, 97, 100, 101, 104, 105, 106, 107, 108, 111, 112, 115, 117, 123, 124, 125, 128, 129, 130, 132, 134, 136, 139, 140, 145, 150, 152, 155, 156, 157, 161, 166, 169, 172, 173, 181, 184], "end_idx": [107, 108], "endang": 97, "endeavor": 89, "endless": 2, "endogen": 0, "endors": [111, 112], "endow": 42, "endpoint": [72, 73], "enemi": [111, 112, 153], "energ": 101, "energi": [3, 49, 50, 53, 77, 86, 98, 101, 111, 112, 119, 152], "enforc": [6, 14, 64, 111, 112, 159, 172], "enfranchis": [111, 112], "eng": 108, "engag": [42, 46, 49, 50, 52, 55, 57, 85, 89, 91, 92, 97, 111, 112, 171, 172], "engel": [111, 112], "engerland": [175, 176, 182], "engin": [1, 5, 8, 12, 42, 47, 56, 59, 62, 69, 71, 74, 75, 89, 91, 92, 96, 98, 111, 112, 121, 129, 130, 145, 149, 150, 155, 162, 168, 186], "england": [111, 112, 174, 175], "english": [10, 49, 85, 93, 95, 105, 111, 112, 116, 117, 120, 121, 122, 130, 135, 136, 137, 140, 142, 143, 144, 145, 149, 150, 152], "english_stop": 152, "enhanc": [2, 5, 9, 12, 37, 38, 45, 49, 50, 51, 52, 53, 54, 59, 64, 65, 67, 74, 76, 77, 79, 83, 85, 86, 93, 98, 100, 111, 112, 115, 116, 134, 138, 148, 150, 159, 160, 165, 167, 169, 172], "enhua": 0, "enjoi": [3, 65, 97, 111, 112, 160], "enjoy": 89, "enlighten": [111, 112], "enorm": 143, "enough": [9, 23, 97, 106, 111, 112, 139, 140, 174], "enrag\u00e9": [111, 112], "enrich": [0, 41, 46, 49, 52, 55, 59, 113, 170], "enrol": [37, 111, 112], "ensembl": [12, 73, 117, 138], "enslav": [111, 112], "ensu": 59, "ensur": [1, 5, 6, 7, 10, 12, 28, 38, 42, 43, 45, 46, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 85, 88, 89, 91, 92, 93, 95, 97, 98, 100, 105, 106, 111, 112, 116, 126, 130, 133, 136, 142, 144, 146, 151, 159, 160, 161, 163, 164, 166, 167, 169, 171, 172, 185], "enta": 107, "entail": [50, 52, 98, 111, 112, 117, 147], "entelecheia": [1, 14, 16, 17, 22, 24, 30, 128, 145, 152, 173, 174, 175, 180, 184, 185], "enter": [3, 46, 51, 76, 77, 81, 82, 111, 112, 145, 166], "enterpris": [57, 59, 65, 71, 160, 169, 171], "entertain": [6, 7, 8, 11, 91, 111, 112], "enthusiast": [111, 112, 114], "entir": [5, 9, 10, 38, 42, 46, 52, 63, 64, 71, 92, 97, 101, 103, 110, 111, 112, 113, 116, 117, 128, 132, 133, 136, 138, 154, 158, 159, 161, 172], "entiti": [12, 44, 49, 50, 52, 74, 77, 91, 98, 111, 112, 113, 115, 122, 125, 130, 134, 143, 144, 156, 165, 169], "entranc": [111, 112], "entrant": 59, "entri": [8, 14, 15, 21, 43, 55, 79, 111, 112, 120, 136, 156, 157, 166, 172], "entropi": [0, 127, 128, 152], "enumer": [23, 24, 97, 108, 127, 128, 142, 149, 152, 155, 167, 170], "env": [15, 16, 17, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 45, 73, 79, 123, 152], "env_or_fil": 42, "environ": [6, 16, 17, 19, 20, 21, 22, 29, 35, 42, 44, 45, 46, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 70, 71, 74, 77, 80, 83, 89, 95, 115, 123, 136, 152, 159, 160, 163, 171, 172], "environment": [6, 12, 50, 55, 98, 111, 112, 120], "envis": [42, 57], "eo": [95, 97, 100], "eos_id": [103, 105], "eos_piec": [103, 105], "eos_token_id": [97, 100, 111], "eou": 79, "ep": [101, 141, 142, 152], "epc": [111, 112], "epel": 60, "epfl": 6, "ephem": 135, "epigenet": [111, 112], "epilepsi": [111, 112], "epoch": [45, 51, 99, 110, 111, 112, 113, 127, 128], "epsilon": [112, 147], "epu": [119, 137], "equ": 101, "equal": [9, 28, 83, 88, 111, 112, 115, 116, 126, 127, 136, 147, 154], "equat": [53, 111, 112, 126, 128, 132, 143, 145, 156], "equilibrium": 38, "equip": [42, 44, 50, 52, 77, 80, 89, 167, 170, 186], "equit": [88, 98], "equiti": [101, 128, 152], "equival": [9, 53, 105, 126, 132], "er": [101, 107, 108, 165, 169], "era": [2, 38, 56, 83, 111, 112], "erag": 107, "eras": 9, "erect": [111, 112], "erg": [101, 107], "eri": [101, 111, 112], "eric": 0, "erlich": [5, 130], "erna": 107, "ernest": [111, 112], "erod": [111, 112], "errico": [111, 112], "erron": 59, "error": [6, 8, 14, 16, 19, 20, 21, 42, 46, 53, 55, 59, 64, 65, 71, 88, 90, 93, 104, 105, 109, 111, 112, 115, 117, 124, 125, 130, 131, 145, 150, 151, 159, 160, 163, 167, 172, 175, 177, 184, 185], "ervi": 107, "ervic": 107, "escal": [50, 53, 164], "escap": [101, 105], "escape_whitespac": [103, 105], "escuela": [111, 112], "esd": 107, "esda": 107, "esdai": 108, "esearch": 120, "esg": [1, 14, 16, 17, 20, 21, 37], "esg_categories_20220905": 19, "esg_category_prediction_check": [16, 19], "esg_cv_polar": [16, 21], "esg_cv_polarity_d": 16, "esg_cv_polarity_data": 16, "esg_cv_top": [16, 21], "esg_cv_topic_data": 16, "esg_invalid": [16, 21], "esg_invalid_20220911": 21, "esg_invalid_cv_pr": 14, "esg_invalid_d": 16, "esg_invalid_data": 16, "esg_invalid_data_cv": 14, "esg_invalid_kr": [14, 16], "esg_invalid_kr_merg": 14, "esg_news_polarities_20220911": 21, "esg_news_polarity_20221229": 14, "esg_news_prediction_results_20221229": 14, "esg_news_topic_20221229": 14, "esg_news_topics_20220911": 21, "esg_news_valid_20220911": 21, "esg_news_valid_20221229": 14, "esg_polar": [14, 19, 22], "esg_polarities_20220905": 19, "esg_polarity_d": 20, "esg_polarity_data": 20, "esg_polarity_data_valid": 14, "esg_polarity_exist": 16, "esg_polarity_further_train": 14, "esg_polarity_kr": [14, 20], "esg_polarity_label": [14, 20], "esg_polarity_labels_valid": 14, "esg_polarity_prediction_check": 19, "esg_polarity_snorkel": 20, "esg_polarity_snorkel_data": 20, "esg_polarity_valid": [14, 16], "esg_prediction_data": 14, "esg_rubrix_topic_data": 16, "esg_top": [19, 22], "esg_topic_data": 20, "esg_topic_data_cv": 14, "esg_topic_data_cved_mreg": 14, "esg_topic_invalid_cv": 14, "esg_topic_invalid_merg": 14, "esg_topic_label": [14, 20], "esg_topic_label_error": 17, "esg_topic_labels_valid": 14, "esg_topic_valid": 14, "esg_topics_cv": 14, "esg_topics_cv_pr": 17, "esg_topics_exist": 16, "esg_topics_improv": [14, 17], "esg_topics_remap": 17, "esg_topics_valid": [14, 16], "esg_valid_polar": 16, "esg_valid_polarity_cv": 16, "esg_valid_polarity_data": 16, "esg_valid_polarity_kr": 16, "esg_valid_top": 16, "esg_valid_topic_d": 16, "esg_valid_topics_cv": 16, "esgml": [15, 17, 19], "esou": 107, "esour": 107, "esourc": 107, "especi": [9, 12, 38, 39, 46, 50, 52, 53, 59, 71, 97, 105, 106, 111, 112, 114, 116, 118, 126, 130, 135, 140, 143, 146, 147, 149, 151, 154, 155, 156, 157, 172], "esperanto": 95, "espous": [111, 112], "espresso": 147, "essai": [49, 84, 111, 112], "essenc": [42, 50, 111, 112, 116, 126, 133, 148], "essenti": [1, 7, 8, 10, 37, 38, 41, 42, 45, 46, 49, 55, 56, 57, 59, 64, 69, 71, 73, 75, 77, 78, 80, 81, 83, 88, 89, 93, 97, 98, 100, 105, 109, 111, 112, 113, 114, 115, 116, 117, 121, 122, 126, 127, 130, 131, 133, 134, 137, 138, 139, 142, 143, 144, 147, 148, 150, 156, 159, 166, 167, 172, 183], "est": [101, 106, 142], "establish": [6, 12, 13, 42, 53, 55, 63, 76, 78, 82, 89, 111, 112, 140, 169, 170, 172], "estim": [0, 8, 26, 27, 49, 53, 54, 88, 92, 101, 111, 112, 116, 120, 131, 133, 138, 145, 147, 151, 152, 167, 169], "estonian": 95, "et": [0, 6, 7, 52, 53, 71, 84, 95, 97, 98, 99, 101, 105, 106, 111, 112, 113, 115, 116, 117, 119, 120, 124, 125, 127, 128, 129, 145, 147], "et_al": 149, "eta": [132, 135, 136, 150, 151, 152, 181], "etc": [51, 64, 78, 80, 81, 97, 98, 99, 104, 105, 111, 112, 133, 134, 136, 140, 144, 145, 154, 159, 167], "etf": [101, 152], "ethic": [1, 4, 41, 45, 47, 50, 55, 59, 74, 86, 89, 92, 93, 98, 109, 111, 112, 170], "ethnic": [111, 112], "etl": 38, "etm": 141, "etn": 141, "etruscan": [111, 112], "etymolog": [111, 112], "eu": [95, 101, 139], "eugen": [0, 111, 112], "eugenia": 0, "eul": 130, "euro": 152, "eurocentr": [111, 112], "europ": [111, 112], "europarl": 93, "european": [111, 112, 140, 152], "ev": [111, 112], "eval": [14, 16, 17, 20, 22, 29, 30, 35, 51], "eval_accuraci": 110, "eval_batch_s": [14, 16, 17, 19, 22, 30], "eval_dataset": 110, "eval_loss": [14, 16, 17, 22, 30, 110, 112], "eval_pr": [51, 110], "eval_result": 112, "eval_runtim": [110, 112], "eval_samples_per_second": [110, 112], "eval_steps_per_second": [110, 112], "evalu": [4, 5, 6, 8, 9, 10, 14, 22, 37, 38, 46, 47, 53, 57, 63, 70, 71, 74, 75, 80, 83, 84, 85, 91, 95, 97, 98, 109, 110, 111, 112, 115, 122, 129, 130, 133, 135, 136, 142, 149, 150, 155, 158, 165, 167, 171, 172], "evaluate_classification_perform": 135, "evaluation_result": 110, "evan": 34, "evangel": [111, 112], "evapotranspir": [111, 112], "even": [1, 5, 6, 9, 10, 12, 42, 45, 49, 50, 56, 59, 61, 64, 76, 77, 88, 90, 92, 93, 97, 98, 100, 102, 106, 111, 112, 113, 115, 116, 118, 120, 122, 124, 125, 130, 132, 133, 136, 138, 139, 140, 142, 143, 145, 146, 147, 150, 152, 154, 155, 156, 159, 169, 171, 174], "evenli": 114, "event": [49, 73, 111, 112, 119, 130, 132, 134, 157], "event_timestamp": [14, 16, 17, 19], "eventu": [52, 111, 112, 150, 184], "ever": [2, 38, 77, 78, 88, 89, 90, 112, 136, 163, 169, 174], "everest": 100, "everett": 97, "evergreen": [111, 112], "everi": [10, 23, 52, 63, 76, 88, 107, 108, 111, 112, 115, 117, 121, 126, 128, 136, 139, 140, 151, 152, 154, 172, 185], "everybodi": [0, 24, 156], "everydai": [88, 111, 112], "everyon": [24, 71, 77, 98, 111, 112, 178], "everyth": [3, 61, 72, 88, 108, 136, 180], "everython": 88, "everywher": [3, 156], "evid": [2, 93, 111, 112, 119, 120, 140, 150], "evidenc": 119, "evil": [111, 112, 150], "eviron": [24, 25, 26, 27, 30, 31, 32, 33, 34, 35], "evolut": [7, 37, 50, 52, 56, 64, 74, 97, 111, 112, 151, 159, 164, 165, 172], "evolutionari": [97, 111, 112, 164, 171], "evolv": [2, 5, 6, 11, 46, 49, 50, 52, 53, 54, 55, 56, 57, 59, 62, 69, 77, 78, 83, 89, 122, 130, 151, 162, 163, 165, 166, 171, 172], "ex": [101, 174], "exacerb": [55, 93, 111, 112], "exact": [112, 117, 132, 144, 147, 150, 154, 155, 156, 178], "exactli": [14, 16, 17, 22, 97, 110, 114, 126], "exam": [47, 85], "examin": [38, 41, 47, 56, 94, 97, 111, 112, 113, 116, 120, 142, 151, 155, 156, 172], "exampl": [8, 9, 12, 30, 41, 45, 46, 49, 52, 59, 60, 61, 64, 65, 67, 69, 71, 73, 76, 77, 79, 80, 92, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 128, 130, 134, 136, 137, 138, 139, 140, 143, 144, 145, 147, 148, 150, 151, 153, 155, 156, 157, 159, 160, 167, 168, 172, 175, 176, 177, 180, 181, 182, 185], "example_id": [14, 22], "excav": [111, 112], "exce": [10, 97], "exceed": [111, 112], "exceedingli": [111, 112], "excel": [6, 8, 40, 41, 42, 46, 49, 53, 55, 59, 76, 85, 98, 115, 116, 123, 136, 148], "except": [2, 10, 57, 108, 111, 112, 116, 128, 139, 152, 154, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "exception": 116, "excess": [59, 130], "exchang": [77, 78, 122], "excis": [111, 112], "excit": [5, 11, 56, 88, 97, 130, 154], "exclam": [117, 140], "exclud": [14, 88, 95, 111, 112, 114, 116, 150, 155], "exclus": [111, 112, 116], "excus": 136, "exec": 60, "execut": [1, 43, 44, 46, 57, 59, 61, 65, 71, 76, 80, 81, 89, 111, 112, 114, 141, 160, 163, 165, 169, 171, 172], "exemplar": 184, "exemplari": [111, 112], "exemplifi": [2, 44, 46, 56, 111, 112], "exercis": [111, 112, 185], "exet": [111, 112], "exhaust": 171, "exhibit": [11, 44, 49, 55, 59, 111, 112], "exil": [111, 112], "exist": [1, 2, 5, 6, 9, 38, 46, 51, 53, 55, 56, 59, 63, 64, 65, 69, 76, 77, 84, 88, 89, 93, 101, 111, 112, 120, 121, 123, 130, 144, 156, 159, 160, 163, 164, 165, 166, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185], "exist_ok": [123, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "existing_data": 16, "existing_polarity_data": 16, "exit": [3, 81, 111, 112, 152, 166, 185], "exmapl": [14, 16, 17, 19, 20, 21, 22], "exmoor": 178, "exogen": 119, "exorbit": 49, "exp": [8, 101, 132], "expand": [5, 50, 52, 53, 59, 91, 95, 111, 112, 130, 148, 172], "expans": [45, 49, 52, 111, 112, 130], "expec": 107, "expect": [4, 5, 6, 14, 16, 17, 22, 37, 45, 46, 50, 54, 55, 71, 73, 89, 91, 98, 101, 105, 106, 110, 111, 112, 115, 117, 128, 130, 143, 147, 150, 151, 152, 155, 157, 164, 167, 171, 172, 180], "expedit": [111, 112], "expel": [111, 112], "expenditur": 119, "expens": [6, 46, 49, 50, 52, 57, 59, 88, 92, 93, 98, 100, 101, 111, 112, 115, 126, 128, 130, 134, 136, 138, 151, 163, 167, 170, 172], "experi": [3, 6, 44, 49, 50, 52, 54, 56, 69, 70, 71, 75, 79, 80, 85, 89, 91, 92, 96, 97, 100, 111, 112, 116, 117, 120, 130, 136, 161, 169, 180, 181], "experienc": [56, 111, 112, 136], "experiment": [6, 55, 65, 71, 100, 160], "experimentalist": 6, "expert": [40, 53, 59, 74, 85, 111, 112, 130, 136, 166, 172], "expertis": [12, 45, 59, 64, 71, 88, 89, 91, 93, 98, 130, 159, 163, 166, 167, 169, 172], "expir": 128, "explain": [6, 12, 41, 50, 51, 53, 59, 68, 79, 82, 85, 98, 109, 111, 112, 115, 116, 119, 120, 128, 130, 136, 140, 147, 148, 151, 167, 170], "explan": [14, 16, 17, 19, 40, 42, 45, 67, 88, 98, 111, 112, 116, 176], "explanatori": 164, "explicit": [10, 46, 52, 100, 105, 130, 151, 154, 156], "explicitli": [8, 9, 10, 17, 53, 73, 95, 105, 111, 112, 121, 130, 150, 170], "explod": [14, 15, 21, 52, 138], "explode_split": [15, 24], "exploit": [38, 53, 63, 77, 111, 112, 130], "explor": [0, 2, 3, 4, 5, 6, 8, 9, 37, 42, 44, 48, 49, 50, 53, 55, 57, 66, 67, 70, 76, 77, 80, 83, 87, 89, 90, 93, 94, 95, 97, 98, 99, 106, 111, 112, 114, 116, 117, 120, 130, 135, 136, 142, 151, 153, 155, 156, 161, 172], "exploratori": [1, 71, 93, 96], "explos": [59, 77, 116], "expon": 132, "exponenti": [0, 93, 105, 116, 128, 132, 143, 148], "export": [6, 12, 20, 45, 51, 60, 111, 112, 152], "export_annot": 20, "exporttyp": 20, "expos": [54, 61, 73, 77, 80, 106, 111, 112, 113, 119, 120, 166, 172], "exposur": [37, 111, 112, 119, 120], "express": [2, 6, 7, 23, 49, 55, 91, 95, 96, 97, 110, 111, 112, 116, 129, 130, 134, 135, 137, 139, 140, 142, 150, 154], "expresswai": [111, 112], "expuls": [111, 112], "ext": [15, 117], "extend": [6, 42, 46, 49, 50, 52, 53, 56, 57, 59, 64, 65, 66, 97, 105, 111, 112, 119, 126, 138, 141, 151, 152, 159, 160, 172], "extens": [2, 5, 6, 45, 46, 50, 52, 59, 60, 62, 65, 79, 88, 93, 95, 97, 109, 111, 112, 116, 119, 124, 138, 139, 143, 151, 152, 154, 160, 172], "extent": [44, 50, 52, 92, 111, 112, 116, 151], "extern": [42, 44, 50, 52, 55, 57, 72, 85, 91, 97, 111, 112, 130], "extinct": 3, "extra": [9, 45, 88, 111, 112, 132, 140, 150, 152, 175], "extract": [0, 6, 7, 9, 12, 38, 41, 43, 51, 60, 71, 73, 91, 93, 95, 98, 100, 103, 105, 106, 111, 112, 116, 117, 118, 120, 121, 130, 135, 136, 138, 140, 144, 145, 146, 147, 148, 150, 151, 155, 165], "extract_arch": 17, "extractor": 7, "extran": 55, "extraordinarili": [111, 112], "extrem": [8, 10, 50, 85, 105, 111, 112, 126, 147, 150, 156, 171], "extrins": 132, "ey": [85, 111, 112, 156], "f": [14, 16, 19, 20, 21, 24, 26, 30, 32, 35, 67, 79, 80, 81, 94, 100, 101, 103, 104, 108, 110, 111, 112, 115, 123, 125, 128, 132, 136, 142, 152, 155, 157, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "f1": [14, 16, 22, 29, 30, 35, 51, 55, 74, 109, 130, 135, 136, 144], "f1_score": 135, "f3e88b4": 177, "f400fc7fc75fc9594a1731f6791aa0215fb1ead5": 184, "f5": [111, 112], "f6": 135, "f70a50493a56c656_": 112, "f9070a12dba861b399012944f966f08d40205281": 184, "f_": 119, "f_c": 155, "f_larg": 28, "f_small": 28, "f_tone": 33, "f_tone_data": 34, "f_w": 155, "f_wc": 155, "fa": [95, 101], "faa": 119, "fabric": [42, 111, 112], "fac": 101, "face": [1, 6, 8, 9, 12, 38, 42, 46, 47, 49, 59, 89, 93, 94, 96, 97, 100, 101, 103, 104, 107, 108, 110, 111, 112, 116, 119, 126, 134, 136, 139, 150, 152, 164, 167, 171], "facebook": [59, 98, 100, 116, 121, 134, 154], "facet": [1, 39, 44, 126, 167], "facetgrid": 26, "facial": [6, 50, 77, 111, 112], "facil": [111, 112], "facilit": [6, 38, 42, 44, 49, 50, 52, 53, 55, 57, 58, 59, 67, 77, 80, 83, 91, 98, 111, 112, 126, 151, 165, 171, 172], "fact": [10, 42, 49, 55, 71, 98, 101, 105, 111, 112, 115, 120, 126, 128, 130, 144], "factbook": 119, "faction": [111, 112], "facto": [111, 112], "factor": [12, 40, 49, 52, 59, 65, 77, 78, 88, 95, 99, 100, 111, 112, 117, 120, 121, 130, 132, 133, 136, 137, 138, 139, 147, 154, 155, 160, 171], "factori": [111, 112], "factual": [57, 84, 85, 98], "fade": [111, 112], "fai": [111, 112], "fail": [40, 106, 111, 112, 137, 147, 152, 156, 176, 177, 185], "failur": [55, 64, 65, 111, 112, 119, 159, 160, 166], "fair": [1, 12, 38, 41, 53, 59, 74, 89, 93, 98, 109, 130], "fairhop": [111, 112], "fairi": 3, "fairli": [114, 115], "faith": [16, 111, 112], "fake": [59, 84, 90, 98, 130], "fall": [28, 41, 84, 101, 111, 112, 119, 140, 152], "fallaci": [111, 112, 150], "fallen": [111, 112], "fals": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 45, 51, 59, 60, 77, 83, 85, 103, 111, 112, 123, 127, 128, 130, 143, 145, 149, 150, 152, 181], "famili": [1, 28, 46, 85, 86, 87, 111, 112, 120], "familiar": [37, 45, 46, 56, 69, 70, 75, 76, 80, 81, 87, 89, 97, 155], "famou": [2, 83, 99, 156], "famous": [111, 112], "fan": [111, 112, 177, 180, 181], "fanat": 150, "fanci": 118, "fangzhou": [0, 6], "fantasi": [3, 111, 112], "fantast": 178, "faq": [35, 169], "far": [53, 59, 95, 97, 111, 112, 116, 118, 156, 176], "fargo": [111, 112], "farm": [111, 112], "farmer": [88, 111, 112], "farmland": 12, "farthest": [111, 112], "fascin": [83, 126, 130], "fascism": [111, 112], "fascist": [111, 112], "fashion": 178, "fast": [6, 55, 95, 102, 105, 112, 121, 133, 141, 143, 145, 150, 166, 171, 177, 179], "fastaimodelartifact": 73, "fastapi": 72, "faster": [6, 49, 63, 64, 65, 71, 77, 88, 110, 111, 112, 120, 126, 128, 130, 150, 159, 160, 171, 172], "fasttext": [1, 126, 129, 138, 156], "fatal": [111, 112, 184], "father": [111, 112, 145], "fauna": [111, 112], "favor": [9, 59, 93, 97, 111, 112, 115, 136, 171], "favour": [111, 112], "favourit": 97, "fawr": [177, 180, 181], "fayett": [111, 112], "fb130a6169eb8f15_": 112, "fc52": 183, "fcdz04": 0, "fda": [111, 112], "fdd": 165, "fe": 101, "fear": [134, 152], "feasibl": [16, 46, 53, 89, 116, 132, 167], "feat": 139, "featherb": 155, "featur": [1, 5, 6, 7, 8, 9, 10, 12, 14, 22, 36, 37, 40, 46, 47, 49, 50, 59, 60, 62, 64, 65, 66, 67, 68, 71, 73, 75, 76, 88, 90, 93, 94, 102, 104, 105, 106, 110, 111, 112, 113, 116, 123, 124, 126, 130, 134, 137, 143, 144, 146, 148, 151, 156, 157, 159, 160, 167, 169, 170, 171, 172, 180, 186], "feature_build": [28, 33], "feature_extract": [136, 143, 150, 158], "featureset": 33, "februari": [111, 112, 129], "fed": [8, 9, 10, 25, 32, 52, 55, 112, 113, 116, 128, 152], "feder": [34, 38, 77, 78, 111, 112, 119, 120, 137], "federalist": [111, 112], "federalreserv": [23, 36], "fedfund": 34, "fedrat": 23, "fedu": 115, "fee": 176, "feed": [8, 40, 49, 52, 53, 71, 99, 111, 112, 113, 115, 116, 117], "feedback": [0, 1, 6, 9, 42, 49, 53, 55, 59, 63, 64, 65, 71, 74, 85, 91, 96, 111, 112, 130, 134, 159, 160, 166, 169, 170, 171, 172], "feeder": [111, 112], "feel": [46, 97, 111, 112, 130, 136, 155], "feet": 150, "fell": [111, 112, 152, 185], "felt": [111, 112, 136], "femal": [111, 112], "femin": [111, 112], "feminist": [111, 112], "feng": [0, 145], "fer": 101, "feral": [111, 112], "ferment": [111, 112], "fernando": [111, 112], "ferrer": [111, 112], "ferri": 167, "fertil": [111, 112], "festiv": [111, 112], "fetal": [111, 112], "fetch": [12, 21, 23, 68, 76, 112, 121, 123, 176, 177, 185], "fetch_20newsgroup": [149, 150], "fetch_builtin_corpu": 15, "fetcher": [21, 23, 24, 31, 34], "feudal": [111, 112], "fever": [92, 111, 112], "few": [2, 6, 47, 49, 51, 53, 55, 57, 65, 72, 97, 98, 109, 111, 112, 113, 114, 115, 117, 130, 136, 139, 144, 147, 151, 154, 160, 173, 174, 176, 182], "fewer": [9, 52, 65, 69, 93, 97, 111, 112, 117, 126, 130, 132, 133, 135, 150, 160], "ff": 101, "ffill": 34, "ffn": 52, "fi": [24, 95, 101, 104], "fiala": [111, 112], "fibroid": 136, "fica": [111, 112], "fiction": [111, 112, 174, 175], "fid": [9, 10], "fiddler": 59, "fidel": [6, 10], "fidler": [0, 6], "field": [2, 5, 6, 7, 8, 16, 38, 42, 49, 50, 52, 53, 54, 55, 59, 71, 76, 81, 83, 86, 88, 89, 91, 92, 93, 95, 96, 98, 111, 112, 113, 116, 118, 120, 122, 126, 129, 130, 141, 142, 143, 144, 150, 151, 152, 156, 157, 169], "field_tdr_date_valu": 23, "fieri": 17, "fifth": [111, 112], "fifti": [111, 112], "fig": [24, 149], "fight": [111, 112], "fight3r": 97, "figsiz": [14, 16, 17, 22, 23, 24, 25, 26, 27, 28, 31, 33, 94, 128, 136, 139, 149, 155], "figur": [6, 8, 12, 13, 14, 16, 17, 22, 23, 24, 25, 26, 27, 28, 31, 33, 94, 111, 112, 114, 119, 128, 136, 139, 155], "figure_format": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 114, 128, 145, 149, 150], "fil": [95, 101], "file": [14, 15, 16, 17, 20, 21, 22, 24, 28, 30, 33, 38, 45, 51, 59, 60, 62, 66, 69, 70, 73, 76, 77, 78, 79, 80, 81, 82, 103, 105, 111, 112, 121, 123, 124, 135, 146, 150, 152, 173, 175, 178, 179, 180, 182, 183, 184, 185], "file_inv": 14, "fileid": 135, "filenam": [14, 15, 16, 19, 21, 30, 135, 150, 152, 179], "filepath": 30, "filesystem": 60, "filetyp": [17, 30], "filipino": 95, "fill": [8, 10, 26, 27, 52, 84, 88, 99, 107, 108, 115, 116, 117, 130, 152, 176, 178], "fillna": [17, 26, 27], "film": [6, 111, 112], "filmmak": [111, 112], "filosottil": 79, "filter": [9, 12, 24, 88, 93, 95, 97, 104, 117, 122, 138, 142, 143, 145, 146, 150], "filter_length": 24, "filtered_data": [14, 15, 19, 21], "filterwarn": 35, "fin": [101, 124], "final": [2, 7, 8, 9, 10, 37, 42, 51, 53, 55, 60, 68, 70, 87, 88, 90, 95, 97, 99, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 123, 127, 128, 130, 133, 136, 140, 142, 144, 147, 149, 150, 152, 153, 155, 167, 172, 177, 183, 184], "financ": [1, 38, 39, 41, 50, 101, 111, 112, 122, 130, 132, 152], "financi": [37, 38, 41, 48, 50, 71, 101, 107, 108, 109, 111, 112, 119, 120, 130, 132, 134, 136, 137, 164, 165, 167, 170], "financial_phrasebank": 30, "finbert": 31, "finbert_col": 35, "finbert_diffusion_minut": [30, 31, 32, 33, 34, 35], "finbert_diffusion_press_conf": [30, 31], "finbert_diffusion_speech": [30, 31, 33, 35], "finbert_diffusion_stat": [30, 31, 32, 33], "finbert_mean_minut": [30, 31], "finbert_mean_press_conf": [30, 31], "finbert_mean_speech": [30, 31], "finbert_mean_stat": [30, 31], "finbert_model": 30, "finbert_ton": [31, 32, 33], "find": [0, 10, 16, 22, 36, 42, 43, 49, 53, 54, 55, 60, 62, 79, 88, 89, 93, 96, 97, 100, 101, 106, 107, 111, 112, 114, 115, 116, 119, 120, 130, 132, 138, 142, 144, 145, 147, 149, 150, 151, 155, 171, 172, 174, 177, 178, 181, 184], "find_corp_cod": 123, "find_dotenv": 123, "find_label_error": [14, 16, 17], "find_local_entropi": 145, "find_merg": 101, "find_speaker_of_sect": 24, "findabl": 38, "findal": [100, 149], "finder": 149, "findfont": 28, "findit": 101, "fine": [1, 6, 8, 9, 12, 14, 41, 47, 51, 53, 55, 57, 71, 75, 83, 84, 86, 88, 91, 93, 96, 97, 98, 99, 100, 106, 109, 111, 112, 115, 122, 130, 138, 144, 157], "finess": 114, "finetuin": [1, 96, 109], "finetun": [10, 45, 110, 117], "finger": 6, "fingerprint": [76, 77], "finish": [16, 17, 22, 88, 97, 128, 172], "finit": [8, 139], "finn": [0, 135], "finnish": [95, 111, 112, 115], "fintech": 59, "fir": [101, 107], "fir57": 0, "fire": [16, 111, 112], "firebrand": 16, "firefli": 17, "firewal": [59, 152], "firm": [0, 49, 56, 111, 112, 120, 152, 171], "firmrisk_": 119, "first": [5, 6, 8, 9, 10, 23, 24, 26, 27, 49, 51, 52, 60, 72, 74, 76, 77, 80, 88, 89, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 120, 123, 124, 126, 127, 130, 132, 133, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 152, 153, 155, 156, 158, 167, 173, 175, 176, 177, 178, 179, 181, 182, 184], "first_nam": 23, "firstli": [59, 138], "firth": [0, 156], "fiscal": [111, 112, 128, 152], "fish": [6, 46, 66, 99, 111, 112], "fishey": 8, "fit": [6, 20, 29, 35, 38, 41, 46, 56, 62, 64, 71, 73, 97, 101, 111, 112, 118, 136, 147, 150, 151, 152, 158, 159, 166, 167, 172], "fit_resampl": 136, "fit_transform": [136, 150, 158], "five": [6, 9, 111, 112, 115, 120, 135, 140, 165, 167], "fix": [1, 8, 9, 52, 63, 64, 65, 68, 71, 77, 88, 97, 105, 106, 111, 112, 114, 115, 116, 117, 120, 132, 133, 140, 143, 146, 151, 152, 157, 159, 160, 161, 166, 169, 171, 172, 180, 183, 186], "fixat": [111, 112, 114], "fixi": 59, "fl": [111, 112], "flag": [14, 22, 59, 61, 64, 79, 100, 103, 159, 173, 176], "flame": [0, 111, 112], "flaml": 35, "flan": 51, "flant5": 51, "flap": [111, 112], "flat": [111, 112], "flatten": [116, 126, 145], "flatter": 97, "flavor": 46, "flaw": [55, 97, 99], "flax": 8, "fled": [111, 112], "flexibl": [6, 8, 9, 42, 44, 45, 46, 50, 59, 60, 62, 69, 73, 74, 88, 106, 121, 126, 130, 151, 163, 166, 167, 169, 171, 172], "fli": 139, "flight": [111, 112], "flip": 128, "float": [25, 31, 88, 115, 124, 150, 152], "float64": 28, "floor": [126, 130], "flop": [88, 115, 150], "flora": [111, 112], "florenc": [111, 112], "florian": [0, 6], "florida": [111, 112], "flourish": [111, 112], "flow": [36, 52, 55, 88, 91, 114, 136, 152, 164, 165, 166, 170, 171, 172], "flowchart": [143, 170], "flower": [9, 16, 111, 112, 147], "fluctuat": [38, 50, 111, 112], "fluent": [84, 97, 98, 131, 139], "fluid": [6, 171], "fluiditi": 171, "fluoxetin": [111, 112], "fluvoxamin": [111, 112], "flux": [64, 111, 112, 159], "fly": [97, 105, 121, 139, 174], "flynt": [111, 112], "fma": [14, 22, 100], "fmri": [111, 112], "fmt": [25, 31, 136], "fn": [14, 16], "fname": 124, "fnc\ubd80\ubb38": 15, "fnielsen": 135, "fo": 101, "foam": [111, 112], "focal": [50, 88, 111, 112], "focu": [7, 11, 47, 49, 50, 52, 55, 56, 59, 60, 65, 70, 74, 84, 87, 89, 93, 96, 97, 102, 103, 104, 105, 111, 112, 113, 114, 116, 122, 129, 130, 134, 150, 160, 167, 169, 171, 172, 186], "focus": [6, 8, 39, 41, 46, 48, 49, 50, 52, 53, 55, 59, 60, 62, 64, 66, 68, 71, 74, 76, 89, 91, 93, 95, 97, 100, 111, 112, 113, 116, 117, 120, 121, 122, 132, 134, 144, 147, 150, 153, 156, 159, 162, 163, 164, 166, 167, 169, 171, 172], "fol": 101, "folder": [69, 173, 185], "foliag": [111, 112], "folk": 150, "follow": [1, 4, 6, 9, 14, 22, 28, 42, 45, 46, 52, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 73, 76, 77, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 124, 125, 126, 128, 130, 132, 133, 135, 139, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 171, 172, 173, 177, 178, 180, 181], "fomc": [0, 1, 12, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37], "fomc_": 30, "fomc_calendar": 23, "fomc_chunk": 24, "fomc_corpu": 24, "fomc_data": 24, "fomc_features_larg": 28, "fomc_features_smal": [28, 29], "fomc_finbert": 30, "fomc_meeting_script": [24, 30], "fomc_minut": 30, "fomc_sect": 24, "fomc_sent": [24, 30], "fomc_sent_senti": 30, "fomc_sent_sentiments_finbert": 30, "fomc_sent_sentiments_t5": 30, "fomc_sentiment_data": 30, "fomc_sentiment_finbert_next": 30, "fomc_sentiment_t5_next": 30, "fomc_t5": 30, "fomc_tone_data_finbert": [30, 31], "fomc_tone_data_lm": [30, 31, 32], "fomc_tone_data_merg": 31, "fomc_tone_data_t5": [30, 31], "fomc_tone_featur": [33, 35], "fomc_tone_finbert": 35, "fomc_tone_lm": 35, "fomc_tone_t5": 35, "fomc_tones_lm": 30, "fomc_train_ton": [33, 34], "fomccalendar": 36, "font": [28, 111, 112], "font_manag": 28, "fontsiz": [23, 24, 28], "fonttool": 136, "foo": 101, "food": [15, 46, 111, 112, 116, 143, 156], "foot": [6, 111, 112, 150], "footbal": [111, 112, 143, 151], "footer": [149, 150], "footprint": [38, 55, 60, 62, 98], "forc": [6, 15, 16, 17, 20, 22, 28, 30, 33, 59, 97, 111, 112, 113, 116, 133, 176], "force_download": [23, 24, 31, 34], "force_extract": 17, "forecast": [1, 12, 23, 24, 25, 26, 27, 31, 36, 37, 39, 40, 41, 113, 152], "forefront": 52, "foreground": 88, "foreign": [111, 112, 119, 145], "foreignrisk_": 119, "foreshadow": 119, "forest": [3, 12, 111, 112, 138], "forestri": [111, 112], "forg": 69, "forgeri": 77, "forget": [51, 174], "forgotten": 178, "fork": [1, 17, 70, 79, 161, 185, 186], "form": [0, 2, 5, 8, 12, 46, 49, 52, 53, 59, 77, 78, 88, 89, 96, 101, 104, 105, 106, 111, 112, 113, 114, 115, 116, 119, 122, 126, 129, 130, 133, 134, 139, 140, 142, 145, 146, 147, 149, 150, 152, 153, 155, 156, 163, 176, 178, 179], "formal": [47, 111, 112, 130, 164, 167, 171], "format": [6, 7, 8, 17, 22, 28, 41, 43, 45, 46, 55, 59, 64, 69, 71, 72, 73, 77, 78, 89, 97, 100, 101, 102, 103, 104, 106, 107, 108, 120, 121, 123, 126, 127, 128, 132, 138, 142, 150, 152, 159, 173], "format_word": 101, "formatted_warn": 30, "former": [9, 95, 111, 112, 136, 145, 152], "formerli": [111, 112, 141], "formid": [42, 53], "formul": [6, 12, 55, 57, 89, 111, 112, 168, 169], "formula": [97, 105, 106, 111, 112, 119, 120, 126, 133, 147, 157], "forrest": [111, 112], "fort": [111, 112], "forti": [111, 112], "fortinet": 82, "forum": [93, 111, 112, 120, 134, 169], "forward": [6, 36, 49, 52, 53, 76, 77, 88, 89, 110, 111, 112, 113, 114, 116, 117, 127, 128, 145, 177, 179], "fossil": [111, 112], "foster": [2, 37, 42, 59, 63, 64, 65, 71, 98, 111, 112, 159, 160, 171], "fought": [111, 112], "found": [8, 10, 15, 28, 33, 35, 45, 59, 69, 76, 84, 88, 89, 94, 97, 98, 100, 101, 103, 107, 108, 110, 111, 112, 114, 115, 116, 117, 119, 120, 121, 136, 145, 151, 156, 184], "foundat": [7, 45, 46, 52, 54, 55, 60, 62, 64, 80, 83, 88, 89, 98, 111, 112, 121, 127, 130, 132, 133, 139, 147, 151, 154, 155, 159, 165, 169, 171], "founder": [59, 111, 112], "four": [3, 9, 38, 42, 64, 88, 104, 111, 112, 115, 116, 119, 147, 149, 150, 151, 152, 159, 171, 172, 179], "fourgram_model": 133, "fourth": [9, 88, 111, 112, 128], "fox": [111, 112, 115, 142, 144, 158], "fp": [6, 14, 16], "fp16": [51, 111, 112], "fr": 95, "frac": [8, 21, 99, 119, 124, 125, 128, 132, 143, 145, 147, 148, 157], "fraction": [10, 52, 71, 111, 112], "fractur": [111, 112], "fragil": [111, 112], "fragrant": 16, "frame": [6, 14, 15, 21, 116, 117, 167], "framework": [1, 6, 10, 12, 38, 44, 50, 53, 54, 56, 57, 64, 71, 72, 74, 80, 92, 98, 111, 112, 156, 159, 164, 166, 167, 169, 170, 172], "franc": [100, 111, 112, 152], "franchis": [111, 112], "francisco": [111, 112, 139], "francoi": 0, "fraud": [38, 111, 112], "fraudul": 49, "fred_api_kei": [30, 31, 32, 33, 34], "freddefrallan": 9, "free": [0, 1, 5, 7, 9, 49, 65, 88, 96, 97, 110, 111, 112, 116, 130, 139, 155, 160, 176], "freed": [111, 112], "freedmen": [111, 112], "freedom": [111, 112], "freeli": [77, 111, 112, 117, 121, 140], "freez": 117, "french": [46, 95, 111, 112, 115, 122, 130, 156], "freq": [101, 107, 108], "freq_dist": 139, "freqdist": 139, "frequenc": [8, 12, 13, 26, 40, 59, 94, 101, 103, 106, 107, 108, 111, 112, 119, 120, 124, 130, 133, 138, 139, 143, 146, 147, 148, 150, 151, 152, 153, 155, 156, 157, 158], "frequent": [10, 12, 13, 42, 46, 55, 65, 93, 101, 103, 105, 106, 107, 108, 111, 112, 119, 120, 126, 128, 132, 136, 137, 138, 139, 140, 142, 143, 147, 150, 153, 157, 160, 164, 171, 172], "fresh": [16, 111, 112, 114, 132], "freshli": [111, 112], "freshwat": [111, 112], "fresnel": [111, 112], "fridai": 128, "friend": [111, 112], "friendli": [59, 62, 69, 73, 76, 88, 95, 111, 112, 123, 126], "friendship": [111, 112], "fring": [111, 112], "frisian": 95, "from": [0, 1, 2, 5, 7, 9, 10, 11, 12, 14, 15, 16, 17, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 68, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127, 128, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 166, 167, 168, 171, 172, 173, 174, 175, 176, 177, 179, 181, 183, 184, 185, 186], "from_dat": [23, 32], "from_fil": [103, 111, 112], "from_pretrain": [51, 97, 100, 104, 110, 111, 112, 114], "from_word": 149, "from_year": [23, 24, 31, 34], "front": [59, 111, 112, 116], "frontend": [60, 69, 181], "frontier": [55, 98, 111, 112, 118], "frost": 16, "frozen": [10, 46, 49, 52, 111, 112], "frugal": 35, "fruitcak": 150, "frustrat": 136, "fs_cfg": [29, 35], "fs_fomc": 29, "fsdp": 83, "fsdp_config": 51, "fsl": 100, "ftp": [77, 121, 150], "ftse": 152, "fu": [0, 101], "fucntion": 20, "fuel": [14, 111, 112, 152], "fugashi": 141, "ful": 139, "full": [1, 3, 6, 9, 25, 45, 46, 49, 52, 53, 57, 65, 76, 77, 81, 88, 93, 99, 111, 112, 116, 120, 126, 128, 140, 150, 152, 154, 160, 172, 175, 185], "full_matric": 150, "fullest": 52, "fulli": [39, 46, 52, 85, 88, 112, 113, 116, 117, 126, 127, 128, 134, 139, 145, 150, 171, 172], "fullnam": 17, "fun": [101, 128], "func": [17, 24], "function": [0, 7, 8, 9, 10, 15, 16, 19, 21, 22, 24, 28, 30, 33, 44, 46, 47, 49, 52, 54, 57, 59, 60, 62, 64, 65, 69, 71, 77, 80, 82, 84, 88, 90, 95, 97, 99, 101, 104, 105, 107, 108, 110, 111, 112, 113, 114, 116, 123, 124, 125, 126, 130, 133, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 147, 150, 151, 152, 155, 159, 160, 166, 167, 169, 170, 171, 172, 178], "functool": [15, 16, 19, 20, 21, 24, 28, 30, 33, 34], "fund": [34, 101, 111, 112, 133, 152], "fundament": [6, 37, 49, 50, 52, 56, 77, 80, 96, 129, 130, 133, 145, 146, 153, 157, 167, 168, 171, 172], "fundamentalist": [111, 112], "funsd": 51, "furnitur": [111, 112], "further": [6, 8, 9, 49, 50, 52, 59, 76, 77, 85, 89, 93, 96, 97, 100, 103, 104, 109, 110, 111, 112, 113, 116, 117, 120, 123, 128, 129, 130, 140, 147, 150, 152, 156, 172], "furthermor": [6, 8, 9, 38, 59, 77, 80, 86, 93, 96, 102, 129, 139], "fuse": 3, "fusiform": [111, 112], "fusion": [2, 54, 111, 112], "futur": [0, 1, 3, 6, 8, 22, 36, 38, 42, 52, 55, 75, 78, 83, 88, 89, 96, 97, 98, 110, 111, 112, 116, 120, 132, 152, 163, 167, 172, 176], "futurewarn": [28, 30, 110, 112], "futurist": [3, 111, 112], "fuzzi": 79, "fx": 181, "fy": [95, 111, 112], "fzf_default_opt": 79, "g": [0, 5, 8, 12, 14, 16, 17, 19, 20, 21, 22, 32, 45, 53, 55, 60, 64, 65, 67, 75, 77, 78, 80, 82, 88, 97, 99, 100, 101, 105, 108, 110, 111, 112, 115, 117, 120, 123, 130, 132, 133, 137, 138, 139, 142, 143, 146, 147, 148, 152, 153, 156, 159, 160, 167, 170, 171, 174, 175, 177, 181], "g1490fd9": 28, "g3d56094": 15, "g69734d6": [24, 31, 32, 33, 34], "g8433774": [23, 25, 26, 27], "g90d1dea": [30, 35], "ga": [14, 95, 101, 111, 112], "gabriel": 0, "gad": [111, 112], "gade": 59, "gadsden": [111, 112], "gaelic": 95, "gai": [111, 112], "gain": [5, 6, 12, 41, 46, 50, 59, 75, 77, 89, 96, 101, 109, 111, 112, 114, 115, 116, 118, 128, 130, 134, 149, 150, 152, 161, 172], "gainer": 101, "galacticentr": 150, "galaxi": [16, 64, 159], "galician": 95, "galleanist": [111, 112], "galleri": 2, "galleria": [111, 112], "game": [5, 6, 42, 53, 54, 97, 111, 112, 130, 133, 136], "gan": [5, 6, 11, 130], "gantt": 170, "gap": [10, 44, 49, 52, 59, 63, 65, 73, 100, 111, 112, 130, 160], "garcilaso": [111, 112], "garden": [3, 117, 147], "gari": [0, 6, 111, 112], "garner": 52, "garrison": [111, 112], "gase": 3, "gasif": 14, "gasolin": 149, "gastrointestin": [111, 112], "gate": [49, 52, 130, 138], "gatewai": [77, 82], "gather": [12, 43, 55, 88, 111, 112, 116, 120, 121, 156, 165, 169], "gating_factor": 52, "gaug": [12, 50, 55, 137], "gaussian": [9, 95, 132], "gave": [111, 112, 116], "gaze": [111, 112], "gb": [52, 117], "gbm": 12, "gca": 155, "gd": 95, "gdmrmodel": 152, "gdp": [12, 13, 23, 25, 26, 27, 34, 111, 112], "gdp_diff_prev": [23, 25, 26, 27, 28, 29, 33, 35], "gdp_diff_year": [25, 26, 27, 28], "gdpc1": 34, "gdpdef": 34, "gdppot": [23, 25], "gdppot_diff_prev": [25, 26, 27, 28], "gdppot_diff_year": [25, 26, 27, 28], "gdpr": [59, 74, 93], "ge": 101, "gear": 88, "geb12c43": 29, "geda": 0, "gelbukh": 129, "gelli": 0, "gelu": [52, 112], "gen": [79, 101], "gender": [88, 98, 111, 112, 120, 140], "gene": [111, 112, 150], "gener": [0, 1, 2, 8, 9, 11, 12, 13, 28, 40, 42, 44, 45, 46, 47, 48, 51, 52, 53, 58, 61, 71, 72, 76, 77, 78, 80, 83, 85, 87, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 105, 109, 111, 112, 113, 114, 116, 117, 119, 120, 121, 122, 124, 126, 128, 129, 133, 136, 138, 139, 140, 143, 144, 147, 148, 149, 150, 151, 152, 154, 164, 165, 167, 169, 176, 181, 182], "general_funct": 30, "generalist": 0, "generaliz": [50, 54, 119], "generate_chain_of_thought": 100, "generate_sent": 133, "generate_speech": 72, "generate_text": [72, 111], "generated_text": [100, 111], "genet": [7, 111, 112], "geneticist": [111, 112], "genom": [111, 112], "genotyp": [111, 112], "genr": [2, 93], "gensim": [12, 147, 149], "gentl": [16, 111, 112], "genuin": 1, "geo": [82, 120], "geochemistri": [111, 112], "geograph": [12, 88, 111, 112, 120], "geographi": [100, 111, 112], "geolog": [111, 112], "geometr": [6, 88, 111, 112], "geometri": [6, 111, 112], "geonam": 119, "georg": [0, 111, 112], "georgia": [111, 112, 133], "georgian": 95, "geq": 145, "ger": 101, "gerard": 0, "german": [95, 98, 111, 112, 115, 117, 122, 139], "germani": [0, 152], "gesehen": 139, "gestur": [111, 112], "get": [3, 16, 17, 20, 24, 54, 64, 71, 79, 80, 81, 88, 89, 97, 99, 101, 111, 112, 115, 119, 123, 124, 128, 132, 133, 136, 137, 139, 140, 141, 143, 150, 155, 159, 171, 173, 175, 176, 177, 183, 184, 185], "get_bigram_count": 101, "get_coherence_per_top": 149, "get_feature_import": 29, "get_feature_names_out": 150, "get_group": 20, "get_irf": 34, "get_peft_config": 51, "get_peft_model": 51, "get_scor": 152, "get_text": 123, "get_tokens_from_vocab": 101, "get_topic_dist": 152, "get_topic_word": 152, "get_topic_word_dist": 152, "get_vocab_s": 111, "get_word_emded": 128, "get_workspac": [17, 19], "getcwd": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "getent": 81, "ggplot": 149, "gh": [69, 101], "ghani": 0, "ghe": 107, "gher": 107, "ghlight": 107, "ghost": [111, 112], "ght": 101, "gi": [101, 112], "giac": [111, 112], "giant": [93, 152], "gib": [103, 121, 130], "gibb": 152, "gibberish": 97, "gic": 101, "gid": 81, "giddi": 16, "gif": 150, "gil": 121, "gimenez": 0, "ging": 101, "ginosar": [0, 6], "giraff": 100, "giraudi": 0, "girl": [3, 111, 112], "git": [1, 64, 65, 66, 67, 68, 69, 70, 71, 75, 79, 80, 81, 159, 160, 161, 167, 169, 175, 178, 180, 182, 183, 185, 186], "git_dir": [174, 177, 179, 180, 181, 182, 184, 185], "git_exampl": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "git_example_dir": [173, 175, 176], "github": [1, 9, 10, 24, 29, 30, 35, 45, 49, 59, 60, 64, 65, 66, 69, 70, 75, 79, 88, 128, 130, 136, 145, 152, 159, 160, 161, 169, 180, 181, 184, 186], "gitignor": 181, "gitlab": [64, 65, 69, 76, 159, 160], "gitop": [1, 65, 70, 160, 161], "give": [9, 52, 53, 59, 101, 106, 111, 112, 113, 116, 130, 132, 136, 139, 144, 149, 156, 157, 158, 167, 169, 171, 176, 178], "given": [5, 6, 8, 9, 10, 11, 20, 35, 38, 42, 44, 46, 50, 51, 52, 53, 59, 86, 88, 89, 90, 92, 93, 97, 98, 99, 100, 101, 102, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 119, 120, 124, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 143, 144, 145, 147, 150, 151, 152, 153, 154, 155, 156, 167, 179], "gl": [69, 95, 111, 112], "glacier": [111, 112], "glanc": 97, "glass": [3, 88, 130], "glassdoor": 120, "glean": 46, "gli": 139, "glid": [5, 130], "glide": 10, "glimps": 98, "glint": [111, 112], "glitter": [16, 125], "global": [0, 9, 54, 76, 88, 97, 101, 111, 112, 119, 125, 132, 152, 154, 173, 174], "global_step": [16, 17, 22, 110, 112], "globalis": [111, 112], "globalrisk_": 119, "globe": [111, 112, 119], "glottal": [111, 112], "glove": [1, 99, 124, 126, 129, 138, 156], "glue": [51, 99, 117, 122], "gluten": [111, 112], "glyder": [177, 179, 180, 181], "glyph": [111, 112], "gmail": 140, "gn": 101, "gnu": [66, 79, 181], "gnupg": 79, "go": [53, 55, 67, 76, 79, 97, 101, 104, 110, 111, 112, 117, 126, 130, 136, 140, 155, 175, 176, 177, 178, 182, 185], "goal": [1, 6, 9, 42, 44, 52, 55, 59, 60, 63, 64, 65, 85, 88, 89, 91, 92, 97, 100, 102, 104, 106, 111, 112, 116, 117, 120, 134, 138, 147, 148, 150, 151, 159, 160, 167, 169, 170, 172], "god": [111, 112, 120, 150], "godwin": [111, 112], "goe": [101, 145], "gold": [101, 115, 125, 130, 152], "goldberg": 136, "golden": [111, 112], "goldman": [111, 112, 152], "goldp": 115, "golf": [111, 112, 136], "golovin": 0, "gomez": 0, "gon": [0, 6], "gondola": 3, "gone": [111, 112, 140], "gong": 0, "gonzalez": 0, "goo": 101, "good": [1, 12, 24, 52, 53, 62, 64, 67, 72, 77, 78, 80, 93, 101, 110, 111, 112, 115, 117, 120, 126, 130, 132, 133, 136, 137, 138, 140, 141, 152, 155, 157, 159, 176, 177, 178, 179, 183, 184], "goodfellow": 5, "goodman": [111, 112], "goodyear": [111, 112], "googl": [2, 5, 9, 10, 12, 17, 21, 24, 31, 32, 33, 34, 42, 49, 51, 53, 59, 64, 66, 70, 71, 80, 89, 93, 98, 100, 105, 106, 110, 111, 112, 115, 116, 123, 130, 139, 143, 152, 154, 159, 173, 174, 175, 177, 179, 180, 181, 182, 184, 185], "googler": 139, "googlif": 139, "googlifi": 139, "gop": [111, 112], "gopher": 98, "gordon": [0, 6], "gorri": [111, 112], "gospel": [111, 112], "got": [17, 136, 183], "gothic": [111, 112], "gov": [23, 36], "govern": [3, 12, 59, 71, 85, 111, 112, 119, 133, 151, 152], "government": [12, 59], "governor": [111, 112], "goyal": 99, "gpdic1": 34, "gpg": [1, 66, 70, 78, 79, 80], "gpgsign": 76, "gpt": [1, 8, 9, 12, 42, 44, 45, 46, 47, 49, 52, 53, 55, 59, 74, 83, 86, 87, 92, 93, 97, 98, 100, 104, 109, 111, 117, 121, 122, 138, 146], "gpt2": [51, 97, 100, 104, 111], "gpt2_log": 111, "gpt2_token": 111, "gpt2_uncas": 111, "gpt2config": 111, "gpt2lmheadmodel": [100, 111], "gpt2token": [97, 100, 111], "gptengin": [42, 44], "gptzero": 90, "gpu": [6, 14, 45, 51, 52, 59, 74, 83, 88, 97, 110, 112, 150, 152], "gqa": 59, "gr": 101, "gra": [111, 112], "grace": 139, "grad": 101, "grade": [46, 49, 52, 71, 111, 112], "gradient": [8, 9, 10, 12, 45, 49, 51, 52, 73, 88, 109, 112, 116, 128, 138, 151], "gradient_accumul": 45, "gradient_accumulation_step": 51, "gradient_checkpoint": [51, 112], "gradient_clip": 51, "gradio": [1, 51, 70, 74], "gradual": [9, 52, 88, 96, 111, 112, 117, 120, 129, 172], "graduat": [111, 112], "grafana": [64, 65, 70, 71, 159, 160], "grain": [6, 111, 112, 144, 152, 157], "gram": [1, 49, 95, 97, 114, 120, 129, 131, 133, 136, 138, 139, 145, 146, 154, 156], "grammar": [53, 93, 98, 111, 112, 130, 131, 138, 139, 144], "grammat": [53, 55, 111, 130, 135, 136, 137, 138, 139, 144, 157], "grandin": [111, 112], "granduri": 0, "grant": [49, 77, 81, 83, 93, 111, 112, 121], "granular": [12, 53, 55, 106, 169], "graph": [6, 38, 54, 55, 98, 116, 177, 178, 180, 181, 183], "graphic": [0, 5, 6, 59, 97, 111, 112, 117, 144, 150], "grappl": 38, "grasp": [55, 80, 134, 179], "grass": [111, 112, 136], "grassroot": [111, 112], "grave": 0, "graviti": 119, "gre": 101, "great": [66, 90, 101, 111, 112, 116, 136, 174, 177, 183], "greater": [1, 9, 10, 42, 53, 65, 88, 90, 97, 111, 112, 116, 160, 172], "greatest": [111, 112, 130, 151], "greatli": [1, 111, 112, 116, 138, 140, 144, 154], "greatly_appreci": 149, "greec": [111, 112, 119], "greedi": 145, "greedili": 97, "greedy_output": 97, "greek": [1, 95, 111, 112, 115], "green": [32, 111, 112, 132, 147, 155, 158, 176, 178], "greenhous": [111, 112], "greenspan": [23, 30, 31], "greet": [111, 112], "greg": 0, "grep": 60, "gretel": 59, "grew": [111, 112], "grid": [8, 25, 26, 32, 88], "griffith": 0, "groceri": [111, 112], "gross": [111, 112], "grossli": [111, 112], "ground": [46, 88, 98, 111, 112], "groundbreak": [7, 83, 88, 113, 116], "groundwork": [139, 165], "group": [6, 20, 42, 55, 59, 64, 65, 80, 83, 87, 95, 98, 101, 108, 111, 112, 119, 120, 126, 137, 138, 143, 148, 150, 152, 159, 160, 163, 169, 170], "group_text": 111, "groupbi": [20, 30], "groupchat": 42, "grow": [10, 41, 50, 55, 77, 84, 89, 93, 101, 111, 112, 116, 118, 120, 122, 130, 148, 151, 152, 163, 164, 171], "grown": [49, 93, 142], "growth": [26, 27, 34, 38, 53, 55, 65, 93, 101, 111, 112, 151, 152, 160], "grpc": 60, "gru": [130, 138], "grunya": [111, 112], "gt": 20, "gth": 107, "gu": [95, 101], "guanaco": 45, "guarante": [97, 133, 138, 150, 151], "guard": 79, "guardian": [12, 13], "guardrail": 59, "gubernatori": [111, 112], "guerrilla": [111, 112], "guess": 150, "gui": [0, 6, 101, 136], "guid": [8, 9, 10, 12, 42, 43, 45, 46, 50, 52, 53, 57, 59, 60, 61, 64, 69, 75, 81, 82, 88, 89, 92, 100, 110, 111, 112, 116, 119, 136, 159, 166, 167, 169, 171, 172], "guidanc": [1, 7, 9, 36, 49, 52, 89, 172], "guidelin": [1, 41, 53, 77, 83, 89, 111, 112, 121, 161, 164, 166, 168], "guilti": 137, "gujarati": 95, "gulf": [111, 112, 119], "gumbel": 8, "gump": 108, "gun": [111, 112], "guntersvil": [111, 112], "guo": [0, 6], "gustav": [111, 112], "gut": [111, 112], "gutenberg": 139, "gv80\uac00": 21, "gvisor": 60, "gy": 101, "gyn": 136, "gz": 135, "gzz": [0, 6], "h": [0, 6, 9, 52, 88, 101, 105, 108, 111, 112, 124, 129, 132, 133, 142, 145, 146, 150, 151, 152], "h1": 150, "h2o": 71, "h2omodelartifact": 73, "h_1": 126, "ha": [1, 2, 5, 6, 8, 9, 10, 17, 23, 36, 39, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 57, 59, 62, 63, 64, 69, 71, 76, 77, 78, 83, 85, 86, 88, 89, 90, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 126, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 144, 145, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 166, 169, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "habitat": [111, 112], "hacktivist": [111, 112], "had": [2, 39, 88, 100, 111, 112, 120, 130, 133, 136, 140, 183], "hadamard": 51, "haddow": 0, "hadlei": [111, 112], "hadoop": 38, "hagu": [111, 112], "hai": 152, "hail": [111, 112, 133], "haitian": 95, "hal": 101, "halax": 97, "haleyvil": [111, 112], "half": [111, 112, 145], "halko": 150, "hallucin": 42, "ham": [132, 158], "hammer": 130, "hamp": 108, "hamper": [111, 112], "han": [0, 111, 112, 116], "hand": [6, 9, 42, 45, 46, 47, 49, 50, 53, 59, 62, 66, 75, 76, 92, 93, 96, 97, 100, 102, 105, 106, 111, 112, 115, 116, 121, 126, 128, 137, 142, 151, 156, 158, 161, 172, 178], "handl": [1, 6, 8, 9, 10, 12, 39, 40, 41, 42, 53, 54, 55, 57, 59, 71, 73, 74, 76, 77, 83, 88, 91, 93, 97, 102, 103, 104, 105, 106, 110, 111, 112, 116, 122, 126, 130, 133, 134, 136, 138, 139, 148, 153, 165, 172], "handle_chinese_char": 112, "handler": [64, 159], "handwash": [111, 112], "handwrit": [69, 111, 112], "handwritten": [111, 112], "hang": 152, "hangout": [111, 112], "hansard": 130, "hansen": [0, 120], "haodi": 0, "hapk": [111, 112], "happen": [24, 45, 50, 63, 110, 111, 112, 126, 130, 136, 137, 150, 156, 174, 175, 178], "happi": [130, 134, 137, 178], "har": [45, 46, 49, 50, 51, 52, 56, 74, 101], "har54": 0, "har70": 0, "haralson": [111, 112], "harass": [111, 112], "harbert": [111, 112], "harbor": [142, 152], "hard": [12, 13, 41, 111, 112, 118, 140, 142, 150, 152, 174, 175, 179], "hard_vocab_limit": [103, 105], "harder": [111, 112, 140, 147, 154, 164], "hardi": 16, "hardli": [111, 112], "hardship": [111, 112, 120], "hardwar": [6, 45, 49, 50, 52, 59, 77, 78, 89, 97, 110, 112, 152, 163, 167, 169, 170], "hardwork": 120, "hare": [111, 112], "harm": [53, 59, 85, 86, 92, 98, 111, 112, 130], "harmon": [38, 55], "harmoni": [3, 111, 112], "harmonica": [111, 112], "harold": 5, "harp": [111, 112], "harri": [0, 145, 156], "harrison": 59, "harsh": [111, 112], "harvard": [96, 129], "harvei": [111, 112], "harvest": 49, "hash": [77, 78, 115, 124, 175, 179, 181, 183], "hashicorp": [64, 65, 159, 160], "hashingvector": 143, "hasn": [7, 9, 88, 112], "hassan": [0, 119], "hat": [65, 99, 111, 112, 126, 160], "hate": [111, 112, 127, 151], "hausa": 95, "have": [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 20, 24, 28, 30, 34, 37, 42, 44, 45, 49, 50, 51, 52, 53, 56, 57, 59, 61, 63, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 138, 139, 140, 143, 144, 145, 147, 149, 150, 151, 152, 154, 155, 156, 157, 163, 164, 167, 171, 173, 174, 175, 176, 177, 178, 180, 181, 183, 184, 185], "haven": [113, 139, 142, 180, 185], "haw": 95, "hawaii": [111, 112], "hawaiian": 95, "hayden": [0, 6], "hayn": 0, "haze": [16, 17], "hdp": 152, "hdpmodel": 152, "he": [99, 101, 105, 108, 111, 112, 116, 130, 133, 136, 139, 152], "head": [8, 9, 10, 14, 16, 19, 20, 21, 25, 26, 27, 28, 30, 33, 52, 67, 68, 72, 88, 109, 110, 111, 112, 114, 132, 136, 149, 174, 177, 179, 180, 181, 183, 184], "head_view": 114, "header": [21, 149, 150], "headlin": [101, 107, 108], "headquart": [111, 112, 119], "heal": 101, "health": [12, 49, 77, 98, 101, 111, 112, 130, 136, 145], "healthcar": [48, 50, 59, 111, 112, 119, 122, 130], "healthi": [71, 145], "hear": [111, 112, 116, 139], "heart": [3, 49, 50, 52, 92, 111, 112, 147], "heat": [111, 112], "heatmap": [25, 31, 136], "heatmap2": 25, "heavi": [111, 112], "heavier": 115, "heavili": [6, 53, 54, 65, 77, 92, 93, 111, 112, 137, 138, 146, 160], "hebrew": 95, "hedg": 152, "height": [10, 26, 79, 111, 112, 136, 156], "heighten": 12, "heightmap": 6, "heigold": 0, "heinrich": [111, 112], "hel": 105, "held": [109, 111, 112, 119, 130], "helium": 3, "hell": 105, "hello": [69, 104, 105, 146], "hello_world": 146, "helm": [64, 65, 159, 160], "help": [7, 9, 10, 12, 24, 38, 45, 50, 52, 56, 59, 60, 61, 63, 64, 65, 68, 69, 71, 72, 74, 76, 77, 78, 79, 80, 88, 89, 93, 96, 97, 98, 100, 102, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 126, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 143, 144, 146, 147, 148, 150, 151, 152, 157, 159, 160, 166, 171, 172, 177, 181, 183], "helpdesk": 169, "helper": [6, 136, 150], "helvellyn": [176, 177, 179, 180], "hemispher": [111, 112], "henc": [111, 112, 126], "heng": 0, "henri": [111, 112], "her": [100, 101, 111, 112, 130], "herald": 119, "herb": [46, 111, 112], "herbert": [111, 112], "herbivor": 3, "here": [8, 23, 30, 36, 42, 51, 64, 65, 68, 69, 71, 73, 76, 88, 93, 97, 98, 100, 104, 105, 107, 108, 110, 111, 112, 113, 114, 115, 116, 120, 126, 132, 133, 136, 139, 140, 141, 142, 143, 144, 146, 147, 149, 151, 152, 153, 155, 157, 159, 160, 173, 175, 176, 177, 182], "herit": [111, 112], "heritag": [111, 112], "hernando": [111, 112], "herzenstein": 0, "hessian": 84, "heterogen": [38, 111, 112, 119], "heterosex": [111, 112], "heterosexu": [111, 112], "heurist": [117, 134, 135, 137, 150], "hf_token": 45, "hf_xxx": 45, "hfr": 15, "hg": [173, 185], "hhvlt19": 0, "hi": [95, 97, 101, 111, 112, 117, 130, 136, 150, 152, 177], "hidden": [0, 66, 88, 97, 112, 115, 126, 127, 138, 144, 151], "hidden1": 127, "hidden2": 127, "hidden3": 127, "hidden_act": 112, "hidden_dropout_prob": 112, "hidden_lay": 128, "hidden_s": 112, "hideout": [111, 112], "hierarch": [11, 111, 112, 126, 137, 138, 144, 148, 152], "hierarchi": [9, 111, 112, 137], "hieroglyph": [111, 112], "high": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 25, 38, 41, 42, 45, 46, 52, 53, 55, 56, 59, 62, 65, 71, 73, 74, 77, 80, 85, 88, 89, 90, 92, 95, 97, 98, 100, 101, 106, 107, 109, 111, 112, 114, 116, 119, 120, 121, 122, 126, 128, 130, 133, 136, 137, 138, 139, 140, 145, 147, 148, 152, 153, 154, 156, 160, 163, 166, 169, 171, 172], "higher": [6, 7, 8, 9, 10, 25, 42, 46, 52, 64, 65, 77, 85, 88, 93, 97, 101, 111, 112, 114, 115, 116, 120, 126, 128, 132, 133, 143, 149, 152, 159, 160, 167], "highest": [9, 93, 97, 100, 101, 108, 111, 112, 119, 145, 155], "highli": [5, 6, 7, 9, 25, 46, 49, 50, 71, 86, 88, 92, 97, 98, 101, 111, 112, 113, 116, 120, 130, 143, 155, 167, 172], "highligh": 101, "highlight": [6, 8, 48, 52, 55, 56, 59, 74, 75, 77, 89, 92, 93, 101, 111, 112, 113, 114, 116, 120, 136, 138], "highwai": [46, 111, 112], "hike": [25, 26, 27, 28, 29, 33, 35, 128], "hill": [111, 112, 129, 174, 175, 176, 177, 178, 182], "hilli": 178, "him": [111, 112, 136, 139, 150], "himself": [111, 112], "hinder": 49, "hindi": [95, 130, 139], "hindranc": 49, "hindu": [98, 111, 112], "hinduism": [111, 112], "hines": 0, "hing": [55, 59], "hinneburg": 0, "hint": 177, "hinton": 53, "hipaa": [59, 77], "hire": [111, 112, 119, 120], "hispan": [111, 112], "hist": 15, "histogram": 94, "histor": [49, 53, 111, 112, 117, 120, 130, 134, 139], "histori": [5, 16, 17, 22, 49, 64, 91, 92, 111, 112, 116, 130, 132, 159, 173, 174, 176, 180, 181, 183, 185], "histplot": [24, 26, 94], "hit": [72, 101, 111, 112, 136, 152, 176, 177], "hks17": [0, 6], "hldamodel": 152, "hlight": 107, "hmm": [14, 144], "hmmr": 6, "hmn": 95, "hmong": 95, "hmp18": 0, "hmr": 6, "hn": 101, "ho": 101, "hoar": [111, 112], "hobbi": 173, "hoberg": [0, 119], "hoc": [111, 112], "hofmann": 151, "hold": [2, 25, 26, 27, 28, 29, 33, 35, 53, 101, 111, 112, 126, 128, 139, 152], "holden": [0, 6], "holdout": [71, 111], "hole": 88, "holidai": [111, 112], "holist": [38, 63], "holland": 0, "holonym": 137, "holt": [0, 111, 112], "holtzman": 97, "home": [23, 49, 66, 79, 80, 81, 94, 100, 101, 103, 107, 108, 110, 111, 112, 114, 132, 133, 135, 136, 141, 142, 150, 155, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184], "homebrew": 79, "homeopathi": [111, 112], "homepag": 17, "homewood": [111, 112], "homonym": 140, "homonymi": 140, "homosexu": [111, 112], "hon": 152, "honda": [111, 112], "hong": [0, 6, 152], "honorif": [130, 140], "hood": 150, "hook": [69, 111, 112], "hooper": [111, 112], "hope": [111, 112, 145, 152], "hopeless": 145, "hopkin": [111, 112], "hopkinsvil": [111, 112], "horizon": 97, "horizont": [111, 112, 178], "horn": [111, 112], "hornsbi": [111, 112], "horowitz": 56, "hors": 117, "horsesho": [111, 112], "hospit": [111, 112, 136], "host": [45, 61, 64, 65, 76, 77, 81, 111, 112, 121, 159, 160, 173], "hostnam": [81, 82], "hot": [5, 111, 112, 126, 128, 130, 137, 154, 156], "hotel": [111, 112, 136], "hotmail": [173, 174, 175, 180, 184], "hotpot": [5, 130], "hotspot": [111, 112], "hotter": [111, 112], "hottest": [111, 112], "hou": 101, "houlsbi": 52, "hour": [111, 112, 136, 144, 167], "hous": [9, 46, 93, 100, 111, 112, 119, 137, 147], "hover": 178, "hovi": 99, "how": [1, 4, 6, 8, 9, 12, 14, 21, 23, 41, 45, 48, 49, 50, 51, 52, 55, 56, 57, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 80, 81, 89, 91, 94, 96, 97, 100, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 117, 119, 120, 123, 126, 128, 129, 130, 131, 136, 143, 144, 145, 147, 150, 151, 152, 155, 157, 165, 166, 170, 172, 174, 175, 176, 177, 178, 182, 186], "howev": [5, 6, 9, 12, 39, 42, 44, 46, 49, 52, 53, 55, 59, 66, 69, 71, 73, 76, 77, 88, 90, 91, 92, 93, 95, 97, 98, 99, 102, 104, 109, 110, 111, 112, 113, 116, 117, 120, 121, 123, 126, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 145, 146, 147, 149, 151, 152, 156, 157, 165, 169, 172, 174], "hp": 35, "hp16": 0, "hpamodel": 152, "href": [43, 152], "hsale": 23, "hsales_d": 23, "hsales_diff_prev": [23, 25, 26, 27, 28], "hsales_diff_year": [23, 25, 26, 27, 28, 29, 33, 35], "hsm": [77, 78], "hsst21": 0, "hsv": [111, 112], "ht": 95, "htm": [23, 36], "html": [10, 12, 29, 35, 43, 55, 93, 100, 101, 103, 108, 110, 111, 112, 114, 121, 123, 135, 136, 146, 152, 169, 182], "htt": 177, "http": [0, 5, 8, 9, 10, 16, 17, 19, 20, 22, 23, 24, 30, 35, 36, 45, 51, 53, 61, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 80, 81, 82, 94, 96, 100, 101, 103, 108, 110, 111, 112, 114, 128, 129, 130, 132, 135, 136, 141, 145, 150, 152, 176, 177, 178, 180, 181, 182, 184, 185], "hu": [52, 95, 101], "hub": [12, 59, 60, 61, 62, 72, 100, 101, 103, 107, 108], "hue": [24, 25, 26], "huemer": [111, 112], "huffman": 128, "hug": [1, 42, 46, 47, 94, 96, 100, 101, 103, 104, 107, 108, 110, 111, 112, 136], "huge": [3, 111, 112], "huggingfac": [1, 17, 30, 47, 50, 59, 72, 94, 100, 101, 103, 107, 108, 110, 111, 112, 117, 136, 146], "hugginggpt": 42, "hugh": [111, 112], "human": [0, 1, 2, 3, 5, 7, 9, 11, 42, 44, 49, 51, 53, 55, 57, 59, 64, 65, 71, 74, 84, 85, 86, 91, 93, 96, 97, 98, 100, 102, 111, 112, 116, 119, 121, 122, 126, 129, 130, 134, 139, 145, 146, 147, 148, 154, 159, 160, 164, 166, 171], "human3": 6, "human_byt": [17, 22, 28], "humanist": [111, 112], "humanloop": 56, "humanml3d": 6, "humid": [111, 112], "hundr": [111, 112, 130], "hungarian": 95, "hunt": [111, 112], "huntsvil": [111, 112], "hurdl": [40, 55, 57, 169], "hurrican": [111, 112], "husband": 136, "hxw": 0, "hy": 95, "hybrid": [40, 41, 52, 89, 166, 167], "hydrogen": [3, 111, 112], "hymenaeus_beta": 149, "hype": 72, "hyperact": [111, 112], "hyperbar": [111, 112], "hyperfast": [1, 68, 70], "hyperlink": 121, "hypernym": [137, 143], "hyperparam": 51, "hyperparamet": [42, 45, 52, 55, 71, 75, 97, 111, 117, 151, 152, 154], "hyperparmet": [29, 35], "hyperplan": 138, "hyphen": 139, "hyponym": 137, "hypothes": 97, "hypothesi": [84, 97, 111, 112, 117, 157], "hyundai": [111, 112], "h\u00e9ll\u00f2": 104, "h\u00f4w": 104, "h\uc9c0\uc218\uc758": [14, 16], "i": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 98, 99, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 138, 142, 143, 145, 147, 148, 149, 150, 151, 154, 155, 156, 160, 162, 163, 164, 165, 166, 167, 169, 171, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185], "ia": [51, 52], "iac": [64, 159], "ian": 5, "ia\u00b3": 52, "ib": 101, "ibm": 49, "ic": [101, 111, 112, 139, 145], "icd": [111, 112], "icecream": 145, "iceland": [85, 95], "ici": [16, 17], "icl": 52, "iclr": [89, 99], "icml": 0, "icon": [17, 82, 130, 177], "ict\uc5c5\uacc4": 16, "id": [0, 8, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 30, 33, 34, 60, 76, 79, 81, 95, 100, 101, 104, 105, 110, 111, 112, 115, 152, 170], "id_ed25519": 76, "id_kei": [15, 24], "id_rsa": 185, "id_to_word": [127, 128], "idea": [1, 2, 6, 52, 71, 89, 96, 97, 100, 108, 110, 111, 112, 113, 114, 116, 129, 132, 133, 136, 139, 150, 151, 156, 157, 163, 167, 169, 180, 183], "ideal": [26, 27, 46, 49, 52, 83, 93, 99, 111, 112, 155, 170], "ident": [10, 14, 16, 17, 22, 76, 77, 78, 79, 104, 110, 111, 112, 120, 147], "identif": [77, 78, 84, 111, 112, 151, 166, 172], "identifi": [0, 1, 2, 7, 9, 12, 49, 50, 52, 53, 55, 59, 63, 64, 65, 71, 74, 83, 84, 88, 90, 95, 98, 105, 106, 108, 111, 112, 116, 119, 120, 122, 126, 130, 131, 134, 136, 137, 138, 139, 147, 148, 150, 151, 155, 156, 157, 159, 160, 167, 169, 170, 172, 174], "ideolog": [111, 112], "ideologi": [97, 111, 112], "idf": [1, 119, 126, 129, 136, 138, 146, 148, 153, 154, 156], "idiomat": 91, "idiosyncrasi": 169, "idiosyncrat": [111, 112], "idri": [180, 181], "idx": [128, 149, 152], "ieee": [0, 6, 89], "ig": 95, "igbo": 95, "igcc": 14, "igh": 107, "igher": 107, "ighlight": 107, "ignor": [35, 40, 124, 128, 132, 154, 173, 174, 175, 176, 177, 179, 180, 182, 184, 185], "igpt": 5, "iguazio": 71, "ii": [1, 59, 78, 89, 111, 112, 118, 119, 129, 151], "iii": [78, 89, 111, 112], "ij": [125, 128], "ik": 107, "il": 101, "ilikeanappl": 145, "ilikechocol": 145, "ill": [97, 101], "illeg": [111, 112, 115], "illegitim": [111, 112], "illia": 0, "illicit": [85, 111, 112], "illinoi": [111, 112], "illumin": [111, 112, 126], "illus": [111, 112], "illustr": [12, 38, 46, 51, 52, 56, 59, 84, 100, 106, 111, 112, 113, 114, 116, 130, 149, 153, 158, 167, 170, 178], "iloc": [23, 136], "ilya": 0, "im": [101, 152], "imag": [0, 1, 2, 4, 6, 7, 8, 12, 40, 41, 50, 51, 59, 62, 72, 73, 75, 85, 100, 111, 112, 122, 126, 138, 150, 151], "imagen": [1, 4, 5, 11, 130], "imagin": [5, 46, 88, 111, 112, 126, 139, 150, 178], "imap": 77, "imbal": [88, 93], "imbalanc": [25, 93], "imblearn": 136, "imdb": 110, "imf": 15, "imier": [111, 112], "imit": [1, 5, 6, 111, 112], "immedi": [12, 46, 96, 106, 111, 112, 129, 172], "immens": [12, 52, 53, 55], "immers": [6, 50, 91], "immigr": [111, 112], "immun": [111, 112], "immut": [64, 159], "impact": [1, 2, 8, 9, 12, 23, 40, 49, 52, 54, 55, 56, 59, 64, 77, 78, 85, 88, 89, 93, 98, 102, 109, 111, 112, 116, 120, 130, 137, 146, 159, 166, 170], "impair": [49, 111, 112, 130, 131], "impart": 47, "imped": 49, "imper": [38, 41, 50, 55, 111, 112], "imperfect": 6, "imperi": [111, 112], "impetu": [111, 112], "implaus": [111, 112], "implement": [1, 7, 10, 12, 30, 43, 46, 47, 50, 52, 55, 57, 60, 64, 68, 70, 74, 75, 76, 77, 83, 85, 87, 96, 97, 102, 105, 106, 110, 111, 112, 120, 129, 130, 132, 134, 136, 142, 143, 144, 145, 147, 152, 154, 156, 157, 158, 159, 166, 167, 171, 172], "impli": [54, 108, 111, 112, 116, 130, 132], "implic": [2, 4, 12, 39, 47, 52, 89, 93, 98, 109, 111, 112, 139, 156], "implicit": 9, "implicitli": 133, "import": [1, 6, 8, 10, 12, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 42, 45, 51, 59, 66, 69, 73, 74, 75, 77, 78, 85, 90, 92, 93, 94, 95, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 120, 123, 124, 126, 127, 128, 130, 132, 133, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 152, 153, 154, 155, 157, 158, 166, 170, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185, 186], "import_fil": 21, "importerror": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "importlib": 136, "impos": [111, 112], "imposit": [111, 112], "imposs": 118, "impract": [46, 50, 53, 89, 111, 112], "imprecis": [8, 150], "impress": [55, 86, 93, 116], "impressionist": [111, 112], "imprint": [111, 112], "imprison": [111, 112], "impro": 101, "improp": 55, "improv": [0, 1, 6, 7, 9, 10, 11, 18, 37, 38, 41, 42, 44, 45, 46, 49, 50, 52, 54, 57, 59, 60, 63, 64, 65, 71, 72, 74, 77, 78, 83, 88, 89, 91, 92, 93, 95, 97, 98, 99, 100, 103, 105, 107, 109, 111, 112, 115, 116, 117, 120, 121, 130, 131, 132, 133, 134, 136, 137, 138, 150, 151, 159, 160, 165, 166, 171, 172, 178], "imshow": 136, "in_colab": 123, "inabl": [111, 112, 133, 135], "inaccess": 77, "inaccur": [130, 132, 150], "inaccuraci": [12, 93, 130], "inact": [111, 112], "inadequ": 164, "inadvert": 55, "inam": 79, "inappropri": [111, 112, 130], "inattent": [111, 112], "inc": [61, 101, 111, 112, 128, 152], "incept": [49, 166], "incest": [111, 112], "incid": [59, 64, 111, 112, 159], "inclin": [111, 112], "includ": [4, 5, 6, 7, 8, 9, 12, 36, 38, 39, 40, 42, 45, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 100, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 119, 120, 121, 122, 123, 126, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 147, 148, 150, 151, 152, 154, 155, 156, 159, 160, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183], "include_percentag": [14, 16, 17, 22], "include_valu": [14, 16, 17, 22], "include_var": [64, 159], "inclus": [59, 98, 146], "incoher": [92, 97], "incom": [73, 88, 101, 111, 112, 152], "incompat": [64, 159], "incompet": 136, "incomplet": [71, 120], "incomprehens": 136, "inconsist": [6, 55, 64, 89, 93, 111, 112, 151, 152, 159, 183], "inconveni": 152, "incorpor": [1, 6, 7, 9, 11, 12, 38, 40, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 64, 72, 74, 77, 85, 89, 91, 93, 98, 100, 105, 111, 112, 113, 114, 116, 130, 133, 138, 151, 159, 166, 169, 170, 171, 172], "incorrect": [12, 20, 57, 59, 93, 102, 130, 134, 137], "incorrectli": 30, "incr": 101, "increa": 152, "increas": [1, 6, 9, 10, 38, 49, 50, 52, 55, 59, 63, 71, 74, 77, 85, 88, 89, 92, 93, 97, 100, 111, 112, 115, 116, 117, 119, 120, 122, 128, 133, 138, 143, 145, 146, 152, 171, 172], "increasingli": [2, 5, 41, 49, 50, 53, 59, 77, 84, 90, 91, 93, 111, 112, 116, 118, 126, 130, 134, 138], "incred": 126, "incredibli": [137, 180], "increment": 171, "increment_or_add": 181, "incub": 142, "incumb": [111, 112], "incur": [50, 115], "ind": 101, "indecis": 165, "indefinit": [111, 112], "independ": [10, 50, 52, 55, 60, 62, 77, 78, 97, 99, 105, 106, 111, 112, 115, 130, 132, 138, 139, 140, 143, 147, 151, 152, 155, 157], "index": [12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 28, 30, 31, 33, 34, 45, 55, 111, 112, 119, 123, 126, 128, 132, 135, 136, 137, 139, 141, 150, 152, 153, 156, 174, 175, 177, 179, 180, 181], "index_column_nam": [15, 28, 33], "indi": [24, 101], "india": 129, "indian": [111, 112], "indic": [9, 13, 16, 17, 19, 21, 30, 36, 49, 52, 53, 60, 76, 77, 88, 97, 101, 107, 108, 111, 112, 113, 114, 116, 118, 119, 120, 126, 130, 132, 133, 136, 137, 138, 139, 140, 145, 146, 147, 149, 151, 155, 178], "indica": 24, "indices_to_print": 101, "indirect": [111, 112], "indirectli": [111, 112], "indirectmeasur": 152, "indispens": [44, 59], "indistinguish": [5, 90, 98], "individu": [6, 8, 12, 38, 40, 46, 49, 76, 91, 96, 100, 105, 106, 108, 111, 112, 113, 116, 119, 129, 130, 132, 138, 140, 142, 143, 144, 146, 147, 153, 154, 156, 161, 164, 169, 171, 172, 186], "individualist": [111, 112], "indo": [111, 112, 140], "indoctrin": [111, 112], "indonesian": [95, 115], "indu": 101, "induc": [111, 112, 142], "industr": 101, "industri": [0, 6, 8, 38, 40, 49, 52, 53, 59, 60, 77, 101, 111, 112, 122, 130, 134, 152, 164, 171], "indycar": [111, 112], "ine": 101, "ineffect": [52, 111, 112, 116, 172], "ineffici": [49, 102, 153, 167], "inequ": [111, 112], "inerti": 6, "inertia": [23, 25, 26, 27, 28], "inertia_diff": [23, 25, 26, 27, 28, 29, 33, 35], "iness": 145, "inevit": [111, 112], "inf": 101, "infami": [111, 112], "infanc": [111, 112], "infant": [111, 112], "infantil": [111, 112], "infeas": [77, 89], "infect": [111, 112, 142], "infecti": [111, 112], "infer": [6, 9, 10, 14, 16, 17, 22, 46, 57, 71, 73, 93, 104, 110, 111, 112, 115, 116, 121, 122, 130, 138, 148, 156], "inferenc": 59, "inference_mod": 51, "infest": [111, 112], "infinit": [8, 9, 59, 105, 139], "infix": 139, "inflamm": [111, 112], "inflammatori": [111, 112], "inflat": [13, 24, 137, 152], "inflect": [59, 111, 112, 115, 130, 139, 142], "inflex": [166, 172], "influenc": [0, 1, 8, 38, 52, 54, 55, 98, 100, 111, 112, 130, 132, 136, 137, 139, 140, 146, 147, 151, 172], "influenti": [87, 111, 112, 116, 120], "influx": [111, 112], "info": [16, 17, 19, 20, 22, 24, 28, 29, 30, 31, 32, 33, 34, 35, 42, 60, 103, 105, 112, 152], "info_fil": 17, "info_list": 17, "info_upd": [17, 22, 28], "inform": [0, 6, 7, 8, 9, 10, 11, 12, 37, 38, 41, 42, 43, 44, 45, 46, 49, 52, 53, 59, 63, 64, 65, 69, 71, 73, 76, 77, 81, 83, 88, 89, 91, 93, 94, 98, 100, 102, 104, 105, 106, 111, 112, 114, 115, 116, 118, 120, 121, 124, 126, 127, 130, 132, 137, 138, 139, 140, 142, 144, 145, 146, 148, 150, 151, 153, 154, 156, 158, 159, 160, 171, 172, 178, 185], "infrastructur": [1, 12, 37, 47, 55, 58, 64, 66, 71, 73, 78, 80, 111, 112, 119, 159, 169], "infrequ": [71, 130, 157], "infring": 121, "infus": 169, "ing": [75, 101, 124, 146], "ingenu": 2, "ingest": [12, 38, 55, 56], "ingredi": [46, 117], "ingress": 80, "inhabit": [119, 139], "inher": [41, 46, 50, 52, 54, 55, 57, 59, 77, 99, 100, 111, 112, 116, 130, 134, 138, 139, 150, 151, 171, 172], "inherit": [53, 111, 112, 130], "inhibit": [111, 112], "inhospit": 83, "ini": [64, 159], "init": [16, 17, 19, 20, 21, 52, 64, 79, 159, 173, 185], "initi": [6, 8, 9, 14, 16, 17, 22, 28, 38, 42, 43, 44, 45, 46, 50, 52, 53, 54, 59, 60, 62, 69, 72, 88, 97, 99, 100, 103, 105, 106, 109, 110, 111, 112, 116, 119, 120, 136, 142, 148, 150, 152, 158, 166, 171, 172, 173, 183, 185], "initial_alphabet": 111, "initialize_vocab": [101, 107, 108], "initializer_rang": 112, "initiate_chat": 42, "initil": 17, "inject": [6, 10, 52], "injuri": [111, 112], "inland": [111, 112], "inlinebackend": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 114, 128, 145, 149, 150], "innat": [111, 112], "inner": [14, 21, 88, 114], "innov": [2, 8, 50, 52, 53, 59, 65, 85, 89, 93, 98, 116, 119, 126, 130, 160, 167, 169], "inoxum": [111, 112], "inpaint": 9, "inplac": [23, 26, 27, 34], "input": [5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 19, 22, 30, 42, 46, 49, 50, 51, 52, 54, 55, 57, 58, 59, 71, 72, 73, 85, 88, 89, 91, 93, 98, 99, 100, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 115, 121, 122, 124, 126, 127, 130, 137, 138, 139, 141, 143, 144, 145, 150, 153, 171, 172], "input_batch": [127, 128], "input_fil": [76, 124], "input_format": [103, 105], "input_id": [30, 97, 100, 104, 110, 111, 112], "input_sentence_s": [103, 105], "input_split": [15, 20, 24, 30], "inquiri": 130, "ins": 101, "inscrib": [111, 112], "inscript": [111, 112], "insert": [52, 79, 99, 107, 108, 114, 115, 139, 152, 174, 175, 176, 177, 180, 181, 182, 183, 184, 185], "insi": 101, "insid": [60, 76, 111, 112, 128, 139], "insight": [6, 12, 40, 41, 42, 45, 50, 51, 57, 89, 94, 114, 116, 118, 130, 133, 134, 135, 136, 138, 139, 144, 146, 147, 149, 151, 157, 167, 168], "insist": [111, 112], "insol": [111, 112], "insomnia": [111, 112], "inspect": [110, 136, 165, 178], "inspir": [1, 2, 5, 6, 8, 53, 69, 83, 88, 100, 111, 112, 116, 130], "instabl": 12, "instagram": [121, 134], "instal": [14, 23, 24, 30, 75, 77, 94, 95, 97, 100, 105, 110, 111, 112, 124, 132, 135, 136, 141, 142, 150, 169, 178, 181], "installshield": 169, "instanc": [2, 38, 42, 45, 46, 49, 50, 51, 52, 59, 64, 73, 77, 80, 93, 95, 98, 102, 105, 106, 111, 112, 113, 120, 123, 126, 132, 134, 136, 137, 139, 140, 143, 144, 146, 147, 151, 152, 156, 159], "instance_data_dir": 51, "instance_dir": 51, "instance_prompt": 51, "instanti": [15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 112, 149], "instead": [6, 9, 22, 23, 46, 59, 60, 71, 76, 84, 88, 93, 97, 99, 106, 110, 111, 112, 115, 116, 117, 124, 126, 128, 134, 139, 143, 151, 154, 158, 173, 175, 177], "instinct": [46, 126], "institut": [77, 89, 111, 112, 130, 186], "instruct": [6, 14, 22, 42, 45, 46, 51, 60, 61, 64, 73, 82, 83, 88, 92, 98, 100, 111, 112, 159, 164, 176, 178, 185], "instructgpt": [46, 92], "instrument": [6, 111, 112, 149], "insuffici": [6, 38, 46, 50, 59, 166], "insular": [111, 112], "insur": [101, 111, 112, 152], "insurg": [111, 112], "insurrectionari": [111, 112], "int": [14, 17, 21, 101, 107, 108, 124, 132, 155], "int32": [110, 112], "int64": [14, 15, 21, 22, 25], "int64index": [14, 15, 21], "int8": [110, 112], "intact": [50, 61], "intak": [111, 112], "intang": 108, "intangibl": 108, "integ": [124, 135, 143, 150], "integr": [2, 6, 7, 14, 39, 40, 42, 45, 46, 49, 52, 54, 55, 57, 59, 60, 62, 63, 64, 66, 70, 71, 72, 76, 77, 78, 80, 88, 91, 105, 111, 112, 116, 159, 164, 166, 169, 172, 177], "intellectu": [59, 74, 98, 111, 112], "intellig": [1, 2, 3, 5, 8, 11, 42, 44, 49, 52, 53, 54, 56, 59, 77, 78, 83, 87, 89, 90, 91, 93, 97, 100, 111, 112, 119, 122, 129, 130, 141], "intellij": 169, "intend": [1, 9, 10, 36, 57, 59, 83, 93, 111, 112, 121, 130, 167, 170], "intens": [12, 46, 49, 50, 52, 53, 55, 57, 59, 77, 93, 98, 111, 112, 113, 116, 126, 132, 137, 172], "intensifi": [12, 50, 93, 111, 112, 137], "intent": [46, 91, 120, 178], "intention": [111, 112, 120], "inter": [12, 99, 101], "interact": [2, 6, 7, 11, 42, 46, 49, 50, 53, 55, 56, 57, 60, 64, 71, 72, 79, 83, 86, 88, 91, 93, 111, 112, 114, 116, 121, 129, 130, 144, 159, 171, 177, 183, 185], "intercept": [77, 82, 111, 112], "interchang": [111, 112, 121], "interconnect": [50, 78, 88, 111, 112, 130], "interdepend": 78, "interdisciplinari": [7, 11, 89], "interest": [6, 9, 12, 23, 93, 97, 105, 111, 112, 116, 118, 119, 120, 130, 136, 137, 147, 150, 152, 167], "interestingli": 118, "interfac": [38, 45, 56, 57, 59, 60, 61, 62, 69, 72, 74, 80, 81, 91, 97, 123, 166, 169, 176, 180], "interfer": [111, 112, 178], "intergovernment": [111, 112], "intergraph": [111, 112], "interject": 140, "interlink": 137, "intermedi": [6, 9, 53, 97, 100, 111, 112], "intermediate_s": 112, "intermingl": [111, 112], "intern": [0, 6, 7, 9, 37, 43, 59, 85, 89, 93, 98, 101, 104, 105, 107, 111, 112, 115, 116, 120, 129, 130, 152, 154], "interna": 107, "internat": 107, "internati": 107, "internatio": 107, "internationa": 107, "internet": [6, 9, 49, 50, 77, 78, 82, 111, 112, 121, 126, 176, 185], "interoper": [38, 60, 62, 77], "interplai": 116, "interpol": [6, 9, 10, 136], "interpret": [1, 4, 8, 10, 37, 38, 39, 41, 49, 53, 57, 71, 85, 89, 91, 93, 98, 102, 109, 111, 112, 113, 114, 116, 120, 122, 126, 130, 131, 134, 138, 146, 147, 148, 149, 150, 151, 170], "interrupt": [111, 112], "intersect": [5, 8, 50, 57, 88, 130], "interst": [111, 112], "intertwin": [111, 112], "interv": [133, 152], "interven": 52, "intervent": [42, 44, 49, 64, 65, 66, 85, 93, 111, 112, 120, 159, 160], "interview": [111, 112, 169], "intestin": [111, 112], "intimaci": [111, 112], "intimid": [111, 112], "intoler": [111, 112], "intra": [49, 111, 112], "intradai": 128, "intraparti": 120, "intrauterin": [111, 112], "intric": [42, 46, 49, 53, 57, 93, 126, 139], "intricaci": [46, 47, 50, 80, 93], "intrigu": [42, 56, 116], "intrins": [50, 59, 111, 112, 132], "introduc": [5, 6, 7, 8, 9, 10, 37, 46, 49, 50, 52, 53, 55, 59, 67, 77, 79, 80, 83, 88, 89, 90, 93, 95, 96, 97, 105, 111, 112, 115, 116, 120, 124, 125, 127, 128, 129, 130, 132, 136, 138, 151, 154, 166, 168, 170, 172, 173, 174], "introduct": [4, 37, 42, 47, 49, 70, 78, 80, 96, 113, 161, 186], "introductori": [80, 97], "intuit": [10, 45, 46, 49, 111, 112, 114, 119, 130, 153, 156], "inuktitut": 130, "inv": 101, "inval_cv_filenam": 14, "inval_cved_filenam": 14, "invalid": 77, "invalid_dataset": 16, "invalid_preds_df": [14, 21], "invalu": [46, 89], "invari": [6, 140], "invent": [5, 111, 112, 120, 183], "inventori": [111, 112], "invers": [9, 111, 112, 120, 130, 138, 158], "invert": [9, 88, 155], "invert_yaxi": 155, "invertebr": [111, 112], "invest": [34, 38, 49, 59, 85, 93, 101, 107, 108, 111, 112, 119, 130, 145, 152, 172], "investig": [47, 111, 112, 147], "investor": [59, 101, 128, 132, 152], "invis": [111, 112], "invit": [111, 112], "invoc": 73, "invok": [71, 79], "involuntari": [111, 112], "involv": [5, 6, 7, 8, 9, 11, 12, 43, 45, 46, 47, 49, 50, 52, 53, 54, 55, 57, 59, 60, 64, 65, 67, 71, 74, 77, 78, 80, 88, 89, 91, 92, 93, 97, 98, 100, 102, 104, 105, 108, 110, 111, 112, 113, 116, 118, 119, 120, 121, 126, 130, 134, 138, 139, 140, 142, 144, 146, 147, 151, 155, 156, 157, 159, 160, 165, 166, 167, 169, 171, 172], "io": [10, 14, 15, 20, 21, 22, 23, 24, 28, 30, 31, 34, 35, 60, 70, 71, 80, 100, 101, 103, 108, 110, 111, 112, 114, 124, 135, 136, 169, 182], "iot": [12, 17, 50, 78], "iou": 88, "iowa": [111, 112], "ip": [77, 78, 81, 82, 101, 140], "ipa": [111, 112], "iphon": 107, "ipo": 123, "iprogress": [100, 101, 103, 108, 110, 111, 112, 114, 136], "ipsec": [77, 78, 82], "ipsum": 117, "ipynb": [9, 51], "ipython": [24, 31, 32, 33, 34, 152], "ipywidget": [100, 101, 103, 108, 110, 111, 112, 114, 136], "iq": [111, 112], "iqbal": [0, 6], "ir": [101, 107], "ira": [0, 6], "iraqi": [111, 112], "irf": 34, "iri": [73, 77], "iris_classifier_servic": 73, "irisclassifi": 73, "irish": [95, 111, 112], "iron": [111, 112], "ironi": 134, "iroquoian": [111, 112], "irp": 20, "irradi": [111, 112], "irregular": [139, 140], "irrelev": [55, 93], "irrig": 12, "irrit": [111, 112], "irst": 107, "is_colab": [14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "is_fast": [111, 112], "is_live_top": 152, "is_notebook": [15, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 152], "isa": 152, "isbn": 37, "isc": 107, "isha": 107, "ishar": [101, 107], "ishii": [0, 145], "isi": 145, "isin": [14, 16], "isit": 145, "isl": [111, 112], "islam": [111, 112], "island": [111, 112], "ism": [111, 112], "isn": [52, 97, 110, 116, 136, 139, 157], "isnul": 25, "iso": [111, 112], "iso22301": 20, "isol": [42, 111, 112, 113, 116], "isomap": 28, "isopropyl": 142, "iss": 107, "issu": [9, 41, 42, 52, 54, 55, 59, 63, 64, 65, 73, 77, 83, 84, 89, 93, 95, 97, 106, 109, 111, 112, 115, 116, 120, 133, 134, 137, 138, 147, 151, 157, 158, 159, 160, 166, 170, 172], "itakura": 151, "ital": [101, 111, 112], "itali": [111, 112], "italian": [95, 111, 112, 116, 139], "itard": [111, 112], "ite": 101, "item": [14, 15, 17, 21, 23, 31, 88, 101, 107, 108, 110, 111, 112, 126, 127, 128, 133, 143, 149, 155, 156], "itemgett": 155, "iter": [9, 42, 43, 46, 55, 65, 71, 85, 86, 88, 100, 101, 105, 107, 108, 116, 128, 148, 151, 152, 160, 164, 169, 171], "iterrow": 32, "itertool": 152, "iti": [101, 107, 108, 145], "itio": 107, "its": [1, 2, 5, 6, 8, 9, 10, 37, 38, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 69, 71, 73, 74, 76, 77, 78, 79, 80, 83, 85, 86, 88, 89, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 120, 121, 122, 123, 124, 126, 128, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 147, 148, 150, 151, 152, 153, 155, 156, 157, 158, 159, 164, 166, 167, 169, 170, 171, 172, 174, 175, 180, 186], "itself": [6, 42, 53, 88, 97, 105, 111, 112, 114, 116, 140, 154, 155, 177, 184], "iu": 107, "iv": [78, 89, 111, 112], "ivan": [111, 112], "ivei": [111, 112], "iw": 95, "ix": 128, "j": [0, 20, 30, 34, 53, 69, 99, 101, 106, 107, 108, 111, 112, 119, 125, 126, 128, 129, 147, 152, 155, 167, 181], "j04": 0, "ja": [95, 105], "jaccard": 152, "jack000": [5, 130], "jacki": 0, "jackson": [111, 112], "jacksonvil": [111, 112], "jacob": [0, 99, 112], "jail": [111, 112], "jaim": 0, "jair": 89, "jakob": 0, "jame": [111, 112, 173], "jan": [101, 152], "jane": 100, "janet": [23, 24], "janpanes": 145, "januari": [30, 101, 111, 112, 152], "japan": [0, 120, 152], "japanes": [0, 95, 102, 105, 111, 112, 120, 141, 152], "jaquet": 5, "jargon": [89, 109, 115, 174], "jason": 0, "jauvin": 0, "java": [49, 97, 141, 169], "javanes": 95, "javascript": [69, 117, 121, 169], "javier": 0, "jax": 8, "jc": 141, "je": [101, 111, 112], "jealousi": [111, 112], "jean": [0, 111, 112], "jeff": 0, "jefferson": [111, 112], "jeffrei": 0, "jeju": [1, 96], "jemison": [111, 112], "jenkin": [64, 65, 71, 75, 159, 160, 169], "jeremiah": [111, 112], "jericho": [111, 112], "jerom": [23, 24, 25, 26, 27, 31], "jess": [0, 111, 112, 130], "jesu": 150, "jetson": 6, "jew": [111, 112], "jewish": [111, 112], "jfif": 150, "ji": [0, 6], "jiangxi": 152, "jianyuan": 0, "jihoon": [0, 6], "jim": [111, 112, 150, 175, 179], "jin": [0, 145], "jinja": 69, "jira": [65, 160, 169], "jiseob": [0, 6], "jitendra": [0, 6], "jitter": 88, "jj": 144, "jkb": 141, "jko": [141, 142], "jmlr": [0, 99], "jnalivxin2qcehqa": 72, "jo": 101, "job": [73, 97, 111, 112, 120, 136, 171], "jobless": [152, 155], "joblib": [15, 20, 24, 30, 132, 135, 141, 150], "joe": 0, "johann": [111, 112], "john": [0, 100, 111, 112], "johnson": 136, "join": [101, 103, 105, 111, 112, 123, 127, 128, 133, 136, 149, 150, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "join_path": 152, "joint": [6, 111, 112], "jointli": [99, 111, 112, 116], "jointplot": 28, "joke": 136, "jon": 101, "jone": [0, 111, 112, 150], "jonni": [0, 6], "joon": [0, 173, 174, 175, 180, 184], "jordan": [111, 112, 152], "josa": 140, "joseph": [111, 112], "josh": 0, "jost": 0, "joulin": 0, "journal": [0, 84, 89, 98, 111, 112, 119, 130, 152], "journei": [53, 139, 171], "journ\u00e9": 142, "joy": [111, 112], "jpeg": [9, 150], "jpss": [111, 112], "jpy66": 152, "jq5": [111, 112], "jr": 129, "json": [14, 20, 21, 64, 69, 73, 100, 103, 104, 111, 112, 114, 121, 145, 159], "jti06": 0, "ju": 101, "judaism": [111, 112], "judg": [83, 111, 112, 136, 137], "judgment": [46, 98, 111, 112, 130, 137], "judici": [111, 112], "judiciari": [111, 112], "judith": [111, 112], "juli": [0, 101, 111, 112, 152], "julian": 0, "july5": [111, 112], "jum": 101, "jump": [6, 85, 115, 117, 142, 144, 152, 158], "jun": [0, 6], "junctur": 50, "june": [93, 111, 112, 128], "junegunn": 79, "jungl": 3, "junit": 169, "jupyt": [29, 35, 100, 101, 103, 108, 110, 111, 112, 114, 136, 144, 173], "jupyter_cli": [24, 31, 32, 33, 34], "jura": [111, 112], "jurafski": 129, "juri": [111, 112], "jurisdict": [111, 112], "just": [2, 6, 17, 46, 51, 52, 53, 56, 59, 64, 65, 71, 73, 77, 88, 92, 96, 97, 98, 105, 109, 111, 112, 113, 116, 126, 128, 129, 130, 133, 136, 140, 143, 146, 147, 152, 154, 159, 160, 171, 173, 174, 178, 179, 180, 181, 183, 185], "justic": [111, 112], "justifi": [111, 112, 165, 167, 170], "justinjohn0306": 9, "jv": 95, "jvc": [111, 112], "jx": 141, "k": [8, 9, 52, 55, 99, 101, 102, 104, 105, 108, 111, 112, 113, 114, 116, 119, 126, 128, 132, 133, 138, 148, 150, 151, 152, 157, 174], "ka": 95, "kai": [0, 111, 112], "kaiser": 0, "kaist": 141, "kakao": 121, "kale": 0, "kalman": 151, "kalyani": 0, "kanazawa": [0, 6], "kanban": [65, 160, 171], "kane": [0, 6], "kang": 0, "kannada": 95, "kanner": [111, 112], "karl": [111, 112], "kata": 60, "katherin": 0, "katz": 0, "kavad": [111, 112], "kazakh": 95, "kb": [132, 135, 136, 150], "kb\uae08\uc735": 19, "kb\uae08\uc735\uc9c0\uc8fc": 19, "kb\uc99d\uad8c": 19, "kc": 105, "kdc": 77, "kde": [24, 26, 94], "kdeplot": 26, "ke": [7, 101], "ked": 101, "keei": 23, "keep": [38, 42, 46, 50, 52, 55, 63, 66, 67, 68, 76, 79, 81, 88, 97, 103, 106, 107, 108, 111, 112, 115, 117, 118, 119, 120, 130, 138, 143, 144, 146, 155, 156, 170, 174, 175, 176, 181, 183, 185], "keepdim": [127, 152], "kei": [5, 6, 9, 10, 12, 15, 28, 34, 46, 52, 55, 59, 62, 64, 65, 71, 72, 73, 76, 78, 80, 81, 82, 85, 88, 89, 91, 92, 93, 94, 98, 101, 106, 107, 108, 110, 112, 114, 116, 123, 129, 130, 133, 144, 149, 155, 159, 160, 167, 170, 172, 176, 181], "kemelmach": [0, 6], "kenlm": 95, "kenton": 0, "kentucki": [111, 112], "kept": [30, 76, 77, 88, 106, 111, 112, 136, 178, 185], "kerasmodelartifact": 73, "kerbero": [77, 78], "kernel": [132, 135, 136, 138, 141, 150], "ket": 107, "kevin": [0, 6], "key_column": 17, "key_id": 76, "keyfil": 72, "keygen": [76, 79], "keypair": 185, "keyword": [91, 92, 93, 136, 145], "khan": 85, "khazatski": 0, "khmer": 95, "ki": [0, 145], "kib": 28, "kibana": [64, 65, 159, 160], "kick": [6, 143], "kill": [111, 112], "kilomet": [111, 112], "kim": [0, 6], "kind": [9, 40, 111, 112, 114, 123, 128, 133, 136, 145, 149, 151, 152, 156, 173], "kinda": 136, "kindergarten": 150, "kinemat": 6, "king": [9, 101, 124, 156, 158], "kirchhoff": [111, 112], "kirillov": 7, "kit": 6, "kitchen": [46, 118], "kitten": 113, "kiwisolv": 136, "kk": 95, "kkc22": [0, 6], "kl": [0, 6, 7, 8], "klan": [111, 112], "kleffner": [111, 112], "klein": 97, "klux": [111, 112], "km": 95, "kmp_duplicate_lib_ok": [15, 16, 17, 19, 21, 24, 29, 31, 32, 33, 34, 152], "kn": 95, "kneser": [95, 133], "knight": [111, 112], "know": [3, 77, 78, 97, 106, 110, 111, 112, 113, 114, 115, 117, 130, 136, 139, 150, 156, 173, 180, 182, 183, 184], "knowledg": [0, 9, 38, 42, 44, 46, 49, 50, 54, 55, 57, 64, 65, 69, 75, 77, 80, 81, 84, 85, 87, 89, 91, 93, 98, 100, 108, 109, 111, 112, 113, 130, 133, 134, 136, 138, 150, 156, 159, 160, 163], "known": [1, 8, 9, 38, 46, 49, 52, 53, 59, 64, 69, 72, 73, 77, 78, 83, 86, 91, 92, 97, 98, 101, 102, 106, 109, 111, 112, 116, 119, 122, 127, 132, 133, 134, 138, 139, 140, 141, 143, 145, 146, 153, 154, 156, 157, 158, 159, 172, 184], "ko": [94, 95, 103, 130, 141], "ko_mc4": 94, "koasati": [111, 112], "koeberl": [111, 112], "kolesnikov": 0, "komura": [0, 6], "kong": 152, "konlpi": 141, "konrad": 0, "koppen": [111, 112], "korea": [0, 12, 120, 123], "korean": [0, 1, 93, 94, 95, 102, 103, 120, 123, 129, 139, 176], "koresh": 150, "kotlin": 169, "kpbs288v": 17, "kpbs288vsync": 17, "krishna": 59, "kristina": 0, "kroneck": 51, "kronstadt": [111, 112], "kropotkin": [111, 112], "ksuccessfulli": 177, "kt": 14, "ktb\ud22c\uc790\uc99d\uad8c": 19, "ku": [95, 111, 112], "kube": 80, "kubectl": [80, 81], "kubeflow": 71, "kubernet": [64, 65, 70, 71, 75, 159, 160, 169], "kud18": 0, "kudo": [0, 105, 106], "kullback": [7, 8, 151], "kumiko": 0, "kuprel": [5, 130], "kurdish": 95, "kuwaiti": [111, 112], "kvfran": 9, "ky": 95, "kyrgyz": 95, "kytea": 105, "l": [0, 6, 8, 9, 14, 20, 21, 34, 88, 99, 101, 102, 105, 106, 108, 111, 112, 125, 126, 128, 145, 146, 152, 173, 177, 181], "l_ff": 52, "l_k": 52, "l_v": 52, "la": [0, 95, 101, 111, 112], "lab": [1, 6, 59, 93, 96, 102, 109, 122, 129, 134, 139, 148, 154], "label": [6, 9, 12, 14, 16, 22, 30, 32, 38, 46, 49, 52, 92, 93, 98, 100, 109, 110, 111, 112, 113, 115, 116, 122, 128, 130, 134, 135, 136, 137, 138, 139, 146, 149, 152, 178, 179, 181, 183], "label_column": 51, "label_config": 21, "label_error_candid": [14, 16, 17], "label_studio_serv": 17, "labelbox": 59, "labelencod": 136, "labelingfunct": 20, "labelrot": 24, "labels_by_annot": 20, "labelstudio": 17, "labor": [34, 57, 84, 111, 112, 120, 139, 163, 170], "labour": [111, 112, 139], "labyrinthin": 38, "lace": 16, "lack": [8, 10, 12, 13, 38, 49, 55, 57, 59, 62, 71, 83, 93, 97, 111, 112, 126, 130, 134, 140, 147, 151, 166, 172], "ladd": [111, 112], "lag": [12, 13, 111, 112], "lai": [59, 101, 139, 169], "laid": [127, 151], "laion": [5, 130], "lake": [16, 111, 112, 176, 177, 179, 180, 182], "lakeland": [176, 177, 179, 181], "lambda": [14, 19, 21, 23, 25, 26, 27, 52, 59, 107, 108, 111, 112, 149, 150, 152], "lambert": [111, 112], "lambertian": [111, 112], "lamda": [49, 52, 98], "lampl": 95, "lan": 99, "land": [111, 112, 133, 152], "landau": [111, 112], "landauer": [111, 112], "landfal": [111, 112], "landfil": 14, "landform": [111, 112], "landmark": 6, "landscap": [2, 3, 38, 46, 49, 50, 55, 56, 59, 63, 77, 78, 93, 111, 112, 126, 169, 172], "lang": 17, "langchain": [1, 42, 56, 59, 70, 74], "langdetect": 117, "langsmith": 57, "languag": [0, 1, 5, 8, 9, 10, 11, 41, 42, 44, 45, 46, 48, 50, 52, 54, 56, 57, 58, 64, 65, 69, 72, 74, 83, 84, 85, 87, 88, 89, 91, 93, 94, 96, 97, 100, 102, 103, 104, 105, 107, 110, 111, 112, 114, 115, 116, 117, 120, 122, 126, 129, 134, 135, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 163, 165, 167, 169, 170, 181, 183], "lao": [95, 111, 112], "laozi": [111, 112], "lapidari": [111, 112], "laplac": [132, 133], "larg": [0, 1, 5, 6, 8, 9, 11, 12, 26, 27, 37, 42, 44, 45, 46, 48, 52, 56, 57, 58, 60, 69, 71, 72, 73, 74, 76, 83, 84, 85, 86, 88, 91, 93, 95, 96, 97, 99, 100, 102, 105, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 128, 130, 132, 133, 134, 136, 137, 138, 139, 143, 144, 148, 149, 150, 151, 152, 154, 155, 156, 158, 163, 166, 169, 171, 172], "larger": [6, 9, 51, 59, 88, 97, 98, 107, 108, 111, 112, 114, 115, 116, 117, 130, 132, 133, 142, 143, 154, 157, 171, 172], "largest": [9, 88, 111, 112, 115, 130, 149, 150, 152], "larson": 150, "last": [9, 16, 17, 22, 24, 34, 53, 59, 88, 101, 103, 108, 111, 112, 113, 116, 117, 119, 120, 128, 136, 150, 152, 174, 185], "last_nam": [23, 32], "lastli": [56, 111, 112, 126], "late": [63, 111, 112, 119, 133, 152, 166, 171, 172], "latenc": [0, 6, 55, 59, 115], "latent": [7, 8, 9, 36, 130, 138, 148, 150, 152], "later": [8, 98, 110, 111, 112, 120, 124, 128, 130, 150, 152, 177, 178], "latest": [55, 60, 63, 77, 78, 80, 81, 85, 87, 89, 93, 96, 111, 112, 130, 175], "latin": [95, 111, 112, 140], "latitud": [111, 112], "latn": 95, "latt": 147, "latter": [9, 50, 111, 112, 145, 150], "lattic": 77, "latvian": 95, "laud": [111, 112], "launch": [51, 59, 82, 150, 169], "lauren": 0, "laurenc": 0, "law": [59, 98, 111, 112, 130, 137], "lawrenc": 34, "lawsuit": [111, 112], "lawyer": [111, 112], "layer": [3, 9, 10, 40, 46, 49, 52, 74, 77, 78, 82, 85, 88, 97, 99, 100, 110, 111, 112, 113, 114, 115, 116, 117, 127, 138, 139, 140], "layer_norm": 52, "layer_norm_ep": 112, "layernorm": 110, "laymen": 6, "layout": 136, "layoutlmfortokenclassif": 51, "lazi": [115, 142, 144, 158], "lb": 95, "lbsa": 30, "lcd": 14, "lcw99": 103, "lcw99___parquet": 103, "ld": [101, 105], "lda": [126, 138, 148], "lda_bas": 152, "ldamodel": 152, "lding": 107, "ldot": [99, 119, 126, 133, 143], "le": [0, 99, 101, 102, 106, 107, 108, 111, 112, 136], "lead": [6, 8, 9, 12, 42, 47, 50, 52, 53, 55, 59, 63, 64, 71, 73, 88, 93, 97, 98, 101, 102, 105, 106, 111, 112, 116, 117, 119, 120, 130, 132, 134, 137, 139, 143, 146, 148, 151, 153, 154, 159, 164, 166, 171, 172], "leader": [59, 71, 111, 112, 151, 152, 177], "leaderboard": 51, "leaderless": [111, 112], "leadership": [111, 112, 151], "leaf": 128, "leagu": [111, 112], "leah": [111, 112], "leakag": [52, 121], "lean": [111, 112, 165, 171], "leaner": [29, 35], "leap": [42, 46, 49, 53, 77, 139], "leapt": 139, "learn": [0, 1, 5, 7, 8, 9, 10, 11, 17, 18, 28, 34, 38, 39, 40, 41, 42, 44, 45, 48, 51, 52, 54, 55, 59, 64, 65, 66, 67, 72, 78, 80, 81, 85, 86, 88, 89, 90, 91, 93, 97, 98, 99, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 118, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133, 134, 135, 136, 140, 141, 143, 144, 146, 148, 151, 152, 153, 154, 156, 159, 160, 167, 169, 173, 178, 186], "learnabl": [8, 50, 52, 116, 127], "learner": [53, 99, 115], "learning_git": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "learning_r": [29, 35, 45, 51], "learninglearn": 17, "least": [64, 77, 95, 97, 107, 108, 111, 112, 116, 117, 120, 125, 139, 149, 150, 151, 159, 167], "leav": [52, 81, 100, 111, 112, 136, 175, 179, 184], "lectur": [12, 39, 41, 44, 48, 50, 52, 56, 57, 59, 67, 68, 72, 76, 77, 79, 80, 89, 97, 99, 100, 101, 102, 103, 106, 108, 111, 112, 114, 132, 135, 136, 141, 142, 150, 153, 155, 158, 161, 165, 167, 168, 169, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185, 186], "lecun": 53, "led": [2, 8, 49, 53, 77, 97, 98, 109, 111, 112, 116, 120, 130], "lee": [0, 1, 53, 99, 103, 110, 111, 112, 120, 151, 152, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "lee22": 0, "leech": 6, "leed": [111, 112], "left": [23, 63, 111, 112, 113, 128, 132, 136, 145, 147, 177, 180, 184, 185], "left_index": [31, 33, 34], "leftist": [111, 112], "leftmost": 149, "leg": [100, 111, 112], "legal": [12, 45, 59, 77, 93, 98, 109, 111, 112, 122, 130, 167], "legend": [23, 26, 32, 139, 149], "legendari": [111, 112, 130], "legion": [111, 112], "legisl": [0, 111, 112, 119, 137], "legislatur": [111, 112, 120], "legitim": [77, 111, 112], "legitimaci": [111, 112], "legwork": 69, "lehman": 119, "lei": [0, 6], "leibler": [7, 8, 151], "leighton": 152, "leipzig": 93, "leisur": [111, 112], "lemair": 0, "lemmat": [104, 136, 138, 142, 150], "lemmatize_text": 136, "lemongrass": 46, "len": [8, 14, 15, 16, 17, 19, 20, 21, 24, 30, 59, 94, 101, 104, 107, 108, 110, 111, 127, 128, 130, 132, 133, 145, 149, 150, 152, 155], "len_byt": [17, 24], "len_column": 24, "len_func": [15, 24], "len_word": [15, 24], "lend": 120, "lendingtre": [111, 112], "leng": 108, "length": [6, 16, 17, 19, 21, 24, 25, 30, 52, 77, 79, 93, 95, 97, 98, 100, 101, 103, 104, 107, 108, 110, 111, 112, 113, 115, 126, 136, 145, 152, 157], "lengthen": [111, 112], "lengthi": [9, 49, 111, 112], "lenin": [111, 112], "lent": 0, "leo": [111, 112], "leq": 157, "lerner": 0, "lesli": [111, 112], "less": [8, 24, 46, 49, 52, 77, 83, 88, 93, 97, 100, 109, 111, 112, 113, 115, 116, 121, 124, 128, 130, 136, 138, 145, 147, 150, 153, 157, 171, 172], "lessen": [111, 112], "lesser": [49, 83], "lesson": [64, 85, 150, 159, 171, 178], "lester": 52, "let": [8, 24, 30, 53, 67, 73, 80, 94, 97, 101, 103, 104, 105, 106, 110, 113, 114, 116, 123, 128, 132, 133, 135, 136, 140, 142, 143, 144, 147, 149, 150, 152, 155, 158, 174, 175, 176, 177, 178, 180], "letter": [49, 108, 111, 112, 136, 146], "letter_freq": 108, "leve": [111, 112], "level": [0, 6, 7, 8, 9, 11, 12, 23, 24, 25, 26, 27, 28, 30, 35, 38, 42, 50, 52, 53, 54, 55, 57, 59, 62, 65, 77, 85, 88, 92, 93, 99, 100, 102, 104, 108, 111, 112, 114, 117, 120, 122, 130, 137, 140, 142, 143, 146, 147, 148, 149, 152, 160, 167, 169, 171], "leverag": [6, 7, 11, 12, 38, 42, 45, 46, 50, 52, 53, 55, 56, 59, 60, 64, 66, 79, 82, 86, 91, 93, 95, 98, 100, 105, 109, 110, 113, 116, 126, 130, 137, 138, 159, 169], "levi": [111, 112], "levin": [0, 6], "lewi": [95, 99, 130, 183], "lexic": [130, 137], "lexicograph": 156, "lexicon": [1, 30, 38, 129, 130, 134, 136, 138, 156], "lf": 20, "lf_summari": 20, "lfg": 14, "lg": 20, "lgbm": [29, 35], "lgbmclassifi": [29, 35], "lgbmclassifierlgbmclassifi": [29, 35], "lgbt": [111, 112], "lg\uac00": [14, 21], "lg\uadf8\ub8f9\uc740": 16, "lg\uc5d0\ub108\uc9c0\uc194\ub8e8\uc158\uc73c\ub85c": 20, "lg\uc720\ud50c\ub7ec\uc2a4": 14, "lg\uc804\uc790\ub294": [15, 19], "lg\ud654\ud559": [14, 20], "lg\ud654\ud559\uacfc": [14, 16], "lg\ud654\ud559\uc740": [14, 16, 20], "lg\ud654\ud559\uc758": 20, "lg\ud654\ud559\uc774": [14, 20], "lh": 32, "li": [0, 3, 6, 38, 41, 49, 52, 53, 59, 84, 86, 101, 111, 112, 114, 116, 126, 147, 151, 166, 171], "liabil": [98, 111, 112], "liali": 52, "liang": [0, 6], "liangzh": 0, "lib": [28, 30, 100, 101, 103, 108, 110, 111, 112, 114, 132, 135, 136, 141, 150], "liber": [0, 28, 111, 112, 120], "libertarian": [111, 112], "liberti": [111, 112], "libnvinf": 14, "libnvinfer_plugin": 14, "librari": [1, 12, 14, 22, 43, 47, 50, 60, 61, 64, 71, 72, 73, 75, 77, 89, 93, 94, 96, 97, 100, 104, 105, 110, 111, 112, 114, 119, 123, 124, 130, 132, 135, 136, 141, 142, 144, 146, 147, 152, 158, 159, 167, 170, 178], "licens": [17, 83, 88, 111, 112, 181], "lid": 120, "lide": 107, "lie": [84, 171, 174, 176, 177, 179], "lieuten": [111, 112], "lif": 101, "life": [1, 2, 3, 6, 60, 71, 93, 111, 112, 136, 152, 161, 162, 172], "lifecycl": [38, 60, 61, 63, 64, 65, 69, 71, 80, 159, 160, 161, 171, 172], "lifelik": 6, "lifetim": [59, 111, 112], "lift": 128, "ligatur": [111, 112], "light": [1, 4, 49, 105, 107, 111, 112, 114], "lightgbmmodelartifact": 73, "lightli": 93, "lightlink": 97, "lightn": [111, 112], "lightweight": [6, 60, 61, 62, 80, 83, 105], "like": [1, 2, 3, 6, 8, 9, 10, 12, 13, 14, 24, 26, 27, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 64, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 80, 83, 84, 85, 86, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 121, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 140, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 185], "likelihood": [49, 64, 89, 90, 97, 100, 105, 106, 107, 115, 127, 128, 131, 133, 147, 151, 152, 159, 163, 167], "liken": 156, "likewis": 112, "limamu": [111, 112], "lime": 12, "limeston": [111, 112], "limit": [0, 5, 6, 9, 14, 39, 42, 43, 44, 45, 46, 52, 54, 57, 59, 60, 74, 76, 80, 83, 86, 89, 90, 93, 97, 98, 99, 100, 102, 111, 112, 115, 116, 117, 119, 121, 130, 132, 133, 135, 137, 138, 146, 147, 150, 151, 155, 156, 157, 166, 167, 170, 171, 172], "limit_alphabet": 112, "linalg": 150, "linchpin": 59, "line": [7, 24, 30, 56, 59, 61, 69, 73, 80, 81, 95, 101, 103, 111, 112, 117, 124, 135, 146, 152, 167, 173, 174, 175, 177, 178, 182, 185], "lineag": [71, 111, 112], "linear": [9, 39, 40, 52, 88, 112, 113, 116, 126, 127, 128, 132, 136, 138, 151, 171, 172, 180, 183], "linear1": 128, "linear2": 128, "linearli": [52, 116, 138, 151], "linearsvc": 136, "linearsvclinearsvc": 136, "lineplot": [23, 25, 26, 27, 31, 32], "linewidth": 32, "linger": [111, 112, 152], "lingual": [93, 95, 109, 122], "linguist": [0, 49, 89, 93, 99, 109, 113, 120, 121, 126, 128, 129, 130, 132, 135, 136, 150, 156], "link": [9, 10, 96, 111, 112, 119, 120, 126, 132, 178], "linkag": [111, 112], "lint": [0, 64, 159], "linux": [60, 61, 75, 81, 174], "liquid": [12, 152], "list": [14, 17, 22, 23, 34, 43, 45, 49, 60, 65, 69, 79, 80, 89, 95, 100, 101, 102, 104, 105, 107, 108, 111, 112, 117, 119, 120, 123, 124, 126, 127, 128, 130, 132, 133, 134, 135, 137, 139, 141, 143, 144, 146, 147, 150, 152, 160, 166, 167, 171, 174, 178, 180, 181], "list_project": [20, 21], "listen": 140, "listseq": 94, "lit": [3, 136], "lite": 99, "liter": [111, 112, 134], "literaci": [85, 111, 112], "literari": [111, 112], "literatur": [6, 46, 49, 52, 93, 111, 112, 120], "lithuanian": 95, "litig": [111, 112], "littl": [6, 100, 111, 112, 114, 128, 138, 142, 150, 172], "liu": [0, 6, 52, 95, 99], "live": [3, 9, 16, 91, 111, 112, 130], "liwc": 126, "lkp19": 0, "ll": [64, 72, 94, 95, 97, 101, 103, 105, 110, 111, 112, 116, 132, 135, 136, 141, 142, 144, 152, 155, 158, 159, 173, 174, 175, 176, 177, 178, 182], "ll54": 183, "ll_per_word": 152, "llama": [52, 59], "llamaindex": 56, "llc": 101, "lldamodel": 152, "lleng": 108, "lli": 101, "llion": [0, 101], "llm": [1, 47, 48, 50, 59, 72, 84, 85, 86, 87, 97], "llm_config": 42, "llmop": [1, 70], "lm": [1, 31, 49, 84, 96, 109], "lm_col": 35, "lm_tone": [31, 32, 33], "lmsa": 30, "ln": 123, "lo": [0, 95, 101, 105, 119, 139], "load": [6, 16, 17, 20, 22, 38, 50, 51, 52, 95, 100, 101, 105, 107, 108, 114, 119, 121, 123, 133, 135, 139, 144, 145, 155], "load_calendar": [23, 24, 31], "load_candid": 30, "load_data": [14, 15, 17, 19, 20, 21, 23, 24, 25, 26, 27, 30, 31, 32, 33, 128, 145, 152], "load_datafram": [16, 20, 28, 33], "load_dataset": [20, 94, 95, 101, 103, 107, 108, 110, 111, 112, 136], "load_dotenv": 123, "load_iri": 73, "load_metr": 110, "load_model": [14, 124], "load_vector": 124, "loader": [14, 15, 21], "loadrunn": 169, "loan": [0, 12, 77, 120], "lobbi": [12, 111, 112, 119], "loc": 32, "local": [6, 7, 16, 17, 22, 30, 54, 60, 61, 66, 67, 68, 69, 76, 80, 81, 97, 110, 111, 112, 115, 119, 120, 125, 133, 136, 138, 145, 154, 169, 177, 178, 179, 180, 181, 182], "local_bar": 185, "local_machin": 51, "locat": [6, 8, 12, 43, 60, 61, 66, 67, 79, 93, 98, 111, 112, 120, 122, 128, 130, 140, 145, 171], "loci": [111, 112], "lock": 152, "locomot": 6, "log": [8, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 41, 51, 60, 64, 72, 75, 76, 80, 84, 90, 99, 103, 105, 106, 107, 108, 110, 114, 121, 125, 127, 128, 132, 145, 147, 151, 152, 153, 155, 157, 159, 175, 176, 177, 179, 180, 181, 183, 185], "log2": 132, "log_2": 128, "log_dir": 111, "log_level": [14, 16, 19, 20, 21, 22], "log_max_bin": [29, 35], "log_prob": 128, "log_prob_sum": 132, "logarithm": [147, 158], "logcond": 152, "logging_dir": 110, "logic": [6, 49, 53, 54, 55, 57, 58, 89, 98, 105, 111, 112, 139, 163, 169], "login": [17, 22, 30], "logist": [12, 128, 134, 136, 138, 151], "logit": [88, 97, 110], "loglikelihood": 152, "loglog": 139, "logstash": [64, 65, 159, 160], "loha": 51, "lokr": 51, "london": [111, 112, 152], "lone": [111, 112], "loneli": [111, 112], "long": [0, 2, 6, 12, 13, 41, 46, 49, 52, 53, 83, 86, 98, 100, 102, 103, 105, 106, 111, 112, 113, 116, 117, 120, 128, 130, 132, 133, 134, 138, 145, 152, 155, 156, 157, 167, 171, 174], "longer": [16, 17, 19, 21, 30, 52, 55, 88, 97, 99, 104, 111, 112, 115, 116, 117, 128, 132, 145, 175], "longest": [101, 108, 110, 111, 112, 145], "longev": 169, "longleaf": [111, 112], "longtensor": [127, 128], "loo": 101, "look": [5, 6, 10, 50, 53, 56, 62, 64, 68, 88, 89, 97, 101, 104, 106, 108, 111, 112, 116, 126, 127, 128, 132, 135, 136, 139, 140, 141, 142, 144, 147, 150, 151, 152, 154, 158, 159, 171, 173, 176, 177, 178, 180, 182, 183], "lookup": [73, 127], "loop": [0, 6, 42, 43, 46, 55, 57, 59, 63, 71, 97, 107, 108, 111, 112, 128, 136, 145, 155, 171, 172], "loos": 10, "lope": [0, 6], "lora": 52, "lora_alpha": [45, 51], "lora_dreambooth": 51, "lora_dropout": [45, 51], "lora_linear": 52, "lora_r": [45, 51], "lora_text_encoder_alpha": 51, "lora_text_encoder_r": 51, "loraconfig": 51, "lorem": 117, "lorenzo": 0, "lose": [0, 50, 111, 112, 115, 116, 126, 143, 152, 167, 175], "loser": [101, 107], "loss": [6, 7, 8, 16, 17, 22, 53, 55, 85, 92, 99, 101, 105, 106, 108, 110, 111, 112, 116, 146, 152, 154], "loss0": [16, 17, 22], "loss1": 17, "loss_funct": 128, "lossi": 143, "lossless": 105, "lost": [111, 112, 143, 145], "lot": [3, 51, 97, 111, 112, 118, 130, 133, 139, 150, 157, 174, 183], "loud": [111, 112], "loughran": [30, 31, 119], "loui": 97, "louisian": [111, 112], "louisiana": [111, 112, 120], "louisvil": [111, 112], "louka": 0, "lovabl": 126, "love": [3, 97, 100, 111, 112, 132, 133, 143, 158], "lovelac": 5, "low": [0, 6, 9, 10, 12, 13, 35, 51, 52, 55, 74, 97, 101, 106, 109, 111, 112, 120, 127, 133, 141, 143, 147, 149, 152, 156, 157, 169], "low_cost_partial_config": 35, "lower": [8, 10, 84, 90, 93, 99, 101, 107, 108, 109, 111, 112, 115, 126, 128, 130, 132, 133, 136, 138, 142, 149, 150, 151, 152, 155], "lowercas": [101, 103, 104, 105, 107, 108, 111, 112, 136, 138, 146], "lowest": [88, 107, 108, 111, 112, 149], "lownd": [111, 112], "loyalist": [111, 112], "lpga": [111, 112], "lr": [16, 17, 22, 127, 128, 147], "lr_schedul": 51, "lr_warmup_step": 51, "lrb": 144, "lsa": [150, 154], "lsmt": 52, "lstm": [6, 41, 52, 99, 130, 134, 138], "lt": [95, 119], "lte": 17, "lu": 101, "luan": 99, "luca": 0, "lucidchart": 169, "lucidrain": [8, 9], "lucio": [0, 6], "lueck": [24, 30], "luggag": 99, "lumber": [111, 112], "lump": 108, "lunar": [111, 112, 150], "lunch": [24, 30], "luong": 99, "luther": [111, 112], "luxembourgish": 95, "lv": 95, "lve": 114, "ly": [101, 126, 139], "lymp": 108, "lymph": 108, "lympho": 108, "lymphom": 108, "lymphoma": 108, "lynch": [111, 112], "lyric": 16, "m": [0, 6, 14, 16, 17, 19, 20, 21, 22, 24, 37, 42, 53, 67, 68, 76, 79, 95, 97, 99, 101, 105, 108, 111, 112, 123, 129, 130, 133, 136, 139, 140, 144, 145, 147, 150, 151, 152, 174, 175, 176, 177, 178, 181], "m2": 34, "m2sl": 34, "m_": 147, "m_r": 147, "ma": [32, 101, 111, 112], "maarten": 0, "mabila": [111, 112], "mac": [61, 174], "macedonian": 95, "mach": 0, "machiel": 181, "machin": [0, 1, 6, 7, 8, 9, 37, 38, 39, 40, 41, 45, 46, 47, 49, 52, 53, 55, 59, 64, 66, 67, 68, 72, 73, 74, 76, 78, 80, 81, 86, 87, 89, 91, 93, 96, 97, 98, 99, 100, 102, 104, 105, 106, 112, 118, 122, 126, 129, 131, 132, 133, 134, 135, 136, 140, 141, 142, 144, 145, 146, 148, 152, 153, 154, 155, 156, 159, 167, 169, 185], "machine_rank": 51, "mackenzi": [0, 6], "maco": [61, 79], "macro": [8, 14, 16, 22, 29, 30, 35, 119, 135, 136], "macroeconom": [118, 120], "made": [2, 3, 8, 9, 52, 53, 59, 63, 64, 67, 71, 92, 95, 111, 112, 116, 120, 121, 126, 127, 130, 136, 137, 159, 175, 176, 178, 180, 181, 183], "madison": [111, 112], "mae": [29, 35, 88], "mag": 141, "magazin": [111, 112], "mage": 5, "magenta": 2, "magic": [111, 112, 126, 173], "magnifi": [10, 59], "magnitud": [111, 112, 113, 147], "mai": [0, 8, 9, 10, 12, 20, 23, 40, 42, 44, 45, 46, 52, 57, 59, 60, 64, 66, 67, 69, 76, 77, 82, 83, 88, 89, 90, 91, 92, 93, 97, 98, 99, 100, 102, 103, 104, 111, 112, 113, 116, 120, 121, 130, 132, 133, 135, 136, 137, 138, 139, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 156, 157, 158, 159, 166, 169, 170, 171, 172, 173, 175, 177, 180, 185], "mail": [136, 150], "main": [0, 6, 9, 23, 24, 30, 37, 41, 51, 52, 65, 67, 68, 75, 77, 80, 87, 89, 91, 97, 99, 100, 102, 104, 108, 109, 111, 112, 114, 116, 120, 130, 132, 133, 137, 138, 139, 142, 145, 146, 151, 152, 154, 155, 156, 160, 167, 171, 172, 173, 174, 175, 176, 177, 180, 181, 182, 183, 185], "main_rebase_carollian": 183, "main_training_funct": 51, "mainli": [97, 100, 105, 111, 112, 119, 166], "mainlin": 171, "mainstream": [111, 112], "maintain": [6, 8, 12, 38, 44, 46, 50, 52, 55, 56, 59, 61, 64, 66, 67, 70, 71, 74, 77, 78, 80, 81, 88, 89, 91, 93, 95, 97, 98, 111, 112, 116, 137, 138, 143, 159, 163, 165, 166, 167, 171, 173], "mainten": [55, 71, 111, 112, 161, 169, 171, 172], "maj": 141, "major": [50, 53, 59, 99, 111, 112, 116, 119, 120, 121, 130, 137, 139, 152, 154, 171], "majuscul": [111, 112], "make": [1, 3, 5, 6, 7, 8, 9, 10, 12, 14, 37, 38, 39, 41, 42, 44, 45, 46, 49, 50, 52, 53, 54, 57, 59, 60, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 76, 77, 79, 80, 81, 83, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 122, 123, 124, 126, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 145, 147, 148, 150, 151, 152, 154, 156, 159, 160, 164, 167, 171, 172, 173, 174, 175, 176, 177, 180, 181, 182, 183, 184, 185], "make_batch": 127, "make_doc": 152, "make_worker_lf": 20, "makedir": [123, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "makefil": 181, "maker": [5, 12, 36, 40, 130], "maketran": [136, 142], "makhno": [111, 112], "maladapt": [111, 112], "malagasi": 95, "malai": 95, "malatesta": [111, 112], "malayalam": 95, "male": [59, 111, 112], "malfunct": [111, 112], "malici": [52, 59, 77, 78, 92, 98], "malik": [0, 6], "maltes": 95, "mamidanna": [0, 6], "mammal": [83, 111, 112], "mammalian": 83, "man": [0, 9, 99, 101, 111, 112, 130, 156], "manag": [1, 6, 30, 42, 50, 53, 55, 57, 59, 61, 62, 68, 69, 70, 71, 73, 74, 75, 76, 80, 91, 100, 101, 111, 112, 116, 119, 120, 121, 123, 126, 128, 132, 133, 152, 161, 162, 164, 166, 167, 169, 170, 172, 173, 174, 186], "mandarin": 130, "mandat": 47, "mandatori": [69, 80], "mandir": [111, 112], "maneuv": 133, "mani": [5, 6, 23, 38, 40, 46, 53, 64, 65, 71, 73, 80, 89, 93, 96, 97, 98, 99, 100, 103, 105, 108, 111, 112, 115, 118, 122, 126, 127, 128, 129, 130, 132, 133, 136, 138, 140, 141, 142, 144, 145, 152, 154, 155, 156, 159, 160, 164, 173, 174, 178, 185], "mania": 150, "manifest": [42, 49, 64, 159], "manifesto": [120, 171], "manifold": [28, 138], "manipul": [6, 8, 9, 12, 92, 111, 112, 116, 121, 126, 130, 152], "manner": [1, 8, 9, 10, 52, 60, 64, 66, 68, 89, 91, 99, 111, 112, 116, 142, 151, 159, 166, 171], "manu": 0, "manual": [46, 59, 64, 65, 66, 71, 88, 93, 97, 104, 105, 111, 112, 120, 121, 132, 135, 138, 150, 159, 160, 164, 167, 169, 175, 177, 178], "manufactur": [111, 112, 120, 152], "manylinux2014_x86_64": [136, 150], "manylinux_2_17_x86_64": [136, 150], "maori": 95, "map": [6, 8, 17, 19, 23, 25, 26, 27, 55, 61, 98, 102, 105, 110, 111, 112, 124, 126, 127, 128, 136, 138, 139, 143, 150, 156], "map_datafram": 26, "mapreduc": 38, "mar": [0, 101, 111, 112, 150], "marathi": 95, "march": [101, 111, 112, 116, 152], "mardi": [111, 112], "marengo": [111, 112], "marga": 30, "margaret": 0, "margin": [40, 97, 111, 112, 115, 117, 152], "marginalis": [111, 112], "mari": [111, 112], "mark": [2, 6, 42, 50, 52, 53, 54, 72, 101, 111, 112, 114, 117, 126, 130, 139, 140, 144, 177], "markdown": [176, 181, 182], "markedli": [111, 112], "marker": [6, 111, 112, 130, 136, 139], "markerless": [0, 6], "market": [0, 1, 36, 40, 41, 49, 50, 59, 64, 65, 71, 98, 101, 111, 112, 118, 119, 120, 126, 128, 132, 134, 150, 152, 159, 160, 166, 167, 169, 171, 172], "marketplac": [65, 160], "markoff": 136, "markov": [144, 151], "marku": 0, "markup": [64, 159, 173], "maron": 0, "marri": [111, 112, 120], "marriag": [111, 112], "marshal": [111, 112], "martha": [111, 112], "martial": 6, "martian": 3, "martin": [34, 111, 112, 129], "marvel": 2, "marx": [111, 112], "marxism": [111, 112], "marxist": [111, 112], "masculin": 140, "mask": [8, 9, 82, 84, 95, 98, 100, 103, 104, 108, 109, 110, 111, 112, 113, 115, 116, 117], "mask_token": [111, 112], "mass": [97, 99, 111, 112, 133, 147, 149], "massiv": [0, 9, 10, 38, 52, 86, 88, 93, 95, 98, 111, 112, 113, 115, 122, 128, 156], "master": [9, 46, 53, 67, 77, 167, 171, 178, 183, 184, 185], "master_merge_carollian": 183, "masteri": 163, "mat": [7, 101, 132, 136, 153], "match": [0, 5, 8, 9, 11, 52, 53, 55, 64, 77, 111, 112, 114, 116, 117, 123, 130, 140, 150, 152, 155, 159, 166], "matched_posit": 101, "matena": [0, 99], "materi": [37, 46, 52, 89, 111, 112, 121, 139, 150, 152, 164], "materialis": 139, "materiel": [111, 112], "matern": [111, 112], "math": [42, 107, 108, 129, 132, 146, 155], "mathbb": [8, 84, 105, 119], "mathbf": [105, 124, 125, 126], "mathcal": [8, 99, 105, 125, 128], "mathchat": 42, "mathemat": [5, 49, 53, 54, 77, 89, 97, 111, 112, 126, 130, 132, 147, 154, 164], "mathematician": 5, "mathesiu": [111, 112], "mathi": [0, 6], "matplotlib": [28, 94, 128, 136, 139, 149, 150, 155, 181], "matric": [50, 52, 99, 112, 150, 151, 158], "matrix": [52, 59, 115, 116, 119, 128, 136, 138, 143, 146, 148, 154, 155, 158, 169], "matter": [59, 111, 112, 136, 173], "matthew": [0, 150], "matthia": [0, 6], "matur": [56, 63, 71, 111, 112, 120], "max": [17, 25, 30, 51, 101, 111, 112, 127, 128, 145, 155], "max_bin": [29, 35], "max_depth": 35, "max_featur": 136, "max_font_s": 136, "max_leav": 35, "max_length": [24, 30, 97, 100, 110, 111, 112], "max_position_embed": 112, "max_scor": 108, "max_sentence_length": [103, 105], "max_sentencepiece_length": [103, 105], "max_seq_length": [14, 16, 17, 19, 22, 30], "max_token": 100, "max_train_step": 51, "maxim": [9, 10, 44, 46, 54, 98, 100, 106, 116, 132, 145, 151], "maximum": [8, 9, 16, 17, 19, 21, 55, 88, 97, 103, 106, 110, 111, 112, 120, 133, 148, 171], "mayb": [174, 175, 176, 182], "mazdak": [111, 112], "mb": [14, 15, 21, 51, 101, 132, 135, 136, 150], "mbe": 107, "mber": 101, "mc4": [1, 93, 96, 109], "mc4_subset_with_five_languag": 95, "mc4gaussian": 95, "mcc": [14, 16, 17, 22], "mcdonald": [30, 31, 119], "mcdonough": 30, "mcgraw": 129, "mcmahon": 0, "mcmc": 151, "mct": 53, "md": [173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185], "mdl": 152, "me": [5, 24, 30, 97, 101, 113, 130, 136, 140, 144, 150, 177, 180], "meal": [111, 112, 130], "mean": [1, 8, 9, 10, 25, 26, 27, 31, 32, 34, 46, 50, 52, 55, 64, 69, 84, 88, 91, 97, 98, 99, 105, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 124, 125, 126, 128, 130, 132, 134, 137, 138, 139, 140, 143, 144, 145, 148, 150, 151, 152, 153, 154, 155, 156, 157, 159, 172, 174, 176, 177, 180], "meaning": [24, 37, 59, 68, 89, 93, 97, 102, 106, 109, 111, 112, 116, 118, 130, 140, 142, 145, 146, 148, 150, 151, 153, 156], "meaningfulli": [89, 146], "meant": [111, 112], "meantim": [111, 112], "meanwhil": [128, 152], "measur": [0, 1, 9, 10, 12, 23, 38, 55, 77, 78, 83, 85, 88, 91, 93, 98, 108, 109, 111, 112, 115, 118, 120, 129, 132, 133, 137, 143, 145, 148, 149, 152, 155, 157, 158, 165, 167, 170, 172], "measure_token_length": 101, "meat": 156, "mecab": [105, 142], "mechan": [8, 11, 38, 48, 54, 55, 56, 59, 77, 92, 98, 111, 112, 114, 115, 130, 138, 165], "medal": 130, "medi": 101, "media": [5, 16, 17, 22, 40, 41, 46, 59, 93, 98, 111, 112, 118, 120, 121, 130, 134, 135, 137, 141, 148, 151, 152], "median": 17, "mediatyp": 60, "medic": [5, 6, 7, 45, 46, 49, 71, 77, 92, 101, 109, 111, 112, 126, 130, 136], "medicar": [111, 112], "medicin": [92, 98, 111, 112], "mediev": [111, 112], "medium": [5, 10, 111, 112, 115], "meek": [111, 112], "meet": [0, 1, 12, 23, 24, 30, 36, 45, 46, 55, 63, 65, 71, 76, 86, 87, 93, 98, 111, 112, 137, 160, 163, 164, 165, 166, 167, 170, 171, 172], "megatron": 93, "megatron_lm_config": 51, "meiosi": [111, 112], "meld": 183, "melodi": 2, "melt": [111, 112], "meltdown": [111, 112], "melvil": 139, "melvin": [111, 112], "mem": 17, "member": [30, 36, 42, 63, 64, 75, 80, 81, 83, 111, 112, 159, 167, 172], "membership": [111, 112], "memor": [111, 112], "memori": [6, 8, 14, 15, 21, 38, 41, 49, 51, 52, 56, 59, 100, 102, 105, 110, 111, 112, 130, 132, 134, 138, 143, 145, 154], "memoryless": 132, "memphi": [111, 112], "men": [101, 111, 112], "mendelian": [111, 112], "ment": [101, 107, 108, 145], "mental": [98, 111, 112], "mention": [14, 80, 111, 112, 114, 117, 120, 130, 134, 138, 143, 167, 170], "menu": [110, 111, 112, 178], "meokda": 130, "mer": 101, "merced": [111, 112], "merchant": 152, "mercuri": [69, 111, 112, 173, 185], "mere": [38, 42, 46, 49, 59, 111, 112, 126], "meredith": 184, "merg": [8, 14, 15, 19, 21, 23, 24, 33, 34, 50, 53, 54, 55, 65, 100, 105, 106, 112, 126, 148, 160, 171, 172, 173, 175, 178, 179, 181, 186], "merge_output": [15, 20, 24, 30], "merge_pair": 108, "merge_vocab": 101, "merged_tone_data": [31, 32, 33], "merger": 101, "merit": 126, "meronym": 137, "merovingian": [111, 112], "mesoamerican": [111, 112], "messag": [24, 42, 46, 68, 72, 76, 77, 91, 111, 112, 117, 121, 130, 150, 174, 175, 177, 184], "messi": 71, "met": [24, 97, 101, 111, 112, 136], "meta": [15, 57, 59, 83, 100, 105], "meta_column": [14, 19], "meta_fil": [17, 22, 28], "meta_piec": [103, 105], "metabol": [111, 112], "metabolit": [111, 112], "metadata": [14, 15, 16, 17, 19, 38, 71, 93, 103, 121, 135, 136, 152, 183], "metagpt": [42, 44], "metal": [75, 111, 112, 152], "metamodel": 10, "meteor": 152, "meteorit": [111, 112], "meteosat": [111, 112], "meter": [40, 111, 112], "method": [0, 1, 6, 7, 9, 10, 12, 16, 17, 19, 21, 29, 30, 37, 38, 39, 46, 53, 54, 55, 59, 66, 76, 77, 78, 82, 84, 88, 89, 93, 95, 97, 98, 100, 101, 104, 105, 106, 109, 110, 111, 112, 116, 118, 119, 120, 121, 123, 126, 127, 128, 129, 130, 132, 133, 134, 135, 140, 141, 142, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 163, 164, 169, 172, 178], "methodist": [111, 112], "methodolog": [50, 111, 112], "methodologi": [1, 6, 37, 41, 50, 52, 64, 65, 71, 96, 119, 121, 129, 148, 159, 160, 161, 162, 163, 165, 167, 169, 170, 172], "methylphenid": [111, 112], "meticul": [55, 57, 172], "metric": [4, 6, 12, 14, 16, 17, 19, 42, 45, 53, 55, 59, 63, 65, 71, 74, 75, 80, 89, 91, 109, 110, 112, 132, 133, 135, 136, 144, 147, 157, 160, 167], "metropolitan": [111, 112], "metzler": 0, "mexico": [111, 112, 152], "mfa": [77, 78], "mg": 95, "mgldamodel": 152, "mgm": [111, 112], "mhmg": 136, "mi": [95, 101], "mi_lik": 149, "miami": 119, "mib": [22, 103], "mic": 101, "mice": [6, 111, 112], "michael": [0, 101, 111, 112], "michal": 0, "mickei": 133, "microk8": 81, "micron": 128, "microscopi": 88, "microservic": [55, 71, 72], "microsoft": [5, 35, 42, 59, 85, 93, 122, 130, 169], "microwav": [111, 112], "mid": [99, 101, 111, 112], "middl": [111, 112, 147], "midjournei": [5, 130], "midland": [111, 112], "midlatitud": [111, 112], "midlif": [111, 112], "midterm": [47, 96, 129, 161], "midwest": [111, 112], "midwestern": [111, 112], "mig": 112, "might": [2, 9, 24, 41, 45, 46, 49, 50, 54, 63, 64, 74, 92, 97, 100, 103, 104, 105, 110, 111, 112, 115, 116, 126, 128, 130, 132, 133, 134, 136, 137, 138, 139, 140, 144, 147, 150, 151, 157, 159, 176, 179, 181, 182, 183, 185], "migrat": [69, 111, 112], "mihir": 0, "mike": [97, 111, 112], "mikhail": [111, 112], "mikolov": [0, 128], "mild": [111, 112], "mildli": 152, "mile": [59, 111, 112], "mileston": [53, 85, 93, 111, 112, 166, 167, 170, 171, 172], "milieu": [111, 112], "milit": [111, 112], "militari": [111, 112], "militia": [111, 112], "milk": [111, 112], "mill": [111, 112], "million": [9, 52, 88, 111, 112, 113, 117, 122, 124, 130, 139, 152], "millionair": 130, "millisecond": 88, "mime": 77, "mimic": [5, 6, 90, 91], "mimick": [42, 53], "min": [5, 17, 25, 101, 130, 155], "min_cf": 152, "min_child_sampl": [29, 35], "min_child_weight": 35, "min_df": [150, 152], "min_frequ": [103, 112, 145], "min_length": 24, "minchul": 0, "mind": [2, 10, 55, 76, 85, 97, 111, 112, 130, 155], "minder": 0, "mindsey": [5, 130], "mine": [0, 59, 98, 111, 112, 134, 148, 151, 152, 177], "miner": [111, 112], "ming": 0, "mingyuan": [0, 6], "mini": [8, 128, 132, 166], "minibatch": [15, 16, 17, 20, 24, 30], "minibatch_s": [15, 20, 24, 30], "minim": [6, 9, 10, 12, 24, 50, 52, 55, 59, 64, 65, 88, 97, 98, 100, 111, 112, 115, 116, 117, 146, 148, 151, 159, 160, 163, 166, 172], "minimagen": 10, "minimalist": [60, 62], "minimis": 8, "minimum": [97, 111, 112, 152], "minor": [46, 98, 111, 112, 117], "minu": [111, 112, 135, 174], "minuscul": [111, 112], "minut": [0, 6, 12, 30, 36, 119, 137, 182], "mirror": [1, 46, 53, 66, 111, 112, 121, 156], "misappropri": [111, 112], "misc": [150, 152], "miscellan": 152, "misconcept": [111, 112], "misconfigur": [64, 159], "misdiagnos": [111, 112], "misgoogl": 139, "misinform": [53, 83, 92, 93], "mislabel": 93, "mislead": [49, 130, 149], "mismatch": [9, 10, 55], "misrepres": 137, "miss": [10, 14, 89, 97, 98, 99, 101, 107, 111, 112, 115, 117, 150, 152], "missil": 133, "mission": [71, 150], "mississippi": [111, 112], "mississippian": [111, 112], "misspel": 145, "mist": 101, "mistak": [1, 42, 93, 130, 136, 161, 173, 186], "mistaken": [111, 112], "misunderstand": [111, 112], "misus": [53, 59, 74, 85, 98, 130], "mit": [20, 53, 77, 101], "mitchel": [0, 84, 129], "mitig": [12, 46, 49, 50, 53, 54, 55, 57, 59, 74, 77, 83, 85, 92, 93, 97, 98, 106, 116, 121, 166, 167, 170, 172], "mix": [6, 9, 40, 97, 111, 112, 139, 151, 179], "mixed_precis": 51, "mixtur": [12, 111, 112, 147, 148, 151], "mk": 95, "mkdir": [80, 81, 185], "ml": [1, 52, 72, 73, 74, 75, 77, 78, 80, 95, 97, 112, 129, 134, 142], "mle": 133, "mle_mu": 132, "mle_p": 132, "mle_sigma": 132, "mlfoundat": 9, "mlk": 0, "mlm": [1, 96, 109, 113], "mlm_probabl": 112, "mlop": [1, 56, 70, 74, 82], "mlp": [88, 116], "mm": 142, "mmc": [0, 6], "mment": 107, "mmlu": 85, "mmr": [111, 112], "mn": 95, "mnli": [100, 117], "mnt": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "mo": 101, "mob": [111, 112], "mobi": 139, "mobil": [71, 101, 111, 112, 169], "mobilenetv2": 6, "moby_dick": 139, "mocap": 6, "mockup": 169, "mod": 124, "modal": [9, 50, 91, 116], "mode": [6, 111, 112, 174, 176, 177, 181, 183, 185], "model": [0, 1, 4, 8, 14, 17, 19, 21, 29, 30, 32, 35, 37, 38, 39, 41, 42, 44, 45, 46, 48, 52, 54, 56, 58, 63, 67, 70, 71, 73, 80, 83, 84, 85, 87, 88, 91, 93, 94, 96, 97, 100, 102, 103, 105, 108, 113, 114, 116, 120, 121, 122, 125, 126, 129, 130, 134, 135, 137, 139, 143, 149, 156, 157, 161, 165, 168, 169, 171], "model_cfg": [16, 17, 19, 21, 22, 29, 30, 35], "model_dir": 14, "model_econ": 35, "model_engin": 100, "model_filenam": 124, "model_finbert": 35, "model_input": [30, 52], "model_lm": 35, "model_loss": [107, 108], "model_max_length": 30, "model_nam": [45, 51, 100], "model_name_or_path": [14, 22, 51], "model_pr": 128, "model_prefix": [103, 105], "model_s": 112, "model_select": 136, "model_t5": 35, "model_typ": [103, 105, 114], "model_vers": [21, 114], "model_view": 114, "model_without_token": [107, 108], "moder": [98, 111, 112, 130], "modern": [6, 9, 41, 44, 52, 59, 64, 69, 76, 111, 112, 121, 133, 146, 159, 185], "moderna": [111, 112], "modest": [111, 112], "modi": [111, 112], "modif": [9, 46, 50, 52, 53, 54, 57, 60, 64, 97, 99, 115, 117, 159, 172], "modifi": [7, 9, 46, 50, 52, 54, 64, 84, 88, 89, 98, 109, 111, 112, 115, 120, 121, 128, 130, 136, 143, 159, 164, 174, 176, 181], "modified_info": 17, "modnet": 7, "modul": [6, 50, 52, 69, 71, 77, 78, 104, 111, 112, 114, 123, 127, 128, 136, 144, 147, 150, 163, 169, 172], "modular": [59, 60, 62, 66, 71], "module_nam": 69, "mohl": [111, 112], "molecul": [64, 159], "mollusk": [111, 112], "molyneux": [111, 112], "moment": 176, "momentum": [111, 112], "mon": [101, 180, 184], "monarchi": [111, 112], "monast": [111, 112], "mone": 101, "monei": [111, 112, 136, 152], "monetari": [0, 1, 12, 23, 36, 37, 111, 112, 137], "monetarypolici": [23, 36], "mong": 95, "mongolian": 95, "moni": [111, 112], "monitor": [55, 58, 59, 60, 63, 64, 70, 71, 73, 75, 81, 82, 85, 98, 130, 134, 159, 163, 169], "monocular": 6, "monolingu": [95, 122], "monolith": [38, 93], "monopoli": [111, 112], "monster": 183, "mont": [53, 151], "montgomeri": [111, 112], "month": [31, 85, 101, 111, 112, 117, 119, 120, 121, 128, 136, 137, 152, 167], "monthli": [95, 111, 112, 119, 137, 167], "monument": [111, 112], "mood": [40, 111, 112, 140], "moon": [10, 30, 111, 112, 150], "moor": [111, 112, 178], "mor": 101, "moral": [111, 112, 171], "morbid": [111, 112], "more": [3, 5, 6, 8, 9, 10, 12, 13, 25, 30, 35, 38, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 83, 84, 85, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 108, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 173, 174, 178], "moreov": [9, 49, 59, 71, 92, 102, 111, 112, 138, 169], "morgan": [85, 111, 112], "morin": 128, "mormon": [111, 112], "morn": [24, 111, 112, 119], "morph": 141, "morphem": [0, 140, 141], "morpholog": [115, 121, 130, 141, 142], "morphologi": [6, 96, 106, 115, 129, 130, 154], "morri": [111, 112], "mortal": [111, 112, 153], "mosaicml": 59, "moscow": [111, 112], "mose": 105, "mosqu": [111, 112], "most": [5, 6, 8, 9, 11, 26, 27, 41, 42, 46, 50, 52, 53, 55, 57, 66, 69, 76, 77, 80, 83, 85, 86, 89, 90, 93, 95, 97, 99, 101, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 126, 128, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 146, 147, 149, 151, 152, 153, 154, 156, 158, 171, 175, 177], "mostafa": 0, "mostli": [111, 112], "mother": [111, 112], "motion": [0, 1, 4], "motiondiffus": 0, "motiv": [89, 111, 112, 116, 163, 171, 172], "motor": [111, 112], "motorsport": [111, 112], "mou": 20, "moun": 101, "mound": [111, 112], "moundvil": [111, 112], "mount": [60, 61, 72, 100, 111, 112, 123, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "mount_google_dr": [14, 16, 17, 19, 20, 21, 22], "mountain": [16, 100, 101, 111, 112, 174, 175, 176, 177, 179, 180, 181, 182, 185], "mountaintop": [111, 112], "mous": [6, 100], "move": [6, 9, 42, 46, 49, 53, 73, 79, 81, 88, 101, 110, 111, 112, 115, 128, 130, 136, 152, 166, 173, 179, 183], "movement": [6, 111, 112, 119, 132], "movi": [100, 110, 111, 112, 117, 122, 134, 137, 138, 149, 150], "movie_review": 135, "mowa": [111, 112], "mozumder_prov": 149, "mp": 120, "mpb": 120, "mpl": 108, "mply": 108, "mpqa": 138, "mpurver": 0, "mr": [24, 30, 95, 139], "mrpc": 51, "msc": 0, "mscoco": 122, "mse": [29, 35], "msl": [111, 112], "mt": [93, 95], "mt0": 51, "mt5": 0, "mtl": 10, "mu": [8, 101, 128, 132, 151], "much": [9, 12, 24, 46, 52, 71, 88, 93, 97, 111, 112, 113, 114, 115, 116, 126, 128, 139, 140, 145, 146, 154, 156, 173, 178], "multi": [6, 51, 52, 53, 57, 59, 61, 62, 77, 78, 79, 83, 88, 111, 112, 114, 126, 130, 136, 152, 154], "multi_label": [14, 16, 17, 19], "multidimension": 9, "multifacet": 55, "multifari": 38, "multifilesentenceiter": [103, 105], "multigen": [111, 112], "multiinst": 174, "multilay": [88, 116], "multilingu": [0, 9, 49, 95, 105, 109, 115, 121, 122, 130], "multimedia": 46, "multimod": [0, 5, 49, 85, 88, 91, 121, 122, 130], "multinomi": [128, 151, 152], "multipl": [0, 1, 6, 9, 12, 38, 39, 42, 44, 51, 52, 53, 55, 56, 59, 61, 64, 65, 66, 69, 71, 88, 91, 93, 97, 100, 105, 106, 109, 111, 112, 113, 115, 116, 117, 122, 128, 130, 134, 137, 139, 140, 141, 142, 147, 151, 153, 157, 159, 160, 161, 164, 170, 171, 172, 186], "multipli": [52, 59, 97, 116, 126, 128, 132, 133, 151], "multitask": [51, 98, 99, 117], "multitud": [111, 112], "mun": 101, "mung": 73, "municip": [111, 112], "murthi": [0, 6], "muscl": [111, 112], "muscoge": [111, 112], "musenet": 2, "museum": [111, 112], "music": [1, 4, 6, 111, 112, 149], "musician": 2, "muskoge": [111, 112], "muskogean": [111, 112], "muslim": [111, 112], "must": [1, 9, 10, 12, 38, 45, 46, 53, 77, 91, 92, 98, 111, 112, 115, 116, 130, 133, 138, 165, 169, 171, 172], "mutat": [111, 112, 115], "mute": [111, 112], "mutual": [111, 112], "mutualist": [111, 112], "mv": [81, 103], "my": [24, 30, 60, 66, 68, 85, 95, 97, 99, 101, 111, 112, 116, 120, 123, 130, 136, 144, 150, 173, 174, 177], "my_copier_templ": 69, "my_vc": 173, "mydriv": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "myfil": 181, "mygitserv": 185, "mymachin": 185, "myron": [111, 112], "myself": [150, 177], "mysteri": 3, "myth": [111, 112], "m\u00e1rmol": [111, 112], "n": [0, 1, 6, 15, 19, 24, 28, 42, 49, 51, 95, 97, 99, 100, 101, 103, 105, 106, 108, 111, 112, 114, 115, 116, 119, 120, 127, 128, 129, 131, 133, 136, 138, 139, 142, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 181], "n1": 94, "n15th": [111, 112], "n1760": [111, 112], "n1819": [111, 112], "n1910": [111, 112], "n1980\ub144\ub300": 15, "n2019": 94, "n20th": [111, 112], "n21st": [111, 112], "n4": 132, "n___________________________________________________": 135, "n_c": 119, "n_class": 127, "n_compon": 150, "n_ctx": 111, "n_d": 119, "n_e": 126, "n_embd": 111, "n_estim": [29, 35], "n_featur": 143, "n_head": 111, "n_i": [119, 126], "n_k": 119, "n_layer": 111, "n_neighbor": 28, "n_posit": 111, "n_w": 126, "n_x": 126, "na": [17, 111, 112, 152], "nabout": [111, 112], "naccord": [111, 112], "naccredit": [111, 112], "nacion": [111, 112], "naerosol": [111, 112], "nafrican": [111, 112], "nafter": [111, 112], "nagricultur": [111, 112], "naiv": [111, 112, 134, 137], "naive_seg": 145, "nalabama": [111, 112], "nalbedo": [111, 112], "naltern": [111, 112], "nalthough": [111, 112], "nam": 101, "name": [9, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 35, 51, 54, 60, 61, 64, 69, 71, 72, 76, 79, 81, 82, 95, 97, 98, 100, 103, 105, 110, 111, 112, 113, 116, 119, 122, 123, 125, 126, 128, 130, 136, 139, 141, 145, 151, 152, 154, 159, 169, 170, 176, 177, 181, 182, 185], "nameerror": 103, "namong": [111, 112], "namoo": 121, "nan": [25, 26, 27, 30, 31, 32, 34, 111, 112], "nanalysi": [111, 112], "nanarch": [111, 112], "nanarchist": [111, 112], "nanarcho": [111, 112], "nancestor": [111, 112], "nancestri": [111, 112], "nani": [111, 112], "nano": [80, 174], "nanoth": [111, 112], "nanti": [111, 112], "naquacultur": [111, 112], "narang": [0, 99], "narasimhan": 99, "narctic": [111, 112], "narea": [111, 112], "naround": [111, 112], "narr": [12, 53], "narrow": [53, 89, 97, 100, 111, 112], "narrowli": [111, 112], "narticl": [111, 112], "nasa": [111, 112, 150], "nascar": [111, 112], "nascent": 40, "nasd": [111, 112], "nasdaq": [128, 152], "nasti": 175, "nat": [31, 111, 112], "natchez": [111, 112], "nathan": [111, 112], "nation": [0, 12, 13, 93, 101, 111, 112, 120, 141, 152], "nationwid": [111, 112], "nativ": [56, 60, 62, 111, 112], "natur": [0, 1, 2, 5, 8, 9, 11, 40, 41, 44, 46, 47, 50, 52, 53, 55, 57, 59, 71, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 105, 106, 107, 110, 111, 112, 113, 116, 117, 120, 121, 122, 125, 126, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 151, 153, 154, 155, 156, 157, 158, 165, 167, 172], "naturalist": [111, 112], "naughti": 117, "nautism": [111, 112], "nautist": [111, 112], "nautomak": [111, 112], "naver": 121, "naviat": [111, 112], "navig": [6, 38, 43, 45, 50, 53, 68, 80, 81, 121, 148, 151, 178], "na\u00efv": 138, "nb": 181, "nbank": [111, 112], "nbc": [111, 112], "nbecaus": [111, 112], "nbefor": [111, 112], "nbegin": [111, 112], "nbest_siz": 105, "nbeyond": [111, 112], "nblack": [111, 112], "nbrasfield": [111, 112], "nbviewer": [29, 35, 136], "nby": [111, 112], "ncaa": [111, 112], "ncahaba": [111, 112], "ncaus": [111, 112], "ncbi": 121, "nce": 128, "ncensu": [111, 112], "ncharacterist": [111, 112], "nchildren": [111, 112], "ncitat": [111, 112], "nciti": [111, 112], "ncivil": [111, 112], "nclassic": [111, 112], "nclassif": [111, 112], "nclimat": [111, 112], "nclimatologi": [111, 112], "nclinic": [111, 112], "ncloud": [111, 112], "ncol": [23, 24, 25, 149], "ncolleg": [111, 112], "ncommun": [111, 112], "ncomput": [111, 112], "nconstruct": [111, 112], "ncontemporari": [111, 112], "ncontigu": [111, 112], "ncontinu": [111, 112], "nconvers": [111, 112], "ncounti": [111, 112], "ncryoconit": [111, 112], "ncultur": [111, 112], "nd": 145, "ndarrai": [14, 22], "ndemograph": [111, 112], "nder": 107, "nderiv": [111, 112], "ndescend": [111, 112], "ndespit": [111, 112], "ndiagnosi": [111, 112], "ndraw": [111, 112], "ndure": [111, 112], "ndustri": 107, "ne": [95, 101, 119], "neal": [111, 112], "nealanalyt": 71, "nearbi": [84, 111, 112, 128, 157], "nearest": [8, 55, 79, 119], "nearli": [111, 112, 120], "nearth": [111, 112], "neater": 183, "neccessari": 150, "necesari": 178, "necess": [50, 52, 172], "necessari": [23, 42, 46, 55, 59, 60, 61, 71, 80, 82, 89, 92, 97, 100, 104, 105, 108, 109, 110, 111, 112, 114, 116, 118, 121, 122, 123, 126, 134, 136, 137, 141, 142, 143, 146, 147, 150, 172, 186], "necessarili": [6, 10, 111, 112], "necessit": [38, 41, 46, 50, 52, 55, 57], "neck": 100, "neconom": [111, 112], "neconomi": [111, 112], "neduc": [111, 112], "need": [0, 5, 6, 8, 9, 10, 12, 25, 41, 42, 45, 46, 49, 51, 52, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 80, 81, 82, 84, 85, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 120, 121, 122, 123, 127, 128, 130, 132, 135, 136, 138, 139, 140, 141, 142, 146, 147, 150, 151, 152, 154, 155, 157, 159, 160, 163, 164, 165, 167, 168, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185], "neg": [9, 14, 16, 19, 20, 21, 22, 30, 77, 84, 90, 93, 98, 100, 105, 107, 110, 111, 112, 113, 114, 117, 119, 120, 127, 130, 132, 134, 135, 136, 137, 138, 147, 149, 155, 157], "negat": [12, 134], "negoti": 171, "nei": [95, 133], "neighbor": [55, 127, 128, 138], "neill": [111, 112], "neither": 53, "nelect": [111, 112], "nelectromagnet": [111, 112], "nelectron": [111, 112], "nemploy": [111, 112], "nenceladu": [111, 112], "nenglish": [111, 112], "neo": [111, 112], "neolog": [111, 112, 141], "nepali": 95, "nepidemiologi": [111, 112], "ner": [122, 125], "nerdyrod": 9, "nerv": [111, 112], "nervou": [111, 112], "ness": 145, "nest": [88, 126, 145], "nestor": [111, 112], "net": [0, 9, 10, 97, 101, 111, 112, 152], "network": [0, 5, 8, 9, 11, 14, 16, 22, 38, 41, 48, 49, 50, 52, 54, 55, 57, 61, 65, 73, 76, 77, 78, 81, 82, 86, 87, 88, 91, 93, 97, 98, 100, 102, 105, 111, 112, 113, 114, 116, 117, 118, 127, 128, 130, 134, 139, 144, 152, 154, 160, 178], "netymologi": [111, 112], "netzer": [0, 120], "neural": [0, 1, 5, 8, 10, 14, 22, 41, 48, 49, 50, 54, 73, 86, 87, 88, 89, 91, 93, 97, 98, 99, 100, 102, 103, 105, 111, 112, 113, 114, 116, 118, 128, 129, 131, 134, 139, 144, 154], "neurip": [89, 99], "neurodevelop": [111, 112], "neurodevelopment": [111, 112], "neurodivers": [111, 112], "neurogenet": [111, 112], "neuroimag": [111, 112], "neuroinflamm": [111, 112], "neurolog": [111, 112], "neurologi": [111, 112], "neuromorph": 50, "neuron": [88, 113, 114, 128, 130], "neuron_model": 114, "neuron_token": 114, "neuron_view": 114, "neuropean": [111, 112], "neuropsycholog": [111, 112], "neuropsychologist": [111, 112], "neurosci": [0, 6], "neuroscientist": [6, 111, 112], "neurotyp": [111, 112], "neuter": 140, "neutr": 101, "neutral": [14, 16, 19, 20, 21, 22, 30, 98, 101, 110, 111, 112, 117, 134, 136, 137], "never": [9, 88, 100, 111, 112, 130, 132, 133, 136, 139, 147, 150, 174], "nevertheless": 132, "nevolutionari": [111, 112], "new": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 16, 17, 22, 38, 41, 42, 45, 46, 49, 50, 51, 52, 53, 55, 56, 59, 60, 61, 64, 66, 71, 76, 77, 78, 80, 82, 83, 84, 88, 89, 90, 92, 93, 94, 95, 97, 98, 100, 101, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 126, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144, 146, 147, 148, 150, 151, 152, 154, 159, 163, 169, 172, 173, 174, 180, 182, 183, 184, 185], "new_token": 108, "new_topic_dataset": 16, "new_usernam": 81, "newborn": 139, "newer": [90, 111, 112], "newest": 135, "newli": [14, 16, 17, 22, 78, 110, 111, 112, 178, 185], "newlin": [112, 124], "newman": 152, "news_data_dir": 14, "news_sent": 133, "news_slic": [14, 21], "newsgroup": 150, "newsgroups_test": 150, "newsgroups_train": 150, "newspap": [111, 112, 119, 121], "nex": 101, "nexampl": [111, 112], "nexposur": [111, 112], "next": [1, 5, 8, 9, 10, 24, 30, 36, 37, 42, 52, 56, 60, 62, 76, 78, 86, 92, 97, 99, 101, 104, 106, 107, 108, 109, 110, 111, 112, 113, 117, 123, 128, 130, 132, 135, 136, 143, 144, 149, 150, 151, 153, 156, 158, 171, 172, 176, 177], "next_decis": [24, 25, 26, 27, 30], "next_meet": [24, 30], "next_rat": [24, 30], "next_start": [107, 108], "next_word": 133, "next_word_candid": 133, "next_word_prob": 133, "nextern": [111, 112], "nfar": [111, 112], "nfc": 104, "nfd": 104, "nfeder": [111, 112], "nfew": [111, 112], "nfinal": [111, 112], "nfkc": [104, 105], "nfkd": 104, "nfl": 151, "nflora": [111, 112], "nfollow": [111, 112], "nfootnot": [111, 112], "nfor": [111, 112], "nfriedrich": [111, 112], "nfrom": [111, 112], "nft": 3, "nfurther": [111, 112], "ng": [101, 107, 132, 152], "ngastrointestin": [111, 112], "ngc": [132, 135, 136, 141, 150], "ngender": [111, 112], "ngener": [111, 112], "ngeographi": [111, 112], "nginx": [60, 64, 159], "nginx_instal": [64, 159], "nglobal": [111, 112], "ngr": 107, "ngra": 107, "ngrad": 107, "ngrade": 107, "ngram": [30, 132, 133, 143], "ngrams_count": 132, "ngt": 107, "nh": [111, 112], "nhealth": [111, 112], "nhealthcar": [111, 112], "nhistori": [111, 112], "nhttp": 94, "nhuman": [111, 112], "ni": [24, 101], "nice": [97, 136, 175, 184], "nich": 59, "nichol": 10, "nichola": 0, "nicknam": [111, 112], "nielsen": [0, 135], "night": [3, 5, 16, 130, 136], "nightcaf": [5, 130], "nightmareai": [5, 130], "nihil": [111, 112], "niki": 0, "nikkei": 152, "nillumin": [111, 112], "nimmigr": [111, 112], "nin": [111, 112], "nincept": [111, 112], "nindigen": [111, 112], "nindividualist": [111, 112], "nindustri": [111, 112], "nine": [9, 85, 111, 112, 122, 140], "nineteen": [111, 112], "nineteenth": [111, 112], "ning": 107, "ninja": [111, 112], "ninsol": [111, 112], "ninth": [111, 112], "nippon": [111, 112], "niso": [111, 112], "nissan": 152, "nit": [111, 112], "nital": [111, 112], "nix": 69, "nj": 129, "njew": [111, 112], "njust": [111, 112], "nkanner": [111, 112], "nkb\uc99d\uad8c\uc774": 19, "nke": 107, "nkei": [111, 112], "nl": [95, 130], "nland": [111, 112], "nlanguag": [111, 112], "nlargest": [111, 112], "nlate": [111, 112], "nlaw": [111, 112], "nleft": [111, 112], "nlegal": [111, 112], "nlegion": [111, 112], "nlg": [91, 93], "nlh19": 0, "nlibertarian": [111, 112], "nliteratur": [111, 112], "nlocal": [111, 112], "nlp": [1, 10, 11, 36, 41, 49, 52, 53, 86, 91, 98, 102, 104, 105, 106, 107, 109, 110, 112, 113, 115, 116, 125, 126, 132, 133, 134, 135, 139, 141, 143, 144, 146, 153, 154, 155, 156, 157, 158, 165], "nlp_deep": 96, "nlte": 17, "nltk": [12, 129, 133, 135, 136, 139, 141, 142, 143, 144, 149, 150, 152, 155], "nltk_data": [132, 133, 135, 142, 150, 155], "nlu": [57, 91], "nm": 88, "nmajor": [111, 112], "nmale": [111, 112], "nmanag": [111, 112], "nmani": [111, 112], "nmatern": [111, 112], "nmechan": [111, 112], "nmedia": [111, 112], "nmedic": [111, 112], "nmember": [111, 112], "nmf": 138, "nmi_dat": 23, "nmi_diff_year": 23, "nmobil": [111, 112], "nmodern": [111, 112], "nmost": [111, 112], "nmt_nfkc": [103, 105], "nmuslim": [111, 112], "nmutual": [111, 112], "nn": [53, 55, 127, 128, 130, 144], "nneurolog": [111, 112], "nng": [141, 142], "nnlm": 127, "nno": [111, 112], "nnon": [111, 112], "nnotabl": [111, 112], "nnote": [111, 112], "nnp": 144, "no_deprecation_warn": [110, 112], "no_repeat_ngram_s": 97, "noah": 0, "noam": 0, "nobject": [111, 112], "noccalula": [111, 112], "nocturn": [111, 112], "node": [38, 53, 57, 60, 62, 88, 113, 128, 130], "node_num": 103, "nodej": 69, "nof": [111, 112], "nofollow": 121, "nois": [6, 9, 10, 12, 45, 55, 88, 93, 109, 111, 112, 138, 146, 147, 148, 150], "noisi": [93, 115, 117, 145, 148], "noisier": 9, "nokai": 24, "nom": 107, "nomin": [130, 140], "nomo": [111, 112], "non": [10, 12, 14, 15, 21, 39, 52, 83, 88, 111, 112, 116, 117, 119, 120, 121, 127, 130, 133, 138, 143, 148, 152, 166, 167, 177, 178, 183], "noncommerci": 83, "nonconsci": 97, "none": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 100, 107, 108, 110, 111, 112, 132, 135, 150, 152], "nonetheless": [111, 112], "nonli": [111, 112], "nonlinear": [6, 40, 128], "nonsens": 49, "nonverb": [111, 112], "nonviol": [111, 112], "nope": 150, "noplugin": 174, "noptic": [111, 112], "nor": [53, 101, 107, 111, 112, 139], "norigin": [111, 112], "norm": [9, 111, 112], "normal": [9, 10, 52, 55, 88, 89, 103, 105, 111, 112, 113, 116, 117, 119, 121, 126, 127, 132, 133, 137, 142, 145, 146, 151, 178], "normalis": 128, "normalization_rule_tsv": [103, 105], "normalize_str": 104, "normalizer_spec": [103, 105], "north": [111, 112], "northeast": [111, 112], "northeastern": [111, 112], "northern": [17, 111, 112], "northernmost": [111, 112], "northport": [111, 112], "northwest": [111, 112], "norwegian": 95, "nosess": 174, "notabl": [6, 7, 11, 12, 42, 59, 71, 86, 101, 111, 112, 116, 130, 156], "notat": [111, 112, 180], "notch": 136, "note": [14, 51, 68, 76, 77, 79, 89, 97, 105, 111, 112, 126, 128, 130, 132, 133, 135, 136, 141, 149, 150, 155, 156, 165, 169, 173, 174, 175, 176, 177, 178, 180, 183, 185], "notebook": [15, 17, 21, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 42, 51, 97, 112, 136, 152, 173, 177], "notebook_tqdm": [100, 101, 103, 108, 110, 111, 112, 114, 136], "notepad": 174, "notetak": [111, 112], "noteworthi": [38, 42, 59], "noth": [150, 173, 176, 178], "nother": [111, 112], "notic": [50, 111, 112, 150, 174, 175, 176, 178], "notif": 178, "notifi": 178, "notion": [1, 2, 59, 111, 112, 116], "noun": [111, 112, 119, 130, 135, 139, 140, 141, 143, 144, 145], "nov": 184, "novel": [2, 5, 6, 7, 52, 84, 89, 111, 112, 113, 139], "novelti": [55, 139], "novemb": [111, 112], "noveral": [111, 112], "novikov": 0, "now": [0, 5, 8, 12, 13, 14, 15, 20, 22, 24, 28, 30, 41, 46, 51, 52, 60, 67, 71, 72, 76, 81, 92, 94, 97, 100, 101, 103, 104, 108, 110, 111, 112, 114, 116, 123, 127, 132, 135, 136, 139, 142, 144, 152, 154, 158, 173, 174, 175, 176, 177, 178, 181, 182, 183, 185], "nowcast": [37, 40], "noxiou": [111, 112], "np": [23, 31, 34, 110, 128, 130, 132, 140, 144, 149, 150, 152, 181], "nparent": [111, 112], "nper": 152, "npervas": [111, 112], "nphilosoph": [111, 112], "nphilosophi": [111, 112], "nphonet": [111, 112], "npm": 69, "npmi": [147, 152], "npolit": [111, 112], "nport": [111, 112], "npost": [111, 112], "npp": [111, 112], "npre": [111, 112], "nprevent": [111, 112], "nprimari": [111, 112], "nprofession": [111, 112], "nprognosi": [111, 112], "nproperti": [111, 112], "npublic": [111, 112], "nra": 120, "nradar": [111, 112], "nradiat": [111, 112], "nradiometri": [111, 112], "nrail": [111, 112], "nreconstruct": [111, 112], "nrefer": [111, 112], "nregion": [111, 112], "nrelat": [111, 112], "nrelationship": [111, 112], "nreligion": [111, 112], "nrepetit": [111, 112], "nresearch": [111, 112], "nresult": [111, 112], "nrevolutionari": [111, 112], "nroad": [111, 112], "nrow": [23, 24, 25, 149], "nscatter": [111, 112], "nscreen": [111, 112], "nsecondari": [111, 112], "nsee": [111, 112], "nsever": [111, 112], "nsexual": [111, 112], "nsign": [111, 112], "nsmall": [111, 112], "nsnow": [111, 112], "nsocial": [111, 112], "nsocieti": [111, 112], "nsolar": [111, 112], "nsome": [111, 112], "nsourc": [111, 112], "nsouth": [111, 112], "nsoutheastern": [111, 112], "nsouthern": [111, 112], "nsp": 113, "nspecif": [111, 112], "nspectrum": [111, 112], "nsport": [111, 112], "nstate": [111, 112], "nsteel": [111, 112], "nstudi": [111, 112], "nsubj": 130, "nsummer": [111, 112], "nsurfac": [111, 112], "ntactic": [111, 112], "ntangibl": 108, "ntax": [111, 112], "ntelecommun": [111, 112], "nterminologi": [111, 112], "nterna": 107, "nternat": 107, "nterrestri": [111, 112], "ntertiari": [111, 112], "ntext": 104, "ntf": 158, "nth": [107, 147], "nthank": 24, "nthe": [111, 112], "nthere": [111, 112], "nthi": [24, 111, 112], "nthoma": [111, 112], "nthose": [111, 112], "nthought": [111, 112], "nthree": [111, 112], "ntourism": [111, 112], "ntransport": [111, 112], "ntree": [111, 112], "ntrigram": 132, "ntwo": [111, 112], "ntypograph": [111, 112], "nu": [111, 112], "nuab": [111, 112], "nuanc": [1, 12, 45, 46, 49, 52, 53, 57, 59, 91, 93, 98, 106, 109, 130, 131, 137, 139], "nuclear": [111, 112], "nuclei": [111, 112], "nucleu": [111, 112], "nucor": [111, 112], "nudism": [111, 112], "nueural": 127, "null": [10, 14, 15, 21, 126, 181], "nullifi": 59, "num": [20, 150, 152], "num_attention_head": 112, "num_beam": 97, "num_byt": [17, 22, 28], "num_bytes_count": 17, "num_bytes_max": 22, "num_bytes_median": 22, "num_bytes_min": 22, "num_bytes_sum": 17, "num_class_imag": 51, "num_cod": [14, 15, 19, 21], "num_column": 17, "num_epoch": 45, "num_exampl": [17, 22, 28, 30], "num_examples_stat": 32, "num_hidden": 127, "num_hidden_lay": 112, "num_label": 110, "num_leav": [29, 35], "num_machin": 51, "num_merg": 101, "num_proc": 112, "num_process": 51, "num_return_sequ": [97, 100], "num_row": [14, 94], "num_step": 127, "num_sub_iter": [103, 105], "num_thread": [103, 105], "num_token": [30, 103, 105], "num_tokens_mean": 30, "num_tokens_mean_beigebook": [30, 31, 32], "num_tokens_mean_meeting_script": [30, 31, 32], "num_tokens_mean_minut": [30, 31, 32], "num_tokens_mean_press_conf": [30, 31, 32], "num_tokens_mean_speech": [30, 31, 32], "num_tokens_mean_stat": [30, 31, 32], "num_tokens_mean_testimoni": [30, 31, 32], "num_tokens_median": 30, "num_tokens_sum": 30, "num_tokens_sum_speech": [30, 31, 32], "num_tokens_sum_stat": [30, 31, 32], "num_tokens_sum_testimoni": [30, 31, 32], "num_top": 150, "num_top_word": 150, "num_train_epoch": [14, 16, 17, 19, 22, 30, 110, 111, 112], "num_word": [24, 152], "num_work": [15, 16, 17, 19, 21, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 152], "number": [6, 8, 9, 10, 14, 20, 21, 32, 42, 50, 52, 59, 77, 81, 86, 88, 93, 94, 97, 98, 100, 101, 102, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 124, 126, 127, 128, 130, 132, 133, 136, 137, 138, 139, 140, 142, 143, 145, 147, 148, 151, 152, 154, 155, 157, 158, 171, 176, 178], "numel": 112, "numer": [1, 5, 8, 10, 36, 37, 46, 52, 53, 54, 55, 59, 64, 65, 88, 93, 98, 102, 105, 111, 112, 115, 116, 132, 134, 136, 138, 139, 157, 159, 160], "numexpr": 14, "numexpr_max_thread": 14, "numpi": [14, 22, 23, 31, 34, 110, 128, 132, 136, 141, 149, 150, 152, 178, 181], "numpydoc": 178, "nuniqu": 15, "nunless": [111, 112], "nuntil": [111, 112], "nunusu": [111, 112], "nurseri": [111, 112], "nuse": [111, 112], "nut": 100, "nutrit": [111, 112], "nutshel": [105, 126], "nvda": 42, "nvidia": [2, 6, 14, 59, 93, 112, 132, 135, 136, 141, 150], "nvme1n1p2": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "nvowel": [111, 112], "nwater": [111, 112], "nwell": [111, 112], "nwhat": [111, 112], "nwhen": [111, 112], "nwhere": [111, 112], "nwhile": [111, 112], "nwhite": [111, 112], "nwikipedia": [111, 112], "nwinter": [111, 112], "nwith": [111, 112], "ny": 95, "nyanja": 95, "nyc": 136, "nyse": 152, "nyu": 136, "n\u00aa": [111, 112], "n\u00e5": [111, 112], "n\u00e6": [111, 112], "n\u0250": [111, 112], "n\u0251": [111, 112], "n\u0252": [111, 112], "n\u03b1": [111, 112], "n\u03bb": [111, 112], "n\u0430": [111, 112], "n\u0561": [111, 112], "n\u1d00": [111, 112], "n\u1d90": [111, 112], "n\u1d9b": [111, 112], "n\u6545": 19, "n\ua7bb": [111, 112], "n\uab31": [111, 112], "n\uac00\uc18d\ud558\ub294": 16, "n\uac01": 16, "n\uac1c\ubc1c\uc790": 16, "n\uacb0\uad6d": 19, "n\uace0\uc2b9\ubc94": 15, "n\uad6c\uccb4\uc801": 16, "n\uad6d\ub0b4": 17, "n\uae40\uc6a9\uad6c": 19, "n\ub124\ud2b8\uc6cc\ud06c": 16, "n\ub2e4\ub9cc": 17, "n\uba3c\uc800": 19, "n\ubc30\ud130\ub9ac": 16, "n\ube14\ub85d": 16, "n\uc0ac\uc6a9\uc790": 16, "n\uc0b0\uc5c5\ud1b5\uc0c1\uc790\uc6d0\ubd80\ub294": 15, "n\uc2e0\uc9c0\uc724": 19, "n\uc2e0\ud55c\uc740\ud589": 14, "n\uc5c5\uccb4": 17, "n\uc640\uc774\ube0c\ub85c": 17, "n\uc6b0\ud06c\ub77c\uc774\ub098\uc640": [15, 19], "n\uc720\uc8fc": 14, "n\uc774\ub7ec\ud55c": 17, "n\uc774\uc6c5\uc5f4": 15, "n\uc778\uacf5\uc9c0\ub2a5": 17, "n\uc815\ubcf4\ud1b5\uc2e0": 15, "n\uc99d\uad8c": 16, "n\ucd5c\uadfc": 16, "n\ucf54\uc624\ub871": 15, "n\ud68c\uc0ac\ucc44": [15, 19], "n\ud800\udf00": [111, 112], "n\ud802\udd00": [111, 112], "o": [17, 60, 75, 76, 79, 101, 102, 105, 106, 108, 111, 112, 116, 117, 119, 123, 128, 145, 146, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "oai_config_list": 42, "oauth": [77, 78], "obedi": [111, 112], "obei": [111, 112, 130], "obes": [111, 112], "obj": [103, 105], "object": [5, 6, 9, 10, 14, 15, 21, 22, 23, 28, 46, 50, 54, 59, 63, 65, 88, 89, 92, 95, 100, 102, 104, 109, 110, 111, 112, 113, 115, 116, 122, 125, 126, 130, 140, 144, 150, 151, 160, 165, 168, 169], "oblig": [111, 112], "obscen": 117, "observ": [6, 8, 10, 25, 51, 52, 64, 65, 84, 88, 90, 94, 100, 105, 111, 112, 115, 120, 132, 133, 139, 147, 151, 159, 160], "obsess": [111, 112], "obsolet": [111, 112], "obstacl": [6, 77, 111, 112], "obtain": [6, 8, 9, 10, 23, 49, 52, 53, 93, 97, 98, 100, 111, 112, 113, 116, 121, 123, 125, 130, 132, 147, 148, 154], "oc": [101, 111, 112], "occasion": [50, 111, 112], "occup": [111, 112], "occupi": [59, 90, 111, 112], "occur": [9, 38, 50, 52, 53, 57, 97, 98, 106, 108, 111, 112, 117, 119, 120, 125, 128, 130, 132, 133, 137, 138, 139, 142, 143, 145, 147, 155, 156, 157, 166, 172], "occurr": [43, 111, 112, 114, 119, 132, 133, 147, 148, 151, 153, 154, 157], "ocean": [111, 112], "oci": [60, 62], "ocr": 145, "oct": [128, 133], "octob": [0, 111, 112, 128], "oculist": 156, "od": 0, "odd": [111, 112], "odu": 107, "oduc": 107, "off": [10, 42, 45, 50, 88, 92, 101, 111, 112, 115, 133, 136, 150, 152, 164], "offens": [49, 98], "offer": [6, 8, 9, 12, 13, 37, 38, 39, 40, 41, 42, 45, 49, 50, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 69, 74, 76, 77, 93, 97, 109, 111, 112, 116, 121, 123, 126, 130, 136, 138, 142, 144, 147, 148, 151, 156, 159, 160, 161, 164, 169, 171, 172, 177, 178], "offic": [93, 111, 112, 136], "offici": [42, 61, 82, 111, 112, 121, 152, 178], "offlin": 105, "offload": 51, "offload_optimizer_devic": 51, "offload_param_devic": 51, "offset": [23, 31, 111, 112, 128], "often": [2, 6, 8, 12, 13, 38, 40, 41, 42, 46, 49, 50, 54, 55, 56, 57, 59, 63, 65, 66, 71, 77, 80, 88, 89, 90, 91, 93, 97, 98, 100, 104, 105, 106, 108, 109, 111, 112, 114, 115, 117, 121, 122, 126, 130, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 160, 164, 166, 169, 171, 172, 181], "oh": 66, "ohio": [111, 112], "oil": [101, 111, 112, 152], "oint": 107, "ok": [175, 176, 184], "okai": 24, "okenizer_config": [100, 114], "oklahoma": [111, 112], "ol": 101, "old": [3, 101, 107, 111, 112, 117], "older": [111, 112, 173, 180, 185], "oldest": [111, 112], "olv": 100, "olymp": [108, 130], "olympi": 108, "olympiad": 85, "omega_": 126, "omit": 81, "omment": 107, "omnibu": [111, 112], "omw": 150, "onc": [5, 6, 8, 49, 67, 68, 72, 73, 76, 82, 88, 89, 97, 105, 108, 110, 111, 112, 116, 117, 121, 125, 127, 130, 144, 166, 169, 172, 178, 180], "one": [1, 2, 5, 6, 7, 8, 9, 10, 25, 41, 46, 50, 51, 60, 64, 69, 71, 72, 77, 78, 79, 83, 88, 89, 95, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 126, 127, 128, 130, 131, 132, 133, 134, 136, 139, 140, 142, 144, 145, 147, 148, 150, 152, 154, 155, 156, 158, 159, 163, 166, 167, 171, 172, 174, 175, 176, 177, 178, 180, 181, 183, 184, 185], "one_al": 152, "one_on": 152, "one_pr": 152, "one_set": 152, "one_suc": 152, "oneapi": [14, 22], "onednn": [14, 22], "onelin": [174, 176, 177, 179, 180, 181, 183, 185], "ones": [10, 12, 59, 61, 64, 69, 98, 111, 112, 120, 123, 126, 127, 148, 159, 183], "oneself": [111, 112, 130], "ong": 101, "ongo": [49, 50, 59, 63, 72, 77, 91, 98, 111, 112, 116, 130, 144, 164, 169, 172], "onli": [1, 6, 8, 9, 10, 11, 14, 23, 40, 46, 50, 51, 52, 55, 59, 61, 64, 68, 71, 72, 76, 77, 81, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 105, 111, 112, 114, 115, 116, 117, 119, 122, 125, 128, 129, 130, 132, 133, 136, 143, 148, 150, 151, 152, 153, 158, 159, 163, 171, 172, 174, 176, 178, 181, 183, 185], "onlin": [12, 37, 53, 71, 73, 82, 83, 111, 112, 120, 121, 134], "ons": [80, 101], "onset": [111, 112], "ontanon": 99, "onto": [5, 6, 111, 112, 126, 136, 148, 176, 180, 183], "ontologi": [38, 156], "onu": 38, "onward": [53, 111, 112], "on\u00ed": [111, 112], "oo": 101, "oom": 51, "oov": [102, 103, 106, 133], "op": [65, 71, 101, 107, 114, 160], "opac": 52, "opaqu": [12, 52], "open": [2, 5, 6, 8, 11, 14, 49, 52, 53, 59, 60, 62, 63, 64, 65, 67, 68, 69, 71, 73, 76, 77, 78, 80, 83, 88, 89, 91, 97, 100, 101, 103, 111, 112, 120, 121, 123, 124, 128, 130, 133, 134, 136, 139, 152, 156, 159, 160, 169, 171, 176, 178, 184], "open_clip": 9, "openai": [2, 5, 8, 9, 42, 46, 53, 59, 83, 85, 86, 93, 97, 98, 99, 100, 121, 122], "openid": [77, 78], "openli": [6, 77], "openpgp": 76, "openreview": 0, "openshift": [65, 160], "openwebtext2": 45, "oper": [6, 8, 10, 12, 14, 22, 38, 42, 44, 45, 49, 52, 53, 55, 56, 57, 59, 63, 64, 65, 71, 73, 74, 81, 82, 88, 100, 105, 106, 108, 111, 112, 113, 115, 116, 126, 150, 151, 152, 155, 159, 160, 163, 164, 165, 166, 171, 172, 179], "opera": 75, "operation": 58, "operatornam": [97, 106], "ophnfb": 34, "opim": 128, "opinion": [12, 64, 92, 93, 98, 111, 112, 119, 130, 134, 159], "oppo": 145, "oppon": [111, 112], "opportun": [12, 13, 37, 53, 55, 59, 72, 101, 107, 108, 111, 112, 130, 134, 145], "oppos": [42, 52, 111, 112, 116, 156, 172], "opposit": [9, 111, 112, 114, 120, 134, 137, 147, 154, 157], "oppress": [111, 112], "opt": [28, 30, 46, 51, 81], "optic": [8, 111, 112], "optiguid": 42, "optim": [6, 7, 11, 12, 14, 22, 41, 42, 45, 49, 50, 51, 52, 53, 54, 59, 64, 65, 74, 75, 77, 85, 88, 92, 97, 98, 99, 100, 105, 106, 109, 110, 112, 116, 132, 138, 147, 150, 151, 152, 159, 160, 161, 163, 166, 172], "optima": 54, "optimist": 128, "option": [5, 6, 8, 9, 10, 42, 45, 46, 59, 60, 62, 64, 69, 73, 75, 76, 79, 81, 93, 97, 111, 112, 114, 117, 126, 128, 136, 152, 155, 159], "optometri": [111, 112], "or5": [111, 112], "oral": [87, 163], "orang": [111, 112, 113, 114, 127], "orati": 107, "oratio": 107, "orb": [111, 112], "orbit": 150, "orchestr": [42, 44, 56, 60, 61, 62, 64, 71, 75, 80, 159], "order": [10, 51, 97, 99, 101, 111, 112, 115, 116, 117, 122, 124, 128, 130, 132, 133, 136, 138, 140, 150, 151, 152, 153, 154, 166], "ordereddict": [15, 20, 24, 28, 30], "ordin": [111, 112], "ordinari": [111, 112, 145], "org": [0, 8, 9, 29, 35, 45, 53, 69, 70, 79, 111, 112, 119, 132, 135, 136, 141, 150, 152], "organ": [38, 46, 49, 50, 52, 59, 63, 65, 66, 68, 70, 71, 74, 77, 81, 85, 93, 98, 109, 111, 112, 117, 120, 121, 122, 130, 134, 137, 145, 148, 150, 152, 160, 166, 167, 171, 172], "organis": [111, 112, 177], "orgin": 145, "orient": [6, 32, 42, 62, 111, 112, 130, 150], "origin": [2, 7, 8, 9, 10, 20, 36, 46, 49, 50, 51, 52, 54, 57, 59, 62, 67, 68, 71, 77, 78, 79, 83, 84, 89, 93, 95, 97, 98, 99, 100, 104, 105, 106, 110, 111, 112, 115, 116, 117, 120, 123, 124, 126, 139, 148, 150, 151, 156, 172, 176, 177, 178, 180, 181, 182, 184, 185], "original_label": 17, "orlean": [111, 112], "orm": 53, "orp": 107, "orpor": 107, "orporati": 107, "orporatio": 107, "ors": 101, "ort": 180, "orthodox": [111, 112], "orthogon": [9, 117, 147, 148, 150, 157], "orthographi": [111, 112], "oser": 107, "osni": [111, 112], "oss": 105, "osteopath": [111, 112], "other": [0, 5, 6, 8, 9, 10, 12, 14, 16, 17, 20, 22, 25, 42, 44, 45, 50, 51, 52, 54, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 74, 76, 77, 80, 83, 86, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 126, 128, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 156, 158, 159, 160, 164, 166, 170, 171, 172, 173, 174, 176, 177, 178, 180, 183, 185], "otherwis": [2, 107, 108, 111, 112, 117, 118, 126, 152, 166], "ou": 101, "ought": [51, 111, 112], "ould": 101, "oun": 101, "ound": 101, "ouput": 115, "ouputperform": 125, "our": [1, 2, 10, 24, 46, 72, 77, 89, 91, 97, 101, 103, 104, 106, 107, 108, 110, 111, 112, 115, 116, 120, 130, 136, 139, 142, 143, 144, 147, 150, 153, 154, 155, 158, 166, 167, 173, 175, 176, 178, 181, 183], "ourc": 107, "ourselv": [150, 181], "out": [10, 12, 46, 51, 59, 62, 69, 73, 77, 80, 95, 97, 100, 101, 102, 103, 104, 106, 109, 110, 111, 112, 114, 115, 117, 119, 120, 124, 126, 128, 130, 133, 136, 139, 142, 144, 145, 146, 155, 156, 166, 174, 177, 181, 183, 184], "out_proj": [14, 16, 17, 22], "out_typ": 105, "outag": [55, 65, 160], "outbreak": [111, 112], "outcom": [2, 12, 42, 44, 46, 53, 71, 97, 111, 112, 126, 130, 132, 146, 166, 167, 170, 172], "outdat": [93, 111, 112], "outer": [111, 112], "outflow": 119, "outl": 107, "outlaw": [111, 112], "outlier": [12, 89, 148], "outlin": [46, 56, 67, 89, 98, 111, 112, 155, 167, 169, 170], "outlo": 107, "outloo": 107, "outlook": [101, 152], "outokumpu": [111, 112], "outpac": 93, "outperform": [6, 9, 10, 84, 85, 113, 115, 117, 120, 130, 152], "output": [4, 5, 6, 8, 9, 10, 14, 16, 17, 20, 21, 22, 24, 30, 40, 42, 43, 46, 49, 51, 52, 53, 55, 57, 58, 59, 60, 71, 72, 74, 76, 83, 86, 88, 93, 97, 98, 99, 100, 102, 105, 106, 110, 111, 112, 113, 114, 115, 116, 119, 121, 124, 126, 127, 130, 138, 139, 141, 142, 143, 144, 148, 150, 172, 173, 174, 180, 181], "output_attent": 114, "output_dir": [15, 16, 17, 19, 21, 23, 24, 30, 31, 51, 110, 111, 112], "output_fil": [15, 16, 17, 19, 21, 24, 30, 76, 124], "output_lay": 128, "outset": 171, "outshin": 42, "outsid": [5, 42, 111, 112], "outweigh": [111, 112], "over": [6, 8, 9, 10, 11, 40, 42, 46, 47, 49, 52, 55, 59, 71, 72, 74, 76, 77, 78, 85, 88, 91, 95, 97, 98, 99, 101, 105, 106, 111, 112, 115, 117, 118, 120, 122, 126, 127, 128, 130, 136, 138, 142, 144, 146, 147, 148, 150, 151, 152, 155, 158, 163, 171, 172, 178, 185], "overal": [7, 9, 36, 50, 52, 63, 71, 88, 89, 91, 93, 95, 97, 111, 112, 116, 117, 119, 120, 130, 131, 134, 135, 137, 144, 147, 150, 167, 171], "overarch": 130, "overcom": [42, 54, 55, 57, 59, 71, 77, 93, 97, 116, 130, 134, 151], "overestim": [111, 112, 143], "overfit": [45, 51, 52, 97, 110, 117, 138, 151], "overgener": 55, "overhaul": [50, 163], "overhead": [46, 52, 60, 88, 172], "overlap": [20, 88, 111, 112, 116, 130, 171], "overli": [50, 89, 111, 112], "overload": [111, 112, 121], "overlook": [111, 112, 115, 147], "overnight": 142, "overpopul": 55, "overreli": 55, "overrid": [15, 16, 17, 19, 21, 24, 30, 111, 112], "overrun": 164, "oversampl": 95, "overse": [111, 112], "overseen": [111, 112], "oversight": [12, 59, 111, 112], "oversimplifi": 105, "overt": [111, 112], "overthrow": [111, 112], "overturn": [111, 112], "overview": [6, 9, 12, 37, 56, 59, 65, 71, 73, 77, 84, 89, 97, 110, 130, 160, 165, 167], "overwhelmingli": [53, 111, 112], "overwrit": [111, 174, 175, 176, 177, 180, 181, 182], "overwrite_output_dir": [111, 112], "ovi": 107, "ow": [111, 112], "owasp": 169, "owen": [111, 112, 130], "owl": 41, "own": [4, 6, 8, 9, 38, 42, 45, 49, 59, 68, 69, 71, 88, 89, 92, 96, 97, 102, 103, 111, 112, 116, 119, 124, 129, 130, 134, 136, 141, 144, 148, 150, 152, 166, 172, 176, 177, 178, 183], "owner": [67, 68, 111, 112, 121, 171], "ownership": [77, 111, 112, 130], "owng": 107, "owngr": 107, "owngra": 107, "owngrad": 107, "ox": [111, 112], "ozark": [111, 112], "p": [8, 51, 52, 60, 61, 79, 80, 81, 84, 95, 99, 101, 102, 105, 106, 108, 111, 112, 116, 119, 128, 129, 132, 133, 137, 142, 143, 145, 147, 152, 155, 157, 181, 183, 185], "p06": 0, "p16": 0, "p4g": 20, "p7or7r6x": 16, "p7or7r6xsync": 16, "p8": 112, "p_": [84, 128, 147], "p_1": 132, "p_2": 132, "p_3": 132, "p_4": 132, "p_c": 155, "p_tune": 52, "p_w": 155, "p_wc": 155, "pa": [95, 101, 152], "pablo": 0, "pac": 101, "pace": [111, 112], "pachinko": 152, "pachyderm": 71, "pacifist": [111, 112], "pack": [73, 176], "packag": [6, 23, 24, 28, 30, 42, 45, 60, 61, 62, 64, 65, 69, 71, 72, 73, 80, 81, 94, 100, 101, 103, 108, 110, 111, 112, 114, 121, 132, 133, 135, 136, 141, 142, 146, 150, 152, 155, 159, 160, 169], "pad": [30, 88, 97, 100, 103, 104, 105, 108, 110, 111, 112, 115, 126], "pad_id": [103, 105], "pad_left": 132, "pad_piec": [103, 105], "pad_right": 132, "pad_token": [111, 112], "pad_token_id": [97, 100, 111, 112], "padding_idx": 110, "paddl": [111, 112], "padlock": 82, "page": [0, 6, 23, 29, 35, 43, 60, 67, 93, 95, 96, 117, 119, 122, 123, 130, 136, 144, 176, 177, 178, 181, 185], "pai": [89, 92, 101, 111, 112, 113, 116, 120, 136, 152, 181], "paid": [5, 111, 112, 130], "paideia": [111, 112], "paint": [5, 9, 100], "painter": [2, 5, 111, 112], "pair": [5, 6, 8, 9, 10, 11, 46, 53, 76, 80, 88, 98, 101, 105, 111, 112, 116, 119, 122, 130, 132, 133, 138, 143, 146, 147, 148, 155, 171, 177, 182], "pair_freq": 108, "pair_scor": 108, "pairwis": 9, "paka": 59, "palat": 46, "pale": [111, 112], "palett": [2, 26, 32], "palm": [93, 98], "palmer": [111, 112], "pamodel": 152, "pan": [0, 6, 101], "panda": [12, 14, 15, 21, 23, 73, 94, 123, 136, 141, 149], "panel": [111, 112, 119], "panorama": 8, "paper": [0, 5, 6, 8, 9, 10, 46, 47, 49, 51, 52, 84, 87, 88, 89, 93, 96, 111, 112, 113, 115, 116, 119, 120, 124, 129, 137, 138, 148, 152, 154], "paper1": 51, "paper2": 51, "par": [10, 101], "parad": [111, 112], "paradigm": [47, 49, 54, 56, 59], "paragraph": [9, 55, 134, 143, 153, 154], "parallel": [17, 38, 49, 52, 53, 55, 59, 74, 93, 98, 99, 116, 122, 130, 150, 166, 172, 180], "paralleliz": 59, "param": 51, "paramet": [1, 6, 8, 9, 10, 41, 45, 46, 47, 49, 52, 74, 76, 83, 84, 89, 93, 95, 97, 98, 99, 105, 106, 111, 112, 113, 114, 115, 116, 117, 123, 127, 128, 130, 132, 136, 151, 152], "parameter": [99, 126], "parametr": 6, "paramount": [38, 45, 50, 52, 59], "paraphras": [98, 122], "parent": [43, 111, 112, 128, 136, 179], "pari": [46, 100, 111, 112], "parisotto": 0, "park": [0, 3, 111, 112], "parker": [111, 112], "parkwai": [111, 112], "parmar": 0, "parol": [111, 112], "parquet": [14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 101, 103, 107, 108, 128, 145, 152], "pars": [1, 12, 14, 21, 43, 91, 121, 129, 130, 137, 139, 146], "parser": [14, 15, 21, 123, 130, 142, 157], "parsinlu": 98, "part": [0, 1, 6, 8, 9, 12, 46, 47, 49, 52, 63, 66, 71, 72, 73, 74, 88, 91, 96, 97, 99, 101, 105, 106, 108, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 127, 129, 130, 132, 135, 136, 137, 138, 139, 143, 145, 146, 150, 152, 167, 172, 174, 176, 178], "parti": [0, 5, 61, 77, 78, 111, 112, 120, 130, 134], "partial": [15, 16, 19, 20, 21, 24, 28, 30, 33, 34, 35, 40, 42, 97, 111, 112, 152, 166, 172], "particip": [42, 44, 47, 70, 85, 87, 88, 96, 97, 111, 112, 122, 129, 152, 161, 172], "particl": [111, 112, 140, 144], "particul": [111, 112], "particular": [45, 49, 50, 54, 56, 57, 59, 92, 93, 98, 109, 111, 112, 114, 115, 120, 130, 132, 136, 140, 144, 151, 157, 158, 174, 180, 181, 185], "particularli": [2, 8, 9, 38, 41, 45, 46, 50, 52, 53, 57, 59, 77, 92, 93, 97, 98, 100, 102, 106, 109, 111, 112, 115, 116, 120, 121, 130, 137, 138, 139, 143, 147, 148, 150, 151, 158, 172], "partisan": [111, 112], "partit": [148, 172], "partli": [111, 112], "partn": 101, "partner": [42, 93, 101, 177], "partner_dir": 177, "partnership": 59, "pascal": 0, "pashto": 95, "pass": [1, 8, 10, 30, 49, 52, 64, 66, 70, 72, 77, 100, 111, 112, 113, 114, 116, 127, 128, 150, 152, 159], "passag": [1, 9, 66, 70, 84, 90, 111, 112, 130], "passage_dir": 79, "passeng": [46, 111, 112], "passfil": 79, "passiv": 100, "passphras": 76, "passwd": 81, "password": [1, 64, 70, 76, 77, 78, 82, 145, 159, 176, 185], "password_store_dir": 79, "past": [2, 42, 76, 80, 91, 111, 112, 115, 128, 132, 139, 152, 171], "pastel": 26, "pastri": 46, "pat": [152, 176], "patch": [81, 116, 180], "patel": 98, "patent": [93, 120], "path": [14, 17, 22, 24, 30, 45, 51, 52, 53, 54, 60, 64, 69, 71, 72, 76, 79, 88, 95, 103, 105, 110, 112, 116, 123, 128, 145, 152, 159, 163, 169, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "pathet": 136, "pathfind": 54, "patholog": [111, 112], "pathologist": [111, 112], "pathophysiologi": [111, 112], "pathwai": [9, 46, 53, 111, 112], "patient": [50, 77, 92, 111, 112, 130, 136], "patriarchi": [111, 112], "patron": 136, "pattern": [0, 2, 5, 6, 12, 42, 44, 46, 49, 50, 53, 54, 59, 88, 89, 90, 93, 98, 111, 112, 113, 116, 119, 120, 122, 130, 131, 132, 134, 136, 137, 138, 145, 147, 148, 151, 167], "paul": [23, 24, 31, 111, 112], "paulo": 0, "paulu": 97, "pave": [6, 8, 42, 44, 53, 93, 111, 112, 116], "pavlick": 98, "payment": [111, 112], "payn": [111, 112], "payoff": 115, "pb": [111, 112], "pc": [111, 112], "pc1": 28, "pca": [9, 28, 55, 111, 112, 126, 138, 148, 151], "pcb": [111, 112], "pce": 23, "pce_diff_prev": [25, 26, 27, 28], "pce_diff_year": [23, 25, 26, 27, 28], "pcecc96": 34, "pcoord": 28, "pct_chang": 34, "pd": [23, 94, 136, 149], "pdd": [111, 112], "pdf": [0, 9, 77, 121, 146, 181], "pdfpage": 181, "pe": [20, 24, 30, 101], "peac": [111, 112], "peach": [111, 112], "peak": [51, 111, 112], "peanut": [111, 112], "pearson": 129, "peasant": [111, 112], "peckerwood": [111, 112], "pedant": [111, 112], "pediatr": [111, 112], "pediatrician": [111, 112], "peebl": [111, 112], "peer": [47, 89, 93, 111, 112, 119], "peft": [1, 47], "peft_config": 51, "peft_lora_clm_accelerate_big_model_infer": 51, "peft_lora_layoutlmfortokenclassification_on_funsd": 51, "peft_lora_seq2seq_accelerate_ds_zero3_offload": 51, "peirc": [111, 112], "pelham": [111, 112], "pem": 72, "pen": [101, 177, 180, 181], "penal": [111, 112], "penalti": [97, 111, 112], "penetr": [111, 112], "peng": [0, 6], "penicillin": 155, "peninsula": [111, 112], "penn": [42, 122, 130, 139], "pennin": 185, "pennington": [0, 125], "pensacola": [111, 112], "pentagon": 59, "penygad": 181, "peopl": [3, 6, 71, 98, 111, 112, 116, 130, 145, 150, 151, 152, 178, 183], "pepsico": 152, "per": [6, 24, 52, 60, 88, 101, 105, 111, 112, 115, 117, 149, 152, 164, 180], "per_device_eval_batch_s": 110, "per_device_train_batch_s": [110, 111, 112], "perceiv": [44, 88, 111, 112, 119, 137], "percent": [111, 112, 152], "percent_to_remov": [107, 108], "percentag": [106, 109, 111, 112, 144], "percentil": 10, "percept": [12, 111, 112, 119], "perceptron": [88, 116], "perceptu": 6, "perch": 128, "perf": 112, "perfect": [23, 46, 111, 112], "perform": [6, 9, 10, 14, 22, 38, 40, 41, 42, 44, 45, 49, 52, 53, 54, 57, 59, 60, 62, 63, 64, 65, 71, 73, 74, 75, 76, 77, 83, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 115, 116, 117, 121, 122, 126, 129, 130, 131, 132, 133, 134, 136, 137, 138, 140, 142, 144, 146, 148, 150, 152, 159, 160, 163, 164, 166, 169, 171], "perhap": [88, 111, 112], "period": [23, 64, 93, 111, 112, 117, 120, 139, 144, 151, 152, 159, 169, 171], "perish": [111, 112], "perkin": [96, 129], "perman": [111, 112], "permiss": [75, 80, 81, 121, 176, 178, 185], "permit": [50, 111, 112], "permut": 57, "perpetu": [53, 92, 93, 111, 112], "perplex": [0, 55, 111, 133], "perplexity_model": 95, "perri": [111, 112], "persian": 95, "persist": [16, 20, 28, 33, 61, 111, 112], "person": [6, 46, 50, 59, 66, 67, 71, 91, 93, 98, 111, 112, 117, 120, 121, 122, 130, 176, 185], "personnel": 167, "perspect": [55, 98, 100, 111, 112, 116, 130, 157, 171, 172], "persuad": [111, 112], "pertain": [38, 111, 112], "pertin": [59, 93, 116], "pervas": [111, 112], "pesticid": [111, 112], "pet": [111, 112, 126, 147, 149], "petabyt": [93, 117, 121, 122], "peter": [0, 111, 112], "petit": [111, 112], "petrochina": 152, "petrograd": [111, 112], "pfnn": 6, "pga": [111, 112], "pgp": [77, 78], "ph": [101, 107, 140], "pharm": 101, "pharma": 101, "pharmaci": [111, 112, 136], "phase": [0, 46, 49, 54, 55, 59, 89, 93, 98, 111, 112, 113, 164, 166, 169, 170, 171], "phenix": [111, 112], "phenol": [111, 112], "phenomena": [111, 112, 132, 136], "phenomenon": [10, 57, 59, 130, 139, 140], "phenonema": 115, "phenotyp": [111, 112], "phenylketonuria": [111, 112], "phil": [111, 112], "philadelphia": [111, 112], "philip": [111, 112], "phillip": [0, 119], "philosoph": [2, 111, 112], "philosophi": [65, 111, 112, 160, 172], "philschmid": 51, "phoenician": [111, 112], "phone": [81, 120, 136], "phonem": [0, 111, 112, 130], "phonet": [102, 111, 112, 113, 139], "photo": [9, 51, 88], "photograph": [8, 111, 112], "photographi": 88, "photometr": [111, 112], "photometri": [111, 112], "photometria": [111, 112], "photor": [9, 10], "photorealist": [10, 11], "photosynthesi": [111, 112], "photovolta": [111, 112], "phoutthavihan": [111, 112], "php": 121, "phrase": [0, 8, 55, 91, 92, 97, 98, 111, 112, 116, 117, 122, 130, 131, 134, 135, 136, 138, 139, 140, 142, 143, 144, 146, 154], "phthalat": [111, 112], "physcap": 6, "physi": [111, 112], "physic": [0, 97, 111, 112, 130, 150], "physician": [111, 112], "pi": [23, 101], "pianist": 6, "piano": 6, "picc": 152, "pick": [72, 97, 111, 112, 133, 180, 183], "pictogram": [111, 112], "pictur": [116, 126, 136], "pid": 112, "piec": [2, 4, 5, 49, 59, 88, 89, 103, 105, 110, 112, 134, 142, 146, 154, 171, 183], "piedmont": [111, 112], "pierr": [5, 111, 112], "pieter": [0, 6], "pigment": 5, "pii": 59, "pillow": 136, "pin": [64, 159], "pinch": 181, "pine": [102, 106, 111, 112, 145], "pineappl": [102, 106, 145], "pinecon": 59, "ping": 101, "pinnacl": 55, "pinpoint": 53, "pioneer": [52, 59, 111, 112, 120], "piotr": 0, "pip": [30, 42, 45, 61, 69, 94, 97, 100, 103, 105, 110, 111, 112, 114, 123, 124, 132, 135, 136, 141, 142, 150, 152, 181], "pipe": [15, 16, 19, 20, 21, 24, 28, 30, 33, 34, 111, 112], "pipefail": 79, "pipelin": [1, 6, 7, 15, 16, 18, 19, 20, 21, 24, 28, 33, 34, 37, 38, 41, 53, 56, 57, 58, 64, 65, 66, 70, 74, 75, 82, 85, 96, 100, 102, 105, 106, 111, 115, 139, 159, 160, 170], "pipx": 69, "piqu": 89, "piqua": [111, 112], "pissarro": [111, 112], "pistol": [111, 112], "pit": [111, 112, 128], "pitch": [111, 112], "piv": 79, "pivot": [12, 30, 34, 38, 42, 44, 46, 50, 52, 59, 111, 112, 146, 171], "pixel": [5, 8, 9, 10, 88, 116], "pixrai": [5, 130], "pizza": 132, "pki": 78, "pkm": [0, 6], "pl": [95, 101, 145], "place": [3, 6, 10, 45, 57, 71, 72, 77, 111, 112, 121, 144, 152, 156, 168, 170, 172, 174, 181], "placebo": [111, 112], "placehold": 115, "placement": [144, 148], "plagu": [111, 112], "plai": [5, 6, 42, 46, 50, 51, 52, 54, 55, 64, 71, 72, 76, 77, 89, 92, 96, 97, 111, 112, 116, 117, 122, 129, 131, 138, 140, 143, 144, 145, 146, 147, 150, 159, 178], "plain": [51, 93, 111, 112, 121], "plain_text": 110, "plaintext": [77, 78], "plaintext_pars": [14, 15, 21], "plan": [6, 42, 44, 71, 83, 85, 89, 101, 111, 112, 152, 163, 167, 168, 169, 170], "plane": 150, "planet": [111, 112], "planetari": [111, 112], "plant": [111, 112, 147], "plantat": [111, 112], "planter": [111, 112], "plasma": 17, "plasmid": 142, "plastic": [14, 111, 112], "plateau": [111, 112], "platform": [6, 12, 14, 22, 38, 42, 45, 46, 52, 56, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 73, 74, 76, 80, 91, 100, 110, 111, 112, 120, 121, 130, 134, 159, 160, 169], "plausibl": [6, 8, 10, 57], "play": 22, "player": [52, 53, 59, 133, 151], "pldamodel": 152, "ple": [105, 145], "plead": 120, "pleas": [14, 22, 29, 30, 35, 99, 100, 101, 103, 108, 110, 111, 112, 114, 136, 142, 155], "pleasur": [111, 112], "plethora": 12, "plm": 52, "plot": [14, 16, 17, 22, 23, 24, 26, 27, 28, 31, 33, 40, 42, 94, 95, 136, 139, 149, 155], "plot_distribut": 26, "plot_feature_import": [29, 35], "plot_irf": 34, "plot_learning_curv": [29, 35], "plot_local_entropi": 145, "plot_sentiments_over_chair_period": 32, "plot_sentiments_over_crisis_period": 32, "plt": [94, 128, 136, 139, 149, 150, 155], "plu": [42, 71, 85, 111, 112, 135, 139, 174], "pluggabl": 60, "plugin": [42, 60, 66, 69], "plum": [111, 112], "plummet": 163, "plural": [111, 112, 121, 130, 139], "pmi": [25, 26, 27, 28, 29, 33, 35, 143, 149, 152], "pmi_diff_prev": [25, 26, 27, 28], "pmi_diff_year": [25, 26, 27, 28], "pmi_valu": 155, "pmlr": 0, "pnc": [111, 112], "png": [14, 22, 24], "po": [101, 110, 130, 135, 136, 138, 141, 142], "poarch": [111, 112], "poc": 71, "pod": 60, "poem": 49, "poet": 5, "poetri": [111, 112], "poin": [101, 107], "point": [6, 9, 10, 12, 20, 23, 25, 46, 50, 51, 55, 59, 60, 69, 88, 89, 93, 101, 109, 111, 112, 115, 116, 117, 126, 128, 138, 139, 140, 142, 147, 148, 150, 152, 156, 157, 170, 176, 179, 183], "pointless": 145, "pois": [50, 53, 116, 171], "poke": [111, 112], "pol_data": 14, "pol_fil": 14, "pol_pr": 14, "pol_preds_new": 14, "polairty_pr": 14, "polar": [1, 18, 20, 30, 31, 32, 37, 110, 111, 112, 134, 135, 136, 137], "polarity_data": [14, 21], "polarity_diffus": 30, "polarity_diffusion_beigebook": [30, 31, 32], "polarity_diffusion_label": 30, "polarity_diffusion_meeting_script": [30, 31, 32], "polarity_diffusion_minut": [30, 31, 32, 33, 34, 35], "polarity_diffusion_minutes_d": 31, "polarity_diffusion_press_conf": [30, 31, 32], "polarity_diffusion_speech": [30, 31, 32, 33, 35], "polarity_diffusion_stat": [30, 31, 32, 33], "polarity_label": 30, "polarity_ma": 32, "polarity_mean": 30, "polarity_mean_beigebook": [30, 31, 32], "polarity_mean_label": 30, "polarity_mean_meeting_script": [30, 31, 32], "polarity_mean_minut": [30, 31, 32], "polarity_mean_press_conf": [30, 31, 32], "polarity_mean_speech": [30, 31, 32], "polarity_mean_stat": [30, 31, 32], "polarity_mean_testimoni": [30, 31, 32], "polarity_pr": [14, 19, 21], "polarity_preds_df": [19, 21], "polarity_record": 19, "polarity_scor": 135, "polarity_valid_preds_df": 16, "pole": [111, 112], "polic": [111, 112], "polici": [0, 1, 12, 23, 36, 37, 39, 40, 41, 71, 85, 111, 112, 121, 134, 137], "policymak": [12, 23, 41, 98, 120, 130], "polish": 95, "polit": [0, 111, 112, 130, 134, 137, 151], "politic": [111, 112], "politician": [111, 112, 119, 120], "poll": [111, 112], "pollut": [3, 111, 112], "polosukhin": 0, "polyamori": [111, 112], "polyaxon": 71, "ponferrada": 0, "poodl": 137, "pool": [9, 10, 97, 111, 112, 120, 138], "pooler": [110, 112], "poor": [10, 55, 111, 112, 130, 136, 148, 151], "poorer": [111, 112], "poorli": [52, 93, 110, 111, 112, 172], "pop": [107, 108, 110, 128, 174, 175, 177, 183], "pope": [111, 112], "popul": [59, 111, 112], "popular": [5, 6, 9, 42, 49, 52, 62, 64, 65, 66, 67, 69, 72, 73, 76, 80, 90, 93, 96, 98, 101, 105, 111, 112, 118, 119, 121, 129, 130, 134, 137, 148, 150, 151, 154, 159, 160, 171], "popularli": [111, 112], "por": 101, "porat": 107, "porati": 107, "poratio": 107, "pork": 0, "porsch": 94, "port": [61, 76, 82, 101, 107, 111, 112, 152], "portabl": [60, 62, 66, 71], "portal": [111, 112], "porter": 150, "porter_stemm": 152, "porterstemm": [142, 150, 152], "portfolio": [41, 49, 101, 132], "portion": [50, 111, 112, 128], "portrait": 7, "portugues": [95, 111, 112], "pos_": 144, "pose": [0, 6, 12, 53, 92, 93, 116, 126, 130, 139, 140, 143], "posit": [6, 8, 9, 10, 12, 14, 16, 19, 20, 21, 22, 30, 46, 52, 53, 77, 88, 89, 98, 99, 100, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 128, 130, 134, 135, 136, 137, 138, 145, 147, 149, 150, 152, 153, 155, 156, 184], "possess": [42, 46, 57, 83, 93, 100, 111, 112, 130], "possibl": [2, 5, 6, 8, 11, 17, 52, 53, 74, 89, 97, 98, 99, 105, 106, 108, 111, 112, 114, 116, 117, 130, 132, 138, 139, 145, 147, 166, 169, 172, 175], "possibli": [42, 54, 73, 111, 112, 128, 150, 170], "post": [8, 9, 12, 46, 52, 55, 72, 73, 78, 93, 97, 103, 111, 112, 118, 119, 120, 128, 130, 134, 137, 148, 150, 166, 167, 172], "post0": [14, 16, 17, 19, 20, 21, 22, 152], "poster": [0, 129], "posterior": 151, "postposit": 140, "postprocess": 88, "postprocess_metadata": 24, "postsecondari": [111, 112], "postul": 139, "postur": [0, 6, 63, 77], "pot": [5, 101, 130], "potent": [41, 42, 50], "potenti": [1, 2, 5, 6, 8, 9, 10, 12, 16, 36, 37, 39, 40, 42, 46, 49, 50, 52, 55, 57, 59, 60, 63, 71, 73, 74, 77, 78, 83, 86, 88, 89, 91, 92, 93, 94, 95, 97, 98, 100, 105, 109, 111, 112, 116, 117, 120, 130, 132, 133, 134, 136, 137, 139, 143, 155, 166, 167, 169, 170, 171, 172], "poultri": [111, 112], "pound": [111, 112], "pour": [111, 112], "poverti": [111, 112], "powderi": [111, 112], "powel": [23, 24, 25, 26, 27, 31], "power": [6, 8, 9, 10, 12, 40, 41, 42, 45, 49, 50, 51, 52, 53, 55, 56, 57, 59, 61, 64, 69, 72, 73, 74, 76, 77, 79, 81, 83, 86, 88, 92, 99, 105, 106, 109, 110, 111, 112, 113, 114, 117, 126, 130, 132, 138, 144, 148, 153, 156, 157, 159, 180], "powerhous": [42, 111, 112], "pp": 132, "ppmi": 155, "ppmi_valu": 155, "pport": 108, "pprint": 145, "practic": [5, 9, 10, 12, 42, 44, 45, 46, 47, 51, 52, 55, 56, 65, 66, 67, 68, 70, 71, 78, 85, 87, 89, 92, 96, 97, 98, 101, 105, 111, 112, 113, 116, 122, 129, 130, 133, 135, 136, 141, 142, 146, 149, 157, 160, 161, 166, 168, 169, 172, 181], "practition": [46, 88, 109, 114, 122, 136, 151], "prado": 0, "pragmat": [111, 112], "pranav": [0, 6], "prat": 0, "praxi": [111, 112], "pre": [0, 1, 5, 7, 12, 45, 46, 47, 49, 50, 52, 57, 60, 61, 62, 73, 82, 84, 86, 88, 91, 95, 96, 98, 99, 100, 101, 105, 110, 112, 114, 116, 117, 121, 124, 128, 129, 130, 138, 139, 152, 164, 172, 176], "pre_token": [103, 104, 107, 108, 111, 145], "pre_tokenize_str": 104, "preach": [111, 112], "preacher": [111, 112], "preced": [97, 111, 112, 117, 132, 140], "precipit": [111, 112], "precis": [8, 14, 16, 22, 29, 30, 35, 42, 53, 54, 55, 57, 59, 74, 126, 135, 136, 137, 144, 146, 150, 152], "precision_scor": 135, "precison": [14, 16, 22, 29, 30, 35], "precomput": 88, "preconcept": [111, 112], "precursor": [111, 112, 113, 151], "pred": [14, 16, 19, 20, 21, 128], "pred_fil": 21, "pred_label": [14, 16, 19, 21, 30], "pred_prob": [14, 16, 19, 21, 30], "predatori": [111, 112], "predecessor": [9, 49, 56, 86, 97, 111, 112], "predefin": [44, 55, 59, 64, 91, 97, 105, 134, 135, 137, 143, 156, 159], "predic": [111, 112], "predict": [1, 5, 6, 8, 9, 16, 17, 18, 20, 22, 25, 36, 37, 40, 41, 45, 46, 50, 53, 55, 57, 59, 71, 73, 74, 85, 86, 88, 90, 92, 97, 98, 99, 100, 102, 107, 109, 110, 111, 112, 113, 115, 116, 117, 120, 122, 126, 127, 130, 131, 132, 133, 135, 136, 138, 139, 140, 143, 145, 146, 154, 156, 166, 167, 172], "predict_sent": 30, "predicted_label": 135, "prediction_ag": [14, 16, 17, 19], "prediction_fil": 21, "prediction_loss_onli": 112, "predominantli": [49, 111, 112], "preds_df": [19, 21], "preempt": [111, 112], "preexist": 117, "prefer": [9, 10, 30, 37, 42, 46, 64, 73, 87, 91, 92, 111, 112, 132, 134, 157, 159, 174, 182], "prefigur": [111, 112], "prefix": [30, 51, 52, 79, 81, 105, 108, 111, 112, 117, 130, 133, 139, 145, 174], "pregnanc": [111, 112], "preliminari": [104, 111, 112, 167], "preload": 111, "premia": 119, "premis": [65, 117, 150, 156, 158, 160], "premium": 128, "prenat": [111, 112], "preoccup": [111, 112], "prepar": [1, 6, 7, 8, 18, 30, 36, 37, 46, 71, 75, 77, 89, 96, 100, 105, 106, 109, 116, 129, 135, 136, 138, 139, 149, 152, 167, 169, 170, 171], "prepare_seq2seq_batch": 30, "prepared_data": 152, "preposit": 144, "preprint": [0, 6, 53, 99], "preprocess": [7, 12, 15, 41, 71, 75, 80, 93, 94, 95, 103, 105, 109, 110, 111, 112, 115, 130, 136, 138, 140, 148, 149, 150, 152, 155], "preprocess_funct": 111, "preprocessed_corpu": 152, "preprocessor": [15, 24, 30], "prerequisit": 165, "presbyterian": [111, 112], "preschool": [111, 112], "prescrib": [111, 112, 156], "prescript": [77, 136], "presenc": [93, 106, 111, 112, 115, 130, 136, 137], "present": [6, 7, 8, 9, 38, 41, 52, 53, 55, 59, 64, 75, 77, 79, 86, 87, 88, 89, 92, 95, 98, 102, 106, 109, 111, 112, 113, 114, 115, 116, 119, 120, 124, 129, 130, 138, 139, 159, 167, 170, 171, 172, 176, 177, 178], "preserv": [38, 50, 88, 98, 105, 111, 112, 116, 126, 127, 138, 143, 148, 150, 154], "preset": 152, "presid": [111, 112, 152], "presidenti": 119, "press": [36, 53, 59, 81, 111, 112], "pressur": 152, "prestigi": [111, 112], "presum": [111, 112], "preterm": [111, 112], "pretokenization_delimit": 103, "pretrain": [0, 1, 16, 17, 19, 21, 30, 88, 95, 96, 98, 115, 117, 122], "pretrained_model_name_or_path": 51, "pretrainedtokenizerfast": [110, 111, 112], "pretti": [77, 78, 136, 176, 177], "prettili": 176, "prev_decis": [25, 26, 27, 28, 29, 33, 35], "prevail": 116, "preval": [49, 111, 112, 115, 139, 151], "prevent": [6, 52, 55, 77, 78, 85, 97, 111, 112, 121, 130, 133, 147, 156], "previou": [6, 8, 10, 23, 25, 26, 27, 49, 52, 64, 66, 72, 81, 85, 86, 88, 92, 97, 99, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 128, 132, 133, 138, 147, 152, 159, 167, 169, 172, 177, 181, 183, 184], "previous": [6, 8, 10, 59, 72, 95, 97, 110, 111, 112, 116, 126, 130], "pri": 101, "price": [12, 38, 40, 42, 59, 101, 111, 112, 118, 119, 128, 134, 138, 152], "pride": [89, 111, 112], "primari": [9, 37, 42, 49, 57, 59, 60, 67, 69, 79, 91, 95, 98, 102, 109, 111, 112, 114, 116, 118, 143, 146, 151, 156, 157, 170, 171, 172], "primarili": [9, 41, 49, 53, 54, 76, 105, 111, 112, 114, 116, 122, 126, 138, 169, 171], "prime": [16, 97, 116, 128, 147], "primit": [111, 112], "primitiv": [111, 112], "princeton": 137, "princip": [9, 59, 111, 112, 126, 138, 148, 150], "principl": [9, 46, 50, 52, 64, 65, 66, 71, 80, 111, 112, 116, 130, 133, 140, 146, 151, 159, 160, 161, 162, 163, 171, 172], "print": [3, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 69, 94, 95, 97, 100, 101, 103, 104, 105, 107, 108, 110, 111, 112, 120, 123, 124, 127, 128, 132, 133, 135, 136, 141, 142, 143, 144, 145, 150, 152, 155, 158, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "print0": 79, "print_config": 15, "print_token": 101, "print_trainable_paramet": 51, "printer": 120, "prior": [6, 8, 37, 46, 85, 100, 111, 112, 120, 130, 148, 151], "prior_loss_weight": 51, "priori": 138, "priorit": [7, 50, 55, 93, 111, 112, 130, 171, 172], "prioriti": [41, 111, 112, 165], "prisk_": 119, "prison": 156, "privaci": [1, 38, 41, 45, 47, 59, 71, 74, 78, 79, 82, 85, 88, 89, 93, 109, 111, 112, 121, 130], "privat": [45, 61, 76, 77, 78, 82, 111, 112], "privileg": [42, 64, 81, 111, 112, 159], "prj": 150, "pro": [44, 101, 111, 112, 120], "proactiv": [12, 77, 172], "prob": [143, 152], "probabilist": [0, 6, 8, 49, 54, 105, 106, 120, 121, 130, 138, 148], "probabl": [0, 8, 14, 16, 17, 22, 46, 84, 90, 97, 99, 105, 108, 110, 111, 112, 113, 116, 117, 120, 127, 128, 130, 131, 133, 138, 143, 145, 151, 152, 155, 157, 185], "probat": [111, 112], "probe": 150, "probestim": 152, "problem": [9, 10, 37, 41, 42, 44, 49, 50, 51, 53, 57, 64, 65, 71, 73, 75, 77, 85, 87, 88, 89, 92, 96, 97, 98, 100, 102, 105, 106, 111, 112, 115, 117, 125, 126, 128, 129, 130, 133, 136, 138, 139, 143, 145, 146, 151, 159, 160, 161, 163, 165, 167, 168, 169, 170, 175], "problemat": 59, "proc": [15, 20, 24, 30], "procain": 155, "proce": [45, 111, 112, 133, 136, 167], "procedur": [9, 45, 57, 106, 110, 111, 112, 116, 120, 164, 169], "proceed": [0, 6, 81], "process": [0, 1, 2, 5, 6, 8, 9, 10, 11, 14, 15, 16, 17, 20, 21, 22, 24, 28, 30, 37, 41, 42, 44, 45, 46, 47, 50, 52, 54, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 123, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 143, 144, 147, 148, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 166, 168, 171, 177], "processio": 97, "processor": [111, 112], "proclam": 171, "prod": [97, 107, 143, 157], "prod_": [99, 105, 106, 132], "prodigi": [111, 112], "produ": [101, 107], "produc": [2, 6, 8, 9, 10, 12, 42, 46, 49, 59, 74, 77, 84, 88, 89, 91, 92, 93, 97, 101, 104, 105, 111, 112, 116, 117, 126, 127, 130, 132, 134, 138, 147, 152, 162, 163, 172, 181], "product": [0, 9, 34, 40, 42, 49, 51, 52, 56, 59, 64, 65, 66, 70, 71, 73, 74, 75, 82, 85, 88, 98, 100, 101, 105, 106, 108, 111, 112, 113, 114, 116, 118, 125, 126, 128, 132, 134, 137, 138, 143, 147, 150, 152, 158, 159, 160, 163, 164, 166, 169, 171, 172, 180], "profession": [6, 49, 50, 85, 89, 98, 111, 112, 167, 168], "professor": [96, 111, 112, 129], "profici": [37, 42, 43, 49, 93, 111, 112, 121, 172], "profil": [38, 46, 59, 66, 69, 91, 111, 112, 177, 178], "profit": [34, 117, 121, 152], "profound": [2, 50, 111, 112], "prognosi": [111, 112], "program": [5, 6, 37, 53, 57, 69, 80, 87, 91, 93, 97, 98, 111, 112, 121, 130, 141, 161, 163, 167, 169, 170, 171, 174, 181, 182], "programmat": [0, 59, 69, 120], "progress": [38, 45, 50, 55, 63, 75, 91, 92, 93, 96, 111, 112, 113, 129, 166, 167, 171, 172], "progress_p": [14, 15, 21], "prohibit": [83, 111, 112], "project": [1, 2, 6, 9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 44, 52, 59, 60, 61, 62, 64, 66, 67, 68, 70, 71, 72, 80, 82, 83, 87, 88, 89, 95, 97, 105, 111, 112, 116, 121, 123, 126, 130, 138, 146, 148, 152, 159, 161, 163, 167, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185], "project_dir": [14, 16, 17, 19, 20, 21, 22], "project_id": [20, 21, 45], "project_list": [20, 21], "project_nam": [17, 69], "proletariat": [111, 112], "prolifer": [49, 85, 90, 111, 112], "prolong": 50, "prometheu": [64, 65, 71, 159, 160], "promin": [46, 52, 111, 112, 116], "promis": [2, 6, 12, 40, 50, 53, 54, 77, 90, 92, 97, 98, 116, 120, 130, 144], "promot": [42, 59, 64, 65, 66, 71, 85, 98, 111, 112, 130, 151, 159, 160, 171], "prompt": [1, 2, 4, 6, 8, 10, 46, 47, 51, 53, 55, 64, 74, 76, 80, 81, 82, 92, 96, 98, 111, 159, 181], "prompt_embed": 52, "prompt_token": 52, "prompt_tun": 52, "pron": 144, "prone": [49, 111, 112, 115, 118, 151, 166], "pronoun": [111, 112, 130, 140, 144], "pronounc": [111, 112, 115], "pronunci": [111, 112, 115], "proof": [49, 77, 89], "propag": [49, 50, 55, 109, 127], "propaganda": [111, 112, 130], "propagandist": 150, "propens": [59, 120], "proper": [77, 80, 95, 111, 112, 119, 133, 141, 145], "properli": [10, 14, 38, 45, 107, 108, 111, 112, 145, 155], "properti": [9, 59, 71, 74, 94, 98, 109, 111, 112, 126, 130, 132, 147, 150, 151, 152, 156], "propn": 144, "propon": [111, 112], "proport": [111, 112, 115, 130, 133, 151], "proportion": [111, 112], "propos": [1, 6, 8, 11, 52, 89, 96, 105, 106, 111, 112, 115, 116, 120, 127, 128, 145, 147, 156, 161, 165], "proposit": 59, "proprietari": 59, "proselyt": [111, 112], "prospect": [50, 111, 112], "prosper": [111, 112], "protect": [59, 64, 74, 76, 77, 78, 82, 93, 111, 112, 130, 159], "protest": [111, 112], "proto": [111, 112], "protocol": [12, 55, 76, 78, 82, 176], "prototyp": [59, 72, 165, 171, 172], "proudhon": [111, 112], "prove": [6, 46, 53, 77, 84, 111, 112, 116], "proven": [50, 57, 86, 116, 118, 156], "provid": [1, 2, 6, 7, 8, 9, 10, 12, 35, 37, 38, 40, 41, 42, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 126, 128, 129, 130, 132, 133, 134, 135, 137, 138, 139, 141, 142, 144, 146, 147, 148, 150, 151, 152, 154, 155, 156, 158, 159, 160, 163, 165, 166, 167, 168, 169, 170, 171, 172, 183, 186], "provinc": [111, 112], "proving_exist": 149, "provis": [64, 65, 73, 111, 112, 159, 160], "provoc": [111, 112], "prowess": 1, "proxi": [40, 42, 119], "proxim": [111, 112], "prp": 144, "prune": [52, 55, 74, 79, 106], "pschaldenbrand": 9, "psentiment_": 119, "pseudo": [52, 133, 152], "pseudocod": 169, "psm14": 0, "psychiatr": [111, 112], "psychiatri": [111, 112], "psychiatrist": [111, 112], "psychoact": [111, 112], "psycholog": [111, 112, 137], "psychologi": [89, 111, 112, 130], "psychologist": [111, 112], "psychopath": [111, 112], "psychosoci": [111, 112], "pt": [95, 100, 114], "ptab": 16, "pteridophyt": [111, 112], "ptmodel": 152, "pu": 101, "pub": [76, 150, 156, 185], "public": [12, 36, 59, 61, 62, 72, 76, 77, 78, 80, 81, 85, 92, 97, 111, 112, 117, 119, 120, 121, 130, 134, 151, 167, 176, 177, 181, 185], "publicli": [36, 89, 93, 120, 121], "publish": [1, 9, 12, 13, 36, 37, 87, 111, 112, 116, 119, 129, 152, 161, 177, 186], "pubm": 93, "pull": [1, 60, 64, 70, 76, 80, 81, 159, 161, 177, 180, 181, 182, 183, 185, 186], "puls": [111, 112], "pulse\ub85c": 21, "pulumi": [64, 159], "pump": 108, "punct": 144, "punctuat": [55, 102, 104, 117, 130, 136, 139, 140, 142, 153], "punish": [111, 112], "punjabi": 95, "punk": [111, 112], "punkt": [132, 142], "pupil": [111, 112], "puppet": [64, 65, 159, 160], "puppi": 113, "purchas": [59, 111, 112], "pure": [0, 105, 180], "purpos": [1, 5, 9, 10, 38, 45, 49, 53, 54, 59, 71, 76, 78, 88, 89, 105, 108, 110, 112, 115, 121, 130, 136, 137, 140, 152, 167, 173], "pursu": [50, 111, 112], "pursuit": 100, "purview": [111, 112], "push": [2, 5, 46, 52, 60, 72, 73, 76, 80, 81, 111, 112, 157, 176, 180, 181, 182, 183, 185], "push_to_hub": 45, "put": [1, 18, 37, 52, 111, 112, 121, 128, 136, 172, 177, 181], "puzzl": 53, "pwd": [173, 177], "pwr": 112, "pxp": 116, "py": [28, 30, 43, 51, 61, 69, 80, 100, 101, 103, 108, 110, 111, 112, 114, 135, 136, 181, 184], "py2": 135, "py3": [100, 101, 103, 108, 114, 132, 135, 136, 141, 150], "py_util": 14, "pyautogen": 42, "pyc": 181, "pydant": [30, 31, 32, 33, 34], "pylab": 181, "pyldavi": 152, "pyop": 142, "pypars": 136, "pypi": [73, 132, 135, 136, 141, 150, 152], "pyplot": [94, 128, 136, 139, 149, 150, 155], "pypoetri": [100, 101, 103, 108, 114, 132, 135, 136, 141, 150], "pysbd": [24, 142, 146], "pysbdsegment": 24, "python": [1, 12, 37, 42, 45, 49, 51, 59, 61, 65, 68, 69, 70, 72, 73, 80, 87, 94, 97, 100, 105, 110, 111, 112, 121, 123, 124, 129, 132, 135, 136, 141, 142, 144, 152, 155, 160, 161, 167, 169, 181, 184], "python3": [28, 30, 42, 100, 101, 103, 108, 110, 111, 112, 114, 132, 135, 136, 141, 150], "pytorch": [8, 9, 12, 45, 51, 71, 75, 83, 96, 110, 112], "pytorch_model": [100, 112, 114], "pytorchmodelartifact": 73, "pytz": [136, 141], "pyv": 142, "q": [1, 8, 34, 47, 52, 84, 97, 99, 100, 101, 108, 113, 114, 116, 119, 120, 128], "q1": 101, "q2": 101, "q3": 101, "q4": 101, "qatar": 0, "qe": 23, "qian": 0, "qmul": 0, "qu": 101, "qua": [111, 112], "quadgram": 132, "quadrant": 172, "quadrat": 116, "quadrupl": 10, "qualifi": 126, "qualit": [6, 10, 12, 49, 111, 120], "qualiti": [5, 6, 7, 8, 9, 10, 11, 13, 42, 45, 46, 53, 59, 64, 65, 71, 80, 83, 88, 89, 91, 92, 95, 97, 98, 100, 109, 111, 112, 121, 122, 130, 132, 134, 136, 138, 141, 147, 149, 150, 159, 160, 164, 165, 166, 169, 170, 171, 172], "quandl": [23, 34], "quantif": [111, 112], "quantifi": [111, 112, 126, 132, 147, 148, 155, 157], "quantit": [6, 10, 12, 13, 111, 128], "quantiti": [23, 98, 100], "quantiz": [8, 9, 74], "quantum": [49, 50, 78], "quar": 101, "quart": 107, "quarter": [95, 101, 111, 112, 119, 128, 152], "quarterli": [0, 12, 120, 128], "quartil": 95, "queen": [133, 156], "queer": [111, 112], "queri": [24, 41, 42, 46, 49, 52, 57, 84, 92, 114, 116, 121, 123, 130, 147, 155], "question": [2, 12, 42, 53, 55, 57, 59, 69, 83, 86, 89, 92, 93, 98, 100, 109, 111, 112, 113, 115, 116, 117, 119, 122, 131, 136, 140, 151, 154, 155, 157, 177, 183], "questionnair": [51, 69, 111, 112], "queue": 167, "qui": 101, "quick": [115, 121, 142, 143, 144, 158, 166, 172], "quicker": [52, 53], "quickfact": [111, 112], "quickli": [10, 59, 63, 64, 65, 71, 89, 97, 100, 109, 111, 112, 115, 130, 132, 159, 160, 166, 171, 180], "quickstart": 135, "quit": [46, 97, 111, 112, 128, 130, 140, 142, 149, 152], "quoc": 0, "quot": [76, 149, 150], "quotat": 117, "r": [0, 14, 23, 32, 37, 45, 51, 52, 53, 61, 76, 79, 80, 99, 100, 101, 105, 106, 107, 108, 111, 112, 119, 124, 130, 145, 146, 147, 180], "r2": [29, 35], "ra": [78, 101], "raab": [0, 6], "race": [93, 111, 112], "racehors": 6, "racial": [111, 112], "racism": [111, 112], "racist": [111, 112], "radar": [111, 112], "rade": 101, "radford": 99, "radi": [111, 112], "radiat": [111, 112], "radic": [111, 112], "radicalis": [111, 112], "radios": [111, 112], "radiu": [111, 112], "radviz": 28, "raffel": [0, 115, 117], "raft": 51, "rag": [1, 47, 59], "rage": 25, "rai": [8, 101, 111, 112, 150], "raid": [173, 177, 185], "rail": [111, 112], "railroad": [111, 112], "rain": [111, 112], "rainfal": [111, 112], "rainforest": [3, 111, 112], "rais": [12, 38, 55, 77, 93, 98, 109, 111, 112, 116, 119, 121, 130, 152], "ral": 101, "ralli": [111, 112, 152], "ram": 51, "rami": 0, "ramp": 108, "ran": [101, 113], "random": [8, 9, 12, 77, 88, 95, 97, 98, 99, 105, 111, 112, 115, 128, 132, 133, 136, 138, 144, 149, 152, 184], "random_batch": 128, "random_index": 128, "random_input": 128, "random_label": 128, "random_st": [16, 20, 28, 33, 136, 150], "randomforestclassifi": 73, "randomized_svd": 150, "randomli": [9, 10, 97, 99, 101, 103, 106, 107, 108, 109, 112, 113, 128, 133], "randomundersampl": 136, "rang": [3, 5, 6, 7, 8, 9, 10, 12, 24, 41, 46, 49, 50, 52, 53, 55, 59, 62, 65, 71, 73, 86, 88, 92, 93, 94, 97, 98, 100, 101, 104, 105, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 121, 123, 124, 127, 128, 130, 132, 133, 136, 138, 145, 148, 152, 155, 156, 160, 167, 171], "rangeindex": [14, 21], "rangl": 108, "ranjel": [111, 112], "rank": [0, 8, 9, 51, 52, 55, 88, 92, 97, 101, 106, 111, 112, 116, 130, 139, 143, 152], "rank1d": [28, 33], "rank2d": [28, 33], "ransfer": 117, "ransform": 117, "rape": [111, 112], "rapid": [50, 63, 71, 74, 89, 93, 111, 112, 121, 166, 171, 172], "rapidli": [2, 46, 55, 86, 100, 117, 130], "rapier": [111, 112], "rapporteur": [111, 112], "rare": [0, 102, 106, 111, 112, 119, 125, 128, 139, 143, 157, 158], "rat": [6, 101], "rate": [1, 8, 10, 12, 13, 24, 27, 28, 30, 32, 34, 37, 38, 45, 46, 88, 101, 111, 112, 115, 116, 119, 128, 135, 136, 137, 152], "rate_chang": [23, 24, 25, 26, 27, 31], "rate_decis": [23, 24, 25, 26, 27, 31], "rather": [2, 9, 12, 41, 46, 52, 64, 71, 92, 97, 99, 111, 112, 114, 115, 116, 118, 132, 140, 147, 152, 154, 156, 159], "ratifi": [111, 112], "ratio": [14, 20, 26, 27, 45, 55, 88, 111, 112, 132, 152, 158], "ration": [111, 112], "rational": [170, 171], "raw": [0, 23, 24, 30, 41, 46, 92, 93, 95, 97, 112, 115, 122, 128, 130, 135, 138, 145, 149, 152, 156, 173], "raw_output": [14, 22], "raw_pr": [14, 16, 19, 21, 30], "rawl": [111, 112], "rayid": 0, "raymond": [111, 112], "raz": [111, 112], "rb": [16, 17, 19, 111, 112], "rb_category_dataset": 16, "rb_cfg": [16, 17, 19], "rbs043xj": 16, "rbs043xjsync": 16, "rc4": [77, 78], "rce": 107, "rcparam": [17, 22, 26, 28, 30, 32], "rdf": [14, 41], "rdzv_backend": 51, "re": [0, 1, 45, 46, 52, 69, 79, 80, 81, 100, 101, 104, 107, 108, 110, 111, 112, 126, 130, 139, 144, 149, 150, 152, 155, 156, 161, 162, 174, 175, 176, 177, 181, 185], "re100": [15, 19], "rea": [101, 124], "reach": [2, 6, 9, 50, 53, 97, 106, 108, 111, 112, 120, 156, 179], "react": 167, "reaction": [111, 112], "reactiv": [12, 44], "read": [0, 37, 49, 61, 70, 79, 87, 89, 90, 97, 98, 102, 111, 112, 115, 118, 119, 124, 130, 139, 150, 178, 181], "read_csv": 23, "readabl": [59, 64, 65, 96, 147, 159, 160], "reader": [52, 89, 111, 112, 130], "readi": [59, 73, 110, 111, 112, 178, 180, 181], "readili": [93, 111, 112, 126], "readlin": 124, "readm": [103, 136, 176], "readthedoc": [100, 101, 103, 108, 110, 111, 112, 114, 135, 136], "real": [0, 2, 5, 6, 10, 34, 37, 40, 42, 46, 47, 50, 51, 54, 55, 56, 57, 59, 63, 65, 71, 74, 77, 85, 87, 88, 89, 90, 93, 96, 97, 98, 111, 112, 113, 115, 126, 128, 129, 133, 134, 150, 155, 160, 167, 181], "realism": [6, 11], "realist": [5, 6, 7, 53, 59, 92, 115, 133, 151], "realiti": [6, 50], "realiz": [1, 139], "realli": [3, 97, 130, 132, 136, 174, 176, 178, 183], "realm": [2, 8, 42, 46, 49, 50, 52, 77, 105, 111, 112, 116, 126, 139, 153, 156, 168], "realnew": 117, "reapport": [111, 112], "reason": [6, 8, 53, 54, 57, 59, 71, 85, 92, 97, 98, 106, 111, 112, 115, 117, 118, 126, 130, 131, 135, 149, 163, 174], "reassess": 171, "rebas": [1, 161, 177, 186], "rebelli": [111, 112], "rebellion": [111, 112], "rebuild": [14, 22, 28, 100], "rebuilt": [111, 112], "recal": [14, 16, 22, 29, 30, 35, 55, 74, 135, 136, 144], "recalcul": 116, "recalibr": 46, "recall_scor": 135, "recap": 78, "receiv": [10, 42, 46, 53, 54, 59, 76, 77, 78, 88, 100, 111, 112, 113, 114, 121, 123, 172, 177], "recent": [5, 6, 50, 59, 77, 86, 87, 89, 91, 92, 93, 97, 103, 111, 112, 115, 116, 118, 130, 132, 138, 144, 152, 175], "recent_decis": [24, 30], "recent_meet": [24, 30], "recent_r": [24, 30], "recess": 32, "recip": [46, 83], "recipi": [76, 77, 79, 116], "reciproc": [111, 112], "recit": 6, "reclaim": [111, 112], "reclam": [111, 112], "recogn": [5, 7, 9, 12, 46, 59, 91, 100, 102, 106, 111, 112, 116, 130, 132, 139, 141, 145], "recognit": [0, 6, 9, 49, 50, 77, 98, 111, 112, 113, 116, 122, 125, 129, 130, 131, 132, 133, 143, 144, 145], "recommend": [12, 37, 42, 49, 68, 75, 77, 91, 98, 100, 111, 112, 150, 151, 175], "reconcil": [38, 55, 64, 159], "reconfigur": 59, "reconsid": 97, "reconstruct": [6, 7, 8, 9, 95, 111, 112, 128, 151], "record": [6, 14, 16, 17, 19, 32, 49, 55, 69, 71, 72, 77, 101, 107, 108, 111, 112, 121, 130, 174, 175], "records_with_label_error": [14, 16, 17], "recov": [10, 117, 124], "recoveri": [64, 79, 159], "recreat": [6, 64, 159], "rectifi": 88, "recupero": 37, "recur": 89, "recurr": [6, 12, 49, 91, 99, 114, 116, 126, 130, 134], "recurs": 138, "red": [32, 65, 101, 111, 112, 147, 160, 176], "reddit": [12, 121], "redeem": [111, 112], "redefin": 2, "redesign": 172, "redi": 61, "redirect": [72, 178], "redistribut": [97, 133], "redistrict": [111, 112], "redo": 172, "redraw": [111, 112], "redston": [111, 112], "reduc": [9, 38, 42, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 64, 65, 71, 74, 77, 85, 88, 93, 95, 98, 104, 105, 109, 111, 112, 115, 116, 119, 120, 124, 126, 128, 130, 138, 142, 146, 148, 150, 157, 159, 160, 163, 166, 167, 171, 172], "reduct": [50, 55, 111, 112, 119, 126, 151, 163, 172], "redund": [100, 126, 163, 172], "redworm": [111, 112], "ree": 101, "reed": [0, 116], "ref": [111, 112, 177, 185], "refactor": [171, 172], "refer": [5, 8, 9, 12, 50, 52, 55, 58, 64, 71, 89, 92, 95, 98, 100, 105, 110, 111, 112, 113, 116, 120, 121, 126, 130, 134, 135, 136, 137, 139, 140, 144, 147, 149, 151, 159, 171, 180, 185], "referenc": 55, "referendum": [111, 112], "referr": [111, 112, 136], "refil": 136, "refin": [6, 9, 11, 42, 46, 50, 52, 53, 55, 59, 85, 88, 89, 92, 98, 100, 111, 112, 116, 130, 151, 166, 172], "refineri": [111, 112], "reflect": [2, 6, 8, 9, 10, 42, 44, 53, 59, 89, 90, 111, 112, 151, 171], "reflector": [111, 112], "reflex": 44, "reform": [111, 112, 120], "reformist": [111, 112], "refract": [111, 112], "refresh": 176, "refriger": [111, 112], "refuge": [111, 112], "refund": 59, "refus": [14, 111, 112], "reg": 30, "reg_alpha": [29, 35], "reg_lambda": [29, 35], "regain": [111, 112], "regard": [38, 50, 98, 111, 112, 134], "regardless": [52, 73, 111, 112, 116, 128], "regener": 181, "regex": [30, 132, 135, 141], "region": [9, 12, 55, 84, 88, 90, 111, 112, 116, 120, 139, 148, 152], "regist": [111, 112], "registr": [78, 111, 112], "registri": [60, 62, 71, 73], "regolith": [111, 112], "regress": [6, 80, 88, 97, 111, 112, 117, 118, 120, 125, 126, 128, 134, 136, 138, 152], "regret": [111, 112, 136], "regul": [12, 38, 74, 77, 89, 93, 111, 112, 119, 120, 137, 167], "regular": [0, 8, 12, 30, 36, 63, 88, 103, 106, 133, 140, 144, 151, 171, 172], "regularli": [50, 55, 111, 112, 121, 139, 171], "regulatori": [71, 98], "reinforc": [0, 1, 49, 50, 53, 54, 91, 96, 111, 112, 130], "reinstat": [111, 112], "reit": 101, "reiter": [89, 167, 170], "reject": [111, 112, 185], "rejoin": [111, 112], "rel": [6, 8, 9, 10, 77, 84, 88, 99, 101, 109, 111, 112, 113, 117, 121, 130, 132, 138, 141, 143, 149, 150, 158], "relabelled_dataset": 17, "relat": [9, 10, 12, 35, 46, 50, 51, 53, 55, 57, 64, 66, 71, 72, 77, 89, 92, 98, 100, 109, 111, 112, 116, 118, 119, 120, 123, 126, 128, 136, 138, 139, 144, 147, 148, 149, 151, 152, 154, 155, 157, 159, 172], "relationship": [2, 7, 8, 9, 10, 11, 39, 40, 48, 49, 52, 53, 55, 98, 100, 102, 111, 112, 113, 114, 116, 122, 126, 127, 130, 132, 135, 137, 138, 140, 144, 147, 148, 149, 151, 154, 155, 156, 165, 169, 180], "relativedelta": 23, "relax": 126, "rele": 101, "releas": [10, 22, 23, 36, 60, 63, 65, 71, 83, 88, 93, 95, 97, 111, 112, 115, 117, 119, 121, 132, 135, 136, 141, 150, 152, 160, 171, 172, 180, 181], "releg": [111, 112], "relev": [9, 41, 42, 46, 49, 53, 55, 57, 59, 71, 74, 75, 86, 91, 93, 97, 98, 100, 111, 112, 113, 114, 116, 118, 119, 123, 130, 131, 132, 138, 151, 155, 170, 171], "reli": [6, 8, 9, 12, 13, 30, 46, 49, 64, 65, 69, 76, 77, 84, 93, 100, 105, 111, 112, 113, 120, 122, 130, 131, 132, 134, 135, 137, 138, 144, 145, 159, 160], "reliabl": [12, 38, 55, 59, 63, 64, 65, 71, 85, 93, 98, 100, 111, 112, 132, 159, 160, 162, 163, 166, 172], "relianc": [55, 77, 85], "relic": [64, 159, 169], "reliev": [111, 112], "religi": [10, 111, 112, 150], "religion": [111, 112, 150], "reload": [72, 150, 178], "relogin": [17, 22, 30], "relu": [10, 88, 117, 128], "rema": 101, "remain": [6, 9, 38, 39, 41, 45, 46, 49, 50, 52, 53, 59, 61, 76, 77, 78, 82, 85, 89, 91, 93, 95, 99, 100, 108, 110, 111, 112, 115, 116, 133, 140, 148, 151, 152, 163, 172], "remaining_substr": 101, "remap_cat": 17, "remark": [8, 42, 50, 83, 98, 116, 126], "remedi": [63, 97], "rememb": [89, 95, 103, 110, 111, 136, 141, 142, 144, 146], "remind": [88, 181], "reminisc": 54, "remiss": [111, 112], "remot": [1, 65, 68, 76, 81, 82, 111, 112, 160, 161, 177, 179, 180, 181, 182, 183, 186], "remote_serv": 76, "remov": [6, 9, 10, 14, 16, 22, 24, 30, 34, 45, 52, 55, 60, 88, 93, 95, 101, 104, 106, 107, 108, 110, 111, 112, 115, 117, 120, 128, 130, 136, 138, 140, 142, 145, 146, 148, 149, 150, 152, 173, 175, 176, 180, 181, 182], "remove_column": [111, 112], "remove_extra_whitespac": [103, 105], "remove_punctu": 136, "remove_stopword": 136, "removed_top_word": 152, "ren": [101, 139], "renaiss": [111, 112], "renam": [14, 16, 19, 21, 22, 26, 27, 34], "rename_column": 17, "render": [8, 9, 29, 35, 49, 50, 69, 77, 136, 144, 172, 173, 176, 181], "renew": [98, 111, 112], "reng": 107, "rengt": 107, "rength": 107, "renown": [52, 54, 59, 136], "ren\u00e9": [111, 112], "repair": [111, 112, 120], "repay": 120, "repeat": [88, 97, 98, 101, 106, 111, 112, 116, 117, 133, 136, 145, 147, 172], "repeatedli": [8, 76, 111, 112, 121, 172], "repertoir": 6, "repetit": [55, 65, 90, 97, 111, 112, 115, 160], "rephras": [8, 98], "replac": [9, 10, 30, 31, 46, 60, 76, 79, 80, 81, 82, 84, 95, 99, 101, 105, 108, 111, 112, 115, 116, 117, 126, 128, 132, 133, 140, 142, 143, 146], "replic": [5, 59, 66, 111, 112, 130], "replika": 130, "repo": [43, 69, 185], "repo_id": 45, "repo_nam": 45, "report": [0, 12, 14, 16, 22, 29, 30, 35, 96, 101, 111, 112, 119, 121, 123, 128, 135, 136, 152], "repositori": [38, 45, 60, 64, 65, 66, 69, 75, 76, 78, 93, 117, 159, 160, 174, 177, 179, 180, 181, 182, 183, 185, 186], "repositorynam": 182, "repostiori": 179, "repr": 152, "repres": [6, 8, 44, 45, 46, 49, 50, 52, 53, 54, 56, 57, 59, 73, 77, 81, 88, 89, 93, 97, 99, 102, 105, 106, 109, 111, 112, 113, 115, 116, 119, 120, 124, 125, 126, 127, 128, 130, 132, 133, 136, 137, 138, 139, 140, 142, 143, 144, 146, 147, 148, 150, 151, 153, 154, 157, 158, 164, 170, 171, 172, 183], "represent": [0, 1, 6, 7, 8, 9, 10, 12, 29, 35, 49, 50, 52, 55, 59, 88, 89, 93, 95, 96, 98, 99, 104, 105, 109, 111, 112, 116, 124, 125, 126, 127, 128, 129, 133, 134, 136, 138, 139, 144, 148, 150, 151, 153, 155, 157, 158, 172], "reproduc": [6, 64, 65, 69, 71, 89, 97, 159, 160], "reptil": [111, 112], "republ": [111, 112], "republican": [111, 112], "repurpos": [46, 50], "reput": [52, 89, 93], "request": [42, 55, 64, 72, 73, 77, 111, 112, 120, 121, 123, 159, 172, 180, 182, 186], "requir": [1, 4, 6, 8, 9, 12, 37, 38, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 61, 64, 65, 66, 69, 70, 71, 73, 74, 77, 78, 79, 80, 82, 83, 84, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 102, 105, 106, 109, 111, 112, 114, 115, 116, 117, 120, 121, 123, 124, 126, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 144, 145, 146, 147, 148, 150, 151, 152, 157, 159, 160, 161, 162, 163, 164, 167, 169, 170, 171, 172, 179, 185], "required_char": [103, 105], "rerout": [111, 112], "rerun": [29, 35, 136], "resampl": 34, "rescal": [88, 117], "rescu": 126, "research": [0, 1, 5, 6, 8, 9, 11, 38, 47, 49, 52, 53, 54, 55, 59, 77, 83, 86, 87, 88, 91, 92, 93, 96, 97, 98, 100, 109, 111, 112, 114, 116, 117, 118, 121, 122, 126, 129, 134, 141, 148, 151, 152, 154, 169, 173], "resembl": [97, 111, 112], "reserv": [115, 119, 137], "reset": [15, 179, 181], "reset_index": [14, 15, 16, 20, 21, 23, 24, 28, 33, 34], "reshap": [1, 77, 86, 166], "resid": [111, 112], "residenti": [111, 112], "residu": [9, 10, 52, 116, 117], "resign": [111, 112], "resili": [85, 171], "resist": [77, 111, 112], "resiz": 110, "resize_token_embed": 110, "resnet": [9, 117], "resolut": [9, 51, 55, 88, 111, 112, 116, 130, 172], "resolv": [8, 9, 10, 38, 55, 64, 111, 112, 116, 131, 159, 165, 175], "reson": 1, "resou": 107, "resour": [101, 107], "resourc": [6, 20, 23, 30, 45, 46, 49, 50, 51, 52, 53, 55, 59, 60, 62, 63, 64, 65, 71, 74, 75, 77, 81, 83, 88, 89, 91, 93, 95, 98, 101, 105, 107, 109, 111, 112, 116, 132, 136, 137, 150, 156, 159, 160, 163, 166, 169, 172], "respect": [6, 8, 9, 73, 76, 83, 90, 92, 93, 105, 110, 111, 112, 113, 116, 117, 128, 130, 137, 148, 152, 169, 177], "respond": [6, 44, 49, 55, 65, 91, 111, 112, 120, 130, 160, 171], "respons": [8, 9, 10, 12, 42, 46, 49, 50, 57, 59, 60, 61, 62, 63, 64, 65, 72, 83, 84, 85, 88, 91, 92, 93, 97, 98, 100, 111, 112, 116, 130, 134, 147, 159, 160, 164, 167, 169, 171, 172], "responsibli": [12, 130], "rest": [10, 50, 52, 61, 71, 73, 77, 95, 97, 110, 111, 112, 130, 133, 145, 152], "restart": [132, 135, 136, 141, 150], "restaur": [111, 112, 139], "restock": 100, "restor": [64, 66, 105, 111, 112, 140, 159, 173, 174, 176, 180, 181], "restraint": [111, 112], "restrict": [8, 49, 82, 83, 111, 112, 115, 121], "resu": 101, "resul": 101, "result": [2, 4, 6, 7, 9, 16, 17, 19, 21, 25, 37, 38, 42, 43, 46, 49, 50, 52, 53, 55, 57, 60, 65, 73, 77, 78, 84, 88, 89, 90, 92, 93, 96, 97, 100, 101, 102, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 119, 120, 128, 130, 132, 133, 135, 136, 137, 139, 141, 142, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 166, 171, 172, 173, 177, 181, 183], "resum": 59, "resurg": [111, 112], "reta": 101, "retail": [12, 26, 27, 101, 111, 112, 152], "retain": [9, 49, 50, 51, 52, 88, 102, 106, 111, 112, 116, 117, 120, 140, 183], "retain_graph": 128, "retard": [111, 112], "retarget": 6, "retent": [49, 52], "reti": 101, "retina": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 114, 128, 145, 149, 150], "retir": [101, 166], "retrain": [9, 46, 71, 74, 83, 111], "retreat": 152, "retrench": 119, "retriev": [1, 9, 42, 46, 47, 49, 59, 74, 95, 98, 123, 124, 130, 140, 147, 148, 150, 151, 153, 155, 157], "retrievechat": 42, "retroflex": [111, 112], "retrospect": [111, 112, 171], "rett": [111, 112], "return": [20, 52, 72, 73, 81, 88, 97, 100, 101, 104, 105, 107, 108, 110, 111, 112, 113, 114, 124, 127, 128, 130, 132, 133, 135, 136, 141, 145, 150, 152, 178], "return_num_sequ": 97, "return_parent_dir": 17, "return_special_tokens_mask": 112, "return_tensor": [97, 100, 114], "return_x_i": 149, "reus": [0, 42, 62, 103, 111, 112, 115, 120, 136, 152], "reusabl": [38, 64, 159, 164], "reuter": [122, 152], "reveal": [9, 52, 59, 77, 95, 97, 111, 112, 116, 128, 130, 138, 148, 151, 171, 172], "reven": 101, "revenu": [101, 111, 112, 152], "revers": [9, 10, 52, 79, 101, 105, 107, 108, 111, 112, 124, 134, 137, 139, 149, 155], "reversibli": 105, "revert": [64, 159, 176, 177, 179], "review": [0, 46, 47, 64, 67, 68, 93, 98, 100, 110, 111, 112, 122, 130, 134, 135, 136, 137, 138, 148, 159, 165, 166, 171, 172, 173, 178], "revis": [89, 100, 111, 112, 129, 172, 174, 178, 181, 183, 184], "revisit": [50, 97, 172], "reviv": [111, 112], "revolut": [97, 111, 112], "revolution": [5, 50, 52, 53, 83, 91, 116, 130, 138], "revolutionari": [111, 112], "revolv": 171, "reward": [46, 49, 51, 54, 89, 92, 130], "rework": 172, "rewrit": [111, 112, 132, 183], "reynold": [111, 112], "rf": [107, 177, 184, 185], "rfou": 0, "rgb": [6, 7, 116], "rgi": 107, "rh": 32, "rhyme": [111, 112], "rhythmic": [111, 112], "ri": 101, "rice": [130, 133], "rich": [6, 55, 64, 93, 106, 115, 126, 130, 137, 154, 159], "richard": [0, 111, 112], "richer": [10, 49, 52, 126], "richest": 130, "rickwood": [111, 112], "rico": 0, "rid": [128, 175, 177], "ride": [3, 10, 111, 112, 117], "ridg": [111, 112], "ridgelin": [111, 112], "rifl": 120, "rig": 6, "righ": 107, "right": [24, 45, 50, 67, 68, 71, 88, 97, 98, 101, 102, 106, 111, 112, 113, 120, 128, 130, 132, 136, 144, 145, 147, 154, 165, 173, 176, 177, 178, 180, 185], "right_index": [31, 33, 34], "rightarrow": 117, "rigid": [111, 112, 171, 172], "rigidli": 166, "rigor": [12, 13, 55, 89, 166, 167, 172], "rilei": [111, 112], "ring": [111, 112], "rinoh": 181, "rinohtyp": 181, "riot": [111, 112], "rip": 101, "rise": [0, 3, 5, 44, 49, 56, 101, 111, 112, 138, 139, 140, 152, 156], "rishi": 0, "risk": [0, 1, 24, 41, 50, 52, 59, 63, 64, 65, 71, 74, 77, 85, 86, 92, 93, 98, 111, 112, 120, 121, 130, 132, 152, 159, 160, 166, 169, 171, 172, 183], "riski": [85, 119, 166, 172], "risperidon": [111, 112], "ritual": [111, 112], "ritualist": [111, 112], "rival": [111, 112, 119], "rivalri": 151, "river": [99, 111, 112, 129, 130], "riverchas": [111, 112], "rket": 107, "rl": [46, 53, 54, 92], "rlhf": [1, 49, 91, 96], "rm": [61, 79, 177, 181, 184, 185], "rm_top": 152, "rmi": 61, "rmsprop": 109, "rmtree": 173, "rn50x16": 9, "rn50x4": 9, "rn50x64": 9, "rning": 107, "rnn": [12, 91, 99, 114, 116, 130, 134, 146], "ro": [95, 101], "road": [111, 112], "roadblock": 12, "roadmap": [89, 166, 167, 169], "robert": [0, 99, 111, 112, 120], "roberta": [51, 95, 98, 108, 109, 117, 138], "robi": [111, 112], "robinson": 133, "robot": [1, 4, 5, 6, 53, 54, 59, 89, 91, 121], "robust": [6, 9, 12, 38, 41, 42, 50, 53, 54, 55, 59, 60, 71, 76, 77, 78, 79, 83, 89, 92, 105, 106, 115, 120, 122, 130, 137, 140, 147, 166, 167, 168, 169], "robustli": 99, "rob\u00e9": [111, 112], "rock": [3, 111, 112], "rocket": [111, 112], "rocketship": 10, "rocki": [111, 112, 128], "rod": 156, "roderbh15": 0, "rodrigo": [111, 112], "rodu": 107, "roger": [111, 112], "roi": [111, 112, 167], "rojava": [111, 112], "role": [2, 5, 6, 37, 42, 44, 46, 50, 52, 53, 54, 55, 57, 63, 71, 74, 76, 77, 78, 89, 92, 97, 111, 112, 116, 122, 126, 130, 131, 138, 140, 144, 146, 147, 150, 155, 164, 167, 170], "rolex": [111, 112], "roll": [32, 64, 71, 111, 112, 159, 166, 174], "rollback": [64, 159, 173], "rollout": [64, 159, 169], "rom": 101, "roman": [111, 112], "romanian": 95, "romantic": [111, 112], "romero": 0, "roof": [111, 112, 120], "rooftop": [111, 112], "room": [9, 52, 72, 81, 111, 112, 115, 145], "root": [17, 21, 52, 81, 104, 111, 112, 128, 130, 139, 140, 142, 146, 147, 150, 174], "rosa": [0, 95], "rose": [16, 111, 112, 119, 152], "rosenwald": [111, 112], "rotat": [8, 9], "rou": 101, "roug": [55, 111, 112], "rough": [6, 101, 111, 112, 136], "roughli": [9, 111, 112, 184], "roun": [101, 107], "round": [3, 83, 111, 112], "rout": [46, 72, 82, 111, 112], "routin": [111, 112], "row": [14, 15, 16, 19, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 116, 119, 125, 126, 128, 136, 150, 151, 157, 158], "row_num": 32, "rp": [107, 144], "rpf": 14, "rporat": 107, "rporati": 107, "rporatio": 107, "rrb": 144, "rsa": [77, 78], "rsale": 23, "rsales_d": 23, "rsales_diff_prev": [23, 25, 26, 27, 28], "rsales_diff_year": [23, 25, 26, 27, 28, 29, 33, 35], "rsdai": 108, "rsn20": 0, "rsr": 0, "rstrip": 124, "rsync": 66, "rtc": 181, "rtner": 107, "rtunit": 145, "rtx": 112, "ru": [95, 101, 136], "rubber": [111, 112], "rubella": [111, 112], "rubi": [65, 160], "rubrix": [16, 19], "rui": 0, "rule": [5, 30, 44, 49, 53, 54, 57, 90, 91, 96, 105, 111, 112, 120, 129, 130, 132, 134, 135, 137, 139, 140, 150, 151], "ruler": [111, 112], "rumin": [111, 112], "rump": 108, "run": [6, 14, 16, 17, 19, 21, 22, 29, 30, 35, 45, 51, 53, 62, 69, 71, 72, 76, 79, 80, 81, 88, 97, 100, 103, 105, 110, 111, 112, 114, 115, 119, 123, 132, 133, 135, 136, 141, 146, 150, 152, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "run_auto": 69, "runc": 60, "runic": [111, 112], "runner": 72, "runtim": [60, 62, 64, 80, 88, 110, 112, 159], "runtimeclass": 60, "runtimeerror": 152, "rural": [16, 111, 112], "rush": [111, 112], "russ": 0, "russel": [111, 112], "russia": [111, 112], "russian": [95, 111, 112, 115], "rust": 107, "rvic": 107, "rvice": 107, "ry": 101, "rych": 150, "rzp": 0, "r\u00f6der": 147, "s3": 38, "s_": 128, "s_i": 147, "sa": 88, "saanich": [111, 112], "sabotag": [111, 112], "sac": [111, 112], "sack": [111, 112], "sad": [3, 130, 134], "saddl": 129, "safe": [3, 14, 92, 151, 171, 176], "safeguard": [1, 38, 59, 74, 77, 78, 130], "safer": [52, 63, 77, 85], "safeti": [50, 83, 92, 111, 112], "sagemak": 71, "sagwa": 130, "sahara": [111, 112], "sai": [94, 111, 112, 128, 130, 133, 152, 174, 177], "said": [111, 112, 136, 139, 145, 150, 152, 156, 176, 180], "saisana": 37, "saito": [0, 6, 151], "sake": 112, "sal": 101, "sala": 0, "salakhutdinov": [0, 99], "sale": [12, 26, 27, 101, 111, 112, 152, 167], "saliman": 99, "saltstack": [64, 65, 159, 160], "saltwat": [111, 112], "sam": [7, 132], "same": [6, 8, 9, 10, 52, 55, 64, 66, 71, 77, 78, 88, 95, 97, 99, 100, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115, 116, 117, 119, 121, 124, 126, 128, 130, 133, 135, 137, 139, 140, 142, 143, 145, 146, 147, 151, 152, 155, 156, 157, 158, 159, 173, 175, 178, 181, 183], "same_network": 51, "samford": [111, 112], "samoan": 95, "sampa": [111, 112], "sampl": [0, 6, 9, 10, 21, 28, 75, 84, 88, 90, 94, 101, 103, 105, 107, 108, 111, 112, 115, 121, 130, 132, 134, 136, 143, 151, 152], "sample_data": 94, "sample_hdp_model": 152, "sample_output": 97, "sample_review": 136, "sample_s": 94, "sample_sent": 103, "sampling_method": 95, "samsung": 123, "samuel": 0, "san": [28, 83, 139], "sanitari": [111, 112], "sanja": [0, 6], "santa": [111, 112], "sarcasm": 134, "sasanian": [111, 112], "sat": [132, 153], "satellit": [40, 111, 112, 150], "satisfact": [134, 171, 172], "satisfactori": 45, "satisfi": [6, 10, 132, 135, 136, 141, 150], "satur": 10, "saturn": [111, 112], "sauc": 46, "saunder": [0, 6], "sausag": 158, "savant": [111, 112], "save": [14, 15, 16, 20, 21, 22, 24, 28, 29, 30, 35, 46, 50, 60, 63, 73, 76, 79, 80, 82, 89, 99, 103, 105, 115, 145, 150, 163, 172, 175, 178, 181, 183], "save_a": 17, "save_data": [14, 15, 16, 17, 21, 23, 24, 26, 27, 30, 31, 33], "save_datafram": [15, 24, 30], "save_dir": 152, "save_html": 152, "save_model": [111, 112, 124], "save_path": 152, "save_pr": 20, "save_pretrain": [110, 111, 112], "save_step": [111, 112], "save_total_limit": [111, 112], "saved_path": 73, "savvi": 54, "saw": [23, 53, 111, 112, 113, 130, 133, 152], "saxon": [111, 112], "sc": [101, 111, 112, 141], "scaffold": 69, "scalabl": [38, 41, 45, 46, 49, 50, 59, 65, 71, 74, 77, 88, 90, 91, 116, 130, 160, 162, 166, 169, 172], "scale": [0, 6, 8, 10, 37, 38, 41, 46, 49, 51, 52, 59, 60, 65, 71, 73, 74, 83, 85, 86, 88, 89, 91, 93, 98, 100, 105, 109, 111, 112, 113, 116, 121, 122, 130, 138, 148, 149, 151, 160, 163, 169], "scan": [77, 111, 112], "scandal": [111, 112], "scanner": 40, "scant": [111, 112], "scarc": [46, 98, 130], "scarciti": 93, "scarlet": 17, "scatter": [73, 111, 112, 116, 128], "scatter_cfg": [25, 32], "scatterplot": [23, 25, 32], "scenario": [12, 42, 46, 50, 52, 54, 55, 57, 59, 62, 77, 93, 115, 126, 140, 147, 151, 154, 172], "scene": [5, 8, 9, 111, 112, 116, 149], "sceptic": [111, 112], "sch": 101, "schaeffer": 128, "schedul": [88, 111, 112, 164], "schema": [38, 71], "scheme": [77, 99], "schizophrenia": [111, 112], "schoen": [0, 6], "scholar": [89, 111, 112], "scholarli": 47, "school": [46, 98, 111, 112, 133], "schoolwork": [111, 112], "schreger": 0, "schwa": [111, 112], "schwedel": 0, "sci": [101, 150], "scienc": [0, 1, 12, 38, 39, 41, 49, 54, 57, 72, 73, 89, 93, 97, 111, 112, 126, 129, 130, 150, 168], "scientif": [46, 49, 88, 93, 111, 112, 121, 130, 151, 162], "scientist": [38, 59, 71, 74, 111, 112], "scikit": [12, 136], "scikit_learn": 150, "scipi": [141, 150], "scm": 70, "scope": [48, 49, 50, 52, 54, 59, 75, 166, 168, 172, 176, 177, 179, 180], "score": [9, 12, 14, 16, 22, 29, 35, 52, 55, 74, 85, 88, 90, 92, 97, 109, 113, 114, 116, 117, 119, 120, 128, 130, 134, 135, 136, 137, 138, 144, 146, 147, 151, 152], "score_ngram": 149, "scot": [111, 112], "scotland": [177, 179, 180, 181], "scott": [0, 120], "scottish": 95, "scrape": [43, 89, 93, 95, 117, 120], "scrapi": [12, 93], "scratch": [46, 72, 91, 101, 102, 108, 109, 111, 112], "scratchpad": 98, "screen": [43, 59, 111, 112, 176, 177, 178], "screener": [111, 112], "screw": 183, "scrip": 101, "script": [6, 36, 43, 45, 49, 51, 61, 64, 66, 71, 79, 80, 83, 95, 111, 112, 115, 121, 122, 136, 144, 155, 159], "scrum": [65, 160, 167, 170], "scrutin": 59, "scrutini": [50, 59], "scrypt": 76, "scullei": [0, 71], "sd": [51, 95], "sdai": [101, 107], "sdlc": [1, 161, 162], "sdsks18": [0, 6], "se": 101, "sea": [3, 17, 101, 111, 112], "seaborn": [94, 136, 149], "seafood": [111, 112], "seal": [64, 159], "seamless": [6, 11, 42, 50, 51, 55, 59, 91], "seamlessli": [42, 51, 91], "seaport": [111, 112], "search": [0, 1, 12, 35, 42, 49, 55, 59, 79, 89, 93, 96, 98, 115, 119, 121, 123, 130, 145, 150, 151, 155, 157], "search_keyword": [14, 16, 17, 19], "searcher": 35, "season": [3, 12, 46, 111, 112, 152], "seat": [111, 112], "seattl": [111, 112], "sebastian": 0, "secc": [111, 112], "seced": [111, 112], "secess": [111, 112], "second": [5, 9, 52, 88, 95, 97, 99, 105, 108, 111, 112, 113, 114, 115, 116, 117, 120, 126, 130, 133, 137, 141, 152, 180, 183, 185], "secondari": [111, 112], "secondary_i": [25, 32], "secondli": [59, 111, 112, 138], "secreci": 77, "secret": [3, 66, 77, 78, 79, 80, 130, 176, 183], "secretari": [30, 111, 112], "secretstr": [30, 31, 32, 33, 34], "sect": [111, 112], "sectarian": [111, 112], "section": [8, 9, 12, 43, 49, 52, 55, 60, 63, 71, 72, 73, 76, 77, 81, 82, 89, 95, 103, 110, 111, 112, 116, 117, 142, 149, 175], "section_id": [24, 30], "secto": 107, "sector": [12, 37, 38, 41, 45, 48, 49, 50, 52, 53, 59, 88, 101, 119, 152, 167], "secular": [111, 112], "secur": [1, 45, 49, 59, 60, 63, 64, 70, 71, 79, 81, 82, 111, 112, 120, 121, 130, 152, 159, 165, 167, 169, 170], "sed": [79, 101], "sedol": 53, "see": [5, 9, 23, 24, 25, 26, 27, 30, 51, 60, 72, 91, 97, 99, 100, 101, 103, 104, 108, 110, 111, 112, 114, 128, 130, 133, 136, 142, 143, 152, 173, 175, 176, 177, 178, 180, 185], "seed": [14, 20, 97, 101, 103, 105, 106, 107, 108, 152], "seed_sentencepiece_s": [103, 105], "seek": [50, 76, 111, 112, 130], "seekabl": 76, "seem": [97, 111, 112, 114, 132, 136, 139, 144, 147, 149, 150, 177], "seen": [8, 57, 59, 89, 93, 95, 97, 98, 100, 111, 112, 113, 119, 126, 128, 132, 133, 139, 151, 152, 156, 178], "seg": [142, 152], "seg_cfg": 24, "segment": [0, 1, 15, 24, 52, 87, 99, 104, 105, 106, 107, 108, 111, 112, 129, 130, 139, 140, 142, 152, 171, 172], "segment_na": 145, "segreg": [111, 112], "seiz": [111, 112], "select": [8, 9, 14, 19, 50, 53, 57, 60, 64, 65, 66, 67, 70, 71, 72, 75, 79, 88, 89, 91, 93, 97, 101, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 126, 129, 131, 132, 133, 137, 147, 151, 159, 160, 167, 168, 176, 178, 183], "selected_category_pr": 19, "selected_polarity_pr": 19, "selenium": [93, 121, 169], "self": [0, 10, 20, 42, 59, 73, 88, 89, 98, 99, 105, 111, 112, 114, 127, 128, 130, 138, 139, 163], "self_attent": 52, "self_attention_adalora": 52, "self_attention_ia3": 52, "self_attention_lora": 52, "self_test_sample_s": [103, 105], "sell": [101, 152], "selma": [111, 112], "semant": [1, 6, 10, 12, 38, 49, 55, 59, 88, 93, 96, 98, 100, 102, 106, 109, 110, 113, 115, 126, 127, 129, 130, 135, 138, 139, 140, 141, 146, 147, 150, 153, 154, 155, 157], "semest": 129, "semi": [42, 44, 59, 111, 112, 122, 123], "semiconductor": 128, "semicurs": [111, 112], "semin": [52, 87], "semistructur": [111, 112], "semit": [111, 112], "sen": [0, 6, 101, 127], "senat": [111, 112], "send": [42, 72, 121, 150], "sender": [76, 77, 78], "seng": 152, "senior": [111, 112, 128], "sennrich": [0, 105, 106], "sens": [57, 96, 100, 102, 111, 112, 114, 116, 129, 130, 137, 148, 150, 153, 156, 157], "sensat": [111, 112, 126], "sensibl": 177, "sensit": [6, 38, 45, 46, 49, 52, 54, 59, 64, 71, 74, 76, 77, 93, 97, 111, 112, 115, 119, 130, 132, 135, 138, 147, 148, 159], "sensor": [6, 9, 12, 40, 41, 44, 89, 111, 112], "sensori": [111, 112], "sent": [77, 127, 132, 133, 142, 144, 155], "sent_id": [24, 30], "sent_token": 142, "sentenc": [10, 32, 52, 91, 92, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 121, 122, 124, 125, 126, 127, 128, 130, 132, 134, 136, 137, 138, 139, 143, 144, 145, 147, 150, 153, 154, 155, 157], "sentence_a": 114, "sentence_b": 114, "sentenceiter": [103, 105], "sentencepiec": [1, 96, 102, 106, 115], "sentencepiece_token": 103, "sentencepiece_tokenizer_path": 103, "sentencepiece_train": [103, 105], "sentencepieceprocessor": [103, 105], "sentencepiecetrain": [103, 105], "sentences_nltk": 142, "sentences_pysbd": 142, "sentient": 130, "sentiment": [1, 21, 36, 37, 40, 41, 46, 50, 75, 93, 98, 100, 109, 111, 112, 113, 117, 118, 119, 120, 122, 126, 129, 130, 132, 138, 151, 153, 154, 156], "sentiment_afinn": 135, "sentiment_analysis_model": 110, "sentiment_map": 136, "sentiment_peft": 51, "sentiment_textblob": 135, "sentiment_vad": 135, "sentimentintensityanalyz": 135, "sentinel": [12, 115], "sentiwordnet": 138, "seo": 115, "seoul": 141, "sep": [20, 21, 103, 104, 108, 111, 112, 114, 152, 174, 175, 180, 184], "sep_token": [111, 112], "separ": [6, 9, 15, 24, 52, 61, 69, 71, 74, 76, 77, 80, 84, 90, 95, 99, 101, 102, 104, 105, 106, 108, 111, 112, 114, 120, 124, 128, 130, 135, 138, 140, 143, 144, 150, 151, 158, 176, 178, 179], "sephard": [111, 112], "sept": 128, "septemb": [111, 112], "seq": 52, "seq_2_seq_lm": 51, "seq_embed": 52, "seq_token": 52, "sequenc": [6, 7, 8, 9, 10, 16, 17, 19, 21, 30, 49, 51, 52, 53, 57, 59, 83, 86, 87, 90, 94, 97, 98, 99, 101, 102, 105, 106, 110, 111, 112, 113, 114, 115, 116, 117, 120, 130, 131, 133, 136, 138, 139, 143, 145, 172, 180], "sequence_classif": 51, "sequenti": [49, 52, 53, 99, 116, 138, 146, 166, 171, 172], "sequestr": [111, 112], "ser": [101, 107], "serbian": 95, "seren": 17, "sergei": [0, 6], "sergio": 0, "seri": [6, 9, 12, 41, 46, 53, 65, 71, 86, 87, 94, 100, 101, 111, 112, 116, 120, 130, 147, 160, 164, 166], "series_id": [23, 34], "series_nam": [23, 34], "serif": [28, 111, 112], "seriou": [111, 112], "serv": [1, 2, 7, 8, 9, 40, 43, 46, 48, 49, 52, 54, 56, 57, 59, 60, 64, 71, 75, 83, 88, 89, 111, 112, 114, 116, 121, 126, 132, 133, 137, 144, 147, 148, 159, 165, 166, 167, 169, 172], "server": [1, 55, 64, 65, 70, 72, 73, 75, 76, 77, 80, 121, 159, 160, 169, 176, 178, 180], "server_ip": [81, 82], "serverless": [38, 73], "servi": [101, 107], "servic": [37, 38, 42, 45, 48, 52, 55, 56, 59, 60, 62, 64, 65, 66, 71, 73, 80, 85, 91, 92, 107, 111, 112, 121, 123, 130, 134, 138, 139, 159, 160, 173], "servisfirst": [111, 112], "session": [0, 56, 63, 81, 87, 94, 110, 111, 112, 119, 135, 136, 171, 177], "set": [5, 6, 8, 9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 30, 38, 42, 44, 46, 49, 50, 51, 52, 55, 57, 59, 60, 61, 66, 68, 71, 72, 75, 78, 79, 82, 84, 88, 89, 91, 95, 97, 98, 100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116, 117, 119, 120, 123, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 142, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 161, 163, 167, 169, 171, 172, 176, 177, 178, 180, 182, 184, 185], "set_format": 110, "set_index": [23, 30, 34], "set_se": 97, "set_titl": 149, "set_verbosity_error": 114, "set_word_prior": 152, "set_workspac": [14, 16, 17, 19, 20, 21, 22], "set_xlabel": 149, "set_xlim": [26, 27], "set_ylabel": 149, "setlogg": [15, 17, 24, 29, 31, 32, 33, 34, 152], "setminu": 119, "settl": [111, 112], "settlement": [43, 111, 112], "settler": [111, 112], "setup": [1, 45, 49, 64, 65, 66, 70, 80, 88, 111, 112, 159, 160], "seung": 151, "seven": [111, 112], "seventeen": [111, 112], "sever": [5, 6, 7, 8, 9, 10, 11, 38, 46, 49, 55, 59, 64, 65, 66, 71, 76, 77, 83, 88, 90, 93, 95, 96, 97, 98, 105, 106, 109, 111, 112, 116, 117, 121, 129, 130, 134, 143, 146, 147, 148, 150, 151, 152, 153, 159, 160, 167, 171, 172, 173, 183], "sewel": [111, 112], "sex": [111, 112], "sexual": [111, 112, 130], "sf": [119, 141, 142], "sfa": [77, 78], "sft": [45, 46], "sfv": 0, "sgd": [109, 128], "sh": [45, 80, 101, 184], "sha": [111, 112], "sha256": 135, "shadow": [16, 17, 111, 112], "shafir": [0, 6], "shakespear": [111, 112], "shall": 156, "shallow": [126, 128], "shap": 12, "shape": [2, 8, 14, 16, 20, 21, 23, 26, 27, 41, 52, 53, 59, 77, 111, 112, 143, 150], "shaplei": 40, "shar": 101, "sharan": 0, "share": [2, 6, 14, 62, 63, 64, 65, 71, 75, 76, 77, 78, 82, 83, 88, 89, 99, 101, 105, 111, 112, 113, 119, 120, 122, 126, 127, 145, 147, 152, 155, 156, 159, 160, 171, 173, 177, 180, 185], "sharegpt": 83, "sharehold": 101, "sharp": [8, 95, 97, 100, 111, 112, 152], "sharpen": 97, "sharper": 97, "sharpli": [8, 111, 112, 120, 152], "shatter": [111, 112], "shawn": 184, "shawne": [111, 112], "shazeer": [0, 99], "shb16": 0, "she": [100, 130], "shed": 152, "sheer": 10, "sheet": [111, 112], "shelbi": [111, 112], "shelf": [88, 100], "shell": [66, 81, 173, 185], "shelter": [111, 112], "sheriff": [111, 112], "shg": 0, "shi": 101, "shield": [111, 112], "shift": [23, 25, 26, 27, 38, 46, 49, 53, 59, 63, 64, 65, 74, 97, 105, 111, 112, 142, 150, 159, 160, 165, 171], "shih": 0, "shihao": [0, 6], "shinewar": 141, "ship": [12, 73, 152], "shippabl": 171, "shiri": [0, 6], "shirt": [111, 112], "shkurti": [0, 6], "shlizerman": [0, 6], "sho": 101, "shoal": [111, 112], "shock": [1, 36, 37, 119, 120], "shock_nam": 34, "shockingli": 10, "shoe": [111, 112], "shomayim": [111, 112], "shona": 95, "shonenkov": [5, 130], "shonenkovai": [5, 130], "shoot": [111, 112], "shop": [100, 111, 112], "shor": 101, "shore": [111, 112], "short": [5, 6, 9, 30, 41, 49, 52, 63, 71, 111, 112, 115, 117, 130, 133, 134, 136, 138, 150, 171, 175, 176], "shortcom": 10, "shortcut": [69, 93], "shorten": [111, 112], "shorter": [9, 46, 88, 104, 111, 112, 115, 126], "shortest": 54, "shorthand": 115, "shot": [0, 1, 8, 10, 47, 51, 53, 57, 88, 96, 97, 98, 109, 115], "should": [1, 4, 8, 14, 16, 17, 22, 30, 37, 41, 45, 50, 51, 60, 68, 74, 76, 77, 81, 84, 89, 91, 92, 93, 96, 97, 99, 100, 101, 103, 106, 107, 108, 109, 110, 111, 112, 121, 126, 128, 129, 130, 132, 136, 139, 146, 150, 152, 155, 164, 165, 166, 167, 169, 170, 171, 172, 173, 175, 176, 177, 180, 183, 185], "show": [3, 6, 29, 35, 52, 53, 72, 79, 94, 96, 97, 99, 100, 105, 111, 112, 113, 114, 115, 116, 117, 120, 128, 129, 130, 132, 136, 139, 149, 150, 151, 152, 155, 171, 173, 180, 181, 183], "show_progress": 112, "show_result": [29, 35], "show_top": 150, "showcas": [12, 42, 89, 93, 98, 111, 112, 116], "showinlin": 21, "shown": [42, 50, 83, 90, 97, 100, 103, 109, 111, 112, 116, 130, 138, 176], "shri": [111, 112], "shrink": 117, "shrinking_factor": [103, 105], "shuffl": [14, 20, 28, 95, 101, 107, 108, 117], "shuffle_input_sent": [103, 105], "shutil": 173, "shuttl": [111, 112], "shuttlesworth": [111, 112], "si": [95, 101, 111, 112, 145], "siberia": [111, 112], "sibl": [111, 112], "sick": [111, 112], "siddhant": 0, "side": [88, 98, 111, 112, 121, 145, 172, 178, 180], "siden": 101, "sider\u00fargica": [111, 112], "siefka": 184, "sift": 49, "sigal": [0, 6], "sight": 116, "sigkdd": 0, "sigma": [128, 132, 151], "sigmoid": [88, 128], "sign": [1, 12, 64, 70, 78, 111, 112, 114, 159, 164, 176], "signal": [0, 9, 12, 40, 46, 49, 88, 111, 112, 120, 128, 151], "signatur": [76, 78, 114], "signifi": [9, 53, 57, 59, 116, 147], "signific": [1, 2, 5, 6, 8, 9, 40, 41, 42, 44, 46, 49, 52, 53, 54, 55, 57, 59, 71, 74, 77, 91, 92, 93, 97, 98, 102, 105, 109, 111, 112, 113, 115, 116, 118, 119, 126, 130, 138, 140, 143, 150, 157, 171, 172], "significantli": [6, 42, 45, 46, 50, 52, 54, 74, 77, 86, 91, 93, 95, 97, 98, 100, 102, 111, 112, 115, 116, 119, 120, 130, 137, 146, 166, 171, 172], "signingkei": 76, "signup": [5, 130], "sikhism": [111, 112], "sil": 101, "silent": [111, 112], "silicon": [51, 111, 112], "silli": 175, "silo": [63, 65, 160], "silver": [53, 152], "silveri": 16, "sim": [84, 97, 105, 111, 112, 147], "sim_": 157, "similar": [1, 2, 5, 8, 9, 10, 38, 52, 53, 54, 55, 59, 66, 71, 76, 84, 88, 97, 98, 100, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 125, 126, 128, 129, 133, 138, 143, 145, 146, 149, 150, 151, 154, 158, 174], "similarli": [6, 64, 98, 106, 111, 112, 114, 116, 117, 128, 137, 139, 147, 157, 159], "simmon": [111, 112], "simpl": [1, 6, 7, 8, 14, 16, 17, 22, 42, 44, 50, 53, 57, 64, 65, 70, 71, 72, 73, 77, 78, 88, 91, 96, 97, 104, 105, 108, 111, 112, 113, 114, 118, 129, 130, 132, 133, 135, 136, 137, 138, 139, 140, 141, 147, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 166, 171, 173], "simpleclassif": [14, 16, 22], "simpler": [8, 60, 76, 126, 139, 150, 151], "simplest": [102, 118, 153, 154], "simpletoken": 152, "simpletransform": [14, 22], "simpli": [2, 10, 20, 26, 27, 69, 72, 88, 97, 101, 108, 111, 112, 123, 132, 136, 150, 158], "simplic": [60, 73, 76, 153, 171], "simplif": [98, 132], "simplifi": [8, 9, 42, 56, 59, 60, 61, 62, 64, 65, 66, 74, 76, 77, 88, 98, 105, 112, 117, 123, 126, 128, 132, 148, 150, 151, 159, 160, 164, 166], "simplist": [97, 111, 112], "simul": [6, 53, 55, 88, 89], "simultan": [8, 55, 59, 72, 88, 111, 112, 113, 116, 172], "sinait": [111, 112], "sinc": [6, 9, 10, 24, 36, 46, 52, 59, 64, 77, 80, 88, 97, 100, 105, 111, 112, 113, 115, 116, 117, 119, 121, 123, 124, 125, 128, 130, 132, 140, 147, 150, 152, 153, 159, 183], "sindhi": 95, "sine": [111, 112, 116], "sing": 101, "singl": [6, 8, 9, 20, 21, 51, 52, 55, 57, 61, 64, 66, 69, 71, 73, 77, 78, 88, 100, 101, 105, 106, 111, 112, 113, 115, 116, 117, 122, 126, 128, 132, 134, 139, 141, 143, 147, 149, 152, 158, 159, 177, 183], "singular": [52, 111, 112, 122, 130, 139, 140], "sinhala": 95, "sink": 118, "sion": 101, "siri": [49, 130], "sit": [8, 111, 112, 128, 136, 145], "site": [28, 30, 100, 101, 103, 108, 110, 111, 112, 114, 121, 132, 135, 136, 139, 141, 150, 172, 178], "siti": 101, "situat": [8, 36, 52, 100, 111, 112, 120, 130, 133, 136, 157, 171], "six": [111, 112, 115, 120, 136, 141, 167], "sixteen": [111, 112], "sixteenth": [111, 112], "sixth": [111, 112], "sixti": [111, 112], "sizabl": [50, 115], "size": [9, 10, 15, 16, 17, 20, 24, 30, 38, 41, 42, 45, 46, 49, 50, 51, 52, 53, 59, 74, 77, 83, 88, 95, 97, 103, 105, 106, 107, 108, 110, 111, 112, 115, 116, 121, 124, 125, 126, 128, 130, 132, 133, 135, 136, 139, 143, 146, 147, 151, 152, 153, 154, 155, 156, 163, 164, 166, 171], "size_in_byt": [17, 22, 28], "size_in_human_byt": [17, 22, 28], "sk": [15, 19, 51, 95, 107], "skeleton": [6, 69], "sketch": 169, "skew": [97, 147], "ski": [111, 112], "skill": [0, 37, 42, 46, 49, 64, 67, 70, 71, 80, 85, 87, 89, 97, 100, 111, 112, 120, 121, 130, 159, 163, 167, 169, 172, 186], "skin": [88, 111, 112], "skinni": 150, "skip": [9, 103, 116, 117, 124, 154, 175, 177], "skip_gram": 128, "skip_special_token": [97, 100], "skipgram": [124, 128], "skipgram_test": 128, "skipgrammodel": 128, "skipna": 31, "sklearn": [28, 73, 126, 135, 136, 143, 149, 150, 158], "sklearnmodelartifact": 73, "skool": [111, 112], "skt": 14, "sky": [3, 111, 112, 158], "skyflow": 59, "sk\ub294": [15, 19], "sk\uc774\ub178\ubca0\uc774\uc158": 16, "sk\uc774\ub178\ubca0\uc774\uc158\uc740": 16, "sk\ud558\uc774\ub2c9\uc2a4": [16, 19], "sk\ud558\uc774\ub2c9\uc2a4\ub294": 19, "sl": [92, 95, 101], "slam": 133, "slang": [46, 91, 102, 115, 145], "slant": [111, 112], "slate": 139, "slave": [111, 112], "slaveri": [111, 112], "sldamodel": 152, "sleep": [111, 112], "sleev": [111, 112], "slept": [111, 112], "slerp": 9, "sli": 101, "slice": 151, "slide": [6, 101, 147], "slight": [46, 111, 112], "slightli": [9, 84, 105, 111, 112, 117, 128], "slim": 61, "slimi": 183, "slithi": 183, "slovak": 95, "slovenian": 95, "slow": [49, 99, 103, 111, 112, 117, 120, 121, 141], "slowdown": 115, "slower": [77, 112, 116, 121, 125], "slowli": [10, 111, 112], "slp3": 129, "slump": [108, 152], "sm": [14, 22, 77, 78, 95, 101], "sm_inval": 14, "sm_pol": 14, "sm_topic": 14, "sma": 107, "small": [8, 9, 10, 49, 50, 52, 65, 68, 71, 80, 84, 88, 95, 97, 98, 100, 101, 104, 105, 109, 111, 112, 113, 114, 115, 117, 125, 128, 130, 133, 139, 147, 150, 151, 153, 157, 158, 160, 171, 175, 178], "smaller": [8, 9, 25, 42, 46, 49, 50, 52, 57, 59, 62, 69, 74, 76, 83, 88, 97, 98, 100, 102, 105, 106, 109, 111, 112, 116, 117, 126, 130, 132, 139, 142, 143, 145, 163, 172], "smallest": [97, 130, 140], "smangrul": 51, "smart": [9, 40, 49, 77, 78, 120, 167, 169, 170], "smarter": 130, "smartphon": [111, 112, 120], "smell": 116, "smi": 112, "smile": [111, 112], "smith": [120, 139], "smoke": [111, 112], "smola": 99, "smooth": [6, 8, 16, 80, 89, 95, 111, 112, 132], "smoothli": 6, "smt": [14, 22], "smtp": 77, "smyth": 152, "sn": [15, 94, 95, 107, 136, 149], "snake": [111, 112], "snapshot": [60, 62, 121, 185], "snapshott": 60, "sne": [55, 95, 138, 148], "sne\ub9ac\uc11c\uce58\ub294": 16, "snippet": [6, 49, 51, 52, 57, 97, 130, 142, 143, 150], "snorkel": 59, "snow": [3, 111, 112], "snowdon": [177, 180, 181], "snowfal": [111, 112], "snowmelt": [111, 112], "snowpack": [111, 112], "snowstorm": [111, 112], "so": [8, 10, 14, 25, 51, 53, 57, 59, 67, 72, 77, 88, 95, 97, 100, 101, 104, 106, 108, 110, 111, 112, 113, 114, 117, 118, 120, 126, 127, 128, 130, 132, 136, 139, 140, 143, 144, 146, 147, 149, 152, 153, 154, 155, 156, 167, 171, 173, 174, 175, 176, 177, 178, 180, 183, 185], "soc": [59, 120], "socher": 0, "social": [5, 40, 41, 44, 46, 83, 85, 93, 97, 98, 111, 112, 115, 118, 120, 121, 126, 130, 134, 135, 137, 141, 148, 151], "socialist": [111, 112], "societ": [1, 53, 89, 92, 111, 112], "societi": [2, 92, 97, 111, 112, 130], "socioeconom": [111, 112], "sock": 60, "socket": [77, 78], "socrat": [111, 112], "sof": 101, "soft": [8, 12, 13, 88, 179], "soft_prompt": 52, "softeng": [173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "softmax": [8, 52, 97, 113, 116, 127], "softwar": [1, 6, 38, 42, 49, 59, 61, 63, 64, 65, 69, 70, 71, 73, 77, 82, 89, 97, 111, 112, 121, 129, 150, 159, 160, 162, 168, 177, 178, 180, 185, 186], "soil": [111, 112, 147], "sol": 101, "solar": [111, 112], "sold": [100, 111, 112], "soldier": [111, 112], "sole": [9, 77, 83, 111, 112, 116, 134, 144, 167], "solicit": 133, "solid": [14, 80, 89, 111, 112, 130, 136, 139], "solidar": [111, 112], "solidifi": 97, "solo": [1, 161, 186], "solut": [6, 12, 38, 39, 41, 42, 44, 45, 46, 50, 52, 55, 59, 60, 61, 62, 64, 65, 76, 77, 86, 89, 97, 116, 126, 151, 159, 160, 166], "solv": [37, 42, 44, 50, 53, 57, 65, 71, 73, 77, 85, 88, 89, 96, 97, 100, 112, 114, 128, 129, 130, 145, 146, 160, 161, 163, 165, 167, 170], "solvent": [111, 112], "solver": 6, "somali": 95, "some": [2, 5, 8, 9, 10, 11, 12, 14, 16, 17, 22, 42, 46, 49, 60, 62, 64, 66, 69, 71, 73, 74, 76, 77, 83, 85, 88, 89, 91, 93, 94, 95, 97, 98, 99, 100, 102, 103, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 128, 129, 130, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 147, 148, 149, 150, 151, 152, 156, 157, 159, 173, 174, 175, 177, 179, 180, 182, 183, 185], "somefil": 173, "somenam": 185, "someon": [111, 112, 173, 183, 185], "someth": [5, 56, 77, 78, 107, 108, 111, 112, 130, 136, 139, 156, 173, 174, 182], "sometim": [9, 23, 50, 54, 84, 97, 111, 112, 116, 130, 132, 136, 140, 142, 178, 181], "somewhat": [24, 30, 49, 111, 112, 136], "somewher": 150, "son": 101, "song": 149, "soni": 152, "soohyon": 0, "soon": [5, 83, 111, 112, 130], "sooner": 172, "soot": [111, 112], "sop": [1, 66, 70], "sophist": [12, 13, 44, 53, 54, 55, 77, 85, 90, 93, 113, 116, 130, 147, 153, 154, 172], "sophocl": [111, 112], "sorghum": [111, 112], "sort": [10, 101, 106, 107, 108, 123, 139, 147, 149, 155], "sort_top": 152, "sorted_pmi": 155, "sorted_ppmi": 155, "sorted_scor": [107, 108], "sorted_subword": [107, 108], "sorted_token": 101, "sota": [6, 51], "sotho": 95, "soto": [111, 112], "sou": 101, "sought": [111, 112, 116], "sound": [2, 50, 90, 91, 97, 102, 111, 112, 130, 139, 140], "soup": 123, "sourc": [0, 1, 6, 13, 15, 36, 37, 38, 41, 42, 52, 55, 57, 59, 60, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 80, 83, 84, 91, 93, 95, 97, 98, 105, 107, 111, 112, 114, 116, 120, 123, 124, 130, 134, 150, 159, 160, 169, 170, 173, 176, 178, 181, 184], "south": [0, 83, 111, 112, 123, 178], "southeast": [111, 112], "southeastern": [111, 112], "southern": [95, 111, 112], "southernmost": [111, 112], "southwest": 178, "soviet": [111, 112], "soybean": [111, 112], "sp": 101, "sp500": 34, "space": [0, 7, 9, 51, 53, 55, 59, 88, 97, 101, 102, 105, 106, 111, 112, 115, 116, 124, 126, 130, 132, 136, 138, 139, 140, 141, 143, 145, 148, 150, 151, 153, 156, 157, 177], "space_token": 101, "space_token_len": 101, "spaci": [144, 146], "spain": [111, 112], "spam": [46, 98, 117, 130], "span": [9, 12, 32, 49, 77, 95, 115, 119], "span_arg": 32, "spanish": [0, 49, 93, 95, 111, 112, 115, 122, 130], "spare": 97, "spark": [2, 38], "spars": [8, 53, 55, 88, 111, 112, 115, 126, 151, 153, 154, 155, 157, 158], "sparsiti": [55, 132, 133, 138, 151], "spatial": [8, 9, 10, 49, 116, 121, 126, 138, 148, 156], "spatio": 6, "spawn": 79, "spe": 101, "speak": [111, 112, 130], "speaker": [23, 24, 25, 26, 27, 30, 31, 93, 130], "spearhead": 59, "speci": [3, 6, 111, 112], "special": [6, 8, 10, 12, 38, 42, 44, 45, 46, 47, 49, 50, 52, 53, 55, 56, 57, 59, 64, 88, 89, 101, 104, 105, 106, 109, 111, 112, 114, 115, 125, 133, 143, 146, 151, 159, 168, 177, 182], "special_token": [103, 111, 112], "special_tokens_map": [111, 112], "special_tokens_mask": 112, "specialist": [111, 112, 136], "specif": [6, 8, 9, 12, 30, 37, 38, 41, 42, 44, 45, 46, 52, 53, 55, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 71, 74, 76, 80, 82, 84, 86, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 126, 128, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 144, 145, 146, 147, 151, 152, 156, 157, 158, 159, 160, 164, 166, 168, 169, 171, 172, 174, 178, 180], "specifi": [16, 17, 19, 21, 30, 43, 44, 45, 52, 60, 61, 64, 82, 89, 95, 100, 101, 103, 104, 105, 110, 111, 112, 114, 121, 123, 148, 149, 150, 159, 164, 165, 170, 176, 185], "spectral": [111, 112, 126, 150], "spectrum": [46, 50, 52, 111, 112, 113, 126, 172], "specul": [52, 111, 112], "specular": [111, 112], "specularli": [111, 112], "speech": [1, 36, 43, 50, 55, 111, 112, 116, 121, 122, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 143, 145, 146], "speech2text": 72, "speed": [6, 55, 59, 64, 71, 111, 112, 115, 121, 126, 133, 149, 159, 169], "speedup": 117, "spell": [9, 98, 99, 102, 104, 111, 112, 115, 131, 141, 143, 175], "spend": [12, 111, 112, 119, 150], "spent": [46, 111, 112], "sperm": [111, 112], "spermatophyt": [111, 112], "sphere": [111, 112], "spheric": [8, 9], "spider": 121, "spike": 119, "spin": 6, "spiral": 170, "spite": [111, 112], "splash": [111, 112], "splinter": [111, 112], "split": [14, 15, 16, 17, 20, 21, 22, 28, 30, 33, 71, 76, 94, 95, 101, 102, 104, 105, 106, 107, 110, 111, 112, 124, 126, 127, 128, 136, 138, 139, 141, 143, 144, 145, 146, 150, 152], "split_by_numb": [103, 105], "split_by_unicode_script": [103, 105], "split_by_whitespac": [103, 105], "split_digit": [103, 105], "split_kei": [15, 24], "split_sampl": [16, 20, 28, 33], "split_sent": 141, "splunk": [65, 160], "spm": [103, 105], "spoke": [111, 112], "spoken": [49, 93, 121, 130], "spontan": [111, 112], "sport": [6, 59, 111, 112, 130, 151], "spot": [1, 91, 96, 173], "spracklen": [111, 112], "spread": [90, 111, 112, 120, 172], "spreadsheet": 169, "spring": [111, 112], "springenberg": 0, "springer": [0, 37, 129], "sprint": [167, 169, 171], "spun": [5, 183], "spur": [42, 111, 112], "spuriou": [88, 93], "sq": 95, "sql": 12, "sqrt": [143, 148, 157], "squad": [117, 122], "squar": [52, 88, 111, 112, 114, 125, 148, 151, 184], "squash": 112, "squat": [111, 112], "squeez": [51, 127], "sr": [23, 95, 111, 112, 166, 169], "src_text": 30, "srf": 14, "ss": 101, "ssab": [111, 112], "sse2": 152, "sset": 107, "ssh": [1, 66, 70, 75, 78], "ssion": 101, "ssl": [72, 77, 78, 82], "sso": 77, "ssri": [111, 112], "st": [95, 97, 101, 106, 107, 111, 112, 117], "sta": [101, 107], "stabil": [5, 52, 59, 130, 138, 169, 171, 172], "stabilis": [111, 112], "stabilityai": 51, "stabl": [5, 51, 69, 88, 100, 101, 103, 108, 110, 111, 112, 114, 130, 136, 150, 171, 172], "stable_diffus": 51, "stack": [1, 8, 9, 12, 47, 56, 60, 64, 65, 113, 115, 116, 152, 159, 160, 167, 169, 170], "stack_llama": 51, "stackgan": 11, "stadium": [111, 112, 133], "staf": 169, "staff": [136, 167, 170], "stage": [6, 9, 40, 46, 49, 55, 63, 64, 71, 80, 88, 105, 109, 111, 112, 130, 159, 164, 165, 167, 169, 170, 172, 176, 179, 181], "stai": [52, 63, 65, 74, 77, 78, 93, 118, 130, 136, 151, 160, 167, 171, 175], "stainless": [111, 112], "stake": [111, 112], "stakehold": [92, 98, 165, 166, 167, 169, 170, 171], "stalagmit": [111, 112], "stale": 93, "stalin": [111, 112], "stamp": [57, 167], "stanc": 137, "stand": [6, 9, 46, 49, 50, 52, 59, 69, 104, 111, 112, 113, 116, 125, 126, 139, 143, 171, 173], "standalon": [44, 60, 61, 62, 172], "standard": [6, 9, 28, 38, 41, 45, 46, 59, 60, 66, 67, 71, 73, 74, 76, 77, 78, 97, 104, 105, 110, 111, 112, 114, 115, 116, 117, 130, 132, 136, 139, 142, 144, 146, 163, 165, 172], "stanford": [83, 122, 125, 129, 154], "stanlei": 85, "stapl": [6, 53], "star": [1, 3, 22, 47, 53, 101, 111, 112, 136], "start": [9, 10, 14, 16, 17, 19, 20, 21, 22, 32, 46, 50, 52, 59, 62, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 88, 89, 93, 94, 96, 97, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 116, 117, 124, 125, 128, 129, 130, 132, 133, 136, 139, 142, 148, 150, 154, 155, 159, 160, 164, 167, 171, 172, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186], "start_idx": [107, 108], "start_index": 152, "start_year": [30, 31, 32, 33, 34], "starter": 72, "startswith": 108, "startup": 59, "stat": [17, 20, 28], "state": [0, 6, 8, 10, 42, 50, 52, 53, 54, 64, 65, 66, 71, 77, 85, 88, 89, 98, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 130, 134, 138, 151, 152, 156, 159, 160, 166, 167, 168, 170, 171, 172, 177, 179, 180, 181, 183, 184], "statehood": [111, 112], "stateless": [73, 111, 112], "statement": [30, 31, 32, 36, 55, 134, 139, 167, 169, 172], "statewid": [111, 112], "static": [51, 55, 57, 99], "station": [111, 112], "statist": [5, 20, 28, 37, 48, 49, 53, 71, 98, 107, 111, 112, 121, 126, 130, 132, 140, 145, 146, 147, 154, 157, 158, 167], "statsmodel": 12, "statu": [14, 16, 17, 19, 60, 80, 111, 112, 130, 171, 173, 176, 181, 184], "std": [25, 132], "ste": 101, "steadi": [111, 112], "steadili": 1, "steel": [111, 112], "steelmak": [111, 112], "steep": [111, 112], "steer": 9, "stem": [9, 59, 91, 104, 130, 136, 137, 138, 140, 142, 148, 150, 152], "step": [1, 6, 9, 42, 49, 52, 53, 54, 55, 57, 64, 67, 72, 73, 75, 76, 77, 81, 82, 85, 88, 89, 92, 95, 96, 97, 100, 102, 104, 105, 106, 109, 110, 111, 112, 113, 116, 117, 120, 130, 132, 133, 136, 138, 139, 140, 144, 146, 147, 150, 151, 152, 153, 155, 156, 159, 161, 165, 168, 184], "stephan": 0, "stephen": [0, 111, 112], "stepwis": 95, "stereotyp": [83, 93, 111, 112, 130], "steve": [111, 112], "steven": 0, "stew": 156, "stewart": 0, "stick": 6, "stigma": [111, 112], "still": [6, 10, 40, 50, 51, 69, 93, 97, 111, 112, 114, 116, 124, 126, 130, 132, 133, 135, 136, 139, 149, 152, 156, 172, 175, 176, 179, 183], "stimul": [111, 112], "stimuli": [111, 112], "stirner": [111, 112], "stm": 10, "sto": 101, "stochast": [97, 138], "stock": [38, 41, 42, 101, 119, 123, 128, 152], "stoic": [111, 112], "stoicism": [111, 112], "stone": [111, 112, 139, 169], "stood": 130, "stop": [42, 60, 62, 97, 100, 101, 104, 106, 111, 112, 130, 140, 142, 146, 148, 150, 153, 183], "stop_word": [136, 142, 143, 150], "stopword": [30, 136, 138, 142, 149, 150, 152], "stor": 101, "storag": [56, 59, 60, 61, 65, 66, 73, 74, 77, 78, 80, 160, 167, 170], "store": [12, 38, 43, 46, 51, 52, 53, 55, 57, 59, 60, 61, 64, 65, 66, 71, 74, 76, 77, 79, 110, 111, 112, 114, 121, 128, 135, 145, 150, 152, 159, 160, 176], "storei": [111, 112], "stori": [49, 53, 97, 111, 112, 117, 174, 175], "storm": [111, 112], "storylin": 100, "stow": 66, "stoxx": 152, "str": [14, 15, 17, 21, 22, 28, 30, 31, 101, 105, 111, 112, 136, 142, 152, 155], "str4d": 79, "strai": 59, "straightforward": [57, 71, 73, 80, 91, 97, 101, 130, 134, 139, 140, 144, 147, 166], "strain": [121, 142], "strang": 9, "strate": 101, "strateg": [12, 54, 59, 172], "strategi": [1, 8, 12, 44, 46, 50, 54, 59, 71, 74, 78, 96, 98, 100, 103, 105, 111, 112, 117, 120, 130, 132, 133, 136, 143, 147, 167, 169, 170, 172], "stratify_on": [16, 20, 28, 33], "straw": 114, "strawberri": 114, "stre": 101, "stream": [8, 14, 16, 17, 22, 76, 95, 110, 111, 112, 146], "stream_executor": 14, "streamabl": 76, "streamlin": [42, 46, 49, 55, 56, 61, 63, 64, 65, 69, 71, 74, 76, 105, 159, 160, 163, 172], "street": [3, 101, 113, 119, 130], "stren": 107, "streng": [101, 107], "strengt": 107, "strength": [40, 41, 46, 50, 54, 55, 76, 77, 83, 90, 101, 102, 106, 111, 112, 116, 141, 143, 144, 156, 166, 172], "stress": [59, 111, 112, 172], "stretch": [111, 112], "stri": 101, "strict": [77, 172], "strictli": [52, 130, 167], "stride": [42, 44, 49], "strike": [50, 97, 102, 106, 111, 112], "strikingli": [111, 112], "string": [95, 101, 102, 103, 104, 105, 110, 112, 136, 139, 142, 145, 155], "string_token": 101, "stringent": 59, "strip": [60, 100, 111, 142, 152], "strip_acc": 112, "stripe": [85, 132], "strive": [1, 50, 93], "stroke": [111, 112], "strong": [1, 46, 60, 69, 70, 71, 76, 77, 87, 89, 101, 111, 112, 137, 149, 151, 152, 155, 166, 171, 172], "stronger": [53, 76], "strongest": [111, 112], "stronghold": [111, 112], "strongli": [111, 112, 114, 157, 167], "stru": 101, "struck": [111, 112, 130], "struct": 101, "structur": [0, 2, 7, 10, 38, 40, 41, 42, 43, 46, 47, 49, 50, 53, 54, 55, 59, 64, 66, 68, 69, 80, 91, 92, 93, 94, 98, 99, 111, 112, 113, 119, 122, 126, 128, 130, 131, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 150, 151, 153, 154, 159, 163, 166, 167, 171, 172], "structuralist": [111, 112], "struggl": [41, 54, 55, 84, 91, 93, 97, 102, 111, 112, 130, 134, 138], "strunk": 129, "stry": 107, "stuck": [54, 97], "student": [4, 37, 47, 49, 50, 70, 75, 84, 87, 96, 97, 111, 112, 129, 140, 161, 167, 168, 169, 170, 172, 176, 186], "studi": [0, 7, 38, 59, 76, 88, 89, 96, 97, 111, 112, 119, 120, 126, 129, 156], "studio": [5, 130], "stupend": 150, "style": [2, 5, 7, 8, 9, 49, 55, 89, 111, 112, 117, 129, 130, 136, 139, 144, 149, 171, 173], "style_clipdraw": 9, "styleclipdraw": 9, "stylelog": 181, "stylist": [2, 55], "styliz": 120, "stylometr": 136, "su": [81, 95, 101, 111, 112], "sub": [6, 10, 52, 56, 74, 75, 101, 103, 105, 107, 108, 111, 112, 144, 145], "sub_doc": 123, "sub_it": [103, 105], "subcompon": 117, "subcultur": [111, 112, 142], "subdivid": 59, "subdivis": 119, "subfield": [5, 11, 89, 91, 93, 122, 129, 130], "subfold": 69, "subgroup": [111, 112], "subject": [6, 7, 53, 59, 71, 93, 111, 112, 113, 116, 121, 130, 134, 138, 140, 148, 157, 181], "sublim": 174, "submiss": 51, "submit": [4, 20, 67, 72, 96, 111, 112, 121, 173, 178], "suboptim": [49, 97, 111, 112], "subpar": 46, "subpart": [88, 97], "subplot": [23, 24, 25, 149], "subproblem": 145, "subproject": 69, "subsampl": [35, 95], "subscript": [111, 112], "subsequ": [38, 46, 49, 59, 97, 103, 113, 116, 119, 120, 130, 136, 148, 153], "subset": [8, 15, 20, 31, 50, 52, 95, 111, 112, 114, 122, 147, 149, 150, 153, 171, 172], "subseteq": 147, "subsidi": 12, "subsidiari": [111, 112], "subsist": [111, 112], "subspac": 52, "substack": 105, "substanc": [111, 112], "substanti": [12, 46, 49, 50, 52, 53, 111, 112, 115, 116, 117, 134, 138, 140, 164, 172], "substitut": [105, 143], "substr": [101, 106, 107, 108], "substract": 98, "substring_end_posit": 101, "substring_start_posit": 101, "subtl": [53, 150], "subtleti": 120, "subtract": [98, 113], "subtrop": [111, 112], "suburban": [111, 112], "subvers": [173, 185], "subword": [0, 1, 8, 96, 101, 103, 104, 107, 108, 111, 112, 115, 145], "subwords_freq": [107, 108], "succeed": [111, 112], "success": [6, 8, 16, 17, 22, 41, 42, 52, 53, 54, 55, 63, 71, 74, 76, 89, 93, 97, 98, 100, 111, 112, 116, 117, 118, 121, 126, 130, 138, 145, 146, 151, 165, 166, 167, 171, 172], "successfulli": [6, 8, 16, 17, 22, 60, 63, 74, 76, 97, 111, 112, 132, 135, 136, 138, 150], "successor": 77, "suck": 136, "suddenli": 46, "sudo": [60, 64, 79, 80, 81, 159], "sue": [173, 179], "suffer": [6, 49, 93, 97, 111, 112, 116, 133, 138, 151], "suffici": [6, 9, 52, 57, 88, 98, 100, 115, 116, 130, 132], "suffix": [17, 30, 69, 103, 105, 111, 112, 130, 139], "suffrag": [111, 112], "suggest": [1, 42, 54, 71, 89, 92, 105, 111, 112, 115, 116, 117, 120, 131, 139, 147, 149, 151, 156, 171, 177, 178], "suicid": [111, 112], "suissa": [111, 112], "suit": [6, 9, 41, 45, 50, 52, 60, 77, 82, 89, 93, 106, 109, 116, 136, 137, 151, 166, 167, 171, 172], "suitabl": [7, 49, 50, 52, 57, 60, 62, 76, 88, 89, 97, 98, 105, 110, 111, 112, 121, 136, 138, 142, 145, 146, 148, 150, 151, 152, 166, 172], "sukhareva": [111, 112], "sulski": 0, "sum": [17, 25, 31, 52, 101, 105, 107, 108, 111, 112, 113, 116, 119, 125, 127, 128, 132, 133, 137, 143, 147, 148, 149, 152, 156], "sum_": [8, 99, 105, 106, 119, 124, 125, 128, 145, 147, 148, 157], "summar": [15, 50, 53, 55, 59, 60, 86, 89, 92, 93, 97, 98, 115, 116, 117, 122, 130, 131, 148, 151, 155, 167, 170], "summari": [6, 14, 16, 17, 20, 22, 49, 52, 53, 71, 76, 77, 84, 88, 89, 92, 95, 98, 100, 103, 106, 113, 116, 120, 130, 132, 138, 141, 147, 148, 150, 152, 157], "summaris": 174, "summary_stat": 17, "summaryinfo": 17, "summer": [111, 112], "summerhil": [111, 112], "sump": 108, "sumpt": 108, "sumpti": 108, "sun": [16, 111, 112, 174, 175], "sundai": [111, 112], "sundanes": 95, "sungjoon": [0, 6], "sunlight": [111, 112], "sunset": 16, "suomi": [111, 112], "sup": 101, "super": [16, 17, 53, 101, 111, 112, 127, 128], "superb": 100, "supercomput": 85, "superflu": 55, "superglu": 117, "superimpos": [111, 112], "superior": [53, 85, 111, 112, 171], "superscript": [111, 112], "superspeedwai": [111, 112], "superus": 81, "supervis": [0, 5, 6, 38, 73, 80, 88, 92, 93, 99, 111, 112, 120, 122, 152], "supervisori": 123, "supplant": 49, "supplement": [52, 111, 112, 142], "supplementari": 6, "suppli": [12, 42, 100, 111, 112], "supplier": [111, 112], "support": [6, 10, 14, 16, 22, 29, 30, 35, 42, 44, 45, 59, 60, 63, 65, 66, 69, 76, 78, 82, 88, 89, 91, 93, 98, 105, 111, 112, 130, 134, 135, 136, 137, 138, 141, 144, 147, 152, 160, 169, 171, 172], "suppos": [46, 106, 110, 113, 120, 128, 132, 147], "suppress": [88, 111, 112, 114], "suprem": [111, 112], "supremaci": [111, 112], "suptitl": 149, "sur": 101, "sure": [14, 64, 65, 66, 81, 89, 94, 97, 132, 159, 160, 172, 173, 177, 178], "surfac": [41, 111, 112, 130, 150], "surg": [97, 111, 112], "surgeri": 136, "surmount": 55, "surnam": 150, "surpass": [1, 5, 42, 49, 59, 85, 111, 112, 115], "surpris": [97, 128], "surprisingli": 153, "surreal": [2, 111, 112, 150], "surrealist": [111, 112], "surrend": [111, 112], "surround": [3, 5, 55, 109, 111, 112, 113, 116, 128, 137, 139, 155], "survei": [12, 13, 52, 111, 112, 121, 134, 169], "surveil": [111, 112], "surviv": [111, 112], "suscept": 121, "suspicion": [111, 112], "sustain": [50, 52, 55, 111, 112], "sutskev": [0, 99], "sutton": 53, "suv": 21, "sv": 95, "svc": 72, "svd": [52, 148], "svm": [136, 138], "svn": [173, 185], "sw": [95, 147], "swaggerui": 72, "swahili": [95, 115], "swaminarayan": [111, 112], "swap": 177, "swarm": [60, 62], "swath": 49, "sweat": 0, "swedish": 95, "sweet": 17, "swift": [50, 88, 169], "swing": 128, "swiss": [111, 112], "switch": [59, 67, 68, 79, 111, 112, 115, 126, 177, 180, 182, 184], "sy": [101, 123, 150], "sydnei": 0, "syllabl": [111, 112], "sylvain": 0, "symbiot": 2, "symbol": [100, 101, 106, 111, 112, 132, 146, 177, 180], "symlink": 66, "symmetr": [76, 77, 78, 147, 152], "symmetri": 71, "symptom": [92, 111, 112], "synagogu": [111, 112], "synaps": [111, 112], "synapt": [111, 112], "sync": [16, 17, 22, 30, 55, 66, 67], "synchron": [55, 64, 97, 111, 112, 159, 171], "synchronis": 185, "syndic": [111, 112], "syndicalist": [111, 112], "syndrom": [111, 112], "synergi": 50, "synonym": [55, 62, 111, 112, 119, 120, 137, 143, 156], "synopsi": [0, 167], "syntact": [10, 38, 109, 113, 115, 121, 122, 126, 127, 130, 137, 138, 140, 144, 146, 154, 156], "syntax": [69, 93, 96, 98, 100, 105, 110, 129, 130, 132, 140, 146], "synthes": [6, 116, 130], "synthesi": [0, 1, 4, 9, 11, 49, 56, 111, 112, 130], "synthet": 130, "syria": [111, 112], "syst": 101, "system": [0, 1, 4, 6, 8, 9, 11, 12, 38, 40, 41, 42, 44, 46, 50, 53, 54, 57, 59, 60, 61, 65, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 89, 91, 93, 96, 98, 101, 102, 105, 111, 112, 116, 120, 122, 123, 129, 130, 131, 132, 133, 137, 139, 140, 141, 145, 150, 151, 152, 154, 160, 161, 162, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 176, 185], "systemat": [55, 57, 89, 111, 112, 121, 137, 162, 166, 169, 172], "systemctl": [60, 80], "systemd": [64, 159], "t": [3, 5, 7, 9, 20, 23, 24, 46, 51, 52, 53, 54, 55, 59, 61, 64, 72, 76, 84, 85, 88, 92, 93, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 126, 128, 129, 130, 132, 133, 136, 138, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 157, 159, 166, 174, 175, 176, 177, 178, 180, 181, 182, 185], "t0": 51, "t0_3b": 51, "t4": 51, "t5": [1, 31, 47, 51, 96, 97, 98, 104, 115, 116], "t5_classification_with_simpl": 30, "t5_col": 35, "t5_diffusion_minut": [30, 31, 32, 33, 34, 35], "t5_diffusion_minutes_d": 31, "t5_diffusion_press_conf": [30, 31], "t5_diffusion_press_conf_d": 31, "t5_diffusion_speech": [30, 31, 33, 35], "t5_diffusion_speech_d": 31, "t5_diffusion_stat": [30, 31, 32, 33], "t5_diffusion_statement_d": 31, "t5_model": 30, "t5_tone": [31, 32, 33], "ta": [95, 101], "tab": [72, 110, 135, 178], "tab10": 26, "tabl": [1, 9, 43, 52, 53, 54, 59, 73, 89, 106, 111, 112, 121, 126, 127, 130, 136, 145, 156], "tablet": 120, "tackl": [12, 38, 49, 53, 54, 55, 59, 116, 126, 130, 132, 167], "tactic": [111, 112], "tactil": 91, "tag": [1, 55, 59, 69, 72, 76, 115, 122, 129, 130, 135, 138, 139, 143, 146, 179], "tag_": 144, "tagger": 130, "tahoun": 0, "tai": 0, "taiga": [0, 6], "tail": [14, 19, 21, 23, 24, 25, 26, 27, 30, 100, 130, 132], "tailor": [9, 42, 45, 46, 47, 49, 50, 52, 55, 59, 60, 61, 76, 80, 86, 91, 97, 111, 112, 136, 137, 171, 172], "tain": 101, "taiwan": 152, "tajik": 95, "tak": 117, "takahashi": 36, "take": [1, 6, 8, 9, 10, 44, 52, 53, 54, 63, 64, 71, 72, 73, 80, 88, 89, 92, 96, 97, 99, 102, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 120, 126, 128, 129, 132, 136, 139, 140, 141, 144, 147, 150, 151, 152, 154, 155, 159, 172, 176, 178, 180, 182], "takeawai": 78, "taken": [2, 8, 54, 105, 111, 112, 120, 132, 147], "taku": [0, 6], "tal": 101, "tale": [3, 101], "talent": [111, 112], "talk": [8, 111, 112, 136, 150, 178], "tall": [150, 156, 174, 175, 176, 182], "talladega": [111, 112], "tallapoosa": [111, 112], "tallest": 174, "talli": [111, 112], "tamil": 95, "tamper": 77, "tanaka": [0, 145], "tangibl": [49, 108, 172], "tanh": 127, "taoism": [111, 112], "taoist": [111, 112], "tap": 101, "tape": [101, 128], "tar": [107, 135], "tarek": 0, "target": [6, 9, 26, 27, 28, 30, 33, 43, 46, 49, 50, 52, 59, 64, 71, 73, 81, 84, 88, 93, 98, 99, 100, 105, 106, 109, 111, 112, 116, 117, 121, 123, 127, 130, 131, 132, 134, 136, 137, 145, 150, 152, 154, 155, 157, 159, 167], "target_batch": [127, 128], "target_nam": [136, 150], "target_usernam": 81, "tariff": [111, 112], "tarrida": [111, 112], "task": [5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 19, 20, 21, 22, 38, 41, 42, 43, 44, 46, 49, 50, 52, 53, 54, 55, 56, 57, 59, 64, 65, 69, 71, 74, 75, 76, 81, 86, 88, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 122, 123, 125, 126, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 142, 144, 145, 146, 150, 151, 153, 154, 156, 157, 159, 160, 163, 164, 167, 169, 171, 172], "task_typ": 51, "tasktyp": 51, "tatoeba": 93, "tau": [111, 112, 120], "taught": [102, 111, 112], "tax": [111, 112, 152], "taxpay": [111, 112], "taycan": 94, "taylor": [26, 27, 28, 120], "taylor2": 23, "taylor_diff": [23, 25, 26, 27, 28], "taz": [111, 112], "tbc": 117, "tbt": 15, "tdd": 171, "tdf": 14, "te": [95, 101], "teach": [9, 42, 46, 49, 54, 75, 96, 97, 110, 111, 112, 129, 139], "teacher": [111, 112], "team": [12, 42, 49, 59, 63, 64, 65, 71, 82, 83, 100, 111, 112, 115, 116, 151, 159, 160, 161, 165, 166, 167, 171, 172, 186], "teamwork": [163, 172], "tear": [111, 112], "tech": [59, 71, 93, 101, 120, 171], "technic": [0, 1, 6, 12, 37, 39, 49, 55, 59, 89, 96, 120, 129, 130, 163, 165, 168, 169, 172], "techniqu": [6, 8, 9, 10, 11, 12, 13, 37, 38, 41, 47, 49, 55, 56, 59, 71, 74, 77, 78, 86, 87, 88, 91, 93, 95, 96, 97, 98, 100, 105, 109, 111, 112, 113, 115, 116, 118, 120, 121, 122, 126, 128, 129, 131, 133, 135, 140, 142, 145, 147, 148, 150, 151, 154, 165, 169, 186], "technocrat": 120, "technolog": [55, 152], "technologi": [0, 1, 5, 12, 15, 38, 39, 42, 49, 52, 55, 56, 59, 62, 63, 64, 78, 80, 82, 86, 91, 93, 97, 101, 111, 112, 115, 128, 130, 131, 159, 165, 167, 169, 170, 171], "tediou": [56, 69], "tee": 80, "teh": 139, "tekton": [64, 159], "telescop": [111, 112, 130], "televis": [111, 112], "tell": [10, 136, 139, 173, 178, 180, 181], "telugu": [95, 115], "tem": 107, "temp": 112, "temper": [111, 112], "temperatur": [8, 97, 100, 111, 112], "templ": [111, 112], "templat": [1, 7, 42, 51, 61, 64, 66, 67, 68, 70, 91, 159, 161, 168, 169, 171], "tempor": [6, 49, 94, 111, 112, 116, 121, 151], "temporari": [111, 112], "temporarili": [111, 112, 181], "ten": [6, 111, 112], "tend": [90, 92, 93, 97, 111, 112, 114, 115, 119, 120, 128, 130, 136, 157], "tendenc": [111, 112, 147], "tenet": [111, 112], "tennesse": [111, 112], "tenni": [111, 112], "tens": [120, 139, 140, 144], "tension": [111, 112], "tensor": [51, 110, 111, 112, 116, 128], "tensorflow": [12, 14, 22, 71, 75, 97, 100, 117], "tensorflowsavedmodelartifact": 73, "tensorrt": 14, "tent": [111, 112], "tenth": [111, 112], "ter": 101, "teratogen": [111, 112], "term": [6, 7, 8, 9, 10, 41, 49, 50, 52, 53, 59, 74, 78, 93, 97, 105, 111, 112, 115, 116, 121, 127, 130, 132, 134, 137, 138, 139, 143, 144, 145, 147, 148, 150, 151, 152, 156, 157, 158, 161, 164, 167, 180, 181], "term_frequ": 152, "termin": [76, 80, 111, 112, 117, 178], "terminologi": [89, 92, 111, 112, 139], "termweight": 152, "terra": [111, 112], "terraform": [64, 65, 159, 160], "terrain": [6, 111, 112, 126], "terrestri": [111, 112], "terri": [111, 112], "terribl": 136, "territori": [2, 111, 112], "terror": [111, 112], "terrorist": [111, 112], "tesla": 42, "test": [6, 8, 10, 14, 16, 20, 22, 28, 49, 54, 55, 57, 59, 63, 65, 71, 74, 75, 76, 77, 83, 85, 89, 93, 94, 106, 109, 110, 111, 112, 115, 116, 117, 127, 130, 132, 133, 136, 144, 150, 160, 161, 164, 165, 167, 169, 170, 172, 174, 175, 176, 177, 180, 181, 182, 184], "test_data": [128, 132], "test_dataset": 110, "test_fil": 180, "test_siz": [14, 16, 20, 28, 33, 110, 136], "test_split_ratio": 20, "test_word_count": 132, "testabl": 165, "testimoni": [30, 36, 135], "teuthonista": [111, 112], "tevet": [0, 6], "texa": [111, 112, 133], "text": [0, 1, 4, 8, 12, 14, 15, 16, 17, 19, 20, 21, 22, 24, 30, 32, 36, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 55, 59, 72, 83, 85, 86, 88, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 118, 122, 123, 124, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 174, 175, 178, 183], "text2im": 9, "text2imag": [5, 130], "text2length": 6, "text2mot": 6, "text2speech": 72, "text_columm": 45, "text_column": 112, "text_kei": 17, "text_length": 94, "text_num_word": [24, 30], "textclassificationrecord": [14, 16, 17, 19], "textcoord": 128, "textdataset": 111, "textil": [111, 112], "textmat": 174, "textual": [1, 5, 6, 8, 9, 10, 11, 37, 42, 49, 54, 59, 86, 97, 119, 120, 126, 130, 134, 135, 137, 147], "textur": [8, 150], "tezg\u00fcino": 156, "tf": [1, 14, 97, 100, 107, 119, 126, 129, 136, 138, 146, 148, 153, 154, 156], "tf2tensorrt": 14, "tfgpt2lmheadmodel": [97, 100], "tfidf": 158, "tfidf_matrix": 158, "tfidfvector": [136, 158], "tg": [95, 101], "tgt_text": 30, "th": [24, 95, 97, 101, 108, 125, 128], "thai": [46, 95, 115], "thailand": 119, "than": [2, 3, 6, 8, 9, 12, 16, 17, 19, 21, 24, 25, 30, 41, 43, 46, 50, 52, 53, 64, 71, 73, 74, 77, 88, 90, 92, 93, 95, 97, 99, 100, 101, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 125, 126, 128, 130, 132, 133, 137, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 154, 155, 157, 159, 163, 172], "thank": [24, 120, 124, 126], "thei": [3, 5, 6, 7, 8, 9, 10, 12, 20, 30, 40, 41, 42, 44, 46, 49, 50, 52, 53, 55, 57, 59, 61, 63, 64, 69, 71, 72, 73, 77, 83, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 146, 147, 149, 150, 151, 152, 154, 155, 156, 157, 159, 164, 167, 168, 170, 171, 172, 175, 177, 178, 180, 183, 185], "theirs": [111, 112, 183], "them": [1, 2, 6, 8, 9, 10, 11, 12, 18, 22, 23, 37, 41, 42, 45, 46, 49, 50, 52, 53, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 76, 77, 79, 80, 81, 83, 85, 88, 90, 92, 96, 97, 98, 103, 106, 109, 110, 111, 112, 113, 114, 116, 117, 120, 121, 122, 126, 128, 129, 131, 133, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 150, 153, 154, 157, 159, 160, 164, 166, 167, 171, 172, 174, 177, 178, 180, 181, 183], "themat": [148, 151, 157], "theme": [12, 26, 66, 89, 111, 112, 155], "themselv": [111, 112, 126, 127, 130, 147], "theorem": 138, "theoret": [10, 59, 89, 97, 111, 112, 126, 139, 143, 161, 168], "theori": [0, 1, 89, 96, 97, 111, 112, 119, 120, 129, 132, 139, 150, 155, 157, 161, 186], "theoris": [111, 112], "theorist": [111, 112], "theoriz": [111, 112], "ther": 101, "therapeut": [111, 112], "therapi": [111, 112], "theravada": [111, 112], "thereaft": [111, 112], "therebi": [12, 42, 49, 50, 52, 57, 59, 77, 111, 112, 116, 165], "therefor": [10, 12, 38, 41, 51, 99, 113, 115, 118, 128, 130, 143, 145, 152, 166], "thermal": [111, 112], "thermostat": 49, "thesauri": 156, "thesauru": 137, "thesi": [1, 87], "theta": [84, 99, 105, 128, 147], "theta_": 151, "theta_d": 151, "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 21, 22, 23, 24, 25, 28, 29, 30, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 166, 167, 169, 170, 172, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186], "thick": [111, 112], "thicket": [111, 112], "thin": [24, 150], "thing": [42, 50, 77, 78, 81, 97, 99, 111, 112, 174, 178, 179, 183, 185], "think": [24, 37, 87, 97, 111, 112, 115, 130, 136, 152, 163, 172, 173, 178, 179], "thinker": [111, 112], "thiogalactopyranosid": 142, "third": [61, 77, 78, 88, 111, 112, 113, 115, 130], "thirteenth": [111, 112], "thirti": [111, 112], "thirtieth": [111, 112], "thisislongtext": 145, "thoma": [0, 111, 112, 151], "thompso": 108, "thompson": [108, 111, 112], "thoreau": [111, 112], "thorough": [46, 89, 136, 172], "thoroughfar": [111, 112], "thoroughli": 12, "those": [5, 23, 24, 36, 38, 45, 46, 52, 59, 62, 64, 88, 90, 92, 93, 95, 97, 109, 111, 112, 113, 114, 115, 116, 120, 121, 122, 130, 133, 136, 147, 155, 156, 159, 178, 181], "though": [9, 23, 26, 27, 49, 97, 111, 112, 117, 139, 145, 150, 156, 163], "thought": [20, 49, 55, 98, 111, 112, 116, 121, 130, 150], "thoughtfulli": 53, "thousand": [111, 112, 120], "thread": 14, "threadpoolctl": 150, "threat": [63, 77, 78, 134], "three": [5, 6, 9, 10, 52, 56, 57, 69, 76, 77, 78, 88, 95, 97, 99, 100, 102, 103, 105, 111, 112, 114, 115, 116, 117, 120, 127, 128, 130, 132, 139, 140, 142, 143, 145, 147, 149, 151, 156, 174, 178, 180, 181, 182], "threshold": [88, 97, 130, 145], "thrive": 83, "through": [2, 3, 6, 8, 9, 10, 16, 17, 19, 21, 38, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 64, 72, 73, 76, 77, 81, 82, 85, 87, 88, 90, 91, 92, 100, 101, 107, 108, 109, 110, 111, 112, 113, 116, 117, 120, 121, 127, 128, 130, 136, 137, 138, 139, 144, 151, 152, 155, 159, 161, 166, 168, 171, 172, 176, 177, 185, 186], "throughout": [9, 45, 52, 63, 85, 89, 111, 112, 171], "throughput": 55, "thu": [9, 12, 23, 40, 42, 44, 52, 56, 57, 59, 93, 106, 111, 112, 114, 115, 133, 152, 171, 184], "thudm": [5, 130], "thunder": [22, 111, 112], "thunderstorm": [111, 112], "thur": 101, "thursdai": [101, 108, 152], "thyssenkrupp": [111, 112], "ti": [12, 101, 111, 112, 152], "tial": 101, "tibetan": 140, "tic": 101, "ticket": [59, 77, 134, 167], "tide": [111, 112], "tie": 152, "tier": [111, 112], "tiger": [111, 112], "tight": 119, "tiiuae": 45, "tild": [84, 126, 147], "tilt": 130, "timber": [111, 112], "timdettm": 45, "time": [0, 2, 6, 7, 8, 9, 10, 14, 15, 16, 17, 19, 20, 21, 22, 24, 28, 30, 40, 41, 46, 49, 50, 52, 53, 54, 55, 57, 59, 63, 64, 65, 71, 74, 76, 77, 86, 88, 89, 91, 93, 94, 97, 101, 105, 106, 109, 110, 111, 112, 115, 116, 117, 119, 120, 121, 126, 128, 130, 132, 133, 136, 137, 138, 139, 140, 144, 145, 151, 152, 155, 157, 158, 159, 160, 163, 164, 166, 167, 170, 171, 172, 173, 177, 178, 182, 185], "time_budget": [29, 35], "timeli": 12, "timelin": [169, 172], "timestamp": [15, 24, 30, 95], "timestep": [9, 97], "ting": 101, "tinghui": [0, 6], "tingwu": [0, 6], "tini": 51, "tion": 101, "tire": [14, 111, 112, 149], "tired": [111, 112], "tissu": [111, 112], "titl": [21, 23, 24, 25, 26, 30, 31, 32, 43, 67, 68, 76, 94, 111, 112, 116, 120, 136, 139, 155, 174, 175, 176, 177, 178, 179, 182], "tl": [77, 78, 104], "tlog": 152, "tloo": 107, "tlook": 107, "tmp": [19, 103, 110, 111, 112, 135], "tn": [14, 16, 101], "tner": 107, "tnt": 116, "to_dat": [23, 32], "to_dateparm": 32, "to_datetim": [23, 30, 94], "to_dict": 32, "to_replac": 30, "to_year": 34, "toarrai": 158, "toast": 158, "tobia": 0, "toc": 107, "tock": 107, "todai": [5, 49, 77, 90, 97, 106, 111, 112, 119, 123, 128, 142, 152, 155, 158, 171], "todd": 0, "toddler": [111, 112], "todens": 150, "toe": [111, 112], "tog": [0, 6], "togeth": [1, 3, 6, 9, 18, 37, 55, 64, 65, 71, 73, 98, 100, 101, 106, 108, 111, 112, 113, 116, 126, 128, 130, 143, 148, 150, 154, 155, 156, 159, 160, 171, 172, 177, 183], "toi": [97, 111, 112, 147], "toilet": [111, 112], "token": [0, 1, 7, 8, 9, 16, 17, 19, 21, 30, 32, 46, 49, 52, 55, 77, 78, 88, 91, 92, 96, 97, 99, 100, 114, 116, 117, 124, 125, 126, 129, 130, 132, 133, 136, 138, 144, 145, 148, 149, 150, 152, 153, 155, 157, 176], "token_classif": 51, "token_freq": [107, 108], "token_reg": 101, "token_to_id": 111, "token_type_id": [104, 110, 112], "tokeniz": 101, "tokenization_t5": 30, "tokenization_utils_bas": 30, "tokenize_funct": [110, 111], "tokenized_dataset": [111, 112], "tokenized_text": [101, 107, 108, 143], "tokenizer_config": [111, 112], "tokenizer_name_or_path": 51, "tokenizer_obj": [111, 112], "tokenizer_object": [111, 112], "tokenizers_parallel": 17, "tokyo": [100, 111, 112], "told": [171, 176], "toler": [111, 112], "toll": [111, 112], "tolstoi": [111, 112], "tom": [111, 112], "toma": 0, "tombigbe": [111, 112], "toml": 80, "tommi": [111, 112], "tomorrow": [97, 128], "tomoto": 152, "tomotopi": [0, 1, 129, 148], "ton": [111, 112], "tonam": 21, "tone": [1, 36, 37, 88, 111, 112, 119, 130, 134, 137], "tone_col": [31, 34], "tone_column": 31, "tone_data": 31, "tone_data_finbert": [30, 31], "tone_data_lm": [30, 31, 32], "tone_data_t5": [30, 31], "tones_q": 34, "tong": 7, "tongu": 49, "tonic": 59, "too": [10, 23, 53, 95, 97, 103, 111, 112, 126, 136, 137, 154, 166, 173, 176, 177], "took": [111, 112, 116, 117, 136, 144, 150], "tool": [1, 5, 6, 9, 12, 37, 41, 42, 44, 45, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 62, 63, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 85, 93, 96, 98, 105, 106, 110, 111, 112, 114, 121, 126, 129, 130, 132, 135, 141, 144, 148, 150, 152, 157, 162, 163, 165, 167, 168, 169, 170, 171, 173], "toolbox": 6, "toolkit": [40, 53, 60, 106, 130, 132], "toolset": [52, 62], "top": [8, 46, 56, 65, 66, 67, 73, 77, 78, 99, 101, 106, 110, 111, 112, 114, 120, 125, 133, 136, 145, 147, 149, 150, 152, 155, 160, 176, 177, 178, 182, 183], "top_k": 97, "top_n": 152, "top_p": 97, "top_word": 150, "topic": [0, 1, 12, 19, 20, 21, 46, 49, 55, 60, 69, 71, 80, 87, 93, 95, 96, 98, 111, 112, 119, 120, 126, 129, 130, 155, 167, 173], "topic_cv_merg": 14, "topic_cved_filenam": 14, "topic_dist": 152, "topic_id": 152, "topic_model": 152, "topic_pr": 14, "topic_term_dist": 152, "topic_valid_preds_df": 16, "topic_word": 150, "topographi": [174, 175, 176, 177, 179], "topologi": [42, 111, 112], "torch": [110, 111, 112, 127, 128], "tornado": [111, 112], "toronto": [95, 97, 117], "torresani": 0, "toss": 132, "total": [6, 9, 14, 15, 21, 51, 53, 100, 103, 111, 112, 113, 119, 120, 121, 128, 130, 132, 133, 145, 147, 150, 152, 155, 157, 158, 167], "total_flo": [110, 112], "total_length": 111, "total_loss": 128, "total_sum": [107, 108], "touch": [49, 88, 116, 175, 177], "tour": [111, 112], "tourett": [111, 112], "tourism": [111, 112], "tourist": [111, 112], "tournament": [111, 112], "toutanova": 0, "tove": 183, "tow": [111, 112], "toward": [0, 1, 9, 10, 38, 42, 44, 46, 53, 54, 57, 72, 88, 96, 98, 105, 111, 112, 116, 119, 143, 157], "town": [111, 112, 119], "toxic": [83, 98], "toxin": [111, 112], "toyota": [111, 112, 152], "tp": [14, 16, 152], "tp_add": 14, "tqdm": [23, 100, 101, 103, 108, 110, 111, 112, 114, 128, 132, 135, 136, 141], "tqdmwarn": [100, 101, 103, 108, 110, 111, 112, 114, 136], "tr": [95, 101], "trac": 101, "trace": [53, 111, 112], "traceabl": [64, 111, 112, 159, 169], "traceback": 103, "track": [0, 6, 12, 16, 17, 22, 30, 38, 55, 59, 64, 65, 66, 70, 71, 74, 75, 91, 97, 101, 111, 112, 114, 119, 130, 134, 138, 159, 160, 166, 167, 172, 173, 174, 176, 180, 181, 182, 185], "tractabl": 146, "traction": [59, 77, 111, 112], "trad": 101, "trade": [1, 10, 45, 50, 92, 101, 111, 112, 115, 128, 132, 152], "trademark": 93, "tradeoff": 120, "trader": [111, 112, 128], "tradit": [2, 3, 6, 8, 12, 39, 41, 46, 52, 54, 56, 63, 71, 74, 77, 100, 105, 111, 112, 114, 116, 126, 151, 156, 171, 172], "tradition": [12, 92], "traffic": [3, 40, 55, 76, 77, 82, 111, 112], "tragedian": [111, 112], "trail": [6, 111, 112], "train": [0, 1, 4, 5, 6, 7, 10, 11, 12, 15, 17, 18, 24, 28, 29, 30, 33, 35, 36, 37, 38, 42, 46, 47, 49, 50, 52, 54, 55, 57, 59, 63, 70, 71, 72, 73, 74, 75, 80, 83, 84, 85, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 106, 107, 108, 114, 116, 117, 119, 121, 122, 130, 132, 133, 134, 138, 139, 140, 146, 150, 151, 152, 156, 167, 169, 185], "train_batch_s": [14, 16, 17, 19, 22, 30, 51], "train_data": [28, 33, 132], "train_dataset": [110, 111, 112], "train_dreambooth": 51, "train_epoch_loss": 51, "train_extremely_large_corpu": [103, 105], "train_from_iter": [111, 145], "train_loss": [16, 17, 22, 110, 112], "train_ppl": 51, "train_runtim": [110, 112], "train_samples_per_second": [110, 112], "train_siz": 132, "train_steps_per_second": [110, 112], "train_test_split": [110, 136], "train_text_encod": 51, "train_unsupervis": 124, "trainabl": [50, 51, 52], "trained_model": 14, "trainer": [14, 22, 45, 103, 110, 111, 112], "trainer_interfac": [103, 105], "trainer_spec": [103, 105], "training_arg": [110, 111, 112], "training_loss": [110, 112], "trainingargu": [110, 111, 112], "trainoutput": [110, 112], "trait": [111, 112, 120], "trajectori": [6, 9], "tran": 101, "transact": [0, 6, 40, 49, 77], "transcend": [46, 111, 112], "transcrib": [72, 130], "transcript": [24, 30, 36, 101, 111, 112, 119, 120, 132], "transcultur": [111, 112], "transfer": [0, 1, 5, 6, 10, 12, 46, 51, 55, 76, 77, 88, 93, 96, 98, 99, 100, 109, 111, 112, 115, 116, 123, 130, 150], "transform": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 21, 22, 30, 38, 39, 42, 45, 46, 48, 51, 53, 54, 57, 71, 72, 77, 83, 86, 88, 91, 93, 96, 97, 98, 100, 102, 104, 105, 106, 110, 111, 112, 114, 115, 126, 130, 134, 136, 139, 143, 146, 148, 150, 154, 158, 164, 165, 170, 171], "transform_a_data_to_metadata": 152, "transform_label": [28, 33], "transformer_block": 52, "transformer_block_adapt": 52, "transformer_block_ia3": 52, "transformer_block_llama_adapt": 52, "transformer_block_prefix_tun": 52, "transformers_neuron_view": 114, "transfoxl": 97, "transgress": [111, 112], "transit": [6, 56, 57, 76, 77, 79, 89, 111, 112], "translat": [0, 6, 7, 8, 40, 46, 50, 53, 60, 86, 92, 93, 97, 98, 99, 105, 111, 112, 115, 116, 117, 122, 126, 131, 133, 135, 136, 139, 142, 144, 154, 155, 156, 172, 177, 179, 180, 183], "transliter": [111, 112, 115], "transmiss": [0, 77, 78], "transmissionrisk_": 119, "transmit": [77, 111, 112, 119], "transpar": [0, 53, 59, 71, 74, 77, 85, 92, 111, 112, 130, 169, 171], "transport": [77, 78, 111, 112, 167], "transpos": [52, 88, 116], "trap": [111, 112], "trat": 107, "trauma": [111, 112], "travel": [111, 112], "travers": [43, 54, 111, 112, 121], "travi": [64, 65, 159, 160], "tre": 145, "treasur": [111, 112], "treasury_5": 23, "treasury_yield_url": 23, "treat": [52, 101, 105, 111, 112, 116, 117, 120, 128, 133, 143, 146, 151, 154, 156, 157], "treat_whitespace_as_suffix": [103, 105], "treati": [111, 112], "treatment": [49, 98, 105, 111, 112], "tree": [69, 73, 91, 100, 111, 112, 122, 128, 130, 138, 144, 145, 148, 174], "treebank": [122, 130, 139], "treeless": [111, 112], "trello": [75, 167, 169], "tremend": [111, 112], "trend": [1, 12, 40, 41, 49, 57, 78, 89, 93, 98, 111, 112, 118, 130, 132, 134, 141, 150, 151, 166], "treng": 107, "trengt": 107, "trength": 107, "trent": [111, 112], "trg": [0, 6], "tri": [46, 101, 111, 112, 117, 147, 175, 183], "triad": [111, 112], "trial": [5, 111, 112, 130], "triangl": [111, 112], "triangul": 6, "triangular": [111, 112], "tribal": [111, 112], "tribe": [3, 111, 112], "tribun": 119, "trick": 143, "trigger": [23, 52, 65, 71, 73, 160, 183], "trigram": [132, 133, 143], "trigram_model": 133, "trigram_prob": 132, "trillion": [49, 59, 117, 139], "trim": [17, 111, 112], "trimap": 7, "tripadvisor": 136, "trivia": [111, 112], "trivial": [59, 183], "trl": 51, "troi": [111, 112], "troop": [111, 112], "tropic": [111, 112], "troubleshoot": [64, 65, 89, 159, 160, 164], "trt": 14, "tru": [101, 107], "truck": [46, 111, 112], "true": [3, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 45, 51, 52, 60, 73, 76, 93, 94, 95, 97, 100, 101, 103, 104, 105, 107, 108, 110, 111, 112, 114, 116, 123, 127, 128, 132, 135, 136, 137, 139, 142, 143, 144, 145, 149, 150, 151, 152, 155, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "true_label": 135, "trump": [108, 152], "truncat": [30, 110, 111, 112, 117], "truncated_normal_initi": 112, "trust": [12, 29, 35, 42, 76, 77, 78, 98, 101, 111, 112, 130, 136, 171], "trustworthi": 93, "truth": [55, 64, 66, 88, 159], "truthfulqa": [85, 98], "try": [8, 23, 29, 35, 51, 72, 103, 111, 112, 127, 128, 130, 136, 139, 150, 152, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185], "tryangular": 145, "tryfan": [177, 180, 181], "tsne": 28, "tti": 107, "ttin": 107, "tting": 101, "tu": 101, "tubervil": [111, 112], "tucker": [111, 112], "tug": 116, "tumbl": 152, "tunabl": 151, "tune": [1, 6, 9, 10, 12, 14, 35, 41, 42, 47, 53, 55, 57, 71, 75, 83, 84, 86, 88, 91, 93, 96, 97, 98, 99, 100, 106, 109, 111, 112, 115, 122, 130, 132, 136, 138, 147], "tunnel": [76, 77, 82], "tupl": [133, 141], "tur": 101, "ture": [49, 93, 133, 186], "turkish": [95, 115], "turn": [38, 42, 64, 72, 73, 91, 111, 112, 114, 116, 126, 128, 130, 133, 159], "turner": [111, 112], "tuscaloosa": [111, 112], "tuskege": [111, 112], "tutori": [42, 81], "tv": [14, 21], "tw": [101, 152], "twa": 183, "tweepi": 12, "tweet": [12, 115], "twelv": 171, "twenti": [111, 112], "twentieth": [111, 112], "twice": [97, 111, 112, 128, 135], "twin": [111, 112], "twitter": [12, 119, 121, 134, 141], "twitter_complaint": 51, "two": [5, 6, 9, 10, 14, 25, 42, 52, 59, 61, 62, 64, 66, 67, 69, 71, 72, 76, 77, 78, 88, 91, 92, 95, 97, 98, 99, 100, 104, 105, 109, 110, 111, 112, 113, 114, 116, 120, 121, 122, 126, 127, 130, 132, 133, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 154, 155, 156, 157, 158, 159, 166, 167, 171, 174, 175, 177, 180, 182, 183], "twofold": 146, "txt": [14, 15, 19, 21, 45, 61, 76, 100, 103, 105, 112, 114, 121, 124, 139, 152], "ty": 101, "tydiqa": 115, "tym": 14, "type": [4, 5, 8, 9, 14, 22, 23, 24, 30, 31, 32, 33, 34, 41, 42, 45, 49, 50, 52, 53, 54, 59, 60, 73, 78, 79, 81, 82, 88, 93, 97, 98, 99, 100, 102, 104, 110, 111, 112, 113, 115, 116, 120, 123, 130, 131, 132, 133, 136, 137, 139, 140, 144, 145, 146, 147, 151, 152, 154, 156, 165, 166, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "type_vocab_s": 112, "typic": [6, 8, 9, 45, 46, 50, 52, 55, 57, 58, 64, 66, 71, 76, 77, 78, 80, 88, 89, 90, 91, 92, 93, 97, 98, 100, 102, 104, 105, 111, 112, 115, 116, 119, 120, 121, 122, 130, 136, 138, 139, 142, 146, 150, 153, 159, 178], "typo": 183, "typograph": 9, "tyrant": [111, 112], "u": [9, 10, 40, 79, 97, 101, 104, 105, 108, 110, 111, 112, 113, 116, 119, 120, 124, 125, 126, 130, 132, 133, 136, 137, 139, 140, 142, 143, 144, 147, 150, 151, 152, 154, 155, 157, 174, 178, 180, 181, 185], "u18": 150, "u_": [147, 149], "u_mass": [149, 152], "uab": [111, 112], "uart": 107, "uarter": 107, "ubuntu": [60, 64, 75, 79, 159], "uc": 83, "uci": [147, 149], "ue": 101, "uesdai": 108, "uf": [176, 182, 185], "ugarit": [111, 112], "ui": [57, 169], "uid": 81, "uk": [0, 95, 111, 112, 174, 175, 176, 177, 179, 182], "ukasz": 0, "ukrain": [111, 112], "ukrainian": 95, "ulm": 107, "ultim": [55, 63, 80, 93, 97, 102, 111, 112, 116, 134], "ultra": 6, "ultraviolet": [111, 112], "um": [101, 140], "umap": 138, "umar": [0, 6], "umbrella": 100, "uml": 169, "un": [101, 107, 108, 142, 145], "unabl": [29, 35, 111, 112, 116, 132, 136, 137], "unachiev": [111, 112], "unaffect": [111, 112], "unalt": [77, 78], "unambigu": [8, 88, 100, 105], "unanim": [30, 111, 112, 167], "unansw": 89, "unauthor": [64, 74, 77, 78, 121, 159], "unavoid": [111, 112], "unbalanc": 93, "unbias": 53, "uncas": [104, 114], "uncensor": 120, "unceremoni": [111, 112], "uncertain": [57, 119, 137], "uncertainti": [0, 1, 30, 53, 120, 132, 137], "uncertanti": 145, "unchalleng": 59, "unchang": [50, 111, 112, 175, 179], "unchart": 2, "uncial": [111, 112], "unclear": [111, 112, 116, 155], "uncommit": 181, "uncommon": [90, 145], "uncondit": [9, 10], "unconfirm": [111, 112], "uncontrol": 166, "unconvent": [111, 112], "uncorr": 112, "uncov": [17, 150, 151], "und": 95, "undefin": 147, "under": [30, 46, 50, 55, 60, 62, 67, 68, 69, 83, 84, 88, 101, 106, 110, 111, 112, 115, 120, 132, 140, 150, 151, 152, 156, 170, 172], "under_sampl": 136, "underbrac": 126, "underdiagnos": [111, 112], "underestim": 41, "underexplor": 89, "underfit": 110, "underflow": 132, "underfund": [111, 112], "undergird": [111, 112], "undergo": [46, 52, 98], "undergradu": [111, 112, 119], "underground": [111, 112], "underinvest": [111, 112], "underli": [2, 8, 42, 48, 49, 50, 52, 53, 55, 59, 60, 72, 80, 84, 93, 95, 130, 137, 138, 139, 148, 151, 152, 172], "underlin": [1, 42], "undermin": 97, "underperform": [115, 117], "underpin": 156, "underrepres": [88, 93, 111, 112, 130], "undersampl": 136, "underscor": [42, 50, 52, 55, 59, 116], "underset": 106, "underspecif": 8, "underspecifi": 8, "understand": [0, 1, 2, 4, 7, 8, 9, 10, 11, 12, 37, 38, 42, 43, 45, 46, 47, 49, 51, 52, 53, 55, 57, 59, 61, 63, 64, 66, 68, 70, 71, 75, 76, 77, 79, 80, 83, 85, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 121, 122, 126, 129, 131, 132, 133, 134, 136, 137, 139, 140, 144, 145, 148, 150, 151, 153, 154, 155, 156, 157, 159, 161, 164, 165, 166, 167, 169, 171, 172, 178, 179, 186], "understood": [8, 111, 112, 132, 138, 147, 157, 166, 171, 172], "underw": 46, "underwai": [111, 112], "underwat": 88, "underwhelm": 128, "undesir": [95, 111, 112], "undo": [173, 175, 180], "undocu": [111, 112], "undon": 173, "undoubtedli": [2, 52], "unemp": [25, 26, 27, 28], "unemp_diff_prev": [25, 26, 27, 28, 29, 33, 35], "unemp_diff_year": [25, 26, 27, 28], "unemploi": [111, 112], "unemploy": [111, 112], "unep": 16, "unequ": [12, 111, 112], "uneven": [111, 112], "unexpect": [2, 59, 100, 120, 143, 167, 170], "unfair": [12, 59, 130], "unfamiliar": [139, 156], "unfeas": [111, 112], "unfilt": [93, 117], "unforeseen": [9, 54], "unfortun": 136, "unfreez": [46, 117], "unfrozen": 46, "unfruit": 53, "ungoogl": 139, "ungooglif": 139, "unhealthi": 145, "uni": [99, 101], "unicod": [105, 111, 112], "unicodedata": 104, "unidentifi": [111, 112], "unidirect": 99, "unifi": [0, 50, 99, 116], "uniform": [8, 55, 85, 95, 97, 111, 112, 138], "unigram": [1, 96, 102, 105, 128, 132, 133, 143], "unigram_model_train": [103, 105], "unigram_t5_token": 103, "unigram_token": 103, "unigram_tokenizer_path": 103, "unigramtrain": 103, "unimagin": 126, "unincorpor": [111, 112], "uninform": [143, 146], "unintellig": [77, 78], "unintend": [59, 98], "uninterest": [88, 97], "union": [88, 111, 112], "uniqu": [2, 5, 9, 10, 14, 17, 22, 24, 46, 50, 52, 59, 69, 71, 72, 74, 76, 77, 83, 90, 93, 101, 106, 108, 111, 112, 114, 117, 123, 124, 126, 130, 135, 136, 139, 140, 141, 143, 150, 151, 153, 154, 156, 171, 172, 174, 179], "unison": 66, "unistr": 104, "unit": [0, 8, 49, 57, 59, 62, 65, 71, 77, 88, 93, 102, 105, 106, 111, 112, 115, 119, 120, 130, 138, 139, 140, 142, 146, 152, 160, 166, 169, 171, 172, 184], "unitarian": [111, 112], "united_st": 149, "unitedhealth": [111, 112], "uniti": [111, 112], "univers": [6, 42, 50, 53, 88, 97, 100, 103, 111, 112, 120, 137, 141, 144, 150], "unix": [1, 60, 66, 70, 78], "unjust": [111, 112], "unk": [103, 105, 107, 108, 111, 112, 115, 133, 143], "unk_id": [103, 105], "unk_piec": [103, 105], "unk_surfac": [103, 105], "unk_token": [103, 111, 112], "unknown": [3, 14, 20, 21, 95, 100, 101, 103, 105, 107, 108, 111, 112, 116, 139, 144], "unknown_token": 101, "unkonwn": 145, "unlabel": [49, 59, 113, 115], "unlabl": 117, "unless": [111, 112, 145], "unlik": [6, 8, 9, 24, 42, 49, 52, 53, 84, 88, 96, 97, 99, 105, 111, 112, 126, 129, 140, 144, 145, 151, 171, 172, 176], "unlock": [1, 53, 57, 77, 79, 93, 130], "unmanag": 163, "unnatur": [6, 10, 97], "unnecessari": [111, 112, 142, 163], "unnois": 9, "unnorm": 113, "unnormalis": 128, "unoffici": [9, 111, 112], "unord": 138, "unpack": 50, "unparallel": 116, "unpreced": [38, 111, 112], "unpredict": [57, 71], "unread": 77, "unrealist": [111, 112], "unrel": [9, 10, 111, 112, 156], "unreleas": [5, 130], "unreli": 157, "unrepres": 130, "unresolv": 172, "unrest": 59, "unround": [111, 112], "unsatisfi": 117, "unschedul": [23, 24, 25, 26, 27, 31], "unsecur": 76, "unseen": [8, 12, 50, 105, 110, 122, 132, 133, 139, 151], "unseen_doc": 152, "unselect": [111, 112], "unspecifi": 9, "unstag": [175, 181], "unstress": [111, 112], "unstructur": [38, 39, 40, 41, 46, 56, 57, 130, 142, 148, 151], "unsupervis": [0, 7, 38, 50, 73, 80, 93, 98, 99, 105, 113, 120, 122, 125, 130, 145, 146, 148, 150, 156], "unsupport": [111, 112], "unsurprisingli": 115, "unterthin": 0, "unthreshold": 88, "until": [5, 9, 53, 88, 97, 106, 108, 111, 112, 116, 117, 130, 133, 136, 142, 145, 148, 172], "untrack": [176, 181], "untrain": 6, "unus": [61, 115], "unusu": [90, 111, 112], "unvari": [111, 112], "unveil": 9, "unweight": [114, 119], "unzip": [132, 135], "up": [2, 3, 5, 6, 8, 9, 10, 11, 38, 42, 46, 52, 53, 55, 59, 61, 65, 66, 68, 75, 78, 79, 82, 85, 88, 89, 93, 95, 98, 100, 101, 110, 111, 112, 113, 115, 116, 117, 120, 123, 124, 126, 127, 128, 130, 132, 133, 136, 139, 142, 143, 144, 148, 150, 152, 155, 156, 160, 169, 171, 174, 175, 176, 177, 181, 182, 183, 184, 185], "upa": [111, 112], "upd": 101, "updat": [8, 9, 12, 13, 46, 52, 53, 54, 55, 60, 64, 68, 69, 74, 77, 85, 88, 93, 100, 101, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 121, 130, 132, 135, 136, 141, 150, 151, 159, 166, 169, 171, 173, 174, 175, 176, 177, 181, 183, 185], "update_files_info": 17, "update_info": 17, "update_label_error": 17, "upfront": 172, "upg": 101, "upgrad": [30, 81, 101, 111, 123, 132, 135, 136, 141, 150, 167], "upload": [45, 69, 72, 185], "upon": [42, 44, 46, 47, 54, 57, 64, 65, 70, 87, 89, 97, 111, 112, 113, 116, 117, 159, 160, 166, 167, 172], "upper": [6, 68, 111, 112, 115, 116, 129, 142], "uppercas": [105, 111, 112, 115], "upsampl": [9, 88], "upscal": 88, "upsid": 152, "upstream": [68, 180], "uptick": 128, "upward": 119, "ur": [95, 101, 111, 112], "ural": [111, 112, 140], "urban": [6, 46, 111, 112], "urc": 107, "urdu": 95, "urg": 167, "uri": [17, 24, 30, 41, 128, 145, 152], "url": [0, 43, 45, 69, 72, 76, 94, 95, 111, 112, 121, 123, 145, 177], "urllib": 121, "ursdai": 108, "us": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 14, 15, 16, 22, 23, 24, 26, 27, 30, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 53, 56, 57, 58, 59, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 83, 84, 85, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 126, 127, 129, 130, 131, 134, 136, 137, 138, 139, 140, 141, 142, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 160, 161, 164, 165, 166, 167, 169, 170, 172, 174, 176, 177, 178, 180, 181, 182, 184, 185, 186], "us_equities_news_sampl": [128, 145, 152], "usa": [111, 112, 119], "usabl": [38, 77, 96, 123, 129, 134, 165], "usag": [1, 14, 15, 21, 50, 55, 59, 65, 66, 70, 80, 83, 85, 99, 111, 112, 129, 130, 131, 132, 139, 144, 156, 160, 176], "use_all_vocab": [103, 105], "use_cpu": 51, "use_fp16": 45, "use_int4": 45, "use_lora": 51, "use_name_as_subdir": 17, "use_peft": 45, "used_vocab": 152, "used_vocab_freq": 152, "useless": 145, "usenet": 150, "user": [0, 6, 8, 9, 42, 45, 46, 51, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 84, 88, 91, 92, 93, 98, 100, 111, 112, 114, 120, 121, 123, 130, 131, 134, 141, 147, 148, 150, 155, 159, 160, 165, 166, 169, 172, 173, 174, 177, 178, 185], "user_instal": [100, 101, 103, 108, 110, 111, 112, 114, 136], "user_proxi": 42, "usermod": [80, 81], "usernam": [45, 76, 80, 81, 82, 176, 182], "username_to_remov": 81, "userproxyag": 42, "usg": [111, 112], "uspto": [93, 120], "usr": [79, 110, 111, 112], "ustri": 107, "usual": [22, 46, 67, 104, 110, 111, 112, 115, 119, 126, 132, 133, 134, 136, 138, 139, 140, 143, 146, 156, 176, 177], "uszkoreit": 0, "utf": [103, 112, 115, 124], "uti": 101, "util": [2, 6, 9, 10, 14, 15, 17, 20, 21, 24, 30, 38, 42, 43, 44, 46, 47, 50, 51, 52, 55, 57, 59, 60, 63, 64, 69, 77, 80, 88, 93, 95, 99, 101, 111, 112, 114, 116, 120, 123, 130, 131, 132, 137, 143, 147, 148, 151, 152, 159, 161, 165, 166, 167], "utilis": [111, 112], "utilitarian": [59, 111, 112], "utlo": 107, "utloo": 107, "utlook": 107, "utm_sourc": [5, 130], "utmost": [1, 77], "utopian": [111, 112], "ux": 169, "uz": 95, "uzbek": 95, "v": [0, 9, 38, 53, 57, 61, 78, 89, 97, 99, 101, 106, 108, 111, 112, 120, 124, 128, 132, 133, 136, 137, 139, 145, 147, 149, 150, 170, 176, 185], "v0": [51, 60], "v1": [0, 51, 76, 79, 117, 181], "v5": 30, "va": 128, "vaccin": [111, 112], "vader_lexicon": 135, "vadersenti": 135, "vae": [7, 11], "vagu": [22, 55], "val": [101, 145], "valenc": 135, "valid": [1, 6, 14, 18, 21, 29, 35, 37, 38, 55, 56, 71, 74, 75, 77, 80, 83, 84, 88, 89, 94, 95, 115, 119, 144, 164, 167, 169, 172, 173], "valid_data": [14, 21], "valid_data_dir": 14, "valid_dataset": [16, 110, 112], "valid_existing_data": 16, "valid_existing_topic_data": 16, "valid_pol_fil": 14, "valid_tokenized_dataset": 112, "valid_topic_fil": 14, "vallei": [16, 111, 112], "valohai": [71, 74], "valproic": [111, 112], "valu": [1, 2, 5, 8, 9, 10, 14, 15, 20, 21, 22, 23, 28, 30, 31, 34, 35, 38, 40, 46, 49, 52, 54, 55, 59, 71, 76, 77, 88, 89, 92, 95, 97, 101, 110, 111, 112, 113, 114, 116, 117, 119, 124, 125, 132, 133, 136, 139, 143, 145, 147, 151, 152, 153, 155, 156, 157, 158, 171, 172], "valuabl": [1, 38, 40, 45, 49, 65, 69, 89, 93, 98, 102, 105, 115, 116, 134, 135, 137, 138, 144, 147, 148, 151, 160], "value_count": 14, "vamp": 108, "van": [0, 101], "vanguard": [111, 112], "vanish": [49, 52, 116, 138], "vapor": [111, 112], "var": [60, 119], "vari": [6, 38, 42, 50, 59, 76, 97, 100, 111, 112, 119, 133, 140, 142, 151, 157, 169], "variabl": [6, 8, 15, 16, 17, 19, 20, 21, 22, 29, 40, 45, 60, 64, 79, 89, 97, 105, 111, 112, 114, 120, 126, 139, 145, 152, 159], "varialbl": [24, 25, 26, 27, 30, 31, 32, 33, 34, 35], "varianc": [126, 148], "variant": [6, 49, 52, 78, 95, 99, 102, 105, 106, 111, 112, 114, 117, 130, 157], "variat": [6, 9, 11, 50, 54, 88, 111, 112, 114, 116, 119, 121, 130, 139, 151], "varieti": [0, 5, 38, 46, 50, 53, 55, 59, 73, 85, 94, 96, 111, 112, 113, 116, 117, 139, 140, 169], "variou": [2, 6, 7, 8, 9, 11, 12, 37, 38, 41, 42, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 64, 65, 66, 69, 71, 73, 74, 77, 80, 81, 85, 86, 88, 89, 91, 93, 94, 95, 97, 98, 100, 103, 104, 105, 106, 111, 112, 113, 114, 115, 116, 120, 121, 122, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 146, 147, 150, 151, 153, 157, 159, 160, 161, 163, 166, 167, 169, 172, 180, 181], "various": [111, 112], "vase": 9, "vast": [2, 3, 8, 12, 46, 52, 53, 55, 77, 93, 98, 113, 126, 130, 132, 139], "vastli": 46, "vaswani": [0, 52, 53, 113, 116], "vatt": 0, "vbg": 144, "vbn": 144, "vbz": 144, "vc": [173, 174, 175, 176, 179, 180, 181, 182, 184, 185], "ve": [60, 94, 97, 101, 110, 111, 112, 133, 136, 150, 175, 176, 177, 180, 183], "vec": [147, 157], "vector": [0, 1, 8, 9, 10, 46, 49, 52, 56, 57, 77, 88, 99, 102, 114, 115, 116, 119, 124, 125, 126, 127, 128, 129, 134, 136, 137, 138, 139, 146, 147, 148, 150, 153, 158], "vega": [111, 112], "vegan": [111, 112], "veget": [111, 112], "vehicl": [53, 59, 111, 112, 137], "vein": 66, "veloc": [6, 38, 64, 159], "ven": 101, "venkatesh": [0, 6], "ventur": 56, "venu": [111, 112], "venv": 42, "ver": 101, "vera": 28, "verac": 38, "verag": 101, "verb": [120, 130, 139, 140, 144], "verbal": [111, 112], "verbos": [15, 16, 17, 19, 20, 21, 23, 24, 28, 29, 30, 35, 55, 111, 112, 145, 152, 180], "verg": 116, "veri": [3, 10, 24, 52, 53, 96, 97, 102, 111, 112, 116, 117, 124, 128, 129, 133, 136, 139, 150, 154, 156, 158, 172, 173, 174, 175, 176, 182], "verif": [12, 55, 77, 78, 172], "verifi": [53, 59, 76, 78, 110, 112, 121, 172, 177], "vers": 56, "versa": [92, 156], "versatil": [2, 6, 7, 9, 42, 49, 50, 53, 54, 59, 69, 73, 88, 93, 98, 105, 106, 116, 121], "version": [1, 8, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 42, 45, 49, 51, 53, 54, 61, 64, 70, 71, 72, 73, 74, 75, 80, 84, 88, 95, 110, 111, 112, 114, 116, 117, 120, 135, 141, 145, 150, 152, 159, 161, 167, 169, 172, 174, 176, 177, 179, 180, 181, 185], "versu": [111, 112, 136, 139], "vertic": [111, 112, 178], "vet": [93, 107], "veterinari": [111, 112], "veterinarian": 149, "veto": [111, 112], "vetr": 101, "vh": 150, "vi": [78, 89, 95, 101], "via": [10, 12, 35, 42, 46, 49, 57, 59, 60, 73, 75, 77, 88, 97, 105, 111, 112, 124, 126, 170, 178, 185], "viabil": [50, 165], "viabl": [46, 50, 69, 111, 112], "vibe": 6, "vice": [24, 30, 92, 156], "vicin": 119, "victori": [53, 111, 112], "victorian": 9, "victoryland": [111, 112], "vicuna": 83, "video": [0, 5, 88, 97, 111, 112, 116, 121], "videotap": [111, 112], "vie": 101, "vienna": [111, 112], "vietnam": [111, 112], "vietnames": [95, 115], "view": [2, 5, 8, 12, 21, 36, 38, 60, 94, 101, 111, 112, 113, 114, 126, 127, 128, 130, 133, 139, 146, 148, 151, 173], "viewer": [111, 112], "viewpoint": 8, "viewsourc": 20, "vigor": [111, 112], "vigour": [111, 112], "vii": [78, 89], "viii": 78, "villag": [3, 97], "villega": 0, "vim": [174, 176], "vinai": 0, "vincent": 0, "ving": 101, "violat": 133, "violenc": [111, 112], "violent": [111, 112], "violet": 16, "violin": 6, "violinist": 6, "virtu": 10, "virtual": [3, 6, 42, 48, 50, 62, 77, 81, 82, 91, 98, 105, 114], "virtualenv": [100, 101, 103, 108, 114, 132, 135, 136, 141, 150], "visibl": [64, 111, 112, 117, 159, 166, 172], "visigoth": [111, 112], "visio": 169, "vision": [0, 2, 6, 7, 8, 9, 11, 50, 88, 89, 91, 111, 112, 126, 130, 166], "visit": [69, 111, 112, 176, 177, 180, 182], "visitor": [111, 112], "visual": [1, 2, 6, 7, 9, 10, 11, 12, 14, 16, 17, 22, 23, 24, 25, 26, 27, 31, 32, 36, 37, 40, 41, 42, 57, 65, 88, 89, 91, 96, 97, 111, 112, 113, 116, 130, 133, 136, 137, 138, 144, 160, 170], "visualis": 183, "vit": [9, 88, 116], "vital": [1, 6, 12, 50, 55, 76, 77, 89, 116, 164], "vitamin": [111, 112], "viterbi": 108, "vivid": [6, 111, 112], "vmax": [25, 31], "vmin": [25, 31], "vo": 101, "voc_siz": 128, "vocab": [100, 101, 103, 105, 107, 108, 112, 114, 128, 145, 150, 152], "vocab_in": 101, "vocab_out": 101, "vocab_s": [103, 105, 108, 111, 112, 127, 128], "vocab_token": 101, "vocaboulari": 115, "vocabulari": [8, 59, 101, 102, 103, 105, 111, 112, 115, 124, 126, 127, 128, 132, 133, 138, 139, 146, 147, 149, 150, 153, 154, 156, 157, 158], "vocabulary_output_piece_scor": [103, 105], "vocal": [16, 111, 112], "vocat": [111, 112], "voic": [1, 16, 70, 74, 85, 91, 100, 115, 130, 134, 136, 171], "voicegpt": 72, "vol": [101, 111, 112, 129], "volatil": [112, 119, 172], "volcano": 3, "volcker": [23, 24, 31], "volum": [0, 38, 46, 53, 93, 98, 118, 148, 156], "volume3": 0, "voluntari": [111, 112], "vortex": 16, "vote": [24, 30, 111, 112, 120], "voter": [111, 112, 134, 144], "vow": [111, 112], "vowel": [111, 112], "voxel": 8, "vp": [140, 144], "vpn": [1, 70, 77, 78, 80], "vq": [5, 130], "vqa": 130, "vr": [50, 88], "vsp": 0, "vulner": [12, 63, 77, 78, 85, 111, 112, 130, 169], "vv": [141, 142, 180, 181, 185], "vx": [141, 142], "w": [0, 6, 14, 16, 17, 19, 20, 21, 22, 52, 97, 99, 101, 103, 105, 106, 108, 111, 112, 124, 126, 127, 128, 129, 132, 133, 136, 143, 146, 147, 149, 150, 151, 152, 155, 157], "w1": 150, "w3c": 38, "w3krkvu5": 17, "w3krkvu5sync": 17, "w_": [97, 99, 106, 126, 132, 133, 151], "w_0": [97, 132], "w_1": [52, 99, 126, 132, 133, 143, 147], "w_2": [52, 126, 132, 133, 143, 147], "w_3": [132, 133, 147], "w_4": [133, 147], "w_a": 52, "w_b": 52, "w_i": [99, 126, 128, 132, 133, 143, 145, 147], "w_j": [126, 128, 147], "w_k": [52, 132], "w_n": [132, 147], "w_out": 101, "w_q": 52, "w_t": [97, 128], "w_v": 52, "wa": [5, 8, 9, 23, 30, 46, 49, 55, 59, 64, 69, 72, 77, 83, 88, 93, 95, 97, 99, 100, 102, 103, 106, 111, 112, 113, 115, 116, 117, 120, 124, 125, 126, 127, 128, 130, 136, 137, 139, 142, 150, 151, 152, 156, 159, 180, 182, 183, 184, 185, 186], "waai": [111, 112], "wabm": [111, 112], "waff": [111, 112], "wage": [34, 111, 112], "wai": [6, 8, 9, 10, 40, 42, 44, 45, 46, 49, 52, 53, 57, 59, 64, 66, 71, 73, 77, 86, 88, 91, 92, 93, 97, 98, 100, 101, 102, 103, 104, 105, 106, 110, 111, 112, 115, 116, 117, 119, 126, 127, 128, 130, 132, 133, 137, 139, 143, 147, 150, 152, 153, 154, 155, 156, 157, 158, 159, 173, 174, 176, 177, 180, 181, 183], "waiq": [111, 112], "wait": [16, 17, 22, 67, 72, 100, 111, 112, 121, 148, 184], "waka": [111, 112], "wala": [111, 112], "wale": [177, 179, 180, 181], "walk": [6, 60, 101, 107, 108, 111, 112, 136, 139], "walker": 120, "wall": [5, 9, 101, 111, 112, 116, 119, 130, 150], "wallac": [111, 112], "walsh": 0, "wandb": [14, 16, 17, 22, 30, 70], "wandb_dis": 17, "wandb_project": 17, "wander": 30, "wane": 49, "wang": [0, 6], "want": [10, 23, 24, 30, 46, 60, 64, 67, 68, 76, 81, 95, 97, 104, 107, 108, 109, 110, 111, 112, 113, 116, 128, 132, 133, 136, 140, 144, 145, 147, 150, 152, 155, 157, 159, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183], "war": [101, 111, 112, 116, 119], "ward": [101, 111, 112], "warehous": 38, "warm": [110, 111, 112], "warmer": [111, 112], "warmth": [111, 112], "warmup": [45, 88], "warmup_ratio": 45, "warmup_step": 110, "warn": [12, 14, 15, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 97, 100, 103, 110, 112, 114, 152], "warrant": [59, 111, 112], "warranti": 181, "warren": [111, 112], "warrior": [111, 112], "washington": [42, 111, 112, 119], "wasn": [5, 54], "wast": [111, 112], "wat": [101, 111, 112], "watch": [64, 100, 111, 112, 159], "water": [16, 111, 112], "waterfal": [22, 111, 112, 164, 167, 170, 171], "waterman": 120, "watermark": 84, "waterwai": [111, 112], "watson": 49, "wave": [17, 56, 111, 112, 183], "wavelength": [111, 112], "wavi": [111, 112], "wayn": [111, 112], "wbiq": [111, 112], "wbma": [111, 112], "wbmm": [111, 112], "wbrc": [111, 112], "wc": 155, "wcdma": 17, "wciq": [111, 112], "wcov": [111, 112], "wdbb": [111, 112], "wdfx": [111, 112], "wdhn": [111, 112], "wdiq": [111, 112], "we": [1, 4, 5, 10, 24, 34, 44, 45, 46, 50, 51, 55, 59, 60, 61, 63, 67, 69, 72, 73, 76, 77, 80, 81, 82, 83, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 123, 125, 127, 128, 129, 130, 132, 133, 135, 136, 139, 141, 142, 143, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 167, 172, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185], "weak": [59, 102, 106, 116, 137, 141, 144, 152, 156], "weaken": [111, 112, 137, 152], "weaker": [12, 111, 112, 149, 152], "weakest": 149, "wealth": [46, 111, 112, 130, 148], "wealthi": 130, "weapon": 59, "wear": [111, 112], "weather": [12, 111, 112, 152], "weaviat": 59, "web": [0, 17, 38, 42, 43, 45, 49, 59, 61, 64, 65, 73, 76, 88, 89, 95, 97, 111, 112, 117, 122, 129, 130, 139, 141, 150, 159, 160, 169, 173, 176, 182], "web1": [64, 159], "web2": [64, 159], "webpag": 117, "websit": [12, 36, 43, 82, 91, 93, 97, 111, 112, 120, 121, 124, 125, 130, 139, 173, 177, 182, 185], "webster": 119, "webtext": [117, 122], "webtext2": 93, "wed": 112, "wedg": [111, 112], "wedn": 101, "wee": 101, "weed": [111, 112], "week": [47, 101, 111, 112, 128, 130, 136, 152], "weekli": 101, "weevil": [111, 112], "wei": [0, 6, 53, 98], "weigh": [52, 55, 111, 112, 116, 152], "weight": [6, 14, 16, 17, 22, 29, 30, 35, 45, 49, 50, 51, 52, 59, 70, 72, 83, 88, 95, 99, 107, 109, 110, 111, 112, 113, 114, 116, 119, 125, 126, 128, 132, 135, 136, 138, 144, 147, 148, 152, 158, 167, 181], "weight_decai": [45, 110], "weimin": 0, "weiq": [111, 112], "weissenborn": 0, "weitl": [111, 112], "welcom": [24, 130, 142, 155], "well": [1, 6, 8, 9, 12, 13, 38, 42, 45, 46, 52, 53, 55, 60, 64, 71, 72, 73, 77, 78, 87, 93, 96, 97, 98, 100, 102, 103, 105, 106, 110, 111, 112, 115, 116, 117, 122, 123, 125, 126, 128, 129, 130, 132, 133, 134, 137, 138, 139, 142, 144, 147, 152, 159, 163, 165, 166, 167, 170, 172, 173, 175, 178, 186], "welleck": 97, "welsh": [95, 177, 179, 180], "went": [99, 114, 130, 133, 139, 140], "wenzek": 95, "were": [6, 8, 9, 10, 14, 16, 17, 22, 28, 30, 49, 50, 55, 83, 88, 92, 95, 97, 100, 102, 106, 110, 111, 112, 116, 117, 120, 127, 128, 133, 142, 143, 144, 150, 152, 174, 176, 177, 185], "west": [111, 112, 178], "western": [95, 111, 112], "wet": 152, "wetumpka": [111, 112], "weygandt": [0, 6], "wfiq": [111, 112], "wfna": [111, 112], "wgiq": [111, 112], "wgww": [111, 112], "wh": [101, 150, 151], "what": [3, 5, 9, 10, 34, 52, 53, 56, 88, 97, 100, 101, 111, 112, 113, 116, 125, 133, 136, 150, 151, 156, 164, 165, 166, 167, 169, 170, 174, 176, 178, 181, 183, 185], "whatev": 174, "whdf": [111, 112], "wheel": [135, 137], "when": [0, 5, 6, 8, 9, 10, 12, 14, 16, 17, 22, 23, 30, 41, 42, 45, 46, 50, 52, 55, 57, 59, 64, 65, 66, 69, 71, 72, 73, 76, 88, 92, 93, 97, 98, 100, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 121, 126, 130, 132, 133, 135, 136, 137, 138, 139, 140, 143, 147, 149, 150, 151, 152, 153, 155, 157, 159, 160, 171, 172, 173, 175, 177, 178, 180, 182, 185], "whenev": [80, 88, 152, 174, 185], "where": [1, 2, 3, 6, 7, 8, 9, 10, 38, 42, 45, 46, 49, 50, 52, 53, 55, 57, 59, 60, 63, 64, 65, 71, 77, 88, 93, 97, 98, 99, 100, 105, 107, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 128, 130, 132, 133, 134, 136, 138, 139, 140, 141, 142, 143, 145, 147, 148, 151, 153, 154, 156, 157, 159, 160, 166, 171, 172, 173, 174, 176, 178, 180, 184], "wherea": [8, 59, 69, 111, 112, 115, 147, 171], "wherein": [49, 59], "wherev": 89, "whernsid": 185, "whether": [6, 10, 52, 99, 102, 106, 111, 112, 113, 116, 120, 128, 130, 134, 145, 147, 150, 185], "which": [1, 5, 6, 7, 8, 9, 10, 11, 12, 23, 30, 38, 40, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 64, 66, 67, 71, 72, 73, 74, 76, 77, 80, 81, 83, 84, 86, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 166, 169, 171, 172, 174, 175, 176, 177, 180, 181, 182, 183, 184, 185], "while": [1, 5, 6, 8, 9, 10, 38, 39, 40, 41, 42, 46, 49, 50, 51, 52, 53, 55, 57, 59, 62, 64, 66, 69, 71, 74, 76, 77, 79, 80, 83, 85, 88, 91, 92, 93, 95, 97, 98, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 119, 120, 121, 125, 126, 128, 130, 132, 133, 134, 136, 137, 138, 139, 141, 143, 144, 146, 147, 148, 149, 151, 152, 154, 156, 158, 159, 171, 172, 173, 174], "whilst": [111, 112], "whiq": [111, 112], "whisker": 6, "whisper": 51, "white": [84, 102, 111, 112, 114, 119, 128, 137], "whitespac": [103, 104, 112, 139, 146], "whl": [45, 132, 135, 136, 150], "whnt": [111, 112], "who": [3, 7, 45, 46, 64, 69, 76, 77, 97, 111, 112, 116, 119, 120, 130, 136, 150, 151, 152, 159, 171, 177], "whole": [55, 71, 88, 92, 97, 99, 110, 111, 112, 130, 134, 137, 150, 154, 172, 176, 177, 181], "whom": [111, 112, 116, 119], "whose": [97, 111, 112, 115, 116, 133], "why": [8, 53, 64, 97, 98, 101, 111, 112, 115, 136, 142, 150, 151, 159, 167, 180, 182], "whylab": 59, "wi": 101, "wiat": [111, 112], "wide": [5, 6, 7, 8, 9, 11, 12, 49, 50, 52, 53, 55, 62, 65, 73, 76, 77, 78, 86, 88, 89, 92, 93, 97, 98, 100, 104, 106, 109, 110, 111, 112, 113, 115, 116, 117, 121, 122, 130, 133, 134, 137, 138, 147, 148, 150, 151, 156, 160], "widen": 49, "wider": [50, 52, 98, 111, 112, 113, 115, 128, 152], "widespread": [50, 77, 98, 111, 112], "widget": 72, "width": [9, 10, 95, 97, 136], "wie": 117, "wiiq": [111, 112], "wiki": [103, 111, 112, 121, 173, 178], "wiki_filepath": [103, 112], "wiki_ko": 103, "wikipedia": [93, 95, 103, 109, 111, 112, 117, 121, 122, 130], "wild": [85, 111, 112], "wildcard": 181, "wildcat": [111, 112], "wildflow": 16, "wilhelm": [111, 112], "willi": 0, "william": [30, 111, 112], "win": [53, 101, 111, 112, 144], "wind": 17, "windblown": [111, 112], "windom": [111, 112], "window": [32, 57, 60, 61, 69, 85, 88, 110, 125, 128, 147, 154, 155, 157, 173, 174, 177, 183], "window_s": [128, 155], "wine": 156, "wing": [101, 111, 112], "winn": 101, "winner": 53, "winter": [17, 111, 112], "wip": 181, "wise": [6, 52, 88], "wish": [9, 30, 46, 67], "wit": [111, 112, 113], "with_prior_preserv": 51, "withdraw": [111, 112], "within": [0, 6, 7, 10, 12, 43, 46, 50, 52, 53, 54, 55, 59, 64, 65, 77, 84, 86, 88, 89, 110, 111, 112, 113, 114, 116, 121, 123, 131, 132, 136, 138, 147, 148, 151, 153, 157, 159, 160, 167, 171, 172, 174], "without": [5, 6, 9, 38, 44, 45, 46, 49, 50, 51, 52, 53, 55, 59, 60, 67, 68, 69, 73, 76, 77, 78, 80, 81, 84, 88, 90, 95, 97, 98, 99, 100, 105, 109, 111, 112, 115, 116, 117, 120, 121, 126, 130, 133, 136, 138, 140, 142, 145, 156, 157, 163, 172, 181, 185], "wiya": [111, 112], "wkrg": [111, 112], "wmt": 122, "wncf": [111, 112], "wng": 107, "wngr": 107, "wngra": 107, "wngrad": 107, "wngrade": 107, "wnl": 150, "wocki": 183, "wocky_rebas": 183, "wolff": [111, 112], "woman": [9, 97, 156], "wombo": [5, 130], "women": [111, 112], "won": [88, 104, 107, 108, 111, 112, 130, 133, 182], "wonder": [111, 112, 120], "wood": [111, 112], "woodpeck": [111, 112], "wor": [101, 105], "word": [0, 1, 8, 9, 10, 24, 30, 48, 52, 55, 77, 86, 88, 90, 92, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 109, 111, 112, 113, 116, 117, 119, 122, 124, 125, 129, 130, 131, 134, 135, 136, 140, 144, 146, 147, 148, 149, 150, 151, 158, 170], "word2id": 149, "word2vec": [1, 49, 99, 124, 126, 129, 138, 153, 156], "word_count": 133, "word_emb": 127, "word_freq": [107, 108], "word_given": 101, "word_given_known": 101, "word_given_unknown": 101, "word_list": [127, 128, 150], "word_loss": [107, 108], "word_to_id": [127, 128], "word_to_ix": 128, "word_token": [101, 132, 136, 142, 143], "wordcloud": 136, "wordnet": 150, "wordnetlemmat": [136, 150], "wordpiec": [1, 96, 99, 102, 105, 112, 114, 146], "wordpiece_bert_token": 103, "wordpiece_token": 103, "wordpiece_tokenizer_path": 103, "wordpieces_prefix": 112, "wordpiecetrain": 103, "words_pmi": 155, "words_ppmi": 155, "words_to_vector": 128, "wore": [111, 112], "work": [1, 2, 6, 7, 8, 9, 12, 38, 42, 44, 49, 51, 52, 54, 55, 56, 61, 63, 68, 69, 71, 74, 75, 77, 80, 81, 83, 85, 89, 90, 93, 96, 97, 98, 100, 101, 102, 103, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 117, 123, 126, 128, 129, 130, 132, 133, 136, 138, 144, 146, 152, 154, 155, 156, 157, 161, 163, 171, 172, 177, 178, 179, 180, 181, 183, 184, 186], "work_dir": 42, "workabl": 171, "workd": 99, "workdir": 61, "worker": [20, 111, 112, 136], "worker_": 20, "worker_1": 20, "worker_2": 20, "worker_3": 20, "worker_df": 20, "worker_dict": 20, "worker_id": 20, "worker_lf": 20, "workflow": [1, 42, 45, 51, 59, 61, 63, 65, 70, 71, 72, 74, 76, 97, 160, 164, 186], "workforc": [59, 111, 112], "working_dir": [174, 177, 179, 180, 181, 182, 184, 185], "workingmen": [111, 112], "workload": [59, 73, 74, 172], "workshop": 122, "workspac": [14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 45, 123, 152, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "workspace_dir": [17, 123], "workstat": 59, "world": [1, 2, 4, 5, 6, 12, 37, 40, 42, 47, 50, 51, 53, 54, 55, 56, 59, 71, 74, 77, 83, 85, 87, 88, 89, 93, 96, 97, 98, 100, 105, 111, 112, 116, 119, 126, 129, 133, 134, 142, 146, 151, 152, 155, 174, 176], "worldview": [111, 112], "worldwid": [111, 112], "worri": [24, 51, 152], "wors": [111, 112, 128, 136], "worth": [0, 105, 116, 126], "worthwhil": [10, 150], "wou": 24, "would": [6, 9, 14, 45, 46, 59, 95, 97, 105, 106, 111, 112, 114, 116, 126, 130, 132, 133, 138, 139, 140, 142, 143, 147, 151, 152, 155, 156, 157, 174, 180, 181, 183], "wouldn": [46, 88, 97, 130], "wound": [111, 112], "wpa": [111, 112], "wpmi": [111, 112], "wrangl": 108, "wrangler": 108, "wrgx": [111, 112], "write": [1, 42, 53, 68, 71, 86, 87, 93, 97, 98, 103, 111, 112, 136, 139, 163, 171, 173, 174, 176, 177, 178, 181, 182, 185], "writefil": [173, 174, 175, 176, 177, 180, 181, 182, 185], "writer": [59, 111, 112], "written": [1, 8, 12, 73, 84, 87, 89, 91, 95, 96, 98, 111, 112, 120, 121, 130, 131, 139, 145, 152, 163, 164, 167], "wrong": [53, 152], "wrote": [111, 112], "wsfa": [111, 112], "wt": 128, "wtb": 0, "wto": [111, 112], "wtto": [111, 112], "wtvy": [111, 112], "wu": [0, 53, 99], "wvtm": [111, 112], "www": [0, 5, 23, 36, 51, 70, 82, 97, 130], "wyddfa": 177, "wzdx": [111, 112], "x": [8, 9, 10, 14, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 35, 52, 64, 84, 99, 101, 105, 106, 107, 108, 111, 112, 113, 126, 127, 128, 136, 143, 145, 146, 149, 151, 152, 157, 159, 181], "x0": 9, "x1": 9, "x2": 9, "x25519": 76, "x86": 174, "x_": [105, 106, 125, 145], "x_1": [105, 126], "x_2": 105, "x_col": [28, 33], "x_i": [105, 113, 126, 128, 157], "x_j": [126, 128], "x_l": 126, "x_n": [105, 145], "x_re": 136, "x_test": 136, "x_train": [28, 136], "x_train_balanc": 136, "xa0": [111, 112], "xa0137": [111, 112], "xbc": 0, "xcr": 0, "xd": 169, "xed": 101, "xenial": 80, "xgb_limitdepth": 35, "xgboost": [12, 35], "xgboostmodelartifact": 73, "xh": 95, "xhosa": 95, "xiao": 0, "xiaohua": 0, "xiaoti": 0, "xie": [0, 6], "xingyu": [0, 6], "xini": [0, 6], "xinxin": [0, 6], "xl": [5, 99, 115, 130], "xla": 14, "xlabel": [26, 94, 136, 139, 155], "xlm": 97, "xlnet": [0, 97], "xmax": 32, "xmin": 32, "xml": [121, 123, 146], "xml_text": 123, "xml_text_list": 123, "xnli": [93, 115], "xp": 171, "xpec": 107, "xpect": 107, "xplore": 89, "xsv": [141, 142], "xt": [9, 107], "xt1": 9, "xt2": 9, "xti": 9, "xtick_param": 24, "xticklabel": 136, "xu": [0, 139], "xue": [0, 6, 95, 115], "xwi": [0, 6], "xxl": [51, 115], "xy": 128, "xytext": 128, "x\u209c": 9, "y": [9, 23, 25, 26, 27, 28, 31, 32, 33, 53, 60, 79, 80, 81, 99, 101, 105, 107, 108, 111, 112, 113, 126, 128, 136, 145, 149, 152, 157, 177, 180, 181], "y_": 105, "y_col": [28, 33], "y_dev": [28, 33], "y_i": [105, 157], "y_pred": 136, "y_re": 136, "y_test": [28, 33, 136], "y_train": [28, 33, 136], "y_train_balanc": 136, "ya": 107, "yadm": 66, "yaml": [14, 15, 17, 20, 22, 51, 62, 64, 65, 66, 69, 80, 159, 160], "yang": [0, 6, 99], "yanqi": 0, "yard": 117, "yazoo": [111, 112], "ydy": 0, "ye": [24, 30, 64, 69, 105, 130, 159, 181], "year": [2, 3, 5, 11, 23, 31, 32, 34, 46, 77, 89, 92, 93, 97, 101, 111, 112, 113, 118, 119, 120, 128, 133, 136, 140, 150, 152, 167], "yearli": [111, 112, 119], "yellen": [23, 24, 30], "yellow": [111, 112, 140], "yellowhamm": [111, 112], "yelp": [130, 136], "yelp_review_ful": 136, "yen": 152, "yet": [10, 49, 50, 52, 64, 66, 79, 88, 89, 111, 112, 113, 132, 137, 139, 142, 153, 159, 173, 176, 180, 181], "yeyati": 99, "yi": [0, 95, 101], "yiddish": 95, "yiel": 101, "yield": [2, 6, 8, 10, 12, 41, 50, 52, 101, 111, 112, 113, 116, 124, 126, 128, 144, 147, 152, 157], "yieldal": 23, "yihe": 0, "yime": 0, "yin": 0, "yj": [103, 110, 111, 112, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185], "yjlee": [94, 100, 101, 107, 108, 114, 132, 133, 135, 136, 141, 142, 150, 155, 173, 177, 185], "ylabel": [26, 94, 136, 139], "ylgnbu": [25, 31], "ylim": 32, "yml": [64, 69, 159], "ymp": 108, "yo": [69, 95], "yogatama": 0, "yokohama": [111, 112], "yonatan": [0, 6], "yoonho": 0, "yop": 142, "yope": 142, "york": [97, 105, 111, 112, 119, 129, 139, 143, 147, 152], "yoruba": 95, "yoshua": 0, "you": [0, 3, 8, 9, 14, 16, 17, 22, 23, 24, 30, 42, 43, 45, 52, 53, 60, 61, 64, 66, 67, 68, 69, 71, 72, 73, 76, 77, 79, 80, 81, 82, 83, 89, 93, 94, 95, 96, 97, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 120, 123, 124, 126, 128, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 146, 147, 150, 152, 154, 155, 156, 159, 167, 170, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185], "young": [0, 111, 112, 173, 174, 175, 180, 184], "younger": [111, 112], "youngjoon": 1, "your": [3, 9, 19, 30, 42, 60, 61, 63, 64, 65, 66, 69, 71, 73, 76, 79, 80, 81, 82, 95, 96, 97, 100, 101, 103, 104, 106, 110, 111, 112, 123, 124, 130, 136, 144, 146, 150, 155, 159, 160, 167, 170, 177, 180, 182, 183, 184, 185], "your_api_key_her": 123, "your_email": 76, "your_project_nam": 81, "your_repo_nam": [80, 81], "your_usernam": [67, 80, 81], "yournam": 173, "yourself": [80, 89, 144, 177, 185], "yourusernam": 68, "youth": [111, 112], "youtub": 6, "yp": 23, "ypiii": 142, "yr": 177, "ytd": 42, "yticklabel": 136, "yuan": 0, "yuki": 36, "yuki678": 36, "yum": 60, "yun": [111, 112], "yunh": 0, "yunrong": [0, 6], "yuri": 0, "yzksu5zdwd": 0, "z": [8, 99, 101, 108, 111, 112, 152], "z_": 151, "z_k": 8, "zack": [101, 152], "zani": 16, "zap": 169, "zapatista": [111, 112], "zcp": [0, 6], "zd": 9, "zebra": 156, "zellig": 0, "zendesk": 169, "zenith": [111, 112], "zenodo": 0, "zero": [0, 1, 6, 8, 10, 14, 23, 52, 77, 88, 96, 97, 98, 111, 112, 114, 115, 133, 147, 148, 157], "zero3_init_flag": 51, "zero3_save_16bit_model": 51, "zero_grad": [127, 128], "zero_stag": 51, "zettlemoy": 99, "zh": 95, "zhai": 0, "zhang": [0, 6, 52], "zheng": 0, "zhihui": 0, "zhilin": 0, "zhongang": [0, 6], "zhou": [0, 6, 111, 112], "zhuang": [111, 112], "zi": 9, "zi1": 9, "zi2": 9, "zihang": 0, "zip": [15, 20, 24, 30, 69, 128, 132, 135, 145, 152], "zipf": 130, "zipp": 136, "ziwei": [0, 6], "zolna": 0, "zone": [111, 112, 152], "zoo": [111, 112, 117], "zoom": 88, "zoph": 0, "zou": [0, 6], "zsh": 66, "zsl": 100, "zt": 9, "zt0": 9, "zu": [95, 150], "zulu": 95, "zuo": [0, 6], "zurich": 150, "zurvan": 150, "zvi": 150, "zwaartepunten": 150, "zwak": 150, "zwakk": 150, "zware": 150, "zwart": 150, "zyxel": 150, "\u00b3": 52, "\u00b5": 19, "\u00e0": [111, 112], "\u00e1": [111, 112], "\u00e2": [111, 112], "\u00e3": [111, 112], "\u00e4": [111, 112], "\u00e5": [111, 112], "\u00e5ngstr\u00f6m": [111, 112], "\u00e5rup": 135, "\u00e6": [111, 112], "\u00e7": [0, 6], "\u00e9": [0, 101, 108], "\u00f6": [0, 147], "\u00fc": 104, "\u0101": [111, 112], "\u0103": [111, 112], "\u0105": [111, 112], "\u0121": 104, "\u0121are": 104, "\u0121how": 104, "\u0121you": 104, "\u0131": 0, "\u0142": 0, "\u01ce": [111, 112], "\u01df": [111, 112], "\u01e1": [111, 112], "\u01fb": [111, 112], "\u0201": [111, 112], "\u0203": [111, 112], "\u0227": [111, 112], "\u0250": [111, 112], "\u0251": [111, 112], "\u0252": [111, 112], "\u028c": [111, 112], "\u03b1": [111, 112, 133, 151], "\u03b1\u00b2": 133, "\u03b1\u1f50\u03c4\u03cc\u03c2": [111, 112], "\u03b2": 142, "\u03b7": 9, "\u03b8i": [111, 112], "\u03bcg": 142, "\u03bcm": [111, 112], "\u0430": [111, 112], "\u0561": [111, 112], "\u1d44": [111, 112], "\u1d8f": [111, 112], "\u1e01": [111, 112], "\u1e9a": [111, 112], "\u1ea1": [111, 112], "\u1ea3": [111, 112], "\u1ea5": [111, 112], "\u1ea7": [111, 112], "\u1ea9": [111, 112], "\u1eab": [111, 112], "\u1ead": [111, 112], "\u1eaf": [111, 112], "\u1eb1": [111, 112], "\u1eb3": [111, 112], "\u1eb5": [111, 112], "\u1eb7": [111, 112], "\u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1": 1, "\u2153": [111, 112], "\u2460": 21, "\u2c65": [111, 112], "\u3053\u3093\u306b\u3061\u306f": 105, "\u3053\u3093\u306b\u3061\u306f\u4e16\u754c": 105, "\u4e16\u754c": 105, "\u53bb": 140, "\u53bb\u6211": 140, "\u6211": 140, "\u6211\u53bb": 140, "\u6211\u5f00\u59cb\u5199": 139, "\u6545": 19, "\u6df1\u5733": 20, "\u7f8e": 19, "\u7f8e\uc11c": 20, "\u8bf4": 139, "\u8f9b\u4e11\u5e74": 14, "\ua7bb": [111, 112], "\uac00": [14, 15, 17, 19, 140, 145], "\uac00\uacf5\uc2dd\ud488": 15, "\uac00\ub2a5": 16, "\uac00\ub2a5\uc131": 20, "\uac00\ub2a5\uc131\uacfc": 19, "\uac00\ub2a5\uc131\uc740": [16, 19], "\uac00\ub2a5\ud558\ub2e4": 19, "\uac00\ub2a5\ud55c": 15, "\uac00\ub2e4": [140, 145], "\uac00\ub729\uc774\ub098": [15, 19], "\uac00\ub85c\ub9c9\uc544": 141, "\uac00\ubc29": 145, "\uac00\ubc29\uc5d0": 145, "\uac00\ubc29\uc740": 145, "\uac00\ubc29\uc744": 145, "\uac00\ubc29\uc774": 145, "\uac00\uc6b4\ub370": 19, "\uac00\uc785\uc774": [15, 19], "\uac00\uc785\uc790": 14, "\uac00\uc785\ud55c\ub2e4\uace0": [15, 19], "\uac00\uc790": 140, "\uac00\uc7a5": [14, 19], "\uac00\uc804": [14, 21], "\uac00\uc871": 15, "\uac00\uce58\ub294": 19, "\uac01": [15, 19], "\uac01\uac01": 17, "\uac01\uad11\ubc1b": 14, "\uac04": 20, "\uac04\uc2e0\ud788": 21, "\uac08\ub4f1\uc758": 20, "\uac10\uc18c\uac00": 19, "\uac10\uc18c\uc138\ub85c": 15, "\uac10\uc18c\ud55c\ub2e4\ub294": 16, "\uac10\uc5fc\uc99d": 14, "\uac10\ucdb0\uac00\uace0": 15, "\uac10\ud0c4\uc0ac": 140, "\uac14\ub2e4": [140, 145], "\uac14\uc5c8\ub2e4": 140, "\uac15\ub989\uc6d0\uc8fc\ub300": 19, "\uac15\uc138": 19, "\uac15\uc138\ub97c": 19, "\uac15\uc870": 20, "\uac15\ud654": [16, 17, 19], "\uac15\ud654\uc5d0\ub3c4": 14, "\uac15\ud654\ud558\uaca0\ub2e4": 14, "\uac16\ub294": 14, "\uac19\ub2e4": 16, "\uac19\uc740": 19, "\uac1c\ubc1c": 16, "\uac1c\ubc1c\uc790": 16, "\uac1c\ubc1c\ud560": 14, "\uac1c\uc120\uacfc": [14, 16], "\uac1c\uc2dc": 15, "\uac1c\uc778": 19, "\uac1c\uc815\uc548\uae4c\uc9c0": 19, "\uac1c\ucd5c": 20, "\uac1c\ucd5c\ud588\ub2e4\uace0": 14, "\uac1c\ud3b8": 19, "\uac24\ub7ed\uc2dcz\ud3f4\ub4dc3\uc640": 14, "\uac24\ub7ed\uc2dcz\ud50c\ub9bd3": 14, "\uac70\ub798\ub294": 16, "\uac70\ub798\ub97c": 16, "\uac70\ub798\ube44\uc6a9": 16, "\uac70\ub9ac\ub450\uae30": 15, "\uac70\uce5c": [15, 19], "\uac74\uac15": 14, "\uac78\uc5b4\uc628": 15, "\uac78\uccd0": 14, "\uac80\uc0c9": 16, "\uac80\ud1a0\ub97c": [15, 19], "\uac83\uc73c\ub85c": [14, 16, 19], "\uac83\uc744": [14, 16], "\uac83\uc774": [14, 16, 19], "\uac83\uc774\ub77c\ub294": 19, "\uac83\uc774\uba70": 16, "\uac8c\ud2f0\uc774\ubbf8\uc9c0\ubc45\ud06c": 14, "\uaca9\uc6d4\uac04\uc73c\ub85c": 15, "\uaca9\uc790\uac00": 16, "\uacaa\uc5c8\uc73c\ub098": 20, "\uacac\uc81c": 17, "\uacb0\uacfc": 140, "\uacb0\ub860\uc740": 19, "\uacb0\uc815\ub41c": 15, "\uacb0\uc815\ub41c\ub2e4": 16, "\uacb0\uc815\ud588\ub2e4": 14, "\uacbd\uad6c\uc6a9": 20, "\uacbd\uae30": [19, 141], "\uacbd\uae30\uc0c1\ud669\uc5d0": 141, "\uacbd\ub0a8\ub3c4\uc640": 20, "\uacbd\ubcf4\ub97c": 141, "\uacbd\uc601\uc9c4": 14, "\uacbd\uc601\uc9c4\ub2e8": 123, "\uacbd\uc6b0": [16, 19], "\uacbd\uc790\ub144": 21, "\uacbd\uc7c1": [14, 17], "\uacbd\uc7c1\ub825": [14, 16], "\uacbd\uc81c": [19, 20], "\uacbd\uc81c\uae30\uc0c1\ub3c4": [14, 21], "\uacbd\uc81c\ub294": 14, "\uacbd\uc81c\uc131\uc7a5\ub960": 14, "\uacc4\uc18d": 14, "\uacc4\uc18d\ub418\ub294": 15, "\uacc4\uc5f4\uc0ac": [15, 16, 19], "\uacc4\uc5f4\uc0ac\ub4e4\uc774": [14, 16], "\uacc4\uc5f4\uc0ac\ub97c": 19, "\uacc4\uc5f4\uc0ac\ub9c8\ub2e4": 19, "\uacc4\ud68d\uc774\ub2e4": 14, "\uace0": [14, 15, 16, 19, 142], "\uace0\uac1d": 16, "\uace0\ub9bd\uc5b4": 140, "\uace0\ubc1c\uad8c": [14, 16], "\uace0\uc131\uc7a5": 17, "\uace0\uc218\ud558\ub294": 15, "\uace0\uc6a9": [14, 16, 17, 19, 21, 22], "\uace0\uc6b0": 140, "\uace0\ud615\uc5f0": 14, "\uace8\uc774": 20, "\uacf1": 140, "\uacf5": [14, 16, 21], "\uacf5\uac1c": 94, "\uacf5\uacfc\ub300\ud559\uc5d0\uc11c": 14, "\uacf5\uae09\ub9dd": [14, 16, 17, 19, 21, 22], "\uacf5\uae09\ud55c\ub2e4": 20, "\uacf5\ub3d9": 14, "\uacf5\ub3d9\ucde8\uc7ac\ub2e8": 20, "\uacf5\ub85c": 14, "\uacf5\uc720": [15, 16], "\uacf5\uc7a5\uc774": [19, 20], "\uacf5\uc815\uac70\ub798\ubc95\uc740": [14, 16], "\uacfc": [14, 16, 140, 141], "\uacfc\uac70": 15, "\uacfc\ub294": 16, "\uacfc\uc790": 140, "\uacfc\uc790\ub97c": 140, "\uacfc\uc81c": 14, "\uacfc\uc81c\ub3c4": 14, "\uacfc\uc81c\ub97c": 14, "\uacfc\ud559": 16, "\uad00\uacc4": 16, "\uad00\uacc4\uc0ac\uac00": [15, 19], "\uad00\uacc4\uc5b8": 140, "\uad00\uacc4\uc790": 16, "\uad00\uacc4\uc790\ub294": 15, "\uad00\ub828": [14, 16], "\uad00\ub9ac": 16, "\uad00\uc7a5\uacfc": 19, "\uad00\uce21": 19, "\uad00\uce21\ub418\uc5c8\ub2e4": 141, "\uad00\ud615\uc0ac": 140, "\uad0c": 141, "\uad11\ubc94\uc704": 16, "\uad50\uc218": 19, "\uad50\uc721": [14, 16], "\uad50\uc721\uc744": 14, "\uad50\ucc29\uc5b4": 140, "\uad6c\uac15\uc720\uc0b0\uade0": 14, "\uad6c\uacbd\ubbfc": 20, "\uad6c\uae00": 17, "\uad6c\ub3c4": 19, "\uad6c\ub9e4\ub825": 19, "\uad6c\ubb38": 140, "\uad6c\uc131\ub418\uace0": 14, "\uad6c\uc131\ub418\uba70": 14, "\uad6c\uc778\ub09c": 16, "\uad6c\uc870\uc801": 17, "\uad6d\uac00": 16, "\uad6d\uac00\uc5d0": 141, "\uad6d\ub0b4": [15, 17, 19, 20, 21, 94], "\uad6d\uba74": 17, "\uad6d\ucc45\uc0ac\uc5c5": 17, "\uad74\uc808\uc5b4": 140, "\uad8c\uce60\uc2b9": 14, "\uaddc\uaca9": 17, "\uaddc\uce59": 140, "\uadf8": [16, 140], "\uadf8\uac04": 20, "\uadf8\ub3d9\uc548": 16, "\uadf8\ub7f0\ub370": 15, "\uadf8\ub7fc\uc5d0\ub3c4": 16, "\uadf8\ub8f9": [15, 19], "\uadf8\ub8f9\ub0b4": [14, 16], "\uadf8\ub8f9\uc73c\ub85c": [14, 16], "\uadf8\ub8f9\uc758": [15, 19], "\uadf8\ub97c": 140, "\uadf8\ub9b0\uc5d0\ub108\uc9c0": 20, "\uadf8\uc5b4\ub77c": 140, "\uadf8\uc5b4\uc11c": 140, "\uadf8\uce58\uc9c0": 15, "\uadf8\ud574": 15, "\uadfc\uac70\ub294": 19, "\uadfc\uba74": 14, "\uae00\ub85c\ubc8c": [14, 16, 20, 21], "\uae08": 141, "\uae08\ub144\ub3c4": 14, "\uae08\ub9ac": 141, "\uae08\ub9ac\uc815\ucc45\uc744": 141, "\uae08\uc735": 14, "\uae08\uc735_\uc7ac\ud14c\ud06c": 20, "\uae08\uc735\uc704\uc6d0": 15, "\uae08\uc735\uc704\uc6d0\uc7a5\uc774": 15, "\uae08\uc735\uc9c0\uc8fc": 19, "\uae08\uc735\ud22c\uc790": 20, "\uae08\ud1b5\uc704": 141, "\uae08\ud1b5\uc704\ub294": 141, "\uae09": 16, "\uae0b\uace0": 140, "\uae0b\ub2e4": 140, "\uae30": [20, 103, 141], "\uae30\uac04": 19, "\uae30\ub2a5": 16, "\uae30\ub2a5\uc131": 14, "\uae30\ub2a5\uc744": 20, "\uae30\ub300\uac10\uc774": 19, "\uae30\ub300\ud574\ubcfc": 19, "\uae30\ub85d\uc73c\ub85c": 15, "\uae30\ub85d\ud55c": 14, "\uae30\ub85d\ud560": 14, "\uae30\ubcf8\uc138\uc158": 20, "\uae30\uc220": [14, 16, 17], "\uae30\uc220\uc744": 14, "\uae30\uc220\ud601\uc2e0": 17, "\uae30\uc5c5": [14, 15, 16, 17, 19, 20, 21, 22], "\uae30\uc5c5\ub4e4\ub3c4": 15, "\uae30\uc5c5\ub4e4\uc758": 15, "\uae30\uc5c5\ub4e4\uc774": 15, "\uae30\uc5c5\uc724\ub9ac": [14, 16, 17, 19, 21, 22], "\uae30\uc5c5\uc744": 15, "\uae30\uc5c5\uc774\uc775\uc740": 19, "\uae30\uc790": [14, 15, 16, 19, 20], "\uae30\uc870\uc5f0\uc124\uc5d0\uc11c": 20, "\uae30\uc874": 16, "\uae30\ud55c\uc778": 19, "\uae30\ud68c": 14, "\uae30\ud6c4\ubcc0\ud654": [14, 16, 17, 19, 21, 22], "\uae40": 20, "\uae40\ub3d9\uad00": 20, "\uae40\ubbfc\uc601": 14, "\uae40\uc131\ubbfc": 14, "\uae40\uc131\uc740": 20, "\uae40\uce58\ub97c": 132, "\uae40\ud76c\uc6a9": 14, "\uae4a\uc5b4\uc9c0\uba74\uc11c": 20, "\uae4c\uc9c0\ub3c4": 17, "\ub04c\uc5b4\ubaa8\uc73c\ub294": 19, "\ub05d\ub0b4\uace0": 14, "\ub098": [103, 140], "\ub098\uac00": 141, "\ub098\uac00\uae38": 15, "\ub098\uac00\ub2e4": 145, "\ub098\uac14\ub2e4": 145, "\ub098\ub294": 140, "\ub098\uc11c\uaca0\ub2e4\uace0": 14, "\ub098\uc11c\ub294": 19, "\ub098\uc11c\uc11c": 14, "\ub098\uc120": 15, "\ub098\uc628\ub2e4": 19, "\ub098\uc654\ub2e4": 15, "\ub098\uc774": 103, "\ub098\uce74": 16, "\ub098\ud0c0\ub0b4\ub294": 19, "\ub09c\uc774\ub3c4\uac00": 16, "\ub09c\uc774\ub3c4\ub294": 16, "\ub09c\ud56d": 17, "\ub0a8\uc131\ub4e4\ub85c\ubd80\ud130": [15, 19], "\ub0a9\ubd80": 19, "\ub0a9\ubd80\ub97c": 19, "\ub0a9\ubd80\ud558\ub294": 19, "\ub0a9\ubd80\ud574\uc57c": 19, "\ub0ac\uc9c0\ub9cc": 19, "\ub0b4": 14, "\ub0b4\uac00": 94, "\ub0b4\ub144": 19, "\ub0b4\ub144\uc5d0\ub294": 14, "\ub0b4\ub144\uc5d0\ub3c4": 14, "\ub0b4\ub193\uc740": 15, "\ub0b4\ub194\uc57c": 14, "\ub0b4\ub514\ub518": 16, "\ub0b4\ub9d8\uc744": 94, "\ub0b4\ubd80\uc120": 14, "\ub0b4\uc138\uc6b4": 19, "\ub0b4\uc57c": 19, "\ub0b4\uc77c\uc2e0\ubb38": 14, "\ub0b4\uc9c0": 16, "\ub0b8\ub2e4": 14, "\ub0c9\uc7a5\uace0": [14, 21], "\ub108": 140, "\ub108\ub294": 140, "\ub110\ub9ac": 17, "\ub118\uac8c": 19, "\ub118\ub294": 19, "\ub118\ub294\ub2e4": 19, "\ub118\uc5b4\uc120": 17, "\ub118\uc5b4\uc130\uc73c\ub098": 19, "\ub118\uc744": 19, "\ub124\ud2b8\uc6cc\ud06c": 16, "\ub125\uc3d8": [15, 19], "\ub125\uc3d8\ub294": [15, 19], "\ub144": 17, "\ub144\uc774": 17, "\ub155": 103, "\ub178\ub3d9\ubd80": 16, "\ub178\ub3d9\uc870\ud569": 14, "\ub178\ub4dc\uac00": 16, "\ub178\ub4dc\ub4e4\uc5d0\uac8c": 16, "\ub178\ub77c": 140, "\ub178\ub797": 140, "\ub178\ub825\ud558\ub294": 21, "\ub178\ub825\ud560": 14, "\ub178\uc0ac": 17, "\ub178\uc870": [14, 17], "\ub178\uc870\uc704\uc6d0\uc7a5": 14, "\ub17c\ub780": 14, "\ub192\ub2e4": 19, "\ub192\uc73c\uba70": 16, "\ub192\uc740": [16, 19], "\ub274\uc2a4": 21, "\ub290\ub9b0": 16, "\ub294": [15, 16, 17, 140, 141, 145], "\ub298\uc5b4\ub098\uace0": 15, "\ub298\uc5b4\ub098\ub294": 19, "\ub298\uc5b4\ub0a0": 19, "\ub2a5\ub825": 16, "\ub2c8": [103, 140], "\ub2c8\ub2e4": 103, "\ub2e4": [14, 15, 16, 103, 140, 141, 145], "\ub2e4\uace0": 141, "\ub2e4\ub098\uc640": 94, "\ub2e4\ub974\uace0": [14, 16], "\ub2e4\ub978": [14, 16], "\ub2e4\uc2dc": 15, "\ub2e4\uc591\ud55c": 14, "\ub2e4\uc74c": 14, "\ub2e4\uc74c\uacfc": 16, "\ub2e4\uc74c\ub0a0\uc778": 141, "\ub2e4\uc74c\ub2ec\ubd80\ud130": 14, "\ub2e4\uc774\ub809\ud2b8": 20, "\ub2e4\ud589\ud788\ub3c4": 141, "\ub2e8\uc21c": 140, "\ub2ec": 15, "\ub2ec\uae4c\uc9c0": 14, "\ub2ec\ub77c": 14, "\ub2f4\uae34": 15, "\ub2f4\ub2f9\ud55c": 20, "\ub2f4\ud654": 140, "\ub2f9": 16, "\ub2f9\uc2dc": 15, "\ub2f9\uc7a5": 19, "\ub300\uaddc\ubaa8": 14, "\ub300\uae30\uc5c5": 16, "\ub300\uae30\uc5c5\uc774": 15, "\ub300\ub85c": [14, 16], "\ub300\ub9cc": 141, "\ub300\uba85\uc0ac": 140, "\ub300\ubc95": 16, "\ub300\ubd80\ubd84\uc774": [15, 19], "\ub300\ube44": 19, "\ub300\uc0c1": [20, 140], "\ub300\uc0c1\uc73c\ub85c": [14, 15, 20], "\ub300\uc120": 19, "\ub300\uc138": 19, "\ub300\uc2e0": 15, "\ub300\uc5ec\uc0ac\uc5c5\uc744": 20, "\ub300\uc678\uc801\uc73c\ub85c": 15, "\ub300\uc6a9\ub7c9": 16, "\ub300\uc751\ud558\uae30": 16, "\ub300\uc751\ud574": 14, "\ub300\uc911": 16, "\ub300\uccb4\ud558\ub294": 15, "\ub300\ud1b5\ub839\uc774": [15, 19], "\ub300\ud45c": [14, 21], "\ub300\ud45c\uac00": 14, "\ub300\ud45c\ub294": 20, "\ub300\ud559": 20, "\ub300\ud55c": 20, "\ub300\ud55c\ubbfc\uad6d": 21, "\ub300\ud55c\uc81c\uad6d\uc744": 14, "\ub300\ud574\uc11c\ub294": [14, 16], "\ub300\ud615": [14, 21], "\ub300\ud615\ub9c8\ud2b8": 15, "\ub300\ud615\uc8fc": 19, "\ub354": [15, 16, 19, 20], "\ub354\uc6b1": 14, "\ub370\uc774\ud130": [14, 16], "\ub3c4": 16, "\ub3c4\uad6c": 16, "\ub3c4\ub2ec\ud558\uc9c0": 141, "\ub3c4\uc2dc": 14, "\ub3c4\uc6b0": 140, "\ub3c4\uc785": [14, 17], "\ub3c5": 21, "\ub3c5\ub9bd\uc5b8": 140, "\ub3cc\ud30c\uc5d0": 19, "\ub3d5": 140, "\ub3d5\uae30": 15, "\ub3d9\uad6d\uc81c\uc57d": 14, "\ub3d9\ubc18\uc131\uc7a5": [14, 16, 17, 19, 21, 22], "\ub3d9\uc0ac": [17, 140], "\ub3d9\uc2dc\ub300\ub97c": 20, "\ub3d9\ud559\uac1c\ubbf8\uc6b4\ub3d9": 15, "\ub3d9\ud574\uc548": 141, "\ub3d9\ud574\uc548\uc744": 141, "\ub3d9\ud654\uc57d\ud488": 14, "\ub3d9\ud654\uc57d\ud488\uc740": 14, "\ub3d9\ud654\uc57d\ud488\uc758": 14, "\ub3d9\ud654\uc57d\ud488\uc774": 14, "\ub418\uba74": 14, "\ub418\uc5c8\uace0": 15, "\ub41c": [16, 17], "\ub454\ud654\ud558\uba74\uc11c": 20, "\ub4a4\uc5d0\uc11c": 16, "\ub4dc\ub9ac\uae30": 14, "\ub4e3": 140, "\ub4e4": [16, 17, 140, 145], "\ub4e4\uace0": 145, "\ub4e4\ub2e4": 145, "\ub4e4\uc5b4\uac00\uba74\uc11c": 17, "\ub4e4\uc5b4\uac00\uba74\uc11c\ub4e4\uc5b4\uac00\uba74\uc11c": 17, "\ub4e4\uc5b4\uac00\uc11c": 140, "\ub4e4\uc5b4\uac00\uc168\ub2e4": 145, "\ub4e4\uc5b4\uac00\uc2e0\ub2e4": 145, "\ub4e4\uc5b4\uac14\ub2e4": 145, "\ub4e4\uc5ec\ub2e4\ubcfc": 19, "\ub4ef": 19, "\ub4f1": [14, 15, 16, 17, 19, 20, 21, 141], "\ub4f1\ub3c4": 14, "\ub4f1\ub85d\uc744": 15, "\ub4f1\uc5d0\uc11c\ub294": [14, 21], "\ub4f1\uc73c\ub85c": 17, "\ub4f1\uc744": [14, 15, 16], "\ub4f1\uc7a5\ud588\ub2e4": 15, "\ub4f1\uc7a5\ud588\uc73c\uba70": 15, "\ub514\uc2a4\ud50c\ub808\uc774": [14, 21], "\ub514\uc9c0\ud138": [14, 16, 20], "\ub514\ud53c\uc9c0": 94, "\ub525\ub7ec\ub2dd": 14, "\ub530": 14, "\ub530\ub77c\uc11c": 141, "\ub530\ub77c\uc7a1\uc744": 16, "\ub530\ub974": 14, "\ub530\ub974\uba74": [15, 20], "\ub54c": 14, "\ub54c\ub9c8\ub2e4": 16, "\ub54c\ubb38\uc5d0": 19, "\ub54c\ubb38\uc774": 16, "\ub54c\ubb38\uc774\ub2e4": 19, "\ub5a8\uc5b4\uc9c4": 141, "\ub5a8\uc5b4\uc9c4\ub370\ub2e4": 141, "\ub610": 20, "\ub610\ud55c": 15, "\ub77c\uc774\ube0c": 16, "\ub7ec": 15, "\ub7ec\uc2dc\uc544\uac00": [15, 19], "\ub7f0": 16, "\ub85c": [14, 16, 17, 141], "\ub85c\uace0": 15, "\ub85c\uadf8": 140, "\ub85c\ubd07": 14, "\ub86f\ub370": 16, "\ub86f\ub370\uc1fc\ud551\uacfc": 21, "\ub86f\ub370\uce60\uc131\uc74c\ub8cc\uc758": 14, "\ub8cc": 14, "\ub958": 20, "\ub97c": [14, 16, 17, 19, 20, 103, 140, 142], "\ub9ac\uc11c\uce58\uc13c\ud130\uc7a5\uc740": 19, "\ub9ac\uc6c0\ubbf8\uc220\uad00": 19, "\ub9ac\ucc54": 15, "\ub9c8\ub2e4": 14, "\ub9c8\ub828\uc744": 19, "\ub9c8\ub828\ud55c\ub2e4\ub294": [15, 19], "\ub9c8\uc2a4\ud06c": 14, "\ub9c8\uc774\ub2dd": 14, "\ub9c8\ucf00\ud305": 14, "\ub9cc\ub4e0": 17, "\ub9cc\uba85": 17, "\ub9cc\uba85\uc744": 17, "\ub9cc\uc5d0": [15, 17, 20], "\ub9cc\ud558\ub2e4": 19, "\ub9cc\ud558\ub2e4\ub294": 19, "\ub9ce\uac8c\ub294": 16, "\ub9ce\ub2e4": 15, "\ub9ce\uc740": 19, "\ub9d0": [14, 16], "\ub9d0\ud588\ub2e4": [14, 19], "\ub9db\uc788\ub294": 14, "\ub9de\uace0": 17, "\ub9de\ubb3c\ub824": 19, "\ub9de\ucdb0": [15, 19], "\ub9e4\uac01\ud558\uae30": 20, "\ub9e4\ub144": 15, "\ub9e4\uc6b0": 17, "\ub9e4\uc6d4": 15, "\ub9e4\ucd9c": 14, "\uba38\ub2c8\ud22c\ub370\uc774": [19, 20], "\uba39": [20, 140], "\uba39\uac70\ub9ac\uc5d0": 16, "\uba39\uace0": 94, "\uba39\ub2e4": [130, 140], "\uba39\uc2b5\ub2c8\ub2e4": 132, "\uba39\uc5c8\ub2e4": 140, "\uba39\uc73c\ub7ec": 140, "\uba3c\uc800": [14, 16], "\uba40\ud2f0\ubbf8\ub514\uc5b4": 16, "\uba40\ud2f0\ubbf8\ub514\uc5b4\uacf5\ud559\uacfc": 19, "\uba70": [14, 16, 19], "\uba74\uc81c\ub97c": 20, "\uba85": 140, "\uba85\ubaa9": 16, "\uba85\ubd84": 20, "\uba85\uc0ac": 140, "\uba85\uc608": 14, "\uba85\uc608\ud68c\ubcf5": 14, "\uba85\uc608\ud68c\uc7a5\uc740": 15, "\uba85\ucf8c\ud558\uac8c": 19, "\ubaa8\ub378\uc778": 21, "\ubaa8\ub378\uc785\ub2c8\ub2e4": 141, "\ubaa8\ub450\uac00": 15, "\ubaa8\ubc14\uc77c": 15, "\ubaa8\ubc14\uc77ctv": 16, "\ubaa8\ubc94\uc0ac\ub840\ub85c": 20, "\ubaa8\ud1a0\uac00": 16, "\ubaa9\ud45c\ub85c": 16, "\ubab0\ub9ac\ube0c": 16, "\ubab8\uac12\uc774": 16, "\ubabb\ud558\ub294": 20, "\ubabb\ud558\ub358": 16, "\ubabb\ud588\uae30": 19, "\ubb34\uc0b0\ub420": 20, "\ubb34\uc5ed\ubd84\uc7c1\uacfc": [14, 21], "\ubb34\uc5ed\ubd84\uc7c1\uc774\ub77c\ub294": 21, "\ubb35\ubb35\ud788": 21, "\ubb36\uc5ec\uc9c0\ub294": [14, 16], "\ubb38": 103, "\ubb38\uc7a5": [103, 140], "\ubb38\uc7a5\ubd80\ud638": 140, "\ubb38\uc7a5\uc740": 103, "\ubb38\uc7a5\uc785\ub2c8\ub2e4": 103, "\ubb38\uc7ac\uc778": [15, 19], "\ubb38\uc81c\ub294": 19, "\ubb38\ud654\uacf5\ubcf4\ubd80\uc5d0": 15, "\ubb3c\uac00": 141, "\ubb3c\uac00\uc548\uc815\uacfc": 141, "\ubb3c\ub860": 19, "\ubb3c\ub958\ub300\ub780\uacfc": 14, "\ubbf8": [14, 15, 21, 140], "\ubbf8\uad6d": [16, 20], "\ubbf8\ub2c8\uc2a4\ud0c1": 15, "\ubbf8\ub798": [14, 16], "\ubbf8\ub798\ub97c": 15, "\ubbf8\ub798\uc5d0\uc14b": [14, 20], "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c": 14, "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c\uacfc": 20, "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c\uc740": 20, "\ubbf8\ub9e4\uac01": [15, 19], "\ubbf8\ub9e4\uac01\uc774": [15, 19], "\ubbf8\uc548\ud588\uc5b4\uc694": 21, "\ubbf8\uc57c\ucf54\ud56d\uc5d0": 141, "\ubbf8\ucce4\ub2e4": 15, "\ubbf8\ud761": 17, "\ubbfc\ucca9\ud55c": 14, "\ubc00\uc811\ud558\uac8c": 19, "\ubc0f": [14, 16, 20, 123], "\ubc14\ub780\ub2e4": 15, "\ubc14\ub78c\uc774": 15, "\ubc14\uc774\uc624": 14, "\ubc14\uc774\uc624\uac00\uc2a4": 14, "\ubc14\uc774\uc624\ub294": 14, "\ubc14\uc774\uc624\ub514\uc824": 14, "\ubc15\uc0ac": [14, 20], "\ubc15\uc18c\uc5f0": 19, "\ubc18\ub3c4\uccb4": [14, 17, 21], "\ubc18\ub3c4\uccb4\uc0b0\uc5c5": 19, "\ubc18\uba74": 17, "\ubc18\uc601\ud55c\ub2e4": 16, "\ubc1b\uc558\ub2e4": 16, "\ubc1b\uc740": 16, "\ubc1c": 14, "\ubc1c\uad74": 14, "\ubc1c\uad74\ud558\uace0": 14, "\ubc1c\uad74\ud560": 14, "\ubc1c\uad74\ud574": 14, "\ubc1c\ub839\ud558\uc600\ub2e4": 141, "\ubc1c\ub9de\ucd94\uae30": 14, "\ubc1c\ub9de\ucdb0": 15, "\ubc1c\uc790\ucde8\uc774\uc790": 15, "\ubc1c\uc804": 17, "\ubc1c\ud45c\ud588\uc73c\uba70": 15, "\ubc1c\ud589\ub410\ub2e4": 15, "\ubc1c\ud589\ub418\uae30": 15, "\ubc1c\ud589\ub418\ub358": 15, "\ubc1c\ud589\ud55c": 15, "\ubc1c\ud589\ud588\ub2e4": 15, "\ubc1d\uc558\ub2e4": [14, 21], "\ubc1d\ud614": 141, "\ubc1d\ud614\ub2e4": [14, 15, 19, 141], "\ubc25": 130, "\ubc25\uc744": 130, "\ubc29": 145, "\ubc29\uc2dd": 17, "\ubc29\uc548\uc5d0": 145, "\ubc29\uc5d0": 145, "\ubc29\uc5ed\ubb3c\ud488\uc9c0\uc6d0\uae08": 14, "\ubc29\uc5ed\uc9c0\uc6d0\uae08": 14, "\ubc29\uc73c\ub85c": 145, "\ubc29\uc740": 145, "\ubc29\uc744": 145, "\ubc29\uce68\uc774\ub2e4": 14, "\ubc29\ud5a5\uc744": [14, 16], "\ubc30\ub2f9": 19, "\ubc30\uc6b0": 142, "\ubc30\uc6b0\uace0": 142, "\ubc30\uc6b0\ub294": 21, "\ubc30\uc7ac\ud6c8": 14, "\ubc30\ud130\ub9ac": [16, 20], "\ubc30\ud130\ub9ac\ub97c": 16, "\ubc31\uc2e0": 20, "\ubc31\uc2e0\uae30\uc5c5": 20, "\ubc88\uc9f8": 21, "\ubc8c\uc368\ubd80\ud130": 19, "\ubc95\uc778\uc138": 20, "\ubc97\uc5b4\ub0ac\ub2e4\ub294": 19, "\ubca0\ud2b8\ub0a8": 19, "\ubca4\ucc98\uae30\uc5c5\uac00\ub4e4\ud55c\ud14c": 21, "\ubca4\ucc98\uae30\uc5c5\ud611\ud68c": 16, "\ubcc0\uacbd\ud588\uc73c\uba70": 15, "\ubcc0\ub3d9\ud558\ub294": 16, "\ubcc0\uc218\ub85c": 21, "\ubcc0\ud638\uc0ac\ub294": 20, "\ubcc0\ud638\uc0ac\ub97c": 19, "\ubcc0\ud654": 17, "\ubcc0\ud654\uac00": 19, "\ubcc0\ud654\uc5d0": 14, "\ubcc0\ud654\ud560": 14, "\ubcc4\uc138\ud558\uba74\uc11c": 19, "\ubcd1\ud589": 141, "\ubcf4": 20, "\ubcf4\ub0b4\uc918": 140, "\ubcf4\ub2c8": 19, "\ubcf4\ub984": 14, "\ubcf4\uc600\ub2e4": 19, "\ubcf4\uc720\ud55c": 19, "\ubcf4\uc774\uace0": 19, "\ubcf4\uc778\ub2e4": 19, "\ubcf4\uc870": 14, "\ubcf4\ud1b5\uc8fc": 14, "\ubcf4\ud5d8\uc5c5\ubc95": 19, "\ubcf5\uc0ac": 94, "\ubcf5\uc7a1\ud55c": 19, "\ubcf8\uaca9\ud654\ub2e4": 19, "\ubcf8\uaca9\ud654\ud558\uba74\uc11c": 15, "\ubd24\ub2e4": [14, 19], "\ubd80\ub044\ub7fd\uace0": 21, "\ubd80\ub2f4\ub960\uc740": 20, "\ubd80\ub2f4\uc774": [15, 19], "\ubd80\ubb38": 21, "\ubd80\uc0ac": 140, "\ubd80\uc591": 19, "\ubd80\uc778": 19, "\ubd80\uc7ac": 17, "\ubd80\ud638": 140, "\ubd80\ud68c\uc7a5": 19, "\ubd80\ud68c\uc7a5\uc740": [15, 20], "\ubd80\ud68c\uc7a5\uc758": 19, "\ubd81\ubbf8\ub098": 19, "\ubd81\ubbf8\uc9c0\uc5ed": 14, "\ubd84\uc0ac": [16, 20], "\ubd84\uc11d": 140, "\ubd84\uc11d\uc758\uacac": 123, "\ubd84\uc11d\uc774\ub2e4": 19, "\ubd84\uc11d\ud55c": [14, 16], "\ubd84\uc57c": [14, 20], "\ubd84\uc57c\uc5d0\uc11c": 14, "\ubd84\uc57c\uc5d0\uc11c\ub3c4": 20, "\ubd84\uc704\uae30\uc5d0": [15, 19], "\ubd84\ud560": 19, "\ubd84\ud560\ud560": 20, "\ubd88\uac00\ud53c\ud560": 19, "\ubd88\uace0": 15, "\ubd88\uacf5\uc815": [14, 16, 17, 19, 21, 22], "\ubd88\uacfc\ud55c": 17, "\ubd88\uaddc\uce59": 140, "\ubd88\ub9ac\ub294": 19, "\ubd88\ud544\uc694": 16, "\ubd88\ud655\uc2e4\uc131": 16, "\ubd88\ud655\uc2e4\uc131\uc744": 19, "\ube14\ub85d": 16, "\ube14\ub85d\uc5d0": 16, "\ube14\ub85d\uc774": 16, "\ube44": 16, "\ube44\ub86f\ud558\uc5ec": 141, "\ube44\uc5b4\ub9cc": 16, "\ube44\uc6a9\ubd80\ub2f4": 20, "\ube44\uc804\uacf5\uc790\ub4e4\ub3c4": 16, "\ube45": 21, "\ube45\ub370\uc774\ud130": 14, "\ube45\ub370\uc774\ud130\ub97c": 14, "\ube60\ub974\uac8c": 14, "\ube60\ub97c\uc218\ub85d": 16, "\ube60\uc9c4": 20, "\ubfd0\ub9cc": [15, 16, 19], "\uc0ac": [19, 140], "\uc0ac\uace0": [15, 19], "\uc0ac\uacfc": 130, "\uc0ac\uadf8": 15, "\uc0ac\ub0b4": 15, "\uc0ac\ub791": 140, "\uc0ac\ub791\ud558\ub2c8": 140, "\uc0ac\ub791\ud558\ub2e4": 140, "\uc0ac\ubcf4": 15, "\uc0ac\ubcf4\uac00": 15, "\uc0ac\ubcf4\ub294": 15, "\uc0ac\ubcf4\ub3c4": 15, "\uc0ac\ubcf4\ub85c": 15, "\uc0ac\ubcf4\ub97c": 15, "\uc0ac\ubcf4\uc5d0": 15, "\uc0ac\ubcf4\uc5d0\ub3c4": 15, "\uc0ac\uc5c5": 16, "\uc0ac\uc5c5\uad6c\uc870\uc640\ub3c4": 19, "\uc0ac\uc5c5\ubd80": 16, "\uc0ac\uc5c5\ubd80\ubb38\uc778": 20, "\uc0ac\uc5c5\uc744": 16, "\uc0ac\uc5c5\uc774\ub77c": 16, "\uc0ac\uc5c5\ud611\ub825": 20, "\uc0ac\uc5c5\ud654": 17, "\uc0ac\uc678\uc774\uc0ac": 19, "\uc0ac\uc678\uc774\uc0ac\ub85c": 19, "\uc0ac\uc6a9": 14, "\uc0ac\uc6a9\uc790": 17, "\uc0ac\uc7a5": 14, "\uc0ac\uc7a5\uc740": 16, "\uc0ac\uc9c4": [14, 15, 19, 21], "\uc0ac\ucd94\uc704": 19, "\uc0ac\ud68c\uacc4": 16, "\uc0ac\ud68c\uacf5\ud5cc": [14, 16, 17, 19, 20, 21, 22], "\uc0ac\ud68c\uc801": 15, "\uc0b0\uc5c5": 14, "\uc0b0\uc5c5\uc7ac\ud574": 17, "\uc0b0\uc5c5\ud1b5\uc0c1\uc790\uc6d0\ubd80\ub294": 20, "\uc0b0\uc5c5\ud3d0\uae30\ubb3c": 14, "\uc0b0\uc5c5\ud601\uba85\uacfc": 14, "\uc0b0\ucd9c": 16, "\uc0b0\ucd9c\uc758": 16, "\uc0b0\ud559\uc7a5\ud559\uc0dd": 14, "\uc0b0\ud559\ud611\ub825": 14, "\uc0b0\ud559\ud611\ub825\uc13c\ud130": 14, "\uc0b0\ud559\ud611\ub825\uc13c\ud130\ub294": 14, "\uc0b0\ud559\ud611\ub825\uc744": 14, "\uc0b6\ud130\uc5d0\uc11c": 21, "\uc0bc\uc131": 19, "\uc0bc\uc131sd": 19, "\uc0bc\uc131sdi\ub294": 16, "\uc0bc\uc131\uacfc": [14, 21], "\uc0bc\uc131\uadf8\ub8f9": 19, "\uc0bc\uc131\uadf8\ub8f9\uc758": 19, "\uc0bc\uc131\uadf8\ub8f9\uc8fc": 19, "\uc0bc\uc131\ubb3c\uc0b0": 19, "\uc0bc\uc131\ubc14\uc774\uc624\ub85c\uc9c1\uc2a4\uac00": 20, "\uc0bc\uc131\uc0dd\uba85": 19, "\uc0bc\uc131\uc0dd\uba85\ubc95": 19, "\uc0bc\uc131\uc804\uc790": [17, 19, 123], "\uc0bc\uc131\uc804\uc790\uac00": 14, "\uc0bc\uc131\uc804\uc790\ub294": 19, "\uc0bc\uc131\uc804\uc790\uc11c\ube44\uc2a4": 16, "\uc0bc\uc131\uc804\uc790\uc640": [19, 20], "\uc0bc\uc131\uc99d\uad8c": 19, "\uc0c1\ub300\uc801\uc73c\ub85c": 14, "\uc0c1\ubc18\uae30": 19, "\uc0c1\uc0dd": [14, 16, 17, 19, 21, 22], "\uc0c1\uc18d": 19, "\uc0c1\uc18d\uc138": 19, "\uc0c1\uc18d\uc138\ub97c": 19, "\uc0c1\uc18d\uc138\ub9cc": 19, "\uc0c1\uc2b9": 14, "\uc0c1\uc2b9\uc744": 19, "\uc0c1\uc2b9\uc7a5": 19, "\uc0c1\uc2b9\ud3ed\uc744": 14, "\uc0c1\uc6a9\ud654": 17, "\uc0c1\uc7a5\uc801\uaca9\uc131": 15, "\uc0c1\ud0dc\uc5d0": 20, "\uc0c1\ud488\uc774\ub2e4": 15, "\uc0c1\ud669": [16, 141], "\uc0c8": 21, "\uc0c8\ub85c\uc6b4": 16, "\uc0c8\ubcbd": 141, "\uc0c8\ud574\uac00": [14, 21], "\uc0c8\ud574\uc5d0": 14, "\uc0d8": 103, "\uc0d8\ud50c": 103, "\uc0dd\uac01\ud55c": 16, "\uc0dd\uaca8\ub09c": 16, "\uc0dd\uc0b0": [14, 19], "\uc0dd\uc0b0\uacfc": 19, "\uc0dd\uc0b0\uae30\uc220": 16, "\uc0dd\uc0b0\uc740": 19, "\uc0dd\uc0b0\uc758": 20, "\uc0dd\ud65c\ud3d0\uae30\ubb3c": 14, "\uc11c\ubc84\uc5d0": 140, "\uc11c\ube44\uc2a4": 17, "\uc11c\uc18c\uc815": 14, "\uc11c\uc220": 140, "\uc11c\uc6b8": [15, 20, 21], "\uc11c\uc6b8\ub300": 14, "\uc11c\uc6b8\ub300\ub294": 14, "\uc11c\uc6b8\ub300\uc640": 14, "\uc11c\uc6b8\uc2dc": 15, "\uc11d": [14, 20], "\uc120": [14, 15], "\uc120\ub3c4\ud560": 14, "\uc120\uc21c\ud658": 19, "\uc120\uc5b4\ub9d0\uc5b4\ubbf8": 140, "\uc120\uc804": 20, "\uc120\uc815\ud574": 14, "\uc120\uc9c0\uae09": 14, "\uc120\uc9c4\uad6d": 19, "\uc120\ud0dd\ud55c": [15, 19], "\uc120\ud3ec\ud558\uae30": 14, "\uc124\ub9bd": [14, 16], "\uc124\ub9bd\ub41c": 20, "\uc124\uba85": 21, "\uc12c\uc5d0\uc11c": 141, "\uc131": 15, "\uc131\uacf5": 16, "\uc131\uacfc\ub294": 15, "\uc131\uc7a5": [14, 16], "\uc131\uc7a5\uc138": 14, "\uc131\uc7a5\uc774": 20, "\uc131\uc7a5\ud3ed\uc740": 19, "\uc131\uc7a5\ud558\uace0": 14, "\uc131\ud615\ud0c4": 14, "\uc138": 103, "\uc138\uacc4": [14, 16, 19, 20], "\uc138\uacc4\ub294": 21, "\uc138\uacc4\uc801\uc778": [14, 19], "\uc138\ub300": 17, "\uc138\uc0c1": 14, "\uc138\uc694": 142, "\uc138\ud0c1\uae30": [14, 21], "\uc13c\uc11c": 17, "\uc148\ubc95\uc774": 19, "\uc167\ub2e4\uc6b4\uc73c\ub85c": 19, "\uc18c\uaddc\ubaa8": 141, "\uc18c\ub9c8\ud56d\uc5d0": 141, "\uc18c\ube44\ub294": 19, "\uc18c\ube44\uc790": [14, 16, 17, 19, 21, 22], "\uc18c\uc1a1": [14, 16, 17, 19, 21, 22], "\uc18c\uc2dd\uae4c\uc9c0": [15, 19], "\uc18c\uc2dd\uc5d0": [15, 19], "\uc18c\uc561\uc73c\ub85c": 15, "\uc18c\uc758": 14, "\uc18c\ud1b5\uc218\ub2e8\uc774\ub2e4": 15, "\uc18c\ud1b5\uc5d0": 15, "\uc18c\ud1b5\uc758": 15, "\uc18c\ud504\ud2b8\uc6e8\uc5b4": 14, "\uc18c\ud615": 14, "\uc18d": 16, "\uc18d\ub3c4\uac00": 16, "\uc18d\ub3c4\ub294": [14, 16], "\uc18d\ub3c4\ub97c": 14, "\uc18d\ub3c4\uc758": 16, "\uc18d\ucd9c\ud558\uace0": [15, 19], "\uc190\uc2e4\ubcf4\uc0c1": 14, "\uc190\uc7a1\uace0": 14, "\uc1a1\uc2e0\ub41c\ub2e4": 16, "\uc1fc\ud551": [15, 19], "\uc218": [14, 17, 19, 21], "\uc218\uae09": 19, "\uc218\ub2e8\uc774\ub2e4": 15, "\uc218\ub825": 14, "\uc218\ub825\ubc1c\uc804": 14, "\uc218\ub85d\ub410\ub2e4": 15, "\uc218\ub97c": 16, "\uc218\uc0ac": 140, "\uc218\uc18c\ub97c": 20, "\uc218\uc18c\uc804\uae30\ucc28": [15, 19], "\uc218\uc218\ub8cc": 20, "\uc218\uc2dd\uc5b8": 140, "\uc218\uc5b5": 16, "\uc218\uc694": [14, 16, 19], "\uc218\uc694\uac00": 16, "\uc218\uc694\uc608": [15, 19], "\uc218\uc775\uc744": 16, "\uc218\uc900": 17, "\uc218\ucc9c\ub9cc": 16, "\uc218\ucd9c": [15, 19], "\uc218\ucd9c\uc774": 15, "\uc218\ud589\ud558\uace0": 14, "\uc218\ud589\ud558\ub294": 14, "\uc218\ud589\ud560": 14, "\uc21c\uc11c\ub294": 16, "\uc21c\uc218": 94, "\uc220\ubd80": 140, "\uc2a4": 103, "\uc2a4\uc2a4\ub85c": 14, "\uc2a4\ud2b8": 103, "\uc2a4\ud338\uacfc": 15, "\uc2a4\ud3ec\uce20\uc720\ud2f8\ub9ac\ud2f0\ucc28\ub7c9": 21, "\uc2a4\ud3ec\uce20\uce74": 94, "\uc2a4\ud53c\ud2b8\uc640": 16, "\uc2b5\ub2c8\ub2e4": 142, "\uc2b9\uc778": 20, "\uc2b9\uc9c4": 16, "\uc2dc": 14, "\uc2dc\uac00\ucd1d\uc561": 19, "\uc2dc\uacc4\ubc29\ud5a5\uc73c\ub85c": 19, "\uc2dc\uacc4\uc81c\ub85c": 20, "\uc2dc\uae30\ub97c": 20, "\uc2dc\ub098\ub9ac\uc624\ubcc4": 19, "\uc2dc\ub0b4": 15, "\uc2dc\ub3c4\uc5d0": 15, "\uc2dc\uba58\ud2b8": 14, "\uc2dc\uc2a4\ud15c\uc758": 14, "\uc2dc\uc791": 17, "\uc2dc\uc791\uc810\uc5d0": 19, "\uc2dc\uc791\ud588\uc73c\uba70": 15, "\uc2dc\uc7a5": [15, 17, 19], "\uc2dc\uc7a5\uc5d0": [15, 16, 19], "\uc2dc\uc7a5\uc5d0\uc11c": [14, 21], "\uc2dc\uc7a5\uc5d0\uc11c\ub294": 19, "\uc2dc\uc7a5\uc740": 21, "\uc2dc\uc7a5\uc774": 14, "\uc2dc\uc808\uc778": 15, "\uc2dc\ucf1c": 14, "\uc2dc\ud589\ud574\uc624\ub358": 15, "\uc2dd\ud488\uc758\uc57d\ud488\uc548\uc804\ucc98\uac00": 20, "\uc2e0": 14, "\uc2e0\uace0": 19, "\uc2e0\uace0\uac00": 19, "\uc2e0\uace0\uc11c": 16, "\uc2e0\uaddc": [14, 16], "\uc2e0\ub144\uae30\ud68d": 14, "\uc2e0\ub144\uc0ac\ub97c": 14, "\uc2e0\ub2e4": 145, "\uc2e0\ub3d9\uc900": 19, "\uc2e0\uc0c1\ud6c8": 14, "\uc2e0\uc124": 14, "\uc2e0\uc124\ud558\uace0": 14, "\uc2e0\uc57d\ud6c4\ubcf4\ubb3c\uc9c8": 14, "\uc2e0\uc5d0\ub108\uc9c0\ub294": 14, "\uc2e0\uc784": 19, "\uc2e0\uc7ac\uc0dd\uc5d0\ub108\uc9c0": 17, "\uc2e0\uc885": 14, "\uc2e0\uccad\uc11c\ub97c": [15, 19], "\uc2e0\ucd95\ub144": 14, "\uc2e0\ud559\ucca0": 20, "\uc2e0\ud55c\uae08\uc735": 19, "\uc2e0\ud55c\uae08\uc735\uc758": 19, "\uc2e0\ud55c\uae08\uc735\uc9c0\uc8fc": 14, "\uc2e0\ud55c\uc740\ud589": 14, "\uc2e4\uc2dc": 14, "\uc2e4\uc801": 19, "\uc2e4\uc801\uc774": 19, "\uc2e4\uc815": 17, "\uc2e4\uc81c": 16, "\uc2e4\uc9c8\uc2ec\uc0ac": 15, "\uc2e4\ud328": 17, "\uc2e4\ud589": 16, "\uc2ec\ud654": 16, "\uc2f6\uc5b4\uc11c": 94, "\uc4f0\ub808\uae30": 14, "\uc4f4": 94, "\uc544": 140, "\uc544\ub2c8\ub77c": [15, 16, 19], "\uc544\ubb34\ub3c4": [15, 19], "\uc544\ubc84\uc9c0": 145, "\uc544\ubc84\uc9c0\uac00": 145, "\uc544\ubc84\uc9c0\uac00\uac00\ubc29\uc744\ub4e4\uace0\uac00\uc2e0\ub2e4": 145, "\uc544\ubc84\uc9c0\uac00\ubc29\uc5d0\ub4e4\uc5b4\uac00\uc2e0\ub2e4": 145, "\uc544\ubc84\uc9c0\ub294": 145, "\uc544\uc2dc\uc544\uacbd\uc81c": [14, 20], "\uc544\uc2dc\uc544\ub098\ud56d\uacf5": 20, "\uc544\uc8fc\uacbd\uc81c": [15, 19], "\uc544\uc9c1": [17, 19], "\uc545\ud654\ub41c": [15, 19], "\uc548": [19, 103], "\uc548\ub155": 142, "\uc548\ub155\ud558\uc138\uc694": [103, 141, 142], "\uc548\ub4dc\ub85c\uc774\ub4dc": 17, "\uc548\ubcd1\ub355": 15, "\uc548\uc5d0": [14, 16], "\uc548\uc804\uad00\ub9ac": [14, 16, 17, 19, 21, 22], "\uc548\uc815": 141, "\uc548\ud568": 17, "\uc54a\uace0": 15, "\uc54a\uc558\ub2e4": 141, "\uc54c\ub798\uc2a4\uce74": 141, "\uc54c\ub824\uc84c\ub2e4": 19, "\uc54c\ub9ac\ub294": 15, "\uc55e\uc11c": [14, 16], "\uc55e\uc11c\ub098\uac00\ub294": 20, "\uc55e\uc904": 20, "\uc560\ub110\ub9ac\uc2a4\ud2b8\ub294": 19, "\uc560\ud50c": 17, "\uc560\ud50c\ub9ac\ucf00\uc774\uc158": 16, "\uc561\uc218\uac00": 19, "\uc561\uc815\ud45c\uc2dc\uc7a5\uce58": 14, "\uc571": 15, "\uc57c\uae30": 16, "\uc57d": [14, 20, 141], "\uc57d\uc18d\ud588\ub2e4": 14, "\uc591\uadf9\uc81c": 16, "\uc591\ub300\uadfc": 16, "\uc591\uc0c1\uc744": 19, "\uc591\uc131": 14, "\uc591\uc131\ud558\uae30": 14, "\uc591\uc2ec\uc801\uc778": 16, "\uc591\uce21\uc740": 14, "\uc5b4": 140, "\uc5b4\uac04": 140, "\uc5b4\ub824\uc6b4": 20, "\uc5b4\ub9d0": 140, "\uc5b4\ub9d0\uc5b4\ubbf8": 140, "\uc5b4\ubbf8": 140, "\uc5b8": 140, "\uc5bd\ud600": 19, "\uc5c4\uaca9\ud55c": 19, "\uc5c5\uacc4": [14, 21], "\uc5c5\uacc4\uc5d0": 20, "\uc5c5\ubb34": 14, "\uc5c5\ubb34\ud611\uc57d": 20, "\uc5c5\uc885\ub3c4": [14, 16], "\uc5c5\uc885\ubcc4": [14, 21], "\uc5c5\uc885\ubcc4\ub85c": [15, 19], "\uc5c5\uc885\uc740": [15, 19], "\uc5c5\uccb4\uc758": [14, 21], "\uc5c6\ub294": 16, "\uc5c6\ub2e4": 16, "\uc5c6\uc5b4": 16, "\uc5c6\uc774": 16, "\uc5c8": 140, "\uc5d0": [14, 15, 16, 17, 19, 20, 141, 145], "\uc5d0\uac8c": [14, 16], "\uc5d0\ub108\uc9c0\uacbd\uc81c\uc5f0\uad6c\uc6d0": 14, "\uc5d0\ub108\uc9c0\ubd80\ubb38": 20, "\uc5d0\ub108\uc9c0\uc6d0": [14, 16], "\uc5d0\uc11c": [14, 17, 20, 141], "\uc5d0\uc11c\uc758": 16, "\uc5d0\uce58\uc5d0\ud504\uc54c": 15, "\uc5ec\uae30\uc5d0": 19, "\uc5ec\ub825\uc740": 16, "\uc5ec\uc131": 19, "\uc5ec\ud30c\ub97c": [15, 19], "\uc5ed\ub3d9\uc801\uc774\uba74\uc11c": 21, "\uc5ed\ub7c9\uc744": 14, "\uc5ed\uc0ac\uc801": 19, "\uc5ed\ud560": 20, "\uc5ed\ud560\uc744": 15, "\uc5f0": [15, 19], "\uc5f0\uad6c": [16, 17], "\uc5f0\uad6c\uac1c\ubc1c": 14, "\uc5f0\ub8cc": 14, "\uc5f0\ub8cc\uc720": 14, "\uc5f0\ub8cc\uc804\uc9c0\uc640": 14, "\uc5f0\ubd80\uc5f0\ub0a9\uc81c\ub3c4\ub97c": 19, "\uc5f0\uc548": 141, "\uc5f0\ud569": 15, "\uc5f0\ud569\ub274\uc2a4": 15, "\uc5f4": [14, 20], "\uc5f4\ub3c4\uac00": 141, "\uc5f4\ub9ac\ub294": 20, "\uc5f4\ud48d\uc774": 15, "\uc601\uad6d\ud45c\uc900\ud611\ud68c": 20, "\uc601\ubb38": 21, "\uc601\uc5c5\uc774\uc775": 21, "\uc601\uc5c5\uc774\uc775\uc740": 19, "\uc601\uc5c5\uc774\uc775\uc774": 19, "\uc601\uc5ed\uc5d0\uc11c": 14, "\uc601\uc785\ud560": 19, "\uc601\uc791\ubb38": 21, "\uc601\ud5a5\uc744": 15, "\uc608\uace0": 16, "\uc608\uc0c1": 17, "\uc608\uc0c1\ub41c\ub2e4": 19, "\uc608\uc815\uc774\ub2e4": [14, 19], "\uc624": 21, "\uc624\ub294": 20, "\uc624\ub298\ubd80\ud130": 21, "\uc624\ub974": 140, "\uc624\ub978\ucabd": 20, "\uc624\uc2a4\ud15c": 15, "\uc624\uc2a4\ud15c\uc784\ud50c\ub780\ud2b8": 15, "\uc624\uc804": 14, "\uc624\ud53c\uc2a4": 20, "\uc624\ud6c4": [15, 20, 141], "\uc628": 21, "\uc628\ub77c\uc778": 15, "\uc62c": 140, "\uc62c\ub77c": 140, "\uc62c\ud574": [14, 19], "\uc640": 17, "\uc640\uc774\ube0c\ub85c": 17, "\uc65c": 16, "\uc678": 16, "\uc678\uad6d\uc778\uacfc": 19, "\uc678\uc2dd\uc5c5\uacc4\uc5d0": 15, "\uc678\ud658\uc704\uae30\ub294": 15, "\uc67c\ucabd": 19, "\uc694": 103, "\uc694\ub3d9\uce58\uace0": 19, "\uc694\uc778": 19, "\uc694\uc778\ub4e4\uc774": [14, 16], "\uc694\uccad": 14, "\uc6a9\uc5b8": 140, "\uc6b0\ub4dc": 14, "\uc6b0\ub824\ub3c4": 14, "\uc6b0\ub9ac\uae08\uc735": 19, "\uc6b0\ub9ac\uae08\uc735\uc740": 19, "\uc6b0\ub9ac\ub098\ub77c": [14, 15], "\uc6b0\ub9ac\ub098\ub77c\ub294": 141, "\uc6b0\uc544": 21, "\uc6b0\ud06c\ub77c": 15, "\uc6b4\uc218\uc7a5\ube44": [15, 19], "\uc6b4\uc218\ucc3d\uace0": [15, 19], "\uc6b4\uc601": 14, "\uc6b4\uc601\ub418\ub294": 19, "\uc6b4\uc601\ub41c\ub2e4": 14, "\uc6b4\uc601\ube44": 16, "\uc6b4\uc601\ud558\ub294": 14, "\uc6b4\uc6a9": 20, "\uc6b4\uc6a9\ud558\ub294": [15, 19], "\uc6b8\uc0b0": 20, "\uc6c0\uc9c1\uc784": 19, "\uc6c0\uc9c1\uc784\uc744": 19, "\uc6cc\ub099": 19, "\uc6cc\uc2f1\ud134": 20, "\uc6d0\ubb38": 140, "\uc6d0\uc5d0\uc11c": 16, "\uc6d0\uc744": 16, "\uc6d0\uc790\ub825\ubc1c\uc804": 17, "\uc6d0\uccad": 16, "\uc6d0\ud574\ub85c": 141, "\uc6d0\ud654": 19, "\uc6d4\uac04": 15, "\uc6d4\uac04\uc73c\ub85c": 15, "\uc704": [103, 141], "\uc704\uae30": 17, "\uc704\ubd80\ud130": 19, "\uc704\uc6d0\uc7a5": 14, "\uc704\uc7a5": 16, "\uc704\ud55c": [15, 16, 19, 103], "\uc704\ud574": [14, 15, 16, 19], "\uc704\ud574\uc11c": 14, "\uc704\ud5d8": [14, 16], "\uc704\ud5d8\uc131": 16, "\uc720\uac00\uac00": 14, "\uc720\ub300\uae38": 15, "\uc720\ub3d9\uc131\ubcf4\ub2e4\ub294": 19, "\uc720\ub7fd": 20, "\uc720\ub7fd\ubc1c": 19, "\uc720\uc758": 141, "\uc720\uc758\ud558\ub294": 141, "\uc720\uc8fc": 14, "\uc720\uc9c0\ud558\ub294": 16, "\uc720\ud1b5": 21, "\uc720\ud1b5\uae30\uc5c5": 21, "\uc720\ud1b5\ub300\uc804": 21, "\uc721\uc131\uacfc": 14, "\uc721\uc131\ud558\ub294": 14, "\uc73c\ub85c": [16, 17, 19, 21, 145], "\uc73c\ub85c\ub9cc": 16, "\uc73c\ub85c\uc11c": 16, "\uc740": [14, 15, 16, 17, 103, 140, 145], "\uc740\ud589": 20, "\uc744": [14, 15, 16, 20, 130, 140, 141, 145], "\uc751": 16, "\uc758": [14, 16, 17, 19, 20, 141], "\uc758\ubb38\ud615": 140, "\uc758\ubbf8": 140, "\uc758\ud574": 16, "\uc774": [14, 15, 16, 17, 20, 103, 140, 145], "\uc774\uac74\ud76c": 19, "\uc774\uaca8\ub0b4\uace0": [15, 19], "\uc774\uaca8\ub0b4\ub9ac\ub77c\ub294": 14, "\uc774\uaddc\ud638": 15, "\uc774\ub0a0": 15, "\uc774\ub2e4": 16, "\uc774\ub300\ub85c\ub9cc": 14, "\uc774\ub3d9\uc5d0": 16, "\uc774\ub3d9\ucc2c": 15, "\uc774\ub3d9\ud1b5\uc2e0": 17, "\uc774\ub3d9\ud1b5\uc2e0\ub9dd": 17, "\uc774\ub3d9\ud1b5\uc2e0\uc0ac": 17, "\uc774\ub3d9\ud1b5\uc2e0\uc0ac\uc5c5\uc790": 17, "\uc774\ub77c\uba70": [15, 19], "\uc774\ub904\uc9c8": 19, "\uc774\ub974": 140, "\uc774\ub974\uae30\uae4c\uc9c0": 15, "\uc774\ub974\ub7ec": 140, "\uc774\ub978\ubc14": [15, 19], "\uc774\ub97c": 14, "\uc774\ub984\uc740": 15, "\uc774\ub9c8\ud2b8\uc758": 21, "\uc774\ubbf8": 20, "\uc774\uc0ac\uc758": 123, "\uc774\uc0ac\ud68c\ub97c": 16, "\uc774\uc0c1": [14, 17, 19, 141], "\uc774\uc0c1\uc758": 14, "\uc774\uc18c\uc740": 20, "\uc774\uc288": 14, "\uc774\uc5b4": 15, "\uc774\uc5d0": [15, 19], "\uc774\uc640": 20, "\uc774\uc6c5\uc5f4": 15, "\uc774\uc6d0\ub9cc": 15, "\uc774\uc74c\ud504\ub77c\uc774\ube57\uc5d0\ucffc\ud2f0": 20, "\uc774\uc775": 19, "\uc774\uc775\uc5d0": 16, "\uc774\uc775\uc744": 16, "\uc774\uc7ac\uc6a9": 19, "\uc774\uc804\uc744": 19, "\uc774\uc815\ud55c": 16, "\uc774\ucc3d\ud5cc": 20, "\uc774\ud2c0\uac04": 16, "\uc774\ud6c4": [14, 20], "\uc778": [14, 16, 17], "\uc778\uacf5\uc9c0\ub2a5": [14, 17], "\uc778\ub3c4\uac00": 20, "\uc778\ub825": 14, "\uc778\ub825\uc720\ucd9c": 14, "\uc778\ubb38": 16, "\uc778\uc0ac\ub3cc": 14, "\uc778\uc1c4": 15, "\uc778\uc218\uc804\uc774": 20, "\uc778\uc7ac": 14, "\uc778\uc7ac\ub97c": 14, "\uc778\uc801": 20, "\uc778\uc801\uc790\ubcf8": 17, "\uc778\uc99d\ud6c4": 20, "\uc778\ud130\ubdf0": 14, "\uc778\ud130\ubdf0\ub3c4": 15, "\uc778\ud154": 17, "\uc778\ud55c": 14, "\uc77c": 14, "\uc77c\uac00\uac00": 19, "\uc77c\uac00\uc758": 19, "\uc77c\uae30\uc7a5": 15, "\uc77c\ubcf8": [15, 141], "\uc77c\ubcf8\uae30\uc0c1\uccad\uacfc": 141, "\uc77c\ubd80": [16, 19], "\uc77c\uc0c1\ud654\ub41c": 14, "\uc77c\uc5b4\ub098\uae30": 17, "\uc77c\uc5b4\ub098\uae30\uc77c\uc5b4\ub098\uae30": 17, "\uc784\uc0b0\uc5f0\ub8cc": 14, "\uc784\uc2dc\uc801\uc73c\ub85c": 15, "\uc784\uc9c1\uc6d0\ub4e4\uc744": 14, "\uc785": 103, "\uc785\ub2c8\ub2e4": 103, "\uc785\uc548": 16, "\uc785\uc548\uc790": 16, "\uc785\uc99d\ud558\uae30\ub85c": 16, "\uc787": 140, "\uc787\uce58": 14, "\uc788": 142, "\uc788\ub294": [14, 15, 16], "\uc788\ub2e4": [14, 15, 19, 145], "\uc788\ub2e4\ub294": 19, "\uc788\uc2b5\ub2c8\ub2e4": 142, "\uc788\uc5b4": [14, 19], "\uc788\uc5b4\ub3c4": 16, "\uc788\uc5c8\ub2e4": 145, "\uc788\uc744": 14, "\uc788\uc74c": 17, "\uc790\uad6d": 20, "\uc790\uae08\uc744": [15, 19], "\uc790\uae0d\uc2ec\uc744": 15, "\uc790\ub140\ub4e4\uc774": 19, "\uc790\ub3d9\ucc28": 21, "\uc790\ub8cc": 16, "\uc790\ubb38": 16, "\uc790\ubcf8\uae08": 20, "\uc790\uc0b0\uad00\ub9ac": 20, "\uc790\uc0b0\ud615\uc131\uc744": 15, "\uc790\uc5f0\uc5b4": 142, "\uc790\uc6d0": 16, "\uc790\uccb4": 16, "\uc790\ucde8\ub97c": 15, "\uc791\uc544\ub3c4": 19, "\uc791\uc5c5": 16, "\uc791\uc6a9": 17, "\uc791\uc6a9\ud560": 19, "\uc798\ubabb": 16, "\uc7a1": 140, "\uc7a1\ub2e4": 140, "\uc7a5": 103, "\uc7a5\uad00": 14, "\uc7a5\uad00\uc774": 14, "\uc7a5\uae30\uc801\uc73c\ub85c": 16, "\uc7a5\ub0a8": 15, "\uc7a5\ub144\uce35": [15, 19], "\uc7a5\uc740": 103, "\uc7a5\ucc29\ud55c": 16, "\uc7ac": 15, "\uc7ac\ub7c9\uc131\uc5d0": [14, 16], "\uc7ac\ubb34\uad6c\uc870\ub3c4": [14, 16], "\uc7ac\uc0dd\uc5d0\ub108\uc9c0\ub294": 14, "\uc7ac\uc0dd\uc5d0\ub108\uc9c0\uc758": [14, 16], "\uc7ac\uc6d0": 19, "\uc7ac\uc815\ube44\ub85c": 16, "\uc7ac\uc815\ud655\uc7a5": 19, "\uc7ac\ud574": [14, 16, 17, 19, 21, 22], "\uc800": 103, "\uc800\uae08\ub9ac": 19, "\uc800\ub294": [132, 141], "\uc800\uc7a5": 14, "\uc800\uc7a5\ud574\uc11c": 140, "\uc801": 16, "\uc801\uc6a9\ud560": 14, "\uc804": [14, 19, 20, 21], "\uc804\uac1c\ud558\uace0": 16, "\uc804\uad6d": 15, "\uc804\uae30": 94, "\uc804\uae30\uc804\uc790": [15, 19], "\uc804\uae30\ucc28": 20, "\uc804\ub0a0\ubd80\ud130": 16, "\uc804\ub2f4\uc870\uc9c1\uc744": 14, "\uc804\ub77d\uc801": 20, "\uc804\ub7b5\ubd80\ubb38": 20, "\uc804\ub7b5\uc801": 20, "\uc804\ub9dd": [14, 17, 21], "\uc804\ub9dd\ub418\uace0": 14, "\uc804\ub9dd\uc744": 14, "\uc804\ub9dd\uc774": 19, "\uc804\ub9dd\uc774\ub2e4": 19, "\uc804\uba74\uc801\uc778": 19, "\uc804\ubb34\ub294": 15, "\uc804\ubb38": 19, "\uc804\ubd80": 20, "\uc804\uc138\uacc4": 17, "\uc804\uc5ed\uc5d0\uc11c": 141, "\uc804\uc6a9": 17, "\uc804\uc6a9\ucc28\ub85c": [15, 19], "\uc804\uc778": [14, 21], "\uc804\uc790\uc5c5\uacc4\ub294": 19, "\uc804\uc7c1": 17, "\uc804\uc9c0\uc0ac\uc5c5\ubd80\ubb38\uc740": 16, "\uc804\uccb4": [14, 16], "\uc804\ud1b5": [14, 16], "\uc804\ud30c\ub418\uba74\uc11c": 141, "\uc804\ud574\uc9c0\uba74\uc11c": [15, 19], "\uc804\ud654": 14, "\uc804\ud658": 14, "\uc804\ud658\uc5d0": 14, "\uc804\ud658\uc774\ub77c\ub294": 14, "\uc804\ud658\ud588\ub2e4": 15, "\uc804\ud6c4\ud558\uc5ec": 21, "\uc808\ubc18\ubc16\uc5d0": 19, "\uc810\ub3c4": 19, "\uc810\uc2ec": 140, "\uc810\uc744": 16, "\uc810\uccd0\ubcf8\ub2e4": 19, "\uc811\uadfc": 16, "\uc815\uae30": 19, "\uc815\uae30\uac04\ud589\ubb3c": 15, "\uc815\ub3c4\ub85c": 14, "\uc815\uba74\uc2b9\ubd80\ub85c": 14, "\uc815\ubcf4": [15, 16], "\uc815\ubcf4\uacf5\uc2dc": 17, "\uc815\ubcf4\ud1b5\uc2e0\uae30": 15, "\uc815\ubd80": 17, "\uc815\ubd80\uac00": 15, "\uc815\ubd80\ub294": 14, "\uc815\uc0c1\ud654": 19, "\uc815\uc0c1\ud654\ub294": 19, "\uc815\uc0c1\ud68c\uc758": 20, "\uc815\uc138\ud76c": 20, "\uc815\uc81c": 14, "\uc815\ucc45": [16, 17, 19, 141], "\uc815\ucc45\uae08\uc735": 15, "\uc81c": 14, "\uc81c71\uc870\uc5d0\uc11c": [14, 16], "\uc81c\uac01\uac01": 21, "\uc81c\uacf5": [14, 16], "\uc81c\uae30\ud55c": 16, "\uc81c\ub124\uc2dc\uc2a4\uc758": 21, "\uc81c\ub3c4": 14, "\uc81c\ub3c4\ub97c": 14, "\uc81c\uc548": 14, "\uc81c\uc678": 14, "\uc81c\uc870": 16, "\uc81c\uc870\uc5c5\uc758": 20, "\uc81c\ucd9c\ud558\uba74": [15, 19], "\uc81c\ud488\uc744": 14, "\uc81c\ud638\ub97c": 15, "\uc870\ub2ec\uc2dc\uc7a5": 16, "\uc870\ub2ec\uccad": 16, "\uc870\ub825": 14, "\uc870\uc0ac": 140, "\uc870\uc120\uc774": 14, "\uc870\uc9c1": 16, "\uc870\uc9c1\uc73c\ub85c": 14, "\uc870\uce58": 14, "\uc870\ud604\uc900": 14, "\uc880": 140, "\uc885\uc774": 15, "\uc885\ud569\uc801": 16, "\uc88b\uc544": 19, "\uc88c\uc6b0\ud560": [14, 16], "\uc8fc\uac00": 19, "\uc8fc\uac00\uac00": [14, 19], "\uc8fc\ub825\uc0b0\uc5c5\uc778": 20, "\uc8fc\ubb38\ud588\ub2e4": 14, "\uc8fc\uc2dd": [15, 19], "\uc8fc\uc694": [14, 16, 20], "\uc8fc\uc758\ubcf4\uc640": 141, "\uc8fc\uc8fc": 16, "\uc8fc\uc8fc\uc640": 20, "\uc8fc\uc8fc\ud658\uc6d0": 17, "\uc8fc\ucd1d\uc5d0\uc11c": 19, "\uc8fc\ucd95\uc73c\ub85c": 15, "\uc904\uace7": 16, "\uc904\uc5b4\ub4e4\uace0": 19, "\uc911": [14, 15, 17, 19, 21], "\uc911\uac04\uc9c0\uc8fc\ud68c\uc0ac\uc778": 20, "\uc911\uad6d": [14, 19, 20, 21], "\uc911\uae30\ubd80": 14, "\uc911\ub2e8\ud558\uac70\ub098": 15, "\uc911\uc18c\uae30\uc5c5": 16, "\uc911\uc18c\ubca4\ucc98\uae30\uc5c5\ubd80": 14, "\uc911\uc2ec\uc73c\ub85c": [15, 19], "\uc911\uc5d0\ub3c4": 15, "\uc911\uc720\ub85c": 14, "\uc911\uc774\ub2e4": 14, "\uc911\uc774\ub77c\ub294": 16, "\uc99d\uac00\ub97c": 19, "\uc99d\uac00\uc728\uc740": [14, 16], "\uc99d\uac00\ud558\uace0": [14, 16], "\uc99d\uac00\ud55c\ub2e4": 16, "\uc99d\uac00\ud560": 19, "\uc99d\uad8c": 16, "\uc99d\uad8c\uc0ac": 16, "\uc99d\uad8c\uc0ac\ub4e4\uc758": [15, 19], "\uc99d\uba85": 16, "\uc99d\uc2dc\ub294": 19, "\uc99d\uc2dc\ub85c": 19, "\uc9c0": [14, 16, 19, 20], "\uc9c0\ub09c": [14, 15, 16, 17, 19, 20], "\uc9c0\ub09c\ud574": [14, 15, 19, 21], "\uc9c0\ubc29\uc790\uce58\ub2e8\uccb4\uc5d0": 15, "\uc9c0\ubc30\uad6c\uc870": [14, 16, 17, 19, 20, 21, 22], "\uc9c0\ubc30\uad6c\uc870\ub294": 19, "\uc9c0\ubc30\uad6c\uc870\uc5d0": 19, "\uc9c0\ubd84": 19, "\uc9c0\ubd84\uc744": 19, "\uc9c0\ubd84\uc774": 19, "\uc9c0\uc18d\uac00\ub2a5\uacbd\uc601\uc758": 20, "\uc9c0\uc218\ud568\uc218\uc801\uc73c\ub85c": 16, "\uc9c0\uc2dd": 16, "\uc9c0\uc5ed": 20, "\uc9c0\uc5ed\uc5d0": 19, "\uc9c0\uc5ed\uc758": [14, 16], "\uc9c0\uc5ed\uc801": 16, "\uc9c0\uc5f4": 14, "\uc9c0\uc6d0": [14, 16], "\uc9c0\uc9c4\ubc1c\uc0dd\uc704\uce58\ub85c\ubd80\ud130": 141, "\uc9c0\uc9c4\ud574\uc77c": 141, "\uc9c0\uc9c4\ud574\uc77c\uacfc": 141, "\uc9c0\uc9c4\ud574\uc77c\uc740": 141, "\uc9c0\uc9c4\ud574\uc77c\uc774": 141, "\uc9c0\ud0a4\uae30": 14, "\uc9c0\ud45c": 16, "\uc9c1\uc6d0": 16, "\uc9c1\uc6d0\ub4e4": 14, "\uc9c1\uc804": 15, "\uc9c4\uc559\uc9c0\ub85c\ubd80\ud130": 141, "\uc9c4\uc9dc\ub85c": 21, "\uc9c4\ud589\ub41c": 16, "\uc9c4\ud589\ud558\uace0": 14, "\uc9c8\uc8fc\ud558\uace0": [15, 19], "\uc9d1": 145, "\uc9d1\uc548\uc5d0": 145, "\uc9d1\uc73c\ub85c": 145, "\uc9d1\uc911\ud558\uace0": 14, "\uc9d1\uc911\ud588\ub2e4": 16, "\ucc28\uc138\ub300": 17, "\ucc28\uc774\ub098\ud50c\ub77c\uc2a4": 20, "\ucc28\uc9c0\ud55c\ub2e4": 19, "\ucc3d\uac04\ub410\ub2e4": 15, "\ucc3d\ub9bd": 15, "\ucc3d\uc5c5": 15, "\ucc3d\uc6d0\uc2dc\ub294": 20, "\ucc3d\ucd9c": 17, "\ucc44\uad8c\uc2dc\uc7a5\uc5d0\uc11c": [15, 19], "\ucc44\ud0dd": 17, "\ucc45\uc784": 16, "\ucc45\uc790": 15, "\ucc98\ub9ac": 142, "\ucc98\ub9ac\ub97c": 142, "\ucc98\ubd84\ud558\ub294": 19, "\ucc98\uc74c\uc73c\ub85c": 15, "\ucc9c\ubb38\ud559\uc801\uc778": 19, "\uccab": [20, 21], "\uccab\ubc1c\uc744": 16, "\uccab\ud574": 19, "\uccad\ub144": 21, "\uccad\ub144\uce35\uc758": 15, "\uccad\ub144\ud76c\ub9dd\uc801\uae08\uc740": 15, "\uccb4\uacb0\ud55c": 20, "\uccb4\uc5b8": 140, "\uccb4\uc778\uc744": 16, "\uccb4\uc81c": 19, "\ucd08\uae30": 17, "\ucd1d": [16, 20], "\ucd1d\uc218": 19, "\ucd1d\uc561": [15, 19], "\ucd5c": 19, "\ucd5c\uace0\uc6b4\uc601\ucc45\uc784\uc790": 15, "\ucd5c\uadfc": [14, 15, 16, 17, 20], "\ucd5c\uadfc\ub3c4": 14, "\ucd5c\ub300": [15, 19], "\ucd5c\uc545\uc758": 14, "\ucd5c\uc7ac\ud64d": 19, "\ucd5c\uc885": [15, 19], "\ucd5c\ucd08": 94, "\ucd5c\ucd08\ub85c": [15, 19], "\ucd5c\ucd08\uc758": 14, "\ucd94": 16, "\ucd94\uac00": 14, "\ucd94\uac00\ub420": 16, "\ucd94\uac00\uc801": 14, "\ucd94\uc815\ub41c\ub2e4": 19, "\ucd94\uc9c4": [14, 16], "\ucd94\ucc9c": 19, "\ucd9c\ub801": 21, "\ucd9c\ubc94\ud558\uba70": 16, "\ucd9c\uc2dc\ud55c": 14, "\ucd9c\ud310": 16, "\ucda9": 20, "\ucda9\ub0a8": 20, "\ucda9\ubd84\ud788": 19, "\ucde8\ub4dd": 20, "\ucde8\uc5c5\uc790": [14, 16], "\ucde8\uc5c5\uc790\uc218\ub294": [14, 16], "\ucde8\uc784\ud588\ub2e4": 15, "\uce21\uba74\ub3c4": 15, "\uce58\ub8cc\uc81c": 20, "\uce58\uc19f\uc790": 16, "\uce5c\ud658\uacbd\ucc28\uac00": 16, "\uce60\ub808": 141, "\uce60\uc131\uc0ac\uc774\ub2e4": 14, "\uce68\uacf5": 15, "\uce69": 14, "\uce6d": 16, "\uce74\ub9c8\uc774\uc2dc\ud56d\uc5d0": 141, "\uce74\uce74\uc624\ucee4\uba38\uc2a4": 14, "\uce94\ud584": 15, "\uce98\ub9ac\ud3ec\ub2c8\uc544": 141, "\ucea0\ud398\uc778\uc5d0": 15, "\ucee4\uba38\uc2a4": 16, "\ucee4\uc9c0\uace0": [15, 19], "\ucee8\uc18c\uc2dc\uc5c4": 16, "\ucee8\uc18c\uc2dc\uc5c4\uc5d0": 20, "\ucef4\ud4e8\ud305": 16, "\ucf54\ub85c\ub098": 19, "\ucf54\ub85c\ub09819": [14, 15, 19, 20], "\ucf54\ub85c\ub09819\ub85c": 14, "\ucf54\ub85c\ub09819\uc758": 14, "\ucf54\ub85c\ub098\ubc14\uc774\ub7ec\uc2a4": 14, "\ucf54\ub9ac\uc544\uc138\uc77c\ud398\uc2a4\ud0c0": [15, 19], "\ucf54\uc2a4\ud53c": 19, "\ucf54\uc624\ub871": 15, "\ucf54\uc624\ub871\uadf8\ub8f9": 15, "\ucf54\uc624\ub871\uadf8\ub8f9\uc774\ub2e4": 15, "\ucf54\uc624\ub871\ub274\uc2a4\uc5d0\uc11c": 15, "\ucf54\uc624\ub871\ub274\uc2a4\uc600\ub2e4": 15, "\ucf54\uc624\ub871\ub9cc\uc758": 15, "\ucf54\uc624\ub871\uc0ac\ubcf4\ub85c": 15, "\ucf54\uc624\ub871\uc758": 15, "\ucf54\uc624\ub871\uc778\ub354\uc2a4\ud2b8\ub9ac": 15, "\ucf54\uc624\ub871\uc778\uc740": 15, "\ud06c": 103, "\ud06c\ub2e4": 19, "\ud06c\ub808\uc13c\ud2b8\uc2dc\ud2f0\uc5d0\uc11c": 141, "\ud06c\ub9bc": 14, "\ud070": [14, 17, 19], "\ud074\ub77c\uc6b0\ub4dc": [14, 16], "\ud074\ub77c\uc774\ubc0b": [15, 19], "\ud0a4\uc6cc\ub4dc\ub294": 19, "\ud0a4\uc6cc\uc57c": 16, "\ud0a4\uc6cc\uc654": 15, "\ud0ac\ub9b0": 14, "\ud0c0\uc774\uce78": 94, "\ud0d0\ubc29\uae30\uc0ac\uac00": 15, "\ud0d3\uc5d0": 20, "\ud0dc\uc591": 14, "\ud0dc\uc591\uad11": 14, "\ud0dc\ud3c9\uc591": 141, "\ud0dc\ud3c9\uc591\uc9c0\uc9c4\ud574\uc77c\uacbd\ubcf4\uc13c\ud130\ub294": 141, "\ud0dd\uc2dc\uc5d0": 20, "\ud130\ub110\uc744": 14, "\ud131\uac78\uc774\ud55c": 21, "\ud14c": 103, "\ud14c\uc2a4\ud2b8": 103, "\ud14c\uc2a4\ud2b8\ud558\uae30": 103, "\ud14c\uc774\ube14\uc744": [15, 19], "\ud1a0": 103, "\ud1a0\ud06c": 103, "\ud1a0\ud06c\ub098\uc774\uc800\ub97c": 103, "\ud1a4": 20, "\ud1b5": 141, "\ud1b5\uc2e0\uc2dc\uc7a5": 17, "\ud1b5\ud55c": [14, 20], "\ud1b5\ud574": [14, 15, 16], "\ud1f4\uc784\uc744": 15, "\ud22c\uc378\ud50c\ub808\uc774\uc2a4": 94, "\ud22c\uc790": [15, 19], "\ud22c\uc790\ub9cc": 16, "\ud22c\uc790\uc790": 16, "\ud22c\uc790\uc790\ub97c": 20, "\ud22c\uc9c0": 14, "\ud2b8": 103, "\ud2b8\ub799\ud130": 14, "\ud2b9\uc218\ud55c": [14, 16], "\ud2b9\uc9d1\ud638\ub97c": 15, "\ud2b9\ud5c8\uc2ec\ud310\uc6d0": 16, "\ud2b9\ud788": [14, 16, 19], "\ud2f0\uc640\uc774\uc5e0": 14, "\ud30c\ub098\uc18c\ub2c9\uacfc": 16, "\ud30c\uc6b4\ub4dc\ub9ac": 16, "\ud30c\uc77c": 140, "\ud30c\ud2b8\ub108\uc2ed": 20, "\ud310\ub2e8": 16, "\ud310\ub2e8\ub418\uba74": 16, "\ud310\ub9e4\ub300": 15, "\ud310\ucf5c": 14, "\ud328\ubc00\ub9ac": 20, "\ud32c\ub370\ubbf9": 19, "\ud32c\ub370\ubbf9\uc744": 14, "\ud32c\ub370\ubbf9\uc774\ub77c\ub294": 14, "\ud380\ub354\uba58\ud138": [14, 16], "\ud38c\ud504": 14, "\ud3a0\ub81b": 14, "\ud3b8\uacfc": 14, "\ud3b8\uc911": 17, "\ud3bc\uccd0": 141, "\ud3bc\uccd0\ub098\uac00\uae30\ub85c": 141, "\ud3c9\uac00\ub41c\ub2e4": 19, "\ud3c9\uade0": 16, "\ud3c9\uade0\uce58\ub97c": 16, "\ud3d0\uac00\uc2a4": 14, "\ud3d0\uae30\ubb3c\ub85c": 14, "\ud3d0\uae30\ubb3c\uc740": 14, "\ud3d0\ubaa9\uc7ac": 14, "\ud3d0\ubaa9\uc7ac\ub85c": 14, "\ud3ec\ub974\uc250": 94, "\ud3ec\ub974\uc250\ucf54\ub9ac\uc544": 94, "\ud3ec\ud568": 14, "\ud3ec\ud568\ub410\ub2e4": 16, "\ud3ec\ud568\ud55c": 14, "\ud3f4\ub780\ub4dc": 20, "\ud45c\uc900": 14, "\ud478\ub4dc\ud14c\ud06c": 15, "\ud478\ub974\ub978": 20, "\ud488\uc0ac": 140, "\ud488\uc9c8": 14, "\ud48d\ub825": 14, "\ud504": 19, "\ud504\ub85c\uadf8\ub7a8": 14, "\ud50c": 103, "\ud50c\ub7ab\ud3fc": 16, "\ud53c\ud50c": 14, "\ud544\uc218\uc801": 16, "\ud544\uc694": 14, "\ud544\uc694\uac00": 19, "\ud558": [103, 140, 141, 142], "\ud558\uaca0\ub2e4": 14, "\ud558\uace0": 17, "\ud558\uace0\uc790": 17, "\ud558\uae30": [16, 103], "\ud558\ub098\uac00": 15, "\ud558\ub098\uae08\uc735": 19, "\ud558\ub098\uc600\uc9c0\ub9cc": 17, "\ud558\ub294": [16, 19], "\ud558\ub2c8": 140, "\ud558\ub2e4": 16, "\ud558\ub4dc\uc6e8\uc5b4": 16, "\ud558\ub77d\ud55c": [15, 19], "\ud558\ubc18\uae30": 19, "\ud558\uc218\uc2ac\ub7ec\uc9c0": 14, "\ud558\uc5ec": 140, "\ud558\uc640\uc774": 141, "\ud558\uc9c0\ub9cc": [15, 19], "\ud559\ubd80\uc0dd": 20, "\ud55c": [15, 16, 103], "\ud55c\uad6d": [15, 17, 19], "\ud55c\uad6dm": 20, "\ud55c\uad6d\uac70\ub798\uc18c\ub294": 15, "\ud55c\uad6d\uac70\ub798\uc18c\uc5d0": 14, "\ud55c\uad6d\uacfc": 19, "\ud55c\uad6d\uc5b4\uc758": 140, "\ud55c\uad6d\ud22c\uc790\uc99d\uad8c\uc740": 15, "\ud55c\ub2e4": [14, 16], "\ud55c\ubbf8": 20, "\ud55c\uc0d8\uc740": 20, "\ud55c\ud654\uc194\ub8e8\uc158": 20, "\ud55c\ud654\uc194\ub8e8\uc158\uc740": 20, "\ud55c\ud654\uc194\ub8e8\uc158\uc758": 20, "\ud55c\ud654\ud050\uc140\uc774": 20, "\ud560": [16, 17, 19], "\ud568": 17, "\ud568\uaed8": [15, 20], "\ud569\uc791\uc0ac": 16, "\ud574": [15, 16, 17], "\ud574\ub2e4": 14, "\ud574\ub2f9\ub41c\ub2e4": 19, "\ud574\ub3c4": 19, "\ud574\uc18c": 20, "\ud574\uc678": 14, "\ud574\uc678\uacbd\uc81c": 14, "\ud574\uc678\uc5d0\uc11c\ub3c4": [15, 19], "\ud574\uc678\uc8fc\uc2dd": 15, "\ud574\uc678\uc9c0\uc0ac": 15, "\ud574\uc678\uc9c4\ucd9c\uc774": 15, "\ud575\uc2ec": 14, "\ud575\uc2ec\uacfc\uc81c\ub97c": 14, "\ud588": 141, "\ud588\ub2e4": [14, 15, 16], "\ud588\ub2e4\uace0": [16, 141], "\ud589\uc0ac": [15, 19, 20], "\ud589\uc0ac\uc758": [14, 16], "\ud589\uc704\uc790": 140, "\ud5a5\ubc29\uc744": 19, "\ud5a5\uc0c1": 16, "\ud5a5\ud6c4": [14, 16], "\ud5cc\ubc95\uc7ac\ud310\uc18c\ub294": [14, 16], "\ud5e4\ub7f4\ub4dc\uacbd\uc81c": [16, 20], "\ud601\uc2e0": [16, 17], "\ud601\uc2e0\uc744": 14, "\ud604": 14, "\ud604\uae08\ubc30\ub2f9\uc744": 14, "\ud604\ub300\uae00\ub85c\ube44\uc2a4\uc640": 20, "\ud604\ub300\ubaa8\ube44\uc2a4\uac00": 15, "\ud604\ub300\ucc28": 19, "\ud604\ub300\ucc28\uac00": 16, "\ud604\uc0c1\uc740": 19, "\ud604\uc7ac": [15, 17, 19], "\ud604\uc7ac\ub294": 20, "\ud604\uc9c0\uc2dc\uac04": 20, "\ud604\ud669": [15, 19], "\ud611\ub825\uc5c5\uccb4": 16, "\ud611\ub825\uc744": 14, "\ud611\ub825\ud574\ub098\uac04\ub2e4\ub294": 14, "\ud611\uc0c1": [15, 19], "\ud611\uc57d\uc2dd\uc744": 14, "\ud615": 16, "\ud615\uc6a9\uc0ac": 140, "\ud615\ud0dc": 15, "\ud615\ud0dc\uc18c": 140, "\ud638\ub791\uc774\ucc98\ub7fc": 14, "\ud638\uc7ac\ub85c": 19, "\ud64d\ub77c\ud76c": 19, "\ud64d\uc740\ud0dd": 14, "\ud654\uc7a5\ud488": 14, "\ud654\ud559\ubd84\uc57c": 20, "\ud654\ud569": 14, "\ud655": [15, 19], "\ud655\ub300": 19, "\ud655\ubcf4": [16, 20], "\ud655\ubcf4\ub97c": 16, "\ud655\uc0b0": [15, 19, 20], "\ud655\uc0b0\uacfc": 14, "\ud658\uacbd": [15, 16, 19], "\ud658\uacbd\uc601\ud5a5": [14, 16, 17, 19, 21, 22], "\ud658\uacbd\uc815\ubcf4": 16, "\ud658\uacbd\ud601\uc2e0": [14, 16, 17, 19, 21, 22], "\ud658\uc728": 21, "\ud65c\ub3d9": 16, "\ud65c\uc6a9": 16, "\ud65c\uc6a9\ud55c\ub2e4\uace0": 19, "\ud669\uc724\uc8fc": 20, "\ud68c": 14, "\ud68c\ub2f4": 15, "\ud68c\ubcf5": [14, 19], "\ud68c\ubcf5\uc774\ub2e4": 19, "\ud68c\ubcf5\ud558\uc9c0": 19, "\ud68c\uc0ac": 108, "\ud68c\uc0ac\uc758": 14, "\ud68c\uc0ac\ucc44": [15, 19], "\ud68c\uc7a5": 15, "\ud68c\uc7a5\uacfc": 20, "\ud68c\uc7a5\uc740": 15, "\ud68c\uc7a5\uc758": 19, "\ud68c\uc7a5\uc774": [14, 15, 19], "\ud6a8\uacfc\uc801": 16, "\ud6a8\ub2a5": 14, "\ud6a8\uc131\uadf8\ub8f9": 14, "\ud6c4": [15, 19, 140], "\ud6c4\uba74": 21, "\ud6c4\ubcf4": [14, 19], "\ud6c4\ubcf4\ub294": 19, "\ud6c4\ubcf4\uc778": 19, "\ud6c4\uc18d": [14, 16], "\ud6c4\uc2dc\ub4dc": 14, "\ud6c8\ub828": 16, "\ud750\ub984\uc5d0": 14, "\ud751\uc561": 14, "\ud765\ud589\ub3c4": 14, "\ud76c\ub85c\uc560\ub77d\uc774": 15, "\ud76c\ub9dd": 19, "\ud76c\ub9dd\uc744": 14, "\ud76c\ubc15": 19, "\ufb01": 104, "\uff41\uff42\uff43\uff41\uff42\uff43\uff11\uff12\uff13\u1100\u1161\u1102\u1161\u1103\u1161": 104, "\uff41\uff42\uff43\uff41\uff42\uff43\uff11\uff12\uff13\uac00\ub098\ub2e4": 104, "\ud835\udc43": 97, "\ud835\udc47": 97, "\ud835\udc4a0": 97, "\ud835\udf03": 126}, "titles": ["Bibliography", "Introduction", "Art and Music in Light of AI", "A Brave New World", "AI Art (Generative AI)", "Introduction", "Motion Capture and Motion Synthesis", "Robot Drawing System", "DALL\u00b7E 1", "DALL\u00b7E 2", "Imagen", "Text-to-Image Models", "Alternative Data Sources for Central Banks", "Central Banks", "Putting them together in a pipeline", "Building <code class=\"docutils literal notranslate\"><span class=\"pre\">econ_news_kr</span></code> corpus", "Cross validating datasets", "Improving classification datasets", "ESG Ratings", "Predicting ESG Categories and Polarities", "Preparing training datasets", "Preparing active learning data", "Training Classifiers for ESG Ratings", "Preparing Numerical Data", "Preparing Textual Data", "EDA on Numerical Data", "EDA on Numerical Data", "Create Training Datasets", "Visualizing Features", "Checking Baseline with AutoML", "Predicting Sentiments of FOMC Corpus", "EDA on Sentiments: Correlation", "EDA on Sentiment Data", "Visualize Features", "Monetary Policy Shocks", "Predicting the next decisions with tones", "Textual Analysis of FOMC contents", "Data Science for Economics and Finance", "Technical Challenges", "Introduction", "Data Science in Economics", "Data Analytics Methods", "AutoGen", "AutoGen AutoScraper Agent", "AI Agents", "Fine-Tuning LLMs with Hugging Face AutoTrain", "LLM Fine-tuning", "Large Language Models", "Introduction", "Large Language Models?", "Parameter-Efficient Fine-Tuning (PEFT)", "PEFT in HuggingFace Libraries", "PEFT for LLMs", "Q-Learning", "Q-Star (Q*)", "Retrieval Augmented Generation (RAG)", "LLM App Ecosystem", "LLM Application Architectures", "LLM Stacks", "Generative AI Infrastructure Stack", "<code class=\"docutils literal notranslate\"><span class=\"pre\">containerd</span></code>", "Docker", "Containerization", "DevSecOps", "GitOps", "DevOps", "Dotfiles", "Github\u2019s Fork &amp; Pull Workflow", "GitHub Workflow", "Project Templating Tools", "Machine Learning Systems Design", "Introduction to MLOps", "Deploy a Voice-Based Chatbot with BentoML, LangChain, and Gradio", "Introduction to BentoML", "LLMOps", "MLOps Project", "SSH, GPG, and AGE", "Authentication, Encryption, and Signing", "Security Management", "Unix Password Managers", "Simple MLOps Pipeline", "Server Setup &amp; Usage", "VPN Connectivity", "Meet the Camelids: A Family of LLMs", "DetectGPT", "GPT-4", "Generative Language Models", "Advances in AI and NLP", "Segment Anything", "Writing a Thesis", "How to Spot Machine-Written Texts", "Conversational AI and Chatbots", "Reinforcement Learning with Human Feedback (RLHF)", "Datasets", "Lab: Exploratory Data Analysis (EDA)", "mC4 Dataset", "Deep Learning for NLP", "Decoding and Search Strategies", "Large Language Models", "Pretrained Language Models", "Zero Shot and Prompt Engineering", "BPE Step-by-Step Implementation", "Tokenization", "Lab: Training Tokenizers", "Tokenization Pipeline", "SentencePiece Tokenizer", "Subword Tokenization", "Unigram Step-by-Step Implementation", "WordPiece Step-by-Step Implementation", "Training Language Models", "Lab: Finetuining a MLM", "Lab: Pretraining LMs - CLM", "Lab: Pretraining LMs - MLM", "BERT: Bidirectional Encoder Representations from Transformers", "BERT: Visualizing Attention", "ByT5: Towards a token-free future with pre-trained byte-to-byte models", "Transformers", "T5: Text-To-Text Transfer Transformer", "NLP Applications", "Research Part I", "Research Part II", "Text Data Collection", "Datasets", "Lab: Crawling DART Data", "FastText", "GloVe", "Word Embeddings", "Neural Language Models", "Word2Vec", "Introduction to NLP", "Introduction", "Language Models", "N-gram Language Models", "Usage of Language Models", "Sentiment Analysis", "Lab: Lexicon-based Sentiment Analysis", "Lab: ML-based Sentiment Classification", "Lexicon-Based Methods", "Machine Learning-Based Methods", "Tokenization", "Tokenization in Korean", "Lab: Korean Text Processing", "Lab: Tokenization and Pre-processing", "N-grams for Tokenization", "Part-of-Speech Tagging and Parsing", "Word Segmentation and Association", "Understanding the Basics", "Topic Coherence Measures", "Topic Modeling", "Lab: Topic Coherence", "Lab: Topic Modeling", "Topic Modeling Methodologies", "Lab: Tomotopy", "Bags of Words Model", "Vector Representation", "Lab: Word Similarity", "Vector Semantics", "Word Similarity", "TF-IDF Model", "GitOps", "DevOps", "Software Engineering", "Introduction", "Software Engineering?", "Software Processes", "Requirements Engineering (RE)", "Software Development Life Cycle (SDLC)", "Software Engineering Proposal Guideline", "Project Proposal", "Steps in Software Engineering Projects", "Project Proposal Template", "Agile Software Development", "Software Process Models", "0. Introduction to version control", "1. Solo work with git", "2. Fixing mistakes", "3. Publishing", "4. Collaboration", "5. Fork and Pull", "6. Git Theory", "7. Branches", "8. Advanced git concepts", "9. Publishing from GitHub", "10. Rebasing", "11. Debugging With git bisect", "12. Working with multiple remotes", "Version Control Systems"], "titleterms": {"": [5, 10, 50, 51, 52, 53, 56, 67, 72, 81, 114, 121, 130, 132, 139, 173, 177], "0": [71, 128, 173], "1": [3, 8, 12, 43, 44, 45, 60, 64, 67, 68, 69, 71, 75, 80, 81, 82, 88, 90, 103, 127, 128, 130, 141, 142, 144, 147, 156, 159, 165, 166, 167, 170, 174, 178], "10": [3, 68, 80, 167, 170, 183], "11": [3, 80, 167, 170, 184], "12": [3, 167, 170, 185], "2": [3, 5, 9, 10, 12, 43, 44, 45, 60, 64, 67, 68, 69, 71, 75, 80, 81, 82, 90, 103, 127, 128, 141, 142, 144, 147, 156, 159, 165, 166, 167, 170, 175, 178], "3": [3, 12, 43, 44, 45, 60, 64, 67, 68, 69, 75, 80, 81, 82, 90, 103, 127, 128, 130, 141, 142, 144, 147, 156, 159, 165, 166, 167, 170, 176, 178], "3d": 6, "4": [3, 12, 43, 44, 45, 60, 64, 67, 68, 75, 80, 81, 82, 85, 90, 103, 127, 128, 142, 144, 159, 165, 166, 167, 170, 177, 178], "5": [3, 12, 44, 45, 60, 64, 67, 68, 75, 80, 81, 82, 103, 144, 159, 165, 166, 167, 170, 178], "51": 98, "6": [3, 12, 44, 64, 67, 68, 75, 80, 81, 144, 159, 166, 167, 170, 178, 179], "67": 98, "7": [3, 44, 64, 67, 68, 80, 81, 159, 166, 167, 170, 178, 180], "7b": 45, "8": [3, 64, 67, 68, 80, 81, 159, 167, 170, 178, 181], "9": [3, 68, 80, 81, 167, 170, 182], "A": [3, 10, 49, 53, 69, 76, 77, 83, 88, 89, 106, 115, 116, 117, 123, 146, 174, 175, 180], "And": [20, 115], "In": [49, 115], "Not": 116, "Of": 115, "One": 100, "The": [2, 9, 49, 50, 56, 69, 72, 84, 89, 93, 113, 115, 117, 120, 121, 130, 136, 139, 146, 150, 156, 164, 166, 171, 172, 174, 177, 179, 182], "To": [115, 117], "With": 184, "aaron": 5, "abil": 98, "ablat": 115, "about": [1, 174, 176], "acceler": 51, "accept": 178, "access": [80, 81, 123], "accessor": 145, "achiev": 53, "acquir": 93, "across": [49, 50], "activ": [21, 167], "actual": [25, 114], "ad": [79, 108, 141, 176], "adapt": [50, 51, 53, 73], "add": [23, 81, 174, 181], "addit": [14, 52, 79], "adjust": 120, "adopt": 52, "advanc": [7, 50, 53, 54, 87, 181], "advantag": [40, 41, 53, 150], "advent": 49, "affix": 139, "afinn": 135, "after": 180, "ag": [76, 79], "agent": [42, 43, 44, 57, 116], "agglutin": 140, "aggreg": [30, 147], "agil": [166, 171, 172], "agricultur": 12, "ai": [2, 4, 42, 44, 50, 52, 53, 54, 56, 59, 73, 74, 77, 87, 89, 91], "aihub": 121, "albert": 99, "algorithm": [89, 106, 138, 145, 148, 150], "align": [85, 92], "all": [56, 116], "alloc": 151, "alpaca": 83, "alphago": 53, "altern": [12, 38, 41, 69, 167, 169, 170], "amazon": 3, "ambigu": [88, 130, 137], "among": 137, "an": [7, 14, 15, 16, 49, 61, 81, 126, 133, 183, 184], "analys": 30, "analysi": [10, 12, 36, 52, 94, 110, 118, 134, 135, 136, 137, 140, 146, 151, 165, 166], "analyt": [12, 41, 49], "analyz": 94, "annot": 144, "ansibl": [64, 159], "answer": [49, 130], "antarctica": 3, "antipatch": 175, "anyth": 88, "api": 121, "app": [56, 69, 72], "appli": 80, "applic": [9, 12, 41, 49, 50, 53, 55, 57, 59, 77, 98, 118, 130, 134, 150, 151], "approach": [43, 46, 50, 88, 90, 167, 170], "ar": [2, 49, 98, 115, 116, 126, 139], "architectur": [8, 10, 41, 49, 50, 52, 53, 57, 72, 99, 113, 115, 116, 117, 128, 167, 170], "area": [130, 174, 175], "aren": 139, "art": [2, 4, 5, 146], "articl": 145, "artifact": [72, 73], "artist": [2, 49], "ascend": 49, "assess": [12, 37, 50, 55, 167, 170], "assist": [49, 85, 130], "associ": 145, "assumpt": [106, 130, 132], "atom": 156, "attend": 113, "attent": [49, 52, 113, 114, 116], "attribut": 8, "audio": 6, "augment": [55, 57], "authent": [77, 176], "auto": [29, 35], "autoencod": 8, "autogen": [42, 43, 44], "autom": [49, 71], "automat": 184, "automl": 29, "autonom": 57, "autoregress": 99, "autoscrap": 43, "autotrain": 45, "avail": [55, 85], "aw": 73, "azur": 73, "b": [76, 77, 89], "background": [167, 170], "backoff": 133, "backup": 66, "bad": 139, "bag": [114, 128, 153], "balanc": 50, "bang": 166, "bank": [12, 13], "bare": [64, 159], "bart": 99, "base": [6, 50, 52, 55, 72, 90, 119, 135, 136, 137, 138], "baselin": [29, 117], "basic": [50, 61, 81, 94, 105, 146, 152], "batch": 73, "bbpe": 106, "beam": 97, "befor": 80, "bench": 98, "benchmark": 115, "benefit": [41, 45, 64, 65, 69, 109, 159, 160, 172], "bentocloud": 72, "bentoml": [72, 73], "bentoservic": 73, "bert": [99, 103, 113, 114, 154], "best": [55, 63, 64, 74, 108, 159, 171], "better": 10, "between": [25, 60, 79, 81, 105], "beyond": 130, "bia": 137, "bibliographi": 0, "bidirect": 113, "big": [51, 98, 166], "bigram": [101, 132], "billion": 88, "biometr": 77, "bird": 10, "bisect": 184, "bitfit": 50, "bits_and_byt": 51, "blank": 139, "block": 52, "blockchain": 77, "board": 120, "bodi": 6, "book": 129, "boundari": 145, "bpe": [101, 103, 105, 106], "branch": [67, 68, 145, 178, 180, 182], "brave": 3, "breakthrough": 53, "brown": 133, "budget": [167, 170], "build": [15, 16, 20, 28, 33, 55, 60, 61, 93, 95, 127, 128, 137], "buildkit": 60, "built": 174, "byt5": 115, "byte": [103, 106, 115], "c": [76, 77, 89], "c4": 117, "calcul": [106, 132, 147, 155], "calendar": 23, "call": 121, "camelid": 83, "can": 130, "capabl": [51, 53, 92, 98], "capit": 146, "caption": 10, "captur": [6, 156], "card": 85, "carri": 174, "cascad": 10, "case": [12, 50, 51, 53, 60, 171], "categor": 126, "categori": [14, 19, 21, 22, 99, 165], "causal": 99, "cbow": 128, "cd": [65, 74, 160], "central": [12, 13], "centralis": 185, "ceremoni": 171, "chain": [53, 57, 100], "chairperson": 23, "challeng": [12, 38, 40, 41, 49, 50, 53, 54, 55, 57, 71, 77, 89, 91, 93, 109, 134, 139, 171], "chang": [67, 68, 81, 115, 174, 175, 176, 177, 178, 180, 181], "charact": [6, 102, 108, 124], "characterist": [44, 163], "charaterist": 8, "chatbot": [72, 91, 130], "chatwrapp": 72, "check": [19, 29], "chinchilla": 98, "chip": 59, "choos": [89, 144], "chosen": 89, "chunk": 24, "ci": [65, 74, 160], "class": [23, 24, 72], "classfici": [16, 22], "classic": 150, "classif": [9, 17, 44, 115, 136, 140], "classifi": [10, 14, 22], "clean": [55, 117, 180, 181], "cli": 69, "clip": 9, "clipdraw": 9, "clm": 111, "clone": [67, 68, 81, 178], "cloud": [59, 73], "cluster": [138, 148], "cnn": [12, 138], "co": 125, "code": [14, 15, 21, 43, 49, 65, 123, 158, 160, 174, 177], "codex": 130, "cognit": 49, "coher": [147, 149, 152], "colab": 51, "colaboratori": 176, "collabor": [2, 67, 74, 85, 177, 178], "colleagu": 177, "collect": [89, 93, 121, 144], "colloc": 143, "coloss": 117, "combin": 137, "command": [60, 61], "commit": [67, 68, 174, 176, 177, 178], "common": [117, 121, 146], "compani": [14, 15, 21, 123], "compar": [24, 26, 32, 51, 52, 103], "comparison": [10, 52, 69, 76, 95, 117, 150, 158], "complex": 163, "complianc": [12, 74], "compon": [51, 53, 60, 61, 74, 91, 167], "compos": 61, "composit": 145, "comprehens": 89, "comput": [49, 50, 51, 77, 107, 108, 149], "con": [115, 183], "concept": [41, 50, 52, 73, 131, 179, 181], "conceptu": 53, "concern": [49, 52], "conclud": 56, "conclus": [2, 8, 10, 12, 44, 45, 46, 50, 51, 52, 53, 54, 55, 57, 61, 63, 67, 72, 74, 76, 77, 79, 80, 81, 82, 85, 88, 89, 93, 94, 106, 115, 116, 146, 154, 155, 156, 158, 167, 169, 170, 171], "condit": 10, "conduct": 89, "configur": [55, 64, 65, 66, 80, 82, 159, 160, 173, 174], "confirm": 147, "conflict": [175, 177], "confound": 120, "confront": 2, "conjug": 140, "conjunct": 50, "connect": [81, 82], "consider": [12, 38, 41, 45, 53, 170, 178], "constitu": 144, "constraint": [12, 49], "construct": 95, "consult": 89, "consum": 51, "contain": [60, 61], "container": [62, 65, 160], "containerd": [60, 80], "content": [4, 36, 37, 44, 46, 50, 53, 70, 87, 96, 109, 129, 170, 176], "context": [49, 53, 55, 128, 137, 157], "contextu": [8, 99], "continu": [65, 71, 74, 128, 160, 171], "contrast": [9, 50, 128], "control": [6, 8, 65, 66, 160, 173, 186], "convers": [42, 91], "convolut": [12, 138], "cookiecutt": 69, "copier": 69, "core": [50, 52, 61, 73], "corpor": 123, "corpora": [121, 130], "corpu": [15, 24, 30, 117, 121, 122, 130, 133, 137, 152], "correct": 174, "correl": [25, 31, 151], "corrupt": 117, "cosin": [147, 148, 157], "cost": [49, 163], "cot": 53, "count": [25, 101, 132, 137], "countri": 119, "countvector": 158, "cours": [1, 4, 37, 47, 70, 87, 96, 129, 161], "cover": 175, "crawl": [93, 117, 121, 123], "creat": [26, 27, 55, 60, 61, 67, 68, 69, 77, 80, 81, 111, 112, 128, 144, 176, 178], "creativ": [2, 49], "credit": 186, "crisi": 164, "cross": [16, 17, 115], "crowdwork": 20, "ctm": 151, "ctr": 60, "current": [50, 52, 53], "curvatur": 90, "custom": 57, "cybersecur": 77, "cycl": 166, "d": [76, 77, 89], "dall": [5, 8, 9, 10], "danc": 6, "dart": 123, "data": [12, 14, 15, 19, 20, 21, 23, 24, 25, 26, 27, 31, 32, 35, 37, 38, 40, 41, 52, 55, 56, 59, 71, 88, 89, 93, 94, 95, 110, 111, 112, 121, 123, 128, 136, 144, 149, 150], "databas": [55, 59], "dataset": [16, 17, 20, 22, 27, 31, 32, 45, 55, 93, 94, 95, 101, 103, 107, 108, 110, 111, 112, 117, 122, 136, 152], "deal": 130, "debt": 71, "debug": [57, 184], "deciph": 120, "decis": [23, 25, 26, 35], "decod": [8, 9, 49, 88, 97, 101, 116, 117], "decomposit": 150, "deconstruct": 113, "dedic": 81, "deep": [10, 96, 138, 139], "deeplabcut": 6, "deepspe": 51, "default": 176, "defin": [45, 89, 111, 112, 128, 139, 144, 166], "definit": [44, 50, 53], "deliber": 120, "delimit": 114, "deliver": [167, 170], "deliveri": [65, 71, 160], "dens": [126, 156], "depend": 144, "deploi": 72, "deploy": [45, 59, 73, 74, 166], "descript": [4, 37, 47, 70, 87, 95, 96, 129, 161, 172], "design": [55, 70, 166], "detail": [8, 9, 60, 82, 106, 115, 136], "detect": [7, 84, 90], "detectgpt": 84, "detector": 120, "develop": [7, 56, 75, 89, 164, 166, 171, 172], "devop": [64, 65, 71, 159, 160], "devsecop": 63, "dictionari": [137, 141], "differ": [46, 55, 69, 79, 105, 139, 142, 178], "differenti": [42, 119], "difficult": 130, "difficulti": 140, "diffus": [6, 9, 10, 51, 120], "digit": 77, "dilemma": 12, "dimension": [8, 138, 143, 148], "direct": [12, 50, 147], "directli": 177, "directori": [81, 181], "dirichlet": 151, "disadvantag": 69, "disagr": 137, "disambigu": 55, "disclosur": 123, "discret": 8, "discuss": 50, "displai": 173, "disrupt": 120, "distinct": 42, "distribut": [24, 26, 77, 94, 156, 157, 177, 185], "dive": [10, 80], "divers": 6, "do": [116, 126, 130, 131, 144, 156, 173], "doc2vec": 154, "docker": [61, 73], "dockerfil": [60, 61], "document": [75, 123, 148, 152, 154, 173], "doe": [71, 114, 130, 153], "domain": [49, 50, 93], "dot": 157, "dotfil": 66, "download": [82, 123], "downstream": 51, "draw": [5, 7, 8], "drawback": 172, "driven": [6, 171, 172], "drop": 115, "dropout": [105, 106], "dtm": 151, "dump": 121, "duplic": 55, "dynam": [6, 10, 121, 145, 151, 163], "e": [5, 8, 9, 10, 77], "each": 167, "eas": 23, "easi": 113, "econ": 35, "econ_news_kr": 15, "econom": [12, 23, 32, 37, 40, 41, 119], "ecosystem": 56, "eda": [25, 26, 27, 31, 32, 94, 136], "edg": 7, "edit": [6, 177], "editor": 174, "educ": 49, "effect": [23, 119], "effici": [50, 51], "ekonlpi": 141, "ekorpkit": [121, 130, 152], "electra": 99, "elicit": 165, "elimin": 55, "email": 173, "embed": [49, 55, 99, 126, 128, 138, 154, 156], "emerg": [50, 57, 98], "encod": [9, 10, 49, 88, 101, 103, 106, 107, 108, 113, 116, 117], "encrypt": 77, "end": 71, "endogen": 119, "engin": [9, 49, 57, 61, 88, 97, 100, 136, 138, 161, 163, 165, 167, 169, 172], "english": [115, 139], "enhanc": [42, 46, 55], "ensur": 55, "entiti": 55, "entropi": [132, 145], "environ": [15, 94, 110, 111, 112], "error": 17, "esg": [12, 18, 19, 22], "esg_cv_polarity_kr": 16, "esg_cv_topics_kr": 16, "esg_polarity_kr": [16, 22], "esg_top": 17, "esg_topics_improv": [16, 22], "esg_valid_topics_kr": 16, "estim": [6, 106, 128, 132], "etc": 139, "ethic": [12, 49, 53, 130], "evalu": [16, 45, 55, 89, 90, 128, 132, 144, 145, 147], "even": 51, "event": 23, "everybodi": 6, "everyon": 121, "everyth": 147, "evolut": [44, 49, 53], "evolutionari": 56, "exactli": 139, "exampl": [42, 43, 44, 51, 68, 106, 132, 133, 141, 142, 146, 152, 158, 173, 174, 178, 183, 184], "execut": [42, 167, 170], "exercis": [155, 173], "exist": 50, "expect": 12, "experi": [55, 115], "experiment": 89, "explain": 114, "explor": 69, "exploratori": [94, 136], "extens": 49, "extern": 8, "extract": [101, 123], "ey": 10, "face": [45, 52, 95], "factor": [150, 151], "factual": 55, "falcon": 45, "famili": [83, 99], "fast": [7, 73, 183], "fasttext": [124, 154], "feasibl": 165, "featur": [28, 29, 33, 35, 42, 69, 79, 136, 138, 178], "fed": [23, 31], "feedback": [46, 89, 92, 178], "fetch": 20, "few": 100, "file": [61, 64, 159, 174, 176, 177, 181], "filter": [14, 15, 21], "final": [47, 75], "financ": 37, "financi": [12, 49, 77, 123], "finbert": [30, 35], "find": [17, 108, 123, 180], "fine": [45, 46, 49, 50, 52, 59, 74, 113, 117], "finetuin": 110, "finetun": [9, 51, 99, 109], "firm": 119, "first": [106, 174], "fix": [175, 178], "flame": 6, "flow": 7, "focu": 69, "focus": 114, "fomc": [23, 24, 30, 36, 120], "fork": [67, 68, 178], "form": [6, 177], "format": [49, 110, 111, 112, 117, 124, 139], "forticli": 82, "forward": 183, "foundat": [49, 50, 53, 59], "framework": [42, 49, 59, 66, 73, 75, 117, 171], "free": [6, 10, 115], "french": 142, "from": [6, 8, 20, 23, 46, 69, 79, 98, 105, 113, 120, 123, 132, 133, 178, 180, 182], "frontmatt": 182, "full": 51, "function": [6, 20, 34, 42, 53, 73, 127, 128, 165], "fundament": 53, "further": [14, 53, 170], "futur": [12, 50, 53, 77, 91, 115, 171], "fzf": 79, "game": [96, 129], "gap": 89, "gato": 116, "gener": [4, 5, 6, 7, 10, 20, 49, 50, 55, 57, 59, 69, 79, 84, 86, 88, 115, 130, 131, 132, 137, 145], "generalist": 116, "genesi": 49, "geometr": 147, "geospati": 12, "get": [23, 45, 51, 60, 152, 174], "gh": 182, "git": [76, 173, 174, 176, 177, 179, 181, 184], "github": [67, 68, 76, 80, 81, 173, 176, 177, 178, 182, 185], "gitop": [64, 66, 159], "give": 177, "glide": 9, "glove": [125, 154], "glue": 115, "gnu": 76, "goal": [4, 47, 96, 129, 130, 146, 161], "good": [139, 163, 180], "googl": [52, 73, 176], "got": 53, "gpg": 76, "gpt": [5, 85, 99, 103, 130], "grab": 180, "grade": [47, 70, 87, 96, 129, 161], "gradio": 72, "gram": [124, 128, 132, 143], "grammat": 140, "graph": [53, 179], "grayscal": 7, "greedi": 97, "ground": 38, "groundtruth": 53, "group": 81, "gru": 49, "guanaco": 83, "guard": 76, "guid": [7, 73, 76], "guidanc": 10, "guidelin": 167, "h2o": 73, "hallasan": 3, "hallucin": 57, "handl": [89, 137], "hannanum": 141, "hard": 130, "hardwar": 51, "harvard": 137, "hash": [143, 174], "have": 93, "head": [113, 116, 175], "healthcar": [49, 77], "here": 174, "hidden": [71, 128], "hierarch": 128, "high": [93, 105, 143], "highli": 55, "highlight": [50, 105], "histori": 175, "home": 185, "host": [59, 185], "how": [2, 10, 53, 60, 64, 65, 71, 88, 90, 115, 116, 132, 139, 153, 156, 159, 160, 173], "hug": [45, 52, 95], "huge": 133, "huggingfac": 51, "human": [6, 46, 90, 92], "hunk": 181, "hypothesi": 156, "i": [7, 10, 46, 50, 55, 64, 77, 92, 102, 105, 106, 115, 116, 119, 126, 130, 137, 139, 140, 141, 144, 146, 152, 153, 157, 158, 159, 172, 173, 180], "iac": [65, 160], "ibm": 130, "idea": 128, "ident": 114, "identifi": 89, "idf": 158, "ignor": 181, "ii": [7, 50, 55, 77, 120, 141], "iii": [7, 50, 55, 77, 141], "illustr": 42, "imag": [5, 9, 10, 11, 60, 61, 88, 116, 130], "imagen": 10, "imageri": 12, "impact": 50, "implement": [53, 63, 71, 80, 89, 101, 104, 107, 108, 116], "implic": [50, 53, 54], "import": [21, 50, 52, 55, 56, 63, 76, 89, 102, 122, 156, 163], "improv": [17, 53, 55, 85, 125, 128], "impuls": 34, "includ": 174, "incorpor": 137, "increment": [166, 172], "index": 127, "indic": [12, 23], "indirect": 147, "individu": [55, 98], "industri": [50, 69, 119], "infer": [8, 42, 51, 59, 74, 151, 152], "inferenc": 51, "inflat": 12, "inflect": 140, "influenc": 120, "info": [14, 15, 21], "inform": [55, 123, 143, 147, 155, 157], "infrastructur": [38, 59, 65, 74, 85, 160], "initi": [49, 79, 101, 107, 108], "initialis": 173, "input": [116, 117, 128, 146], "inquir": 137, "inquiri": 137, "insight": 53, "inspect": 60, "instal": [42, 45, 60, 61, 64, 69, 79, 80, 81, 82, 103, 114, 123, 152, 159], "instanc": 94, "institut": 121, "instruct": 43, "instructor": 49, "int8": 51, "integr": [12, 38, 50, 51, 53, 65, 74, 79, 160, 171], "interact": [44, 181], "interdisciplinari": 130, "interest": 89, "intern": [8, 121], "interpret": [12, 40], "intricaci": 139, "introduct": [1, 2, 5, 6, 7, 12, 39, 41, 48, 50, 53, 55, 56, 60, 67, 68, 69, 71, 72, 73, 74, 76, 77, 79, 81, 83, 84, 88, 89, 91, 92, 93, 102, 106, 110, 111, 112, 122, 123, 129, 130, 134, 136, 144, 147, 148, 151, 154, 155, 156, 162, 167, 169, 171, 173], "invalid": [14, 16, 21], "inventori": [64, 159], "iot": 77, "isol": 140, "issu": [98, 121, 130, 132], "iter": [53, 106, 166, 172], "iv": [7, 50, 55, 77], "jean": 5, "jeopardi": 130, "joint": 132, "just": 139, "justifi": 89, "k": 97, "kei": [41, 42, 45, 50, 53, 60, 63, 69, 74, 77, 79, 113, 115, 171, 185], "kera": 73, "kkma": 141, "knowledg": 139, "komoran": 141, "korean": [121, 130, 140, 141, 142, 145], "kss": 141, "kubernet": [60, 73, 80], "lab": [45, 94, 103, 110, 111, 112, 123, 135, 136, 141, 142, 149, 150, 152, 155], "label": [17, 19, 20, 59], "labelmodel": 20, "labelstudio": [20, 21], "lambda": 73, "landscap": 74, "langchain": 72, "languag": [6, 12, 47, 49, 53, 55, 59, 86, 90, 92, 95, 98, 99, 106, 109, 113, 121, 127, 130, 131, 132, 133, 140, 142], "larg": [10, 47, 49, 50, 51, 53, 55, 59, 92, 98], "latent": 151, "law": 139, "layer": [50, 56, 59, 126, 128], "layout": 182, "lda": [151, 152], "leader": 178, "learn": [2, 4, 6, 12, 21, 37, 46, 47, 49, 50, 53, 70, 71, 73, 75, 77, 87, 92, 96, 100, 114, 115, 116, 117, 129, 137, 138, 139, 150, 161], "learner": 100, "lectur": [55, 96], "ledger": 77, "legal": 121, "legisl": 120, "lemmat": 146, "length": [94, 117], "level": [71, 105, 106, 115, 119, 174, 177, 179], "leverag": 49, "lexic": 156, "lexicon": [135, 137], "librari": [45, 51, 69, 95, 103], "lie": 175, "life": 166, "light": 2, "lightgbm": 73, "lightweight": 88, "likelihood": 132, "limit": [40, 49, 50, 53, 55, 85, 109, 153], "line": 60, "lingual": 115, "linguist": [137, 139, 140], "list": [61, 81], "literatur": 89, "live": 6, "liwc": 137, "llama": 83, "llm": [42, 44, 45, 46, 49, 51, 52, 53, 55, 56, 57, 58, 74, 83, 92, 93, 98, 100], "llmop": 74, "lm": [30, 35, 111, 112], "load": [14, 15, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 55, 94, 103, 110, 111, 112, 124, 136, 149, 152], "local": [72, 185], "log": [65, 160, 174], "long": 139, "loop": 53, "lora": [50, 51], "loss": [88, 107, 127, 128], "low": [50, 93, 130], "lower": 23, "lstm": 49, "machin": [2, 5, 12, 50, 70, 71, 75, 77, 84, 90, 115, 116, 130, 137, 138, 139], "made": 185, "main": [69, 128], "mainten": [74, 166], "make": [67, 68, 178], "manag": [38, 49, 60, 64, 65, 66, 77, 78, 79, 81, 143, 159, 160, 163, 165, 171], "mani": 139, "manner": 55, "manual": 184, "mar": 3, "marg": 95, "mariana": 3, "markdown": 173, "market": [12, 23], "markov": 132, "mask": [88, 99], "masteri": 53, "match": [120, 145], "matrix": [125, 126, 145, 150, 151, 157], "matter": 71, "maximum": [132, 145], "mbart": 95, "mbert": 95, "mc4": [94, 95], "md": 123, "mdm": 6, "mean": 147, "measur": [119, 147], "mecab": 141, "mechan": [49, 52, 53, 113, 116], "media": 12, "median": 147, "medium": 51, "meet": 83, "merg": [31, 67, 68, 101, 108, 177, 180, 183], "metadata": 24, "metal": [64, 159], "method": [41, 49, 50, 51, 52, 57, 90, 102, 117, 137, 138, 139, 171], "methodologi": [12, 89, 98, 117, 151, 171], "microk8": 80, "migrat": 79, "mine": 120, "minut": 120, "miss": [26, 27], "mistak": [174, 175], "ml": [5, 29, 35, 50, 71, 136], "mle": 132, "mlm": [110, 112], "mlop": [71, 75, 80, 81], "mmlu": 98, "mobil": 77, "model": [5, 6, 7, 9, 10, 11, 12, 16, 20, 22, 40, 47, 49, 50, 51, 53, 55, 57, 59, 72, 74, 75, 86, 89, 90, 92, 95, 98, 99, 104, 106, 107, 109, 110, 111, 112, 115, 117, 124, 127, 128, 131, 132, 133, 136, 138, 144, 146, 147, 148, 150, 151, 152, 153, 154, 158, 164, 166, 167, 170, 172], "modifi": [110, 137], "modul": [64, 159], "modular": [64, 159], "monetari": [34, 120], "monitor": [12, 57, 65, 74, 80, 160], "more": [50, 130], "morph": 139, "morphem": 139, "morpholog": 140, "motion": 6, "motiondiffus": 6, "motiv": 150, "mountain": 3, "mpqa": 137, "mt5": 115, "multi": [42, 44, 113, 116, 117], "multilingu": 93, "multimod": 116, "multipl": [8, 49, 126, 176, 185], "muse": 2, "music": 2, "must": 93, "mutual": [143, 147, 155, 157], "n": [124, 132, 143], "naiv": 145, "name": 173, "nation": 121, "natur": [6, 12, 49, 163], "necess": 41, "necessari": [45, 81, 103], "need": [116, 126, 131, 144, 166], "neg": [128, 150, 151], "negat": 137, "net": 130, "network": [6, 10, 12, 53, 119, 126, 138, 177], "neural": [6, 12, 53, 126, 127, 130, 138], "neuro": 54, "new": [3, 40, 67, 68, 69, 81, 145, 175, 176, 178], "newer": 69, "next": [35, 44, 46, 50, 53, 65, 66, 68, 74, 80, 91, 93, 98, 102, 114, 116, 118, 122, 126, 131, 134, 139, 148, 154, 160, 174], "nlp": [12, 50, 87, 93, 96, 118, 122, 129, 130, 137, 142], "nltk": 132, "nmf": [150, 151], "nmt": 105, "nois": [115, 128], "non": [150, 151, 165], "nonconflict": 177, "normal": [104, 147], "note": 96, "noth": 174, "now": 6, "nucleu": 97, "number": [24, 105, 146], "numer": [23, 25, 26, 27], "object": [7, 8, 37, 43, 70, 75, 87, 99, 117, 124, 167, 170, 172], "observ": 59, "obtain": [82, 106, 177], "occurr": [106, 125], "offlin": [73, 121], "okt": 141, "onc": 176, "ongo": 55, "oov": 143, "op": 56, "open": 141, "openai": [52, 130], "openassist": 45, "opendartread": 123, "oper": [75, 76, 101], "opportun": 89, "optim": [55, 107, 127, 128], "orchestr": [59, 65, 160], "organ": [75, 89], "origin": 113, "other": [46, 105, 114, 130, 141], "our": 174, "out": [14, 15, 21, 143, 152, 180], "outcom": [37, 75], "outlin": [47, 161, 172], "output": [12, 117, 128, 146], "over": 125, "overal": 55, "overfit": 50, "overview": [42, 50, 52, 53, 60, 75, 85, 109, 121, 123, 139, 151, 171], "own": [93, 137], "p": 97, "page": [121, 182], "pair": [103, 106, 108], "paper": 98, "paradigm": 164, "paragraph": 146, "paramet": [50, 51], "pars": 144, "part": [55, 119, 120, 140, 141, 142, 144], "partial": 49, "partnership": 2, "pass": 79, "passag": 79, "password": [79, 81], "pattern": 114, "peft": [50, 51, 52], "pencil": 7, "perform": [46, 50, 51, 55, 85, 135], "period": 32, "permiss": 177, "permut": 99, "perplex": [95, 132], "person": 49, "perspect": 8, "perturb": 84, "phase": [6, 167, 172], "physic": 6, "pine": 152, "pipelin": [14, 30, 50, 55, 71, 80, 81, 104, 130, 146], "plai": [53, 176], "plan": [75, 166, 171, 172], "platform": 49, "playbook": [64, 159], "playground": 56, "plm": 99, "plot": [25, 32, 34], "plsa": 151, "plugin": [64, 79, 159], "pmi": [147, 155, 157], "po": [140, 144], "point": 171, "pointwis": [143, 147, 155, 157], "polar": [14, 16, 19, 21, 22], "polici": [34, 51, 53, 119, 120], "polit": 119, "popular": [122, 138], "pork": 120, "posit": 157, "post": 104, "posterior": 8, "postprocess": [24, 104], "potenti": [17, 53, 54], "power": 116, "ppmi": 157, "practic": [50, 63, 64, 74, 76, 77, 132, 145, 155, 159, 171, 178], "pre": [9, 104, 108, 113, 115, 142, 146], "predetermin": 105, "predict": [12, 14, 19, 21, 30, 35, 49, 114, 128], "prepar": [14, 15, 16, 17, 20, 21, 22, 23, 24, 45, 55, 101, 103, 107, 108, 110, 111, 112, 123, 128], "preprocess": [25, 26, 27, 89], "prerequisit": [37, 70, 80, 81, 87], "preserv": 77, "pretrain": [99, 109, 110, 111, 112], "previou": 114, "price": 132, "principl": [53, 63, 74], "prior": [9, 152], "privaci": [12, 52, 76, 77], "privat": 176, "prm": 53, "pro": [115, 183], "probabilist": [20, 151], "probabl": [106, 132, 147], "problem": [54, 55, 84, 116, 150, 172], "process": [7, 12, 49, 53, 55, 89, 104, 108, 139, 141, 142, 146, 150, 164, 165, 167, 170, 172], "product": [119, 157], "program": [145, 164, 173], "project": [4, 47, 50, 69, 75, 81, 96, 129, 166, 168, 169, 170, 171], "prompt": [9, 49, 50, 52, 56, 57, 88, 97, 100], "promptabl": 88, "propos": [4, 167, 168, 170], "proprietari": 93, "prospect": 53, "protect": [38, 79], "protocol": 77, "prototyp": 166, "proven": 38, "public": [69, 93, 123], "publish": [176, 180, 182], "pull": [61, 67, 68, 178], "punctuat": 146, "push": [67, 68, 177, 178], "put": [14, 147], "python": [43, 104, 158], "pytorch": 73, "q": [53, 54], "qualiti": [12, 38, 52, 55, 93, 163], "quantit": 23, "quantiti": 38, "quantum": 77, "queri": [55, 56, 113], "question": [49, 130], "quick": [52, 123], "r": 95, "rad": 166, "rag": [55, 57], "rage": 79, "random": [84, 150], "rank": 50, "ranker": 51, "rate": [18, 22, 23, 25, 26, 31, 117], "rational": 41, "raw": 105, "re": [17, 165], "read": 53, "real": [12, 44, 49, 130], "reason": [49, 100], "rebas": 183, "recap": 172, "record": 24, "recurr": 138, "recurs": 145, "reduct": [138, 148], "redund": 55, "refer": [0, 2, 6, 7, 10, 36, 53, 56, 57, 59, 67, 73, 83, 85, 88, 99, 114, 115, 117, 129, 133, 145, 175], "referenc": [90, 185], "regardless": 174, "registri": 61, "regular": 105, "regulatori": 12, "reinforc": [6, 46, 92], "reject": 177, "relat": [95, 114, 130, 132, 137], "relationship": 60, "relev": [50, 89], "remark": 56, "remot": [176, 185], "remov": [61, 81], "reparameter": 52, "repeat": 108, "repo": 178, "report": 85, "repositori": [67, 68, 80, 81, 173, 176, 178, 184], "repres": 156, "represent": [113, 130, 154, 156], "request": [67, 68, 178], "requir": [75, 165, 166], "research": [50, 85, 89, 119, 120, 130], "reset": 175, "resolut": 10, "resolv": [88, 177], "resourc": [12, 70, 80, 130, 167, 170], "respons": [34, 55, 74], "result": [8, 10, 32, 98, 115], "retriev": [55, 57, 79], "revert": 175, "review": [52, 89, 174, 175], "revis": 179, "reward": 53, "rewrit": 175, "reykjavik": 3, "risk": [12, 32, 49, 119, 167, 170], "rlhf": [46, 51, 92], "rnn": [49, 138], "roberta": 99, "robot": 7, "robust": 10, "role": [49, 56, 64, 159, 171, 172], "rubrix": 17, "rule": [23, 25], "run": [60, 61, 64, 73, 159], "safeti": [59, 85], "sam": 88, "same": 177, "sampl": [8, 95, 97, 106, 128, 133, 145], "sampler": 10, "satellit": 12, "save": [17, 26, 27, 51, 72, 110, 111, 112, 124, 152], "scalabl": [55, 163], "scale": [50, 55, 117, 171], "scenario": 60, "scienc": [37, 40, 71], "scikit": [73, 150], "scope": [89, 167, 170, 173], "score": [30, 32, 107, 108, 149], "scrape": [12, 121], "scrum": 171, "sdlc": 166, "search": [53, 97], "second": 106, "secret": [64, 159], "section": [13, 24, 39, 48, 58, 123, 162, 168, 172, 186], "secton": 24, "secur": [12, 52, 74, 76, 77, 78], "see": [98, 174], "seek": 89, "segment": [7, 88, 141, 145, 146, 147], "select": 52, "self": [46, 49, 52, 53, 116], "semant": [7, 41, 137, 151, 156], "semiconductor": 59, "sentenc": [24, 30, 105, 114, 133, 140, 141, 142, 146], "sentencepiec": [103, 105], "sentiment": [12, 30, 31, 32, 110, 134, 135, 136, 137], "sentiwordnet": 137, "sequenc": [132, 146], "serengeti": 3, "serv": [55, 72, 73], "server": [20, 81, 82, 185], "servic": [49, 61, 72, 77], "set": [26, 28, 29, 33, 35, 45, 64, 76, 80, 81, 94, 128, 144, 159, 173], "setup": [75, 79, 81, 135, 141], "sfv": 6, "share": [38, 66, 176], "shell": 76, "shock": 34, "shortcom": [130, 150], "shot": [9, 49, 84, 100], "should": 145, "sidestep": 130, "sign": [76, 77], "signal": 53, "signatur": 77, "signific": [50, 89], "silicon": 3, "similar": [147, 148, 155, 156, 157], "simpl": [60, 79, 80, 81], "singular": 150, "site": 23, "size": 117, "sketch": 7, "skill": 6, "skip": 128, "small": 51, "smooth": [133, 157], "snorkel": 20, "so": 116, "social": [12, 177], "societ": 49, "soft": 52, "softmax": 128, "softwar": [81, 161, 163, 164, 165, 166, 167, 169, 170, 171, 172], "solo": [173, 174], "solut": [49, 53, 54, 57, 71], "solv": [54, 184], "some": [146, 176, 178], "somewher": 173, "sota": 117, "sourc": [12, 40, 89, 119, 121], "space": [8, 154], "span": 117, "spars": [50, 156], "sparsiti": 130, "special": [93, 108], "specif": [43, 49, 50, 137, 165, 167, 170], "speech": [140, 141, 144], "spell": 139, "spiral": [166, 172], "split": [24, 108], "splitter": 141, "spot": 90, "spotlight": 50, "squad": 130, "squash": 183, "sr": 165, "ssh": [76, 80, 81, 82, 185], "stabil": 12, "stack": [58, 59], "stage": [166, 174], "standalon": 42, "standard": [52, 55, 69, 99], "star": 54, "start": [45, 51, 60, 61, 123, 152, 174], "stash": 181, "state": 93, "statement": 123, "static": [10, 121], "statist": [90, 94, 137, 139], "statu": 174, "stem": [139, 146], "step": [45, 71, 101, 103, 107, 108, 127, 128, 142, 169], "stewardship": 38, "stock": 132, "stop": 61, "stopword": 146, "storag": 51, "stori": 171, "strategi": [49, 53, 55, 97, 139, 180], "stroke": 7, "structur": [8, 52, 89, 139], "struggl": 9, "studi": [50, 53, 115, 117, 130, 165, 171], "stupid": 133, "subject": 137, "subset": 49, "subword": [102, 105, 106, 146], "sudoer": 81, "summar": 49, "summari": [41, 55, 85, 97, 127, 133, 135, 149, 165, 166, 167, 170, 171], "sun": 3, "super": 10, "superglu": 115, "supersens": 137, "supervis": [46, 49, 53, 59, 116, 138], "supervisor": 89, "support": [51, 73, 95], "surfac": 139, "surround": 98, "svd": 150, "sweat": 120, "switch": 81, "symbol": [54, 105, 156], "sync": 68, "synchron": 66, "synset": 137, "syntax": 137, "synthes": [50, 89], "synthesi": 6, "synthet": [59, 115], "system": [7, 32, 49, 55, 64, 66, 70, 71, 75, 85, 121, 159, 167, 170, 186], "systemat": 117, "t": 139, "t5": [10, 30, 35, 99, 103, 117], "tabl": [4, 70, 87, 96, 129, 170], "tackl": 139, "tag": [140, 141, 144, 181], "tagger": 144, "tail": 139, "take": 130, "target": [12, 23, 128], "task": [45, 51, 98, 115, 117, 130, 136], "taylor": [23, 25], "team": [75, 80, 81, 173, 177, 178], "technic": [9, 38, 43, 53, 71, 85, 105, 115, 167, 170], "techniqu": [7, 46, 50, 52, 53, 54, 57, 130, 134, 138, 146, 171], "technologi": [40, 41, 50, 77, 120], "tell": [174, 176], "templat": [69, 170], "tensorflow": 73, "term": [4, 55, 96, 129], "terminologi": 57, "test": [64, 159, 166, 171], "text": [5, 6, 9, 10, 11, 49, 84, 90, 94, 103, 108, 117, 119, 120, 121, 130, 141, 146, 173], "textblob": 135, "textbook": [37, 70, 129], "textual": [12, 24, 36, 118], "tf": 158, "than": 10, "them": 14, "theori": 179, "thesi": 89, "thi": [116, 173], "think": 169, "third": 106, "thought": [53, 57, 100], "three": [8, 93], "threshold": 10, "through": [12, 93], "time": [12, 150], "timebox": 171, "timelin": [5, 167, 170], "timesform": 116, "timestamp": 94, "timestep": 10, "tingu": 5, "titl": 170, "todai": 93, "togeth": [14, 147], "token": [101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 115, 139, 140, 141, 142, 143, 146], "tomotopi": 152, "tone": [33, 35], "tool": [2, 40, 56, 60, 64, 65, 66, 69, 159, 160], "top": 97, "topic": [14, 16, 89, 138, 147, 148, 149, 150, 151, 152], "tot": 53, "toward": 115, "track": 175, "tradit": [40, 50, 130, 138, 146], "train": [8, 9, 14, 16, 20, 22, 26, 27, 45, 51, 53, 88, 99, 103, 105, 109, 110, 111, 112, 113, 115, 124, 125, 127, 128, 136, 144], "tranform": 116, "transact": 12, "transfer": [49, 50, 117], "transform": [49, 50, 52, 99, 113, 116, 117, 138, 152], "translat": [49, 130], "transmiss": 119, "transpar": 120, "treasuri": 23, "tree": 53, "trench": 3, "trend": [50, 77], "triangular": 145, "truncat": 150, "truth": 38, "tta": 54, "ttc": 54, "tune": [45, 46, 49, 50, 51, 52, 59, 74, 113, 117], "tunnel": 3, "tutori": 173, "tweetqa": 115, "two": [128, 176], "type": [12, 77, 89, 91, 121, 122, 134, 142, 169], "typo": 139, "u": 23, "ubuntu": 81, "ugli": 139, "ui": 72, "uncertainti": [8, 32, 119, 145], "unclip": 9, "underfit": 50, "undersea": 3, "understand": [50, 54, 67, 130, 142, 143, 146, 147], "unicod": 104, "unifi": 117, "unigram": [103, 106, 107], "uniqu": 105, "unix": 79, "unknown": [130, 133, 145], "unlabel": 117, "unmodel": 130, "unseen": 152, "unstag": 174, "unsupervis": [117, 138], "up": [45, 64, 76, 80, 81, 94, 159, 173, 178, 180], "updat": [79, 80, 81, 144], "upgrad": 152, "us": [2, 6, 12, 17, 20, 51, 52, 55, 60, 61, 64, 69, 76, 81, 82, 92, 95, 115, 124, 125, 128, 132, 133, 135, 143, 144, 150, 152, 159, 173, 175, 183], "usag": [68, 69, 79, 81, 105, 114, 133], "user": [81, 171], "util": [12, 49, 72], "v": [7, 42, 46, 50, 52, 55, 64, 77, 92, 93, 121, 125, 126, 159, 164, 166, 171, 172, 183], "vader": 135, "vae": 8, "valid": [16, 17, 64, 110, 111, 112, 159, 165], "vallei": 3, "valu": [26, 27, 53, 150], "variabl": [128, 130], "variant": [53, 139, 145], "variat": 8, "varieti": 145, "vatt": 116, "vault": [64, 159], "vc": 177, "vector": [7, 55, 59, 113, 143, 154, 156, 157], "venic": 3, "verifi": [60, 77], "version": [65, 66, 113, 160, 173, 186], "versu": [71, 185], "vertex": 52, "vi": [50, 55, 77], "via": 82, "vicu\u00f1a": 83, "video": 6, "view": 10, "vii": [50, 55, 77], "virtual": [49, 130], "vision": 116, "visual": [8, 28, 33, 114, 128, 149, 152, 155], "vocabulari": [106, 107, 108, 143], "voic": 72, "volum": 61, "vpn": 82, "vq": 8, "vqgan": 9, "wai": 178, "waterfal": [166, 172], "watson": 130, "we": [116, 126, 131, 144, 145, 156, 173], "web": [12, 41, 69, 77, 93, 121], "weight": 10, "well": 89, "what": [46, 49, 64, 92, 98, 102, 105, 106, 114, 115, 126, 130, 139, 140, 144, 146, 152, 153, 157, 158, 159, 172, 173, 180], "when": [120, 128], "whitespac": 105, "who": 52, "whole": [96, 129], "why": [6, 10, 71, 73, 92, 102, 106, 116, 126, 130, 131, 143, 144, 145, 163, 173], "win": 130, "wise": 50, "within": 120, "without": 15, "word": [49, 99, 102, 107, 108, 114, 115, 120, 126, 127, 128, 132, 133, 137, 138, 139, 141, 142, 143, 145, 152, 153, 154, 155, 156, 157], "word2vec": [125, 128, 154], "wordnet": 137, "wordpiec": [103, 106, 108], "work": [10, 53, 60, 64, 65, 88, 145, 153, 159, 160, 173, 174, 175, 176, 185], "workflow": [64, 66, 67, 68, 81, 159, 174], "world": [3, 44, 49, 130], "write": [20, 49, 64, 89, 159], "written": 90, "xgboost": 73, "xlm": 95, "xlnet": 99, "xml": 23, "xsum": 115, "yaml": 182, "yeoman": 69, "yield": 23, "yml": 61, "you": [116, 130], "your": [45, 67, 68, 89, 93, 137, 173, 174, 175, 176, 178, 181], "yubikei": 79, "zero": [9, 49, 84, 100], "zipf": 139, "\ud65c\uc6a9": 140}})