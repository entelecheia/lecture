Search.setIndex({"alltitles": {"0. Introduction to version control": [[174, "introduction-to-version-control"]], "1. Atomic Symbols": [[157, "atomic-symbols"]], "1. Cookiecutter: The Industry Standard": [[70, "cookiecutter-the-industry-standard"]], "1. Create a new user": [[82, "create-a-new-user"]], "1. Data Quality and Integrity": [[13, "data-quality-and-integrity"]], "1. Defining the Tag Set": [[145, "defining-the-tag-set"]], "1. Definition of AI Agents": [[45, "definition-of-ai-agents"]], "1. Download and install FortiClient": [[83, "download-and-install-forticlient"]], "1. Executive Summary": [[168, "executive-summary"], [171, "executive-summary"]], "1. Feasibility Study": [[166, "feasibility-study"]], "1. Fork repository": [[179, "fork-repository"]], "1. Install BuildKit": [[61, "install-buildkit"]], "1. Install containerd": [[81, "install-containerd"]], "1. Installation:": [[65, "installation"], [160, "installation"]], "1. Installing containerd": [[61, "installing-containerd"]], "1. Introduction to GitHub Workflow": [[69, "introduction-to-github-workflow"]], "1. Natural Language Processing (NLP) for Sentiment Analysis": [[13, "natural-language-processing-nlp-for-sentiment-analysis"]], "1. Objective": [[44, "objective"]], "1. Overview of containerd": [[61, "overview-of-containerd"]], "1. Project planning and team organization": [[76, "project-planning-and-team-organization"]], "1. Real-Time Economic Indicators": [[13, "real-time-economic-indicators"]], "1. Real-Time Economic Monitoring Using Social Media Data": [[13, "real-time-economic-monitoring-using-social-media-data"]], "1. Segmentation": [[148, "segmentation"]], "1. Set up the server": [[82, "set-up-the-server"]], "1. Solo work with git": [[175, "solo-work-with-git"]], "1. Textual Data": [[13, "textual-data"]], "1. Undersea Tunnel": [[4, "undersea-tunnel"]], "1. Understanding Fork & Pull Workflow": [[68, "understanding-fork-pull-workflow"]], "10. Example Usage": [[69, "example-usage"]], "10. Monitor the pipeline": [[81, "monitor-the-pipeline"]], "10. Rebasing": [[184, "rebasing"]], "10. Silicon Valley": [[4, "silicon-valley"]], "10. Technical Specifications": [[168, "technical-specifications"], [171, "technical-specifications"]], "11. Debugging With git bisect": [[185, "debugging-with-git-bisect"]], "11. Mars": [[4, "mars"]], "11. Timeline and Deliverables": [[168, "timeline-and-deliverables"], [171, "timeline-and-deliverables"]], "11. Update the pipeline": [[81, "update-the-pipeline"]], "12. Conclusion": [[168, "conclusion"], [171, "conclusion"]], "12. Undersea Tunnel": [[4, "id1"]], "12. Working with multiple remotes": [[186, "working-with-multiple-remotes"]], "2. Add a user to the sudoers group": [[82, "add-a-user-to-the-sudoers-group"]], "2. Amazon": [[4, "amazon"]], "2. Background": [[168, "background"], [171, "background"]], "2. Characteristics of AI Agents": [[45, "characteristics-of-ai-agents"]], "2. Clone your forked repo": [[179, "clone-your-forked-repo"]], "2. Collecting and Annotating Data": [[145, "collecting-and-annotating-data"]], "2. Configure containerd": [[81, "configure-containerd"]], "2. Configure inventory file:": [[65, "configure-inventory-file"], [160, "configure-inventory-file"]], "2. Create a Dockerfile": [[61, "create-a-dockerfile"]], "2. Data Security and Privacy": [[13, "data-security-and-privacy"]], "2. Fixing mistakes": [[176, "fixing-mistakes"]], "2. Forking a Repository": [[68, "forking-a-repository"], [69, "forking-a-repository"]], "2. Key components of containerd": [[61, "key-components-of-containerd"]], "2. Market Sentiment Analysis": [[13, "market-sentiment-analysis"]], "2. Obtain VPN connection details": [[83, "obtain-vpn-connection-details"]], "2. Operating system setup": [[76, "operating-system-setup"]], "2. Probability Calculation": [[148, "probability-calculation"]], "2. Requirement Elicitation and Analysis": [[166, "requirement-elicitation-and-analysis"]], "2. Social Media Analytics": [[13, "social-media-analytics"]], "2. Sparse Vectors": [[157, "sparse-vectors"]], "2. Specifications": [[44, "specifications"]], "2. Update the server": [[82, "update-the-server"]], "2. Using the ctr command-line tool": [[61, "using-the-ctr-command-line-tool"]], "2. Web-Scraping for Inflation Expectations": [[13, "web-scraping-for-inflation-expectations"], [13, "id1"]], "2. Yeoman: A New Alternative for Web Apps": [[70, "yeoman-a-new-alternative-for-web-apps"]], "3. Build the image using BuildKit": [[61, "build-the-image-using-buildkit"]], "3. Choosing a Model": [[145, "choosing-a-model"]], "3. Classification of AI Agents": [[45, "classification-of-ai-agents"]], "3. Cloning a Repository": [[69, "cloning-a-repository"]], "3. Cloning the Forked Repository": [[68, "cloning-the-forked-repository"]], "3. Configure FortiClient": [[83, "configure-forticlient"]], "3. Confirmation Measure": [[148, "confirmation-measure"]], "3. Copier: A Newer Alternative (Main Focus)": [[70, "copier-a-newer-alternative-main-focus"]], "3. Create a feature branch": [[179, "create-a-feature-branch"]], "3. Dense Vectors (Word Embeddings)": [[157, "dense-vectors-word-embeddings"]], "3. ESG Risk Assessment": [[13, "esg-risk-assessment"]], "3. Install MicroK8s": [[81, "install-microk8s"]], "3. Install the necessary software": [[82, "install-the-necessary-software"]], "3. Machine Learning for Financial Risk Assessment": [[13, "machine-learning-for-financial-risk-assessment"], [13, "id2"]], "3. Machine learning framework setup": [[76, "machine-learning-framework-setup"]], "3. Model Interpretability": [[13, "model-interpretability"]], "3. Objectives": [[168, "objectives"], [171, "objectives"]], "3. Publishing": [[177, "publishing"]], "3. Remove a user": [[82, "remove-a-user"]], "3. Running a simple container": [[61, "running-a-simple-container"]], "3. Serengeti": [[4, "serengeti"]], "3. Software Requirement Specification (SRS)": [[166, "software-requirement-specification-srs"]], "3. Technical Approach": [[44, "technical-approach"]], "3. Transactional Data": [[13, "transactional-data"]], "3. Working with containerd": [[61, "working-with-containerd"]], "3. Write playbooks:": [[65, "write-playbooks"], [160, "write-playbooks"]], "4. Collaboration": [[178, "collaboration"]], "4. Configure MicroK8s": [[81, "configure-microk8s"]], "4. Connect to the VPN": [[83, "connect-to-the-vpn"]], "4. Convolutional Neural Networks (CNN) for Satellite Imagery": [[13, "convolutional-neural-networks-cnn-for-satellite-imagery"]], "4. Creating a New Branch": [[68, "creating-a-new-branch"], [69, "creating-a-new-branch"]], "4. Evolution to LLM Agents": [[45, "evolution-to-llm-agents"]], "4. Financial Stability Monitoring": [[13, "financial-stability-monitoring"]], "4. Geospatial Data": [[13, "geospatial-data"]], "4. Instructions for AutoGen Agent": [[44, "instructions-for-autogen-agent"]], "4. Make, commit and push changes to new branch": [[179, "make-commit-and-push-changes-to-new-branch"]], "4. Managing container images": [[61, "managing-container-images"]], "4. Mariana Trench": [[4, "mariana-trench"]], "4. Model development": [[76, "model-development"]], "4. Regulatory Compliance": [[13, "regulatory-compliance"]], "4. Run playbooks:": [[65, "run-playbooks"], [160, "run-playbooks"]], "4. Scope": [[168, "scope"], [171, "scope"]], "4. Set up SSH access for the team": [[82, "set-up-ssh-access-for-the-team"]], "4. Software Requirement Validation": [[166, "software-requirement-validation"]], "4. Switch between users": [[82, "switch-between-users"]], "4. Training the Model": [[145, "training-the-model"]], "4. Use cases and scenarios": [[61, "use-cases-and-scenarios"]], "4. Utilizing Satellite Imagery for Agricultural Output Predictions": [[13, "utilizing-satellite-imagery-for-agricultural-output-predictions"]], "4. Verify the image in containerd": [[61, "verify-the-image-in-containerd"]], "5. Clone the GitHub repository": [[82, "clone-the-github-repository"]], "5. Connect to the server via SSH": [[83, "connect-to-the-server-via-ssh"]], "5. Create Pull Request": [[179, "create-pull-request"]], "5. Ethical Dilemmas": [[13, "ethical-dilemmas"]], "5. Evaluating the Model": [[145, "evaluating-the-model"]], "5. Fork and Pull": [[179, "fork-and-pull"]], "5. Hallasan Mountain": [[4, "hallasan-mountain"]], "5. Inflation Targeting Through Social Media": [[13, "inflation-targeting-through-social-media"]], "5. Inspecting container details": [[61, "inspecting-container-details"]], "5. List users on the server": [[82, "list-users-on-the-server"]], "5. MLOps setup": [[76, "mlops-setup"]], "5. Making Changes and Committing": [[68, "making-changes-and-committing"], [69, "making-changes-and-committing"]], "5. Multi-Agent Interaction with AutoGen": [[45, "multi-agent-interaction-with-autogen"]], "5. Set up SSH access for the team": [[81, "set-up-ssh-access-for-the-team"]], "5. Software Process Model": [[168, "software-process-model"], [171, "software-process-model"]], "5. Software Requirement Management": [[166, "software-requirement-management"]], "5. Use roles for modularity:": [[65, "use-roles-for-modularity"], [160, "use-roles-for-modularity"]], "6. Budget": [[168, "budget"], [171, "budget"]], "6. Change a user\u2019s password": [[82, "change-a-users-password"]], "6. Create a dedicated directory for the project": [[82, "create-a-dedicated-directory-for-the-project"]], "6. Feedback from team leader": [[179, "feedback-from-team-leader"]], "6. Finalization and documentation": [[76, "finalization-and-documentation"]], "6. Git Theory": [[180, "git-theory"]], "6. Pushing Changes to GitHub": [[69, "pushing-changes-to-github"]], "6. Pushing Changes to Your Fork": [[68, "pushing-changes-to-your-fork"]], "6. Real-World Examples of AI Agents": [[45, "real-world-examples-of-ai-agents"]], "6. Resource Constraints": [[13, "resource-constraints"]], "6. Set up the GitHub repository": [[81, "set-up-the-github-repository"]], "6. Use Ansible Vault for secrets management:": [[65, "use-ansible-vault-for-secrets-management"], [160, "use-ansible-vault-for-secrets-management"]], "6. Using and Updating the Model": [[145, "using-and-updating-the-model"]], "6. Venice": [[4, "venice"]], "7. Antarctica": [[4, "antarctica"]], "7. Branches": [[181, "branches"]], "7. Conclusion": [[45, "conclusion"]], "7. Connect to the server": [[82, "connect-to-the-server"]], "7. Create a simple MLOps pipeline": [[81, "create-a-simple-mlops-pipeline"]], "7. Creating a Pull Request": [[68, "creating-a-pull-request"], [69, "creating-a-pull-request"]], "7. Fixes by collaborator": [[179, "fixes-by-collaborator"]], "7. System Architecture": [[168, "system-architecture"], [171, "system-architecture"]], "7. Use Ansible modules and plugins:": [[65, "use-ansible-modules-and-plugins"], [160, "use-ansible-modules-and-plugins"]], "8. Advanced git concepts": [[182, "advanced-git-concepts"]], "8. Collaborating and Merging": [[68, "collaborating-and-merging"]], "8. Configure Kubernetes resources": [[81, "configure-kubernetes-resources"]], "8. Leader accepts pull request": [[179, "leader-accepts-pull-request"]], "8. Manage the server": [[82, "manage-the-server"]], "8. Merging a Pull Request": [[69, "merging-a-pull-request"]], "8. Reykjavik": [[4, "reykjavik"]], "8. Risks Assessment": [[168, "risks-assessment"], [171, "risks-assessment"]], "8.Test and validate playbooks:": [[65, "test-and-validate-playbooks"], [160, "test-and-validate-playbooks"]], "9. Apply the Kubernetes configurations": [[81, "apply-the-kubernetes-configurations"]], "9. Publishing from GitHub": [[183, "publishing-from-github"]], "9. Resources": [[168, "resources"], [171, "resources"]], "9. Sun": [[4, "sun"]], "9. Syncing Your Fork": [[69, "syncing-your-fork"]], "9. Use the server for the project": [[82, "use-the-server-for-the-project"]], "A Brave New World": [[4, "a-brave-new-world"]], "A Systematic Study of Transfer Learning Methodology": [[118, "a-systematic-study-of-transfer-learning-methodology"]], "A Traditional Tokenization Pipeline": [[147, "a-traditional-tokenization-pipeline"]], "A first example file": [[175, "a-first-example-file"]], "A good branch strategy": [[181, "a-good-branch-strategy"]], "A new lie": [[176, "a-new-lie"]], "A. Data collection and preprocessing": [[90, "a-data-collection-and-preprocessing"]], "A. Digital Signatures": [[78, "a-digital-signatures"]], "A. Identifying your research interests": [[90, "a-identifying-your-research-interests"]], "A. Importance of SSH in Git and GitHub Operations": [[77, "a-importance-of-ssh-in-git-and-github-operations"]], "A. Quantum Computing": [[78, "a-quantum-computing"]], "A. Secure Web Applications": [[78, "a-secure-web-applications"]], "A. The importance of a comprehensive literature review": [[90, "a-the-importance-of-a-comprehensive-literature-review"]], "A. The significance of a well-defined methodology": [[90, "a-the-significance-of-a-well-defined-methodology"]], "A. The structure of a thesis": [[90, "a-the-structure-of-a-thesis"]], "A. Types of Authentication": [[78, "a-types-of-authentication"]], "A. Types of Encryption": [[78, "a-types-of-encryption"]], "AARON": [[6, "aaron"]], "AFINN": [[136, "afinn"]], "AI Agents": [[45, "ai-agents"]], "AI Agents vs Standalone LLMs": [[43, "ai-agents-vs-standalone-llms"]], "AI Art (Generative AI)": [[5, "ai-art-generative-ai"]], "AI as a Collaborator": [[3, "ai-as-a-collaborator"]], "AI as a Muse": [[3, "ai-as-a-muse"]], "AI as a Tool": [[3, "ai-as-a-tool"]], "AIHub": [[122, "aihub"]], "AI\u2019s Evolutionary Role in Development": [[57, "ais-evolutionary-role-in-development"]], "ALBERT": [[100, "albert"]], "ALPACA": [[84, "alpaca"]], "API Calls": [[122, "api-calls"]], "AWS Lambda": [[74, "aws-lambda"]], "Ablation Study": [[116, "ablation-study"]], "About": [[2, null]], "Accessing Company Overview Information": [[124, "accessing-company-overview-information"]], "Accessing Disclosure Documents": [[124, "accessing-disclosure-documents"]], "Accessing Public Disclosure Information": [[124, "accessing-public-disclosure-information"]], "Accessor Variety": [[146, "accessor-variety"]], "Acquiring High-Quality Datasets": [[94, "acquiring-high-quality-datasets"]], "Activities for Each Phase": [[168, "activities-for-each-phase"]], "Adapters": [[74, "adapters"]], "Adapting AlphaGo\u2019s Strategies to Large Language Models (LLMs)": [[54, "adapting-alphagos-strategies-to-large-language-models-llms"]], "Adaptive and Layer-wise Fine-Tuning": [[51, "adaptive-and-layer-wise-fine-tuning"]], "Add Quantitative Easing as a Lower event": [[24, "add-quantitative-easing-as-a-lower-event"]], "Add Rate and Decisions": [[24, "add-rate-and-decisions"]], "Add Taylor Rule": [[24, "add-taylor-rule"]], "Adding Passwords": [[80, "adding-passwords"]], "Adding Special Tokens": [[109, "adding-special-tokens"]], "Adding a new remote to your repository": [[177, "adding-a-new-remote-to-your-repository"]], "Additional Features": [[80, "additional-features"]], "Additive Methods": [[53, "additive-methods"]], "Adjusting for Confounding with Text Matching": [[121, "adjusting-for-confounding-with-text-matching"]], "Advanced Search Techniques": [[54, "advanced-search-techniques"]], "Advanced Techniques: TTC and TTA": [[55, "advanced-techniques-ttc-and-tta"]], "Advancement to Tree of Thought (ToT)": [[54, "advancement-to-tree-of-thought-tot"]], "Advancements and Variants": [[54, "advancements-and-variants"]], "Advances in AI and NLP": [[88, "advances-in-ai-and-nlp"]], "Advancing Research in PEFT": [[51, "advancing-research-in-peft"]], "Advantages of Data Science Technologies": [[41, "advantages-of-data-science-technologies"]], "Advantages of PRMs": [[54, "advantages-of-prms"]], "Advantages of randomized algorithms:": [[151, "advantages-of-randomized-algorithms"]], "Agglutinative Languages": [[141, "agglutinative-languages"]], "Aggregate sentiment scores": [[31, "aggregate-sentiment-scores"]], "Aggregation": [[148, "aggregation"]], "Agile Development Techniques": [[172, "agile-development-techniques"]], "Agile Model": [[167, "agile-model"]], "Agile Project Management": [[172, "agile-project-management"]], "Agile Software Development": [[172, "agile-software-development"]], "Agile vs Plan-Driven Development": [[172, "agile-vs-plan-driven-development"]], "Algorithms for Subword Tokenization": [[107, "algorithms-for-subword-tokenization"]], "AlphaGo: A Case Study in AI Mastery": [[54, "alphago-a-case-study-in-ai-mastery"]], "Alternative Approaches": [[168, "alternative-approaches"]], "Alternative Approaches and Further Considerations": [[171, "alternative-approaches-and-further-considerations"]], "Alternative Considerations": [[39, "alternative-considerations"]], "Alternative Data Sources for Central Banks": [[13, "alternative-data-sources-for-central-banks"]], "Ambiguity": [[131, "ambiguity"]], "An embedding layer is matrix multiplication:": [[127, "an-embedding-layer-is-matrix-multiplication"]], "An example rebase": [[184, "an-example-rebase"]], "An example repository": [[185, "an-example-repository"]], "An example using the Brown Corpus": [[134, "an-example-using-the-brown-corpus"]], "Analyzing the dataset": [[95, "analyzing-the-dataset"]], "Ansible": [[65, "ansible"], [160, "ansible"]], "Antipatch": [[176, "antipatch"]], "Application Methods for Leveraging Large Language Models": [[50, "application-methods-for-leveraging-large-language-models"]], "Application in AI": [[54, "application-in-ai"]], "Applications": [[99, "applications"], [152, "applications"], [152, "id3"]], "Applications and Implications": [[54, "applications-and-implications"]], "Applications and Utilities of Large Language Models": [[50, "applications-and-utilities-of-large-language-models"]], "Applications in Central Banking": [[13, "applications-in-central-banking"]], "Applications in Economics": [[42, "applications-in-economics"]], "Applications of Sentiment Analysis": [[135, "applications-of-sentiment-analysis"]], "App\u2019s Architecture": [[73, "apps-architecture"]], "Architectural Evolution of LLMs": [[50, "architectural-evolution-of-llms"]], "Architectural Insights": [[54, "architectural-insights"]], "Architecture": [[129, "architecture"]], "Architectures": [[118, "architectures"]], "Architectures and Applications": [[42, "architectures-and-applications"]], "Art and Music in Light of AI": [[3, "art-and-music-in-light-of-ai"]], "Artifacts": [[74, "artifacts"]], "Ascendancy of Large Language Models": [[50, "ascendancy-of-large-language-models"]], "Assessing PEFT\u2019s Limitations": [[51, "assessing-pefts-limitations"]], "Assessing the overall performance": [[56, "assessing-the-overall-performance"]], "Assessment": [[38, "assessment"]], "Assumptions and Probability Calculation": [[107, "assumptions-and-probability-calculation"]], "Assumptions of traditional NLP pipelines": [[131, "assumptions-of-traditional-nlp-pipelines"]], "Attending to Language": [[114, "attending-to-language"]], "Attention Is Not All You Need": [[117, "attention-is-not-all-you-need"]], "Attention Mechanism": [[114, "attention-mechanism"]], "Attention Mechanism: A Partial Solution": [[50, "attention-mechanism-a-partial-solution"]], "Attention in BERT (Easy Version)": [[114, "attention-in-bert-easy-version"]], "Attention is all you need?": [[117, "attention-is-all-you-need"]], "Attention to identical/related words in other sentence": [[115, "attention-to-identical-related-words-in-other-sentence"]], "Attention to identical/related words pattern": [[115, "attention-to-identical-related-words-pattern"]], "Attention to other words predictive of word": [[115, "attention-to-other-words-predictive-of-word"]], "Attention to previous word": [[115, "attention-to-previous-word"]], "Audio to Body Dynamics": [[7, "audio-to-body-dynamics"]], "Augmentation Problems": [[56, "augmentation-problems"]], "Authentication, Encryption, and Signing": [[78, "authentication-encryption-and-signing"]], "Auto ML": [[30, "auto-ml"]], "Auto ML with LM tones": [[36, "auto-ml-with-lm-tones"]], "Auto ML with T5 tones": [[36, "auto-ml-with-t5-tones"]], "Auto ML with econ data": [[36, "auto-ml-with-econ-data"]], "Auto ML with finbert tones": [[36, "auto-ml-with-finbert-tones"]], "AutoGen": [[43, "autogen"]], "AutoGen AutoScraper Agent": [[44, "autogen-autoscraper-agent"]], "Autoencoders": [[9, "autoencoders"]], "Autonomous LLM Agents": [[58, "autonomous-llm-agents"]], "Availability:": [[86, "availability"]], "Azure Functions": [[74, "azure-functions"]], "B. Authentication Protocols": [[78, "b-authentication-protocols"]], "B. Biometric Authentication": [[78, "b-biometric-authentication"]], "B. Consult with your supervisor": [[90, "b-consult-with-your-supervisor"]], "B. Creating and Verifying Digital Signatures": [[78, "b-creating-and-verifying-digital-signatures"]], "B. Developing AI models and algorithms": [[90, "b-developing-ai-models-and-algorithms"]], "B. Identifying relevant sources": [[90, "b-identifying-relevant-sources"]], "B. IoT Security": [[78, "b-iot-security"]], "B. Key Management and Distribution": [[78, "b-key-management-and-distribution"]], "B. Setting Up SSH for Git and GitHub Operations": [[77, "b-setting-up-ssh-for-git-and-github-operations"]], "B. The writing process": [[90, "b-the-writing-process"]], "B. Types of AI research methodologies": [[90, "b-types-of-ai-research-methodologies"]], "BART": [[100, "bart"]], "BERT": [[100, "bert"], [155, "bert"]], "BERT: Bidirectional Encoder Representations from Transformers": [[114, "bert-bidirectional-encoder-representations-from-transformers"]], "BERT: Visualizing Attention": [[115, "bert-visualizing-attention"]], "BIG-Bench (67 tasks):": [[99, "big-bench-67-tasks"]], "BPE Implementation": [[102, "bpe-implementation"]], "BPE Step-by-Step Implementation": [[102, "bpe-step-by-step-implementation"]], "BPE-Dropout": [[107, "bpe-dropout"]], "Backup and sharing tools:": [[67, "backup-and-sharing-tools"]], "Bag of Words attention pattern": [[115, "bag-of-words-attention-pattern"]], "Bags of Words Model": [[154, "bags-of-words-model"]], "Balancing Efficiency with Performance": [[51, "balancing-efficiency-with-performance"]], "Baseline": [[118, "baseline"]], "Basic Docker Commands": [[62, "basic-docker-commands"]], "Basic User Management for an Ubuntu Server": [[82, "basic-user-management-for-an-ubuntu-server"]], "Basic statistics": [[95, "basic-statistics"]], "Beam search": [[98, "beam-search"]], "Benefits of Copier:": [[70, "benefits-of-copier"]], "Benefits of DevOps": [[66, "benefits-of-devops"], [161, "benefits-of-devops"]], "Benefits of GitOps": [[65, "benefits-of-gitops"], [160, "benefits-of-gitops"]], "Benefits of Pretraining and Finetuning": [[110, "benefits-of-pretraining-and-finetuning"]], "BentoML Service": [[73, "bentoml-service"]], "BentoService": [[74, "bentoservice"]], "Best Practices for Implementing DevSecOps": [[64, "best-practices-for-implementing-devsecops"]], "Best Practices for LLMOps": [[75, "best-practices-for-llmops"]], "Best Practices for Setting up GitOps Tools": [[65, "best-practices-for-setting-up-gitops-tools"], [160, "best-practices-for-setting-up-gitops-tools"]], "Bias in Lexicons": [[138, "bias-in-lexicons"]], "Bibliography": [[0, "bibliography"]], "Big Bang Model": [[167, "big-bang-model"]], "Bigram Counts": [[102, "bigram-counts"]], "Bigram Model": [[133, "bigram-model"]], "Bigram Probability Calculation": [[133, "bigram-probability-calculation"]], "Bisecting manually": [[185, "bisecting-manually"]], "Branching Entropy": [[146, "branching-entropy"]], "Build a corpus": [[16, "build-a-corpus"]], "Build a dataset using the data generated by the label model": [[21, "build-a-dataset-using-the-data-generated-by-the-label-model"]], "Build a valid polarity dataset": [[17, "build-a-valid-polarity-dataset"]], "Build a valid topic dataset": [[17, "build-a-valid-topic-dataset"]], "Build an invalid dataset": [[17, "build-an-invalid-dataset"]], "Build and load a feature set": [[29, "build-and-load-a-feature-set"]], "Build and load a feature set with tones": [[34, "build-and-load-a-feature-set-with-tones"]], "Build cross-validated esg_cv_polarity_kr dataset": [[17, "build-cross-validated-esg-cv-polarity-kr-dataset"]], "Build cross-validated esg_cv_topics_kr dataset": [[17, "build-cross-validated-esg-cv-topics-kr-dataset"]], "Build the Image": [[62, "build-the-image"]], "Build the extension (assuming you have Node.js installed on your system):": [[1, "build-the-extension-assuming-you-have-node-js-installed-on-your-system"]], "Building Docker Images with Dockerfile": [[62, "building-docker-images-with-dockerfile"]], "Building Your Own Lexicons": [[138, "building-your-own-lexicons"]], "Building econ_news_kr corpus": [[16, "building-econ-news-kr-corpus"]], "Building the Dataset": [[96, "building-the-dataset"]], "Building your own dataset through web crawling": [[94, "building-your-own-dataset-through-web-crawling"]], "ByT5: Towards a token-free future with pre-trained byte-to-byte models": [[116, "byt5-towards-a-token-free-future-with-pre-trained-byte-to-byte-models"]], "Byte Pair Encoding (BPE)": [[104, "byte-pair-encoding-bpe"], [107, "byte-pair-encoding-bpe"]], "Byte Pair Encoding (BPE) - A Detailed Example": [[107, "byte-pair-encoding-bpe-a-detailed-example"]], "Byte Pair Encoding (BPE) - GPT": [[104, "byte-pair-encoding-bpe-gpt"]], "Byte-level Byte Pair Encoding (BBPE)": [[107, "byte-level-byte-pair-encoding-bbpe"]], "C. Blockchain and Distributed Ledger Technologies": [[78, "c-blockchain-and-distributed-ledger-technologies"]], "C. Defining the scope of your research": [[90, "c-defining-the-scope-of-your-research"]], "C. Encryption Protocols": [[78, "c-encryption-protocols"]], "C. Experimentation and evaluation": [[90, "c-experimentation-and-evaluation"]], "C. Justifying your chosen methodology": [[90, "c-justifying-your-chosen-methodology"]], "C. Organizing and synthesizing the literature": [[90, "c-organizing-and-synthesizing-the-literature"]], "C. Practical Applications of Digital Signatures": [[78, "c-practical-applications-of-digital-signatures"]], "C. Secure Mobile Applications": [[78, "c-secure-mobile-applications"]], "C. Seeking feedback": [[90, "c-seeking-feedback"]], "C. Using SSH for Git and GitHub Operations": [[77, "c-using-ssh-for-git-and-github-operations"]], "C4: Colossal Clean Crawled Corpus": [[118, "c4-colossal-clean-crawled-corpus"]], "CLIP": [[10, "clip"]], "CLIP applications": [[10, "clip-applications"]], "CLIP image encoders": [[10, "clip-image-encoders"]], "CLIP prompt engineering: CLIPDraw": [[10, "clip-prompt-engineering-clipdraw"]], "CLIP prompt engineering: VQGAN-CLIP": [[10, "clip-prompt-engineering-vqgan-clip"]], "CLIP text encoders": [[10, "clip-text-encoders"]], "CLIP: technical details": [[10, "clip-technical-details"]], "Capabilities and Applications": [[54, "capabilities-and-applications"]], "Capabilities of LLMs": [[99, "capabilities-of-llms"]], "Capability vs. Alignment": [[93, "capability-vs-alignment"]], "Capitalization": [[147, "capitalization"]], "Caption Conditioning": [[11, "caption-conditioning"], [11, "id1"]], "Carry on regardless": [[175, "carry-on-regardless"]], "Case Studies Across Domains": [[51, "case-studies-across-domains"]], "Case Studies and Best Practices": [[172, "case-studies-and-best-practices"]], "Categorical Embeddings": [[127, "categorical-embeddings"]], "Categories of Pretrained Language Models": [[100, "categories-of-pretrained-language-models"]], "Categories of Software Requirements": [[166, "categories-of-software-requirements"]], "Causal Masked Language Modeling": [[100, "causal-masked-language-modeling"]], "Central Banks": [[14, "central-banks"]], "Chain of Thought (CoT)": [[54, "chain-of-thought-cot"]], "Chain-of-thought prompting": [[58, "chain-of-thought-prompting"]], "Chairpersons": [[24, "chairpersons"]], "Challenges": [[42, "challenges"]], "Challenges and Achievements": [[54, "challenges-and-achievements"]], "Challenges and Considerations": [[54, "challenges-and-considerations"]], "Challenges and Ethical Considerations": [[13, "challenges-and-ethical-considerations"]], "Challenges and Future Prospects in Advanced LLM Training": [[54, "challenges-and-future-prospects-in-advanced-llm-training"]], "Challenges and Limitations": [[54, "challenges-and-limitations"], [110, "challenges-and-limitations"]], "Challenges and Methods in Customizing LLMs": [[58, "challenges-and-methods-in-customizing-llms"]], "Challenges and Solutions": [[54, "challenges-and-solutions"]], "Challenges and Solutions in AI Problem-Solving": [[55, "challenges-and-solutions-in-ai-problem-solving"]], "Challenges in Adaptation": [[54, "challenges-in-adaptation"]], "Challenges in Collecting Data": [[94, "challenges-in-collecting-data"]], "Challenges in Conversational AI": [[92, "challenges-in-conversational-ai"]], "Challenges in Machine Learning Systems": [[72, "challenges-in-machine-learning-systems"]], "Challenges in Scaling": [[172, "challenges-in-scaling"]], "Challenges in Sentiment Analysis": [[135, "challenges-in-sentiment-analysis"]], "Challenges of scaling LLM applications": [[56, "challenges-of-scaling-llm-applications"]], "Changing two files at once": [[177, "changing-two-files-at-once"]], "Character Tokenization": [[103, "character-tokenization"]], "Character n-grams": [[125, "character-n-grams"]], "Characteristics of a Good Software Engineer": [[164, "characteristics-of-a-good-software-engineer"]], "Check and label predictions": [[20, "check-and-label-predictions"]], "Checking Baseline with AutoML": [[30, "checking-baseline-with-automl"]], "Choosing a Research Topic": [[90, "choosing-a-research-topic"]], "Classifier-Free Guidance": [[11, "classifier-free-guidance"]], "Cleaning and standardizing the data": [[56, "cleaning-and-standardizing-the-data"]], "Cleaning up after a branch": [[181, "cleaning-up-after-a-branch"]], "Cleaning your directory": [[182, "cleaning-your-directory"]], "Clustering": [[139, "clustering"]], "Clustering Algorithms": [[149, "clustering-algorithms"]], "Co-occurrence matrix": [[126, "co-occurrence-matrix"]], "Code Generation and Automation": [[50, "code-generation-and-automation"]], "Cognitive and Reasoning Limitations": [[50, "cognitive-and-reasoning-limitations"]], "Collaboration": [[75, "collaboration"]], "Collaborations:": [[86, "collaborations"]], "Collocations": [[144, "collocations"]], "Colossal Clean Crawled Corpus": [[118, "colossal-clean-crawled-corpus"]], "Combining Lexicon-Based Methods with Machine Learning": [[138, "combining-lexicon-based-methods-with-machine-learning"]], "Commit logs": [[175, "commit-logs"]], "Commit the resolved file": [[178, "commit-the-resolved-file"]], "Commit with a built-in-add": [[175, "commit-with-a-built-in-add"]], "Common Crawl": [[118, "common-crawl"], [122, "common-crawl"]], "Comparative Analysis": [[53, "comparative-analysis"]], "Compare distributions by rate decisions": [[27, "compare-distributions-by-rate-decisions"]], "Compare number of records": [[25, "compare-number-of-records"]], "Comparison": [[11, "comparison"], [77, "comparison"]], "Comparison of Methods": [[53, "comparison-of-methods"]], "Comparison of Project Templating Tools": [[70, "comparison-of-project-templating-tools"]], "Comparison to Related Models": [[96, "comparison-to-related-models"]], "Comparison with CountVectorizer": [[159, "comparison-with-countvectorizer"]], "Components of Conversational AI": [[92, "components-of-conversational-ai"]], "Computational and Financial Costs": [[50, "computational-and-financial-costs"]], "Compute Scores": [[108, "compute-scores"]], "Computing Coherence Scores": [[150, "computing-coherence-scores"]], "Computing Pair Scores": [[109, "computing-pair-scores"]], "Conceptual Foundation": [[54, "conceptual-foundation"]], "Concluding Remarks": [[57, "concluding-remarks"]], "Conclusion": [[3, "conclusion"], [9, "conclusion"], [11, "conclusion"], [47, "conclusion"], [52, "conclusion"], [53, "conclusion"], [54, "conclusion"], [55, "conclusion"], [58, "conclusion"], [62, "conclusion"], [64, "conclusion"], [68, "conclusion"], [73, "conclusion"], [75, "conclusion"], [77, "conclusion"], [80, "conclusion"], [81, "conclusion"], [82, "conclusion"], [83, "conclusion"], [86, "conclusion"], [89, "conclusion"], [90, "conclusion"], [94, "conclusion"], [95, "conclusion"], [107, "conclusion"], [116, "conclusion"], [117, "conclusion"], [147, "conclusion"], [155, "conclusion"], [156, "conclusion"], [157, "conclusion"], [159, "conclusion"], [172, "conclusion"]], "Conclusion and Alternative Thinking": [[170, "conclusion-and-alternative-thinking"]], "Conclusion and Considerations": [[46, "conclusion-and-considerations"]], "Conclusion and Future Directions": [[13, "conclusion-and-future-directions"]], "Conducting a Literature Review": [[90, "conducting-a-literature-review"]], "Configuration Management and Infrastructure as Code (IaC):": [[66, "configuration-management-and-infrastructure-as-code-iac"], [161, "configuration-management-and-infrastructure-as-code-iac"]], "Configuration frameworks:": [[67, "configuration-frameworks"]], "Configuring Git with your editor": [[175, "configuring-git-with-your-editor"]], "Configuring Git with your name and email": [[174, "configuring-git-with-your-name-and-email"]], "Conflicted reverts": [[176, "conflicted-reverts"]], "Conflicting commits": [[178, "conflicting-commits"]], "Conjugation (\ud65c\uc6a9)": [[141, "conjugation"]], "Cons": [[116, "cons"]], "Constituency Parsing": [[145, "constituency-parsing"]], "Constraints of RNNs, LSTMs, and GRUs": [[50, "constraints-of-rnns-lstms-and-grus"]], "Containerization": [[63, "containerization"]], "Containerization and Orchestration:": [[66, "containerization-and-orchestration"], [161, "containerization-and-orchestration"]], "Contents": [[37, "contents"], [110, "contents"]], "Contextualized Word Embeddings": [[100, "contextualized-word-embeddings"]], "Continuous Bag of Words (CBOW)": [[129, "continuous-bag-of-words-cbow"]], "Continuous Delivery and Automation Pipelines": [[72, "continuous-delivery-and-automation-pipelines"]], "Continuous Integration and Continuous Delivery (CI/CD):": [[66, "continuous-integration-and-continuous-delivery-ci-cd"], [161, "continuous-integration-and-continuous-delivery-ci-cd"]], "Continuous Integration and Deployment (CI/CD)": [[75, "continuous-integration-and-deployment-ci-cd"]], "Continuous Integration and Test-Driven Development": [[172, "continuous-integration-and-test-driven-development"]], "Contrasting with Traditional Fine-Tuning Approaches": [[51, "contrasting-with-traditional-fine-tuning-approaches"]], "Contrastive pre-training": [[10, "contrastive-pre-training"]], "Controlling Attributes": [[9, "controlling-attributes"]], "Conversational AI and Chatbots": [[92, "conversational-ai-and-chatbots"]], "Convolutional Neural Networks (CNN)": [[139, "convolutional-neural-networks-cnn"]], "Core Components of Docker": [[62, "core-components-of-docker"]], "Core Concepts": [[51, "core-concepts"]], "Core Concepts of BentoML": [[74, "core-concepts-of-bentoml"]], "Core Concepts of Transformer Architecture": [[53, "core-concepts-of-transformer-architecture"]], "Corpora": [[131, "corpora"], [131, "id1"]], "Corpora Sources": [[122, "corpora-sources"]], "Corpus and transform": [[153, "corpus-and-transform"]], "Corpus-Specific Lexicons": [[138, "corpus-specific-lexicons"]], "Correcting mistakes": [[175, "correcting-mistakes"]], "Correlated Topic Model (CTM)": [[152, "correlated-topic-model-ctm"]], "Correlation": [[26, "correlation"], [32, "correlation"]], "Correlation between Taylor rule and actual rates": [[26, "correlation-between-taylor-rule-and-actual-rates"]], "Corrupted Span Length": [[118, "corrupted-span-length"]], "Corruption Rates": [[118, "corruption-rates"]], "Cosine Similarity": [[149, "cosine-similarity"]], "Cost Management": [[164, "cost-management"]], "Course Content": [[38, "course-content"]], "Course Description": [[48, "course-description"], [71, "course-description"], [162, "course-description"]], "Course Description:": [[88, "course-description"]], "Course Objectives": [[38, "course-objectives"]], "Course Outline": [[48, "course-outline"], [162, "course-outline"]], "Courses": [[2, null]], "Covering your tracks": [[176, "covering-your-tracks"]], "Crawling the MD&A Section from the Financial Statement": [[124, "crawling-the-md-a-section-from-the-financial-statement"]], "Create Training Data Set": [[27, "create-training-data-set"]], "Create Training Datasets": [[28, "create-training-datasets"]], "Create a Dockerfile": [[62, "create-a-dockerfile"]], "Create a Volume": [[62, "create-a-volume"]], "Create a docker-compose.yml File": [[62, "create-a-docker-compose-yml-file"]], "Create and Run a Container": [[62, "create-and-run-a-container"]], "Creating a POS Tagger": [[145, "creating-a-pos-tagger"]], "Creating a Template": [[70, "creating-a-template"]], "Creating a Tokenizer": [[112, "creating-a-tokenizer"], [113, "creating-a-tokenizer"]], "Creating a repository": [[177, "creating-a-repository"]], "Creating the vector database": [[56, "creating-the-vector-database"]], "Creative Writing and Artistic Generation": [[50, "creative-writing-and-artistic-generation"]], "Credits": [[187, "credits"]], "Cross validating datasets": [[17, "cross-validating-datasets"]], "Cross validation of esg_topics dataset": [[18, "cross-validation-of-esg-topics-dataset"]], "Cross-lingual Benchmarks": [[116, "cross-lingual-benchmarks"]], "Cross-validate esg_polarity_kr dataset": [[17, "cross-validate-esg-polarity-kr-dataset"]], "Cross-validate esg_valid_topics_kr dataset": [[17, "cross-validate-esg-valid-topics-kr-dataset"]], "Crowdworker labeling functions": [[21, "crowdworker-labeling-functions"]], "Current Adoption of PEFT": [[53, "current-adoption-of-peft"]], "Current Challenges": [[54, "current-challenges"]], "D. AI and Machine Learning in Cybersecurity": [[78, "d-ai-and-machine-learning-in-cybersecurity"]], "D. Financial Services": [[78, "d-financial-services"]], "D. Handling challenges": [[90, "d-handling-challenges"]], "D. Identifying gaps and opportunities": [[90, "d-identifying-gaps-and-opportunities"]], "D. SSH Signing": [[77, "d-ssh-signing"]], "DALL\u00b7E 1": [[9, "dalle-1"]], "DALL\u00b7E 1 Architecture": [[9, "dalle-1-architecture"]], "DALL\u00b7E 1 Charateristics": [[9, "dalle-1-charateristics"]], "DALL\u00b7E 1 Results": [[9, "dalle-1-results"]], "DALL\u00b7E 2": [[6, "dalle-2"], [10, "dalle-2"]], "DALL\u00b7E 2 technical details": [[10, "dalle-2-technical-details"]], "DALL\u00b7E 2 technical details: decoders": [[10, "dalle-2-technical-details-decoders"]], "DALL\u00b7E 2 technical details: encoders": [[10, "dalle-2-technical-details-encoders"]], "DALL\u00b7E 2 technical details: the prior": [[10, "dalle-2-technical-details-the-prior"]], "DALL\u00b7E 2 technical details: training": [[10, "dalle-2-technical-details-training"]], "DALL\u00b7E 2/unCLIP": [[10, "dalle-2-unclip"]], "Data Analytics Methods": [[42, "data-analytics-methods"]], "Data Description": [[96, "data-description"]], "Data Dumps": [[122, "data-dumps"]], "Data Instances": [[95, "data-instances"]], "Data Integration and Sharing": [[39, "data-integration-and-sharing"]], "Data Management and Infrastructures": [[39, "data-management-and-infrastructures"]], "Data Processing": [[151, "data-processing"]], "Data Quality and Provenance": [[39, "data-quality-and-provenance"]], "Data Quantity and Ground Truth": [[39, "data-quantity-and-ground-truth"]], "Data Science for Economics and Finance": [[38, "data-science-for-economics-and-finance"]], "Data Science in Economics": [[41, "data-science-in-economics"]], "Data Security and Privacy Concerns": [[53, "data-security-and-privacy-concerns"]], "Data science steps for ML": [[72, "data-science-steps-for-ml"]], "Dataset Construction": [[96, "dataset-construction"]], "Dataset Preparation": [[102, "dataset-preparation"], [108, "dataset-preparation"], [109, "dataset-preparation"]], "Datasets": [[94, "datasets"], [123, "datasets"]], "Dealing with ambiguity": [[131, "dealing-with-ambiguity"]], "Deciphering Monetary Policy Board Minutes with Text Mining": [[121, "deciphering-monetary-policy-board-minutes-with-text-mining"]], "Decoder": [[9, "decoder"], [117, "decoder"]], "Decoding": [[102, "decoding"]], "Decoding and Search Strategies": [[98, "decoding-and-search-strategies"]], "Deconstructing Attention": [[114, "deconstructing-attention"]], "Deep Learning Techniques": [[139, "deep-learning-techniques"]], "Deep Learning for NLP": [[97, "deep-learning-for-nlp"]], "DeepLabCut": [[7, "deeplabcut"]], "DeepLabCut-Live!": [[7, "deeplabcut-live"]], "Defining the Model": [[112, "defining-the-model"], [113, "defining-the-model"]], "Definition and Overview": [[51, "definition-and-overview"], [54, "definition-and-overview"]], "Delimiter-focused attention patterns": [[115, "delimiter-focused-attention-patterns"]], "Dependency Parsing": [[145, "dependency-parsing"]], "Deploy a Voice-Based Chatbot with BentoML, LangChain, and Gradio": [[73, "deploy-a-voice-based-chatbot-with-bentoml-langchain-and-gradio"]], "Deploy to BentoCloud": [[73, "deploy-to-bentocloud"]], "Deployment": [[74, "deployment"]], "Deployment Guides with BentoML": [[74, "deployment-guides-with-bentoml"]], "Deployment and Inference for LLMs": [[75, "deployment-and-inference-for-llms"]], "Description": [[38, "description"]], "Designing the application for scalability": [[56, "designing-the-application-for-scalability"]], "DetectGPT": [[85, "detectgpt"]], "DetectGPT: Zero-shot Machine-Generated Text Detection with Random Perturbations": [[85, "detectgpt-zero-shot-machine-generated-text-detection-with-random-perturbations"]], "DevOps": [[66, "devops"], [161, "devops"]], "DevOps Tools": [[66, "devops-tools"], [161, "devops-tools"]], "DevOps versus MLOps": [[72, "devops-versus-mlops"]], "DevSecOps": [[64, "devsecops"]], "Developing a Research Methodology": [[90, "developing-a-research-methodology"]], "Differences between pass and passage": [[80, "differences-between-pass-and-passage"]], "Different LLM Fine-Tuning Techniques": [[47, "different-llm-fine-tuning-techniques"]], "Different ways of collaborating": [[179, "different-ways-of-collaborating"]], "Difficulty of Korean Tokenization": [[141, "difficulty-of-korean-tokenization"]], "Diffusion model": [[10, "diffusion-model"]], "Dimensionality Reduction": [[139, "dimensionality-reduction"], [149, "dimensionality-reduction"]], "Direct Confirmation Measure": [[148, "direct-confirmation-measure"]], "Disadvantages of Copier:": [[70, "disadvantages-of-copier"]], "Disagreement among Lexicons": [[138, "disagreement-among-lexicons"]], "Disambiguating entities and terms": [[56, "disambiguating-entities-and-terms"]], "Discrete Spaces": [[9, "discrete-spaces"]], "Displaying Text in this Tutorial": [[174, "displaying-text-in-this-tutorial"]], "Distinctive Features of AutoGen": [[43, "distinctive-features-of-autogen"]], "Distributed VCS in teams with conflicts": [[178, "distributed-vcs-in-teams-with-conflicts"]], "Distributed versus centralised": [[186, "distributed-versus-centralised"]], "Distribution of chunks": [[25, "distribution-of-chunks"]], "Distribution of corpus": [[25, "distribution-of-corpus"]], "Distribution of sectons": [[25, "distribution-of-sectons"]], "Distribution of sentences": [[25, "distribution-of-sentences"]], "Distributional Semantics": [[157, "distributional-semantics"]], "Distributional Similarity": [[158, "distributional-similarity"]], "Doc2Vec": [[155, "doc2vec"]], "Docker": [[62, "docker"], [74, "docker"]], "Docker Compose": [[62, "docker-compose"]], "Docker Containers": [[62, "docker-containers"]], "Docker Engine": [[62, "docker-engine"]], "Docker Images": [[62, "docker-images"]], "Docker Registry": [[62, "docker-registry"]], "Docker Volumes": [[62, "docker-volumes"]], "Dockerfile": [[62, "dockerfile"]], "Document Clustering": [[149, "document-clustering"]], "Document Embeddings": [[155, "document-embeddings"]], "Documents in the Model and out of the Model": [[153, "documents-in-the-model-and-out-of-the-model"]], "Domain Specificity and Personalization": [[50, "domain-specificity-and-personalization"]], "Dot Product as Similarity": [[158, "dot-product-as-similarity"]], "Dotfiles": [[67, "dotfiles"]], "Dotfiles in a GitOps workflow": [[67, "dotfiles-in-a-gitops-workflow"]], "Dotfiles managers:": [[67, "dotfiles-managers"]], "Download and Extract Company Disclosure from DART": [[124, "download-and-extract-company-disclosure-from-dart"]], "Download the latest release:": [[1, "download-the-latest-release"]], "Download the repository:": [[1, "download-the-repository"]], "Drawing Multiple Objects": [[9, "drawing-multiple-objects"]], "Dynamic Nature": [[164, "dynamic-nature"]], "Dynamic Programming": [[146, "dynamic-programming"]], "Dynamic Thresholding": [[11, "dynamic-thresholding"]], "Dynamic Topic Models (DTM)": [[152, "dynamic-topic-models-dtm"]], "E. Healthcare": [[78, "e-healthcare"]], "E. Privacy-Preserving Technologies": [[78, "e-privacy-preserving-technologies"]], "EDA on Numerical Data": [[26, "eda-on-numerical-data"], [27, "eda-on-numerical-data"]], "EDA on Sentiment Data": [[33, "eda-on-sentiment-data"]], "EDA on Sentiments: Correlation": [[32, "eda-on-sentiments-correlation"]], "EDA on numerical data": [[26, "id1"], [27, "id1"], [28, "eda-on-numerical-data"]], "ELECTRA": [[100, "electra"]], "ESG Ratings": [[19, "esg-ratings"]], "Editing directly on GitHub": [[178, "editing-directly-on-github"]], "Educational Platforms": [[50, "educational-platforms"]], "Effective FED Rate": [[24, "effective-fed-rate"]], "Eliminating duplicate or redundant information": [[56, "eliminating-duplicate-or-redundant-information"]], "Embedding Layers vs. Dense Layers": [[127, "embedding-layers-vs-dense-layers"]], "Embedding the query and retrieved context": [[56, "embedding-the-query-and-retrieved-context"]], "Emergent abilities of large language models": [[99, "emergent-abilities-of-large-language-models"]], "Encoder": [[117, "encoder"]], "Encoder-Decoder Framework": [[50, "encoder-decoder-framework"]], "Encoder-Decoder Transformer Model": [[118, "encoder-decoder-transformer-model"]], "Encoding": [[102, "encoding"]], "Encoding Words": [[109, "encoding-words"]], "Encoding and Decoding": [[102, "encoding-and-decoding"]], "End-to-end MLOps Solutions": [[72, "end-to-end-mlops-solutions"]], "English Classification Tasks (GLUE, SuperGLUE)": [[116, "english-classification-tasks-glue-superglue"]], "English Generation Tasks (XSum, TweetQA, DROP)": [[116, "english-generation-tasks-xsum-tweetqa-drop"]], "Enhanced LLM Inferences": [[43, "enhanced-llm-inferences"]], "Ensuring factuality of the data": [[56, "ensuring-factuality-of-the-data"]], "Estimating Bigram or N-gram Probabilities using Maximum Likelihood Estimation (MLE)": [[133, "estimating-bigram-or-n-gram-probabilities-using-maximum-likelihood-estimation-mle"]], "Estimating Joint Probabilities of Word Sequences": [[133, "estimating-joint-probabilities-of-word-sequences"]], "Estimating Probabilities from Counts": [[133, "estimating-probabilities-from-counts"]], "Estimating Subword Occurrence Probabilities": [[107, "estimating-subword-occurrence-probabilities"]], "Ethical Issues in NLP": [[131, "ethical-issues-in-nlp"]], "Ethical and Societal Concerns": [[50, "ethical-and-societal-concerns"]], "Ethical and Technical Challenges": [[54, "ethical-and-technical-challenges"]], "Evaluating Language Models": [[133, "evaluating-language-models"]], "Evaluating Topics": [[148, "evaluating-topics"]], "Evaluating individual parts of the application": [[56, "evaluating-individual-parts-of-the-application"]], "Evaluation": [[129, "evaluation"], [129, "id5"]], "Evaluation of Compositions": [[146, "evaluation-of-compositions"]], "Everybody Dance Now": [[7, "everybody-dance-now"]], "Evolution": [[54, "evolution"]], "Evolution into Language Modeling": [[50, "evolution-into-language-modeling"]], "Example": [[133, "example"]], "Example 1: Part-of-Speech Tagging with eKoNLPy": [[142, "example-1-part-of-speech-tagging-with-ekonlpy"]], "Example 2: Adding Words to Dictionary": [[142, "example-2-adding-words-to-dictionary"]], "Example 3: Sentence Segmentation with KSS": [[142, "example-3-sentence-segmentation-with-kss"]], "Example Exercise": [[174, "example-exercise"]], "Example Python Code for AutoGen Agent": [[44, "example-python-code-for-autogen-agent"]], "Example of PEFT model inference using \ud83e\udd17 Accelerate\u2019s Big Model Inferencing capabilities": [[52, "example-of-peft-model-inference-using-accelerates-big-model-inferencing-capabilities"]], "Example of PEFT model training using \ud83e\udd17 Accelerate\u2019s DeepSpeed integration": [[52, "example-of-peft-model-training-using-accelerates-deepspeed-integration"]], "Examples": [[153, "examples"]], "Examples of MLE": [[133, "examples-of-mle"]], "Executing Multi-Agent Conversations": [[43, "executing-multi-agent-conversations"]], "Experimenting with different configurations": [[56, "experimenting-with-different-configurations"]], "Experiments on Synthetic Noise": [[116, "experiments-on-synthetic-noise"]], "Explaining BERT\u2019s attention patterns": [[115, "explaining-berts-attention-patterns"]], "Exploratory Data Analysis (EDA)": [[137, "exploratory-data-analysis-eda"]], "Exploring Public Templates": [[70, "exploring-public-templates"]], "FLAME: Free-form Language-based Motion Synthesis & Editing": [[7, "flame-free-form-language-based-motion-synthesis-editing"]], "FOMC contents": [[37, "fomc-contents"]], "Fast Forwards": [[184, "fast-forwards"]], "Fast Robotic Pencil Drawing": [[8, "fast-robotic-pencil-drawing"]], "Fast.ai": [[74, "fast-ai"]], "FastText": [[125, "fasttext"], [155, "fasttext"]], "Feature Comparison": [[70, "feature-comparison"]], "Feature Engineering": [[137, "feature-engineering"], [137, "id1"], [139, "feature-engineering"]], "Feature Learning in Deep Learning Models": [[139, "feature-learning-in-deep-learning-models"]], "Fetch the labeled dataset from the labelstudio server": [[21, "fetch-the-labeled-dataset-from-the-labelstudio-server"]], "Few-shot learning:": [[101, "few-shot-learning"]], "Filter out data without code info": [[16, "filter-out-data-without-code-info"]], "Filter out invalid data": [[15, "filter-out-invalid-data"], [22, "filter-out-invalid-data"]], "Filter out invalid topics": [[15, "filter-out-invalid-topics"]], "Final Project": [[48, "final-project"]], "Financial Services and Risk Management": [[50, "financial-services-and-risk-management"]], "Find out what is on a branch": [[181, "find-out-what-is-on-a-branch"]], "Finding Corporate Codes": [[124, "finding-corporate-codes"]], "Finding the Best Pair": [[109, "finding-the-best-pair"]], "Fine-Tuning": [[60, "fine-tuning"]], "Fine-Tuning LLMs with Hugging Face AutoTrain": [[46, "fine-tuning-llms-with-hugging-face-autotrain"]], "Fine-Tuning Methods": [[118, "fine-tuning-methods"]], "Fine-tuning": [[114, "fine-tuning"]], "Fine-tuning as a Transfer Learning Strategy": [[50, "fine-tuning-as-a-transfer-learning-strategy"]], "Finetuning": [[110, "finetuning"]], "Finetuning of PLMs": [[100, "finetuning-of-plms"]], "Firm-Level Political Risk: Measurement and Effects": [[120, "firm-level-political-risk-measurement-and-effects"]], "First Iteration": [[107, "first-iteration"]], "Forking a repository on GitHub": [[179, "forking-a-repository-on-github"]], "Form a team": [[178, "form-a-team"]], "Format": [[125, "format"]], "Formatting the Data": [[112, "formatting-the-data"], [113, "formatting-the-data"]], "Foundation Models: An Extension or Subset?": [[50, "foundation-models-an-extension-or-subset"]], "Framework Overview": [[43, "framework-overview"]], "Frameworks Supported by BentoML": [[74, "frameworks-supported-by-bentoml"]], "Frameworks for Scaling Agile": [[172, "frameworks-for-scaling-agile"]], "From Pork to Policy": [[121, "from-pork-to-policy"]], "Functioning of PRMs": [[54, "functioning-of-prms"]], "Fundamentals of Q-Learning": [[54, "fundamentals-of-q-learning"]], "Future Prospects": [[54, "future-prospects"]], "Future of Agile Methodologies": [[172, "future-of-agile-methodologies"]], "Future of Conversational AI": [[92, "future-of-conversational-ai"]], "GATO: A Generalist Agent": [[117, "gato-a-generalist-agent"]], "GLIDE": [[10, "glide"]], "GLIDE finetuning": [[10, "glide-finetuning"]], "GLIDE technical details": [[10, "glide-technical-details"]], "GNU Privacy Guard (GPG)": [[77, "gnu-privacy-guard-gpg"]], "GPT Family": [[100, "gpt-family"]], "GPT-4": [[86, "gpt-4"]], "GPT-4 Overview:": [[86, "gpt-4-overview"]], "GPT-4 System Card": [[86, "gpt-4-system-card"]], "GPT-4 Technical Report": [[86, "gpt-4-technical-report"]], "GPT-4-assisted Safety Research:": [[86, "gpt-4-assisted-safety-research"]], "GUANACO": [[84, "guanaco"]], "General Concept": [[132, "general-concept"]], "General Dictionaries": [[138, "general-dictionaries"]], "Generating Diverse and Natural 3D Human Motions from Text": [[7, "generating-diverse-and-natural-3d-human-motions-from-text"]], "Generating Passwords": [[80, "generating-passwords"]], "Generating a Project from a Template": [[70, "generating-a-project-from-a-template"]], "Generating a response using the LLM": [[56, "generating-a-response-using-the-llm"]], "Generating segment variants": [[146, "generating-segment-variants"]], "Generation": [[131, "generation"]], "Generation Problems": [[56, "generation-problems"]], "Generative AI Infrastructure Stack": [[60, "generative-ai-infrastructure-stack"]], "Generative Language Models": [[87, "generative-language-models"]], "Genesis of Natural Language Processing": [[50, "genesis-of-natural-language-processing"]], "Geometric Mean": [[148, "geometric-mean"]], "Get comparable performance to full finetuning by adapting LLMs to downstream tasks using consumer hardware": [[52, "get-comparable-performance-to-full-finetuning-by-adapting-llms-to-downstream-tasks-using-consumer-hardware"]], "Getting Started": [[153, "getting-started"]], "Getting Started with AutoTrain": [[46, "getting-started-with-autotrain"]], "Getting Started with Containerd": [[61, "getting-started-with-containerd"]], "Getting Started with PEFT": [[52, "getting-started-with-peft"]], "Getting from US Treasury Site as xml": [[24, "getting-from-us-treasury-site-as-xml"]], "Getting started": [[175, "getting-started"]], "Git != GitHub": [[174, "git-github"]], "Git Solo Workflow": [[175, "git-solo-workflow"]], "Git concepts": [[180, "git-concepts"]], "Git hunks": [[182, "git-hunks"]], "Git log": [[175, "git-log"]], "Git will not by default commit your new file": [[177, "git-will-not-by-default-commit-your-new-file"]], "GitHub Workflow": [[69, "github-workflow"]], "GitHub as a social network": [[178, "github-as-a-social-network"]], "GitHub authentication for Google Colaboratory": [[177, "github-authentication-for-google-colaboratory"]], "GitHub private repositories": [[177, "github-private-repositories"]], "GitOps": [[65, "gitops"], [160, "gitops"]], "GitOps Tools": [[65, "gitops-tools"], [160, "gitops-tools"]], "GitOps vs. DevOps": [[65, "gitops-vs-devops"], [160, "gitops-vs-devops"]], "Github\u2019s Fork & Pull Workflow": [[68, "githubs-fork-pull-workflow"]], "Giving permission": [[178, "giving-permission"]], "GloVe": [[126, "glove"], [155, "glove"]], "GloVe vs word2vec": [[126, "glove-vs-word2vec"]], "Goals of NLP": [[131, "goals-of-nlp"]], "Goals of Tokenization": [[147, "goals-of-tokenization"]], "Google Cloud Run": [[74, "google-cloud-run"]], "Google\u2019s Vertex AI": [[53, "googles-vertex-ai"]], "Grab changes from a branch": [[181, "grab-changes-from-a-branch"]], "Grading": [[48, "grading"], [71, "grading"], [162, "grading"]], "Grading:": [[88, "grading"]], "Gradio UI": [[73, "gradio-ui"]], "Graph of Thoughts (GoT)": [[54, "graph-of-thoughts-got"]], "Graph of Thoughts and Chain of Thought in Large Language Models (LLMs)": [[54, "graph-of-thoughts-and-chain-of-thought-in-large-language-models-llms"]], "Greedy Search": [[98, "greedy-search"]], "Groundtruth Signal for LLMs": [[54, "groundtruth-signal-for-llms"]], "H2O": [[74, "h2o"]], "Handling Negations and Modifiers": [[138, "handling-negations-and-modifiers"]], "Hannanum": [[142, "hannanum"]], "Harvard General Inquirer": [[138, "harvard-general-inquirer"]], "Hash Codes": [[175, "hash-codes"]], "Hashing Vectorizer": [[144, "hashing-vectorizer"]], "Healthcare Analytics and Prediction": [[50, "healthcare-analytics-and-prediction"]], "Hidden Technical Debt in Machine Learning Systems": [[72, "hidden-technical-debt-in-machine-learning-systems"]], "Hierarchical softmax": [[129, "hierarchical-softmax"]], "High Dimensionality in N-grams": [[144, "high-dimensionality-in-n-grams"]], "High level differences between SentencePiece and other tokenizers": [[106, "high-level-differences-between-sentencepiece-and-other-tokenizers"]], "High-Quality vs. Low-Quality Data": [[94, "high-quality-vs-low-quality-data"]], "Highlighting Applications in NLP and Transformer Models": [[51, "highlighting-applications-in-nlp-and-transformer-models"]], "Home-made SSH servers": [[186, "home-made-ssh-servers"]], "Hosting Servers": [[186, "hosting-servers"]], "Hosting a local server": [[186, "hosting-a-local-server"]], "How DevOps works": [[66, "how-devops-works"], [161, "how-devops-works"]], "How GitOps works": [[65, "how-gitops-works"], [160, "how-gitops-works"]], "How Imagen Works: A Bird\u2019s-Eye View": [[11, "how-imagen-works-a-birds-eye-view"]], "How Imagen Works: A Deep Dive": [[11, "how-imagen-works-a-deep-dive"]], "How Q-Learning Works": [[54, "how-q-learning-works"]], "How SAM works: Promptable segmentation": [[89, "how-sam-works-promptable-segmentation"]], "How Tokens Are Used": [[116, "how-tokens-are-used"]], "How artists are using and confronting machine learning": [[3, "how-artists-are-using-and-confronting-machine-learning"]], "How do we Represent Words to Capture Word Similarities?": [[157, "how-do-we-represent-words-to-capture-word-similarities"]], "How do we implement this attention mechanism?": [[117, "how-do-we-implement-this-attention-mechanism"]], "How do we use version control?": [[174, "how-do-we-use-version-control"]], "How does it work?": [[154, "how-does-it-work"]], "How many different words are there in English?": [[140, "how-many-different-words-are-there-in-english"]], "How to Spot Machine-Written Texts": [[91, "how-to-spot-machine-written-texts"]], "How to create a container image": [[61, "how-to-create-a-container-image"]], "How to generate n-grams using NLTK": [[133, "how-to-generate-n-grams-using-nltk"]], "How to implement MLOps": [[72, "how-to-implement-mlops"]], "How to input images into a transformer?": [[117, "how-to-input-images-into-a-transformer"]], "Huge Language Models and Stupid Backoff": [[134, "huge-language-models-and-stupid-backoff"]], "Hugging Face \ud83e\udd17": [[53, "hugging-face"]], "Hunks": [[182, "hunks"]], "I. Introduction": [[8, "i-introduction"], [78, "i-introduction"]], "I. Introduction to Large Language Models (LLMs)": [[56, "i-introduction-to-large-language-models-llms"]], "I. Introduction to PEFT": [[51, "i-introduction-to-peft"]], "I. Setup": [[142, "i-setup"]], "IBM\u2019s Watson: Winning at Jeopardy and Beyond": [[131, "ibms-watson-winning-at-jeopardy-and-beyond"]], "II. Authentication": [[78, "ii-authentication"]], "II. Edge Detection in Robotic Drawing Systems": [[8, "ii-edge-detection-in-robotic-drawing-systems"]], "II. Foundational Concepts": [[51, "ii-foundational-concepts"]], "II. Strategies for Enhanced Performance": [[56, "ii-strategies-for-enhanced-performance"]], "II. eKoNLPy": [[142, "ii-ekonlpy"]], "III. Data Preparation": [[56, "iii-data-preparation"]], "III. Encryption": [[78, "iii-encryption"]], "III. KSS (Korean Sentence Splitter)": [[142, "iii-kss-korean-sentence-splitter"]], "III. Semantic Segmentation and Object Detection Models": [[8, "iii-semantic-segmentation-and-object-detection-models"]], "III. Techniques and Methods in PEFT": [[51, "iii-techniques-and-methods-in-peft"]], "INT8 training of large models in Colab using PEFT LoRA and bits_and_bytes": [[52, "int8-training-of-large-models-in-colab-using-peft-lora-and-bits-and-bytes"]], "IV. Building the RAG Pipeline": [[56, "iv-building-the-rag-pipeline"]], "IV. Practical Applications of PEFT": [[51, "iv-practical-applications-of-peft"]], "IV. Signing": [[78, "iv-signing"]], "IV. Stroke Generation Techniques": [[8, "iv-stroke-generation-techniques"]], "Ignoring files": [[182, "ignoring-files"]], "Illustrative Examples of AutoGen Functionality": [[43, "illustrative-examples-of-autogen-functionality"]], "Image GPT": [[6, "image-gpt"]], "Image Generator": [[11, "image-generator"]], "Image Generator: Network Architecture": [[11, "image-generator-network-architecture"]], "Image Super-Resolution": [[11, "image-super-resolution"]], "Image encoder": [[89, "image-encoder"]], "Imagen": [[11, "imagen"]], "Implementation in LLMs": [[54, "implementation-in-llms"]], "Implementing Tokenization in Python": [[105, "implementing-tokenization-in-python"]], "Implementing a Simple MLOps Pipeline": [[81, "implementing-a-simple-mlops-pipeline"]], "Implementing the Research": [[90, "implementing-the-research"]], "Implications and Potential of Q-Star": [[55, "implications-and-potential-of-q-star"]], "Implications for AI and Machine Learning": [[51, "implications-for-ai-and-machine-learning"]], "Import data to labelstudio": [[22, "import-data-to-labelstudio"]], "Importance in Machine Learning and AI": [[51, "importance-in-machine-learning-and-ai"]], "Importance in PEFT": [[53, "importance-in-peft"]], "Importance in Word Representation": [[157, "importance-in-word-representation"]], "Importance of Corpus and Datasets": [[123, "importance-of-corpus-and-datasets"]], "Importance of Data Quality": [[53, "importance-of-data-quality"]], "Importance of DevSecOps": [[64, "importance-of-devsecops"]], "Importance of Ongoing Optimization and Improvement in RAG Systems": [[56, "importance-of-ongoing-optimization-and-improvement-in-rag-systems"]], "Importance of Software Engineering": [[164, "importance-of-software-engineering"]], "Improved Performance:": [[86, "improved-performance"]], "Improvement over word2vec": [[126, "improvement-over-word2vec"]], "Improving classification datasets": [[18, "improving-classification-datasets"]], "Improving predictive functions": [[129, "improving-predictive-functions"]], "Incorporating Syntax and Semantics": [[138, "incorporating-syntax-and-semantics"]], "Incremental Development Benefits": [[173, "incremental-development-benefits"]], "Incremental Development Problems": [[173, "incremental-development-problems"]], "Incremental Model": [[167, "incremental-model"], [173, "incremental-model"]], "Indirect Confirmation Measure": [[148, "indirect-confirmation-measure"]], "Individual emergent tasks from papers:": [[99, "individual-emergent-tasks-from-papers"]], "Industry-Specific Applications": [[51, "industry-specific-applications"]], "Inference": [[152, "inference"], [152, "id2"]], "Inference for Unseen Documents": [[153, "inference-for-unseen-documents"]], "Inferring Contextual Details": [[9, "inferring-contextual-details"]], "Inflectional Languages": [[141, "inflectional-languages"]], "Infrastructure for Fine-Tuning LLMs": [[75, "infrastructure-for-fine-tuning-llms"]], "Initial Framework: Self-supervised Learning & RNNs": [[50, "initial-framework-self-supervised-learning-rnns"]], "Initialising the repository": [[174, "initialising-the-repository"]], "Initialization": [[80, "initialization"], [102, "initialization"]], "Initializing pass": [[80, "initializing-pass"]], "Initializing passage": [[80, "initializing-passage"]], "Input/output/hidden layer": [[129, "input-output-hidden-layer"]], "Input:": [[147, "input"]], "Install Docker Compose": [[62, "install-docker-compose"]], "Install or upgrade of ekorpkit": [[153, "install-or-upgrade-of-ekorpkit"]], "Install the extension in Google Chrome:": [[1, "install-the-extension-in-google-chrome"], [1, "id1"], [1, "id2"]], "Installation": [[43, "installation"], [62, "installation"], [70, "installation"], [80, "installation"], [115, "installation"], [124, "installation"]], "Installation from source manually": [[1, "installation-from-source-manually"]], "Installation from the Chrome Web Store": [[1, "installation-from-the-chrome-web-store"]], "Installation using GitHub releases": [[1, "installation-using-github-releases"]], "Installing age and rage": [[80, "installing-age-and-rage"]], "Installing pass": [[80, "installing-pass"]], "Installing \u2018age-plugin-yubikey\u2019": [[80, "installing-age-plugin-yubikey"]], "Instructor Tuning for Zero-Shot Prompting": [[50, "instructor-tuning-for-zero-shot-prompting"]], "Integrating AlphaGo\u2019s Principles in LLMs": [[54, "integrating-alphagos-principles-in-llms"]], "Integrating Q-Learning with Large Language Model (LLM) Training": [[54, "integrating-q-learning-with-large-language-model-llm-training"]], "Integrating with fzf": [[80, "integrating-with-fzf"]], "Integration into Existing ML Pipelines": [[51, "integration-into-existing-ml-pipelines"]], "Integration with LLMs": [[54, "integration-with-llms"]], "Interactive add": [[182, "interactive-add"]], "Internal System Data": [[122, "internal-system-data"]], "Interpretability Challenge": [[41, "interpretability-challenge"]], "Introduction": [[2, "introduction"], [3, "introduction"], [6, "introduction"], [7, "introduction"], [13, "introduction"], [40, "introduction"], [42, "introduction"], [49, "introduction"], [57, "introduction"], [61, "introduction"], [68, "introduction"], [70, "introduction"], [73, "introduction"], [75, "introduction"], [77, "introduction"], [80, "introduction"], [82, "introduction"], [84, "introduction"], [85, "introduction"], [89, "introduction"], [90, "introduction"], [92, "introduction"], [93, "introduction"], [94, "introduction"], [103, "introduction"], [107, "introduction"], [111, "introduction"], [112, "introduction"], [113, "introduction"], [123, "introduction"], [131, "introduction"], [135, "introduction"], [137, "introduction"], [148, "introduction"], [149, "introduction"], [152, "introduction"], [155, "introduction"], [156, "introduction"], [157, "introduction"], [163, "introduction"], [168, "introduction"], [170, "introduction"]], "Introduction to Agile Software Development": [[172, "introduction-to-agile-software-development"]], "Introduction to BentoML": [[74, "introduction-to-bentoml"]], "Introduction to Large Language Models": [[54, "introduction-to-large-language-models"]], "Introduction to MLOps": [[72, "introduction-to-mlops"]], "Introduction to NLP": [[130, "introduction-to-nlp"]], "Introduction to OpenDartReader": [[124, "introduction-to-opendartreader"]], "Introduction to Part-of-Speech (POS)": [[145, "introduction-to-part-of-speech-pos"]], "Introduction to RAG-based LLM applications": [[56, "introduction-to-rag-based-llm-applications"]], "Isolating Languages": [[141, "isolating-languages"]], "Isolating, Inflectional, and Agglutinative Languages": [[141, "isolating-inflectional-and-agglutinative-languages"]], "Iterative Learning and Self-Improvement": [[54, "iterative-learning-and-self-improvement"]], "Iterative Model": [[167, "iterative-model"], [173, "iterative-model"]], "Iterative Model Benefits": [[173, "iterative-model-benefits"]], "Iterative Model Problems": [[173, "iterative-model-problems"]], "Jean Tinguely\u2019s drawing machine": [[6, "jean-tinguelys-drawing-machine"]], "Key Benefits of Fine-Tuning LLMs:": [[46, "key-benefits-of-fine-tuning-llms"]], "Key Changes To the mT5 Architecture": [[116, "key-changes-to-the-mt5-architecture"]], "Key Components of AlphaGo": [[54, "key-components-of-alphago"]], "Key Components of LLMOps": [[75, "key-components-of-llmops"]], "Key Concepts": [[42, "key-concepts"]], "Key Differences": [[70, "key-differences"]], "Key Differentiators of LLM Agents**:": [[43, "key-differentiators-of-llm-agents"]], "Key Features:": [[70, "key-features"]], "Key Practices and Techniques": [[172, "key-practices-and-techniques"]], "Key Principles of DevSecOps": [[64, "key-principles-of-devsecops"]], "Key features of \u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1.\u03ac\u03b9 LectureBot:": [[1, "key-features-of-lecturebot"]], "Kkma": [[142, "kkma"]], "Komoran": [[142, "komoran"]], "Korean Part-of-Speech (POS) Tagging": [[141, "korean-part-of-speech-pos-tagging"]], "Kubernetes": [[74, "kubernetes"]], "LDA Basics": [[153, "lda-basics"]], "LDA Visualization": [[153, "lda-visualization"]], "LDA coherence": [[153, "lda-coherence"]], "LIWC: Linguistic Inquiry and Word Count": [[138, "liwc-linguistic-inquiry-and-word-count"]], "LLAMA": [[84, "llama"]], "LLM App Ecosystem": [[57, "llm-app-ecosystem"]], "LLM Application Architectures": [[58, "llm-application-architectures"]], "LLM Debugging and Monitoring": [[58, "llm-debugging-and-monitoring"]], "LLM Fine-tuning": [[47, "llm-fine-tuning"]], "LLM Ops": [[57, "llm-ops"]], "LLM Stacks": [[59, "llm-stacks"]], "LLMOps": [[75, "llmops"]], "LLMOps Landscape": [[75, "llmops-landscape"]], "Lab Exercise: Calculating PMI": [[156, "lab-exercise-calculating-pmi"]], "Lab: Crawling DART Data": [[124, "lab-crawling-dart-data"]], "Lab: Exploratory Data Analysis (EDA)": [[95, "lab-exploratory-data-analysis-eda"]], "Lab: Finetuining a MLM": [[111, "lab-finetuining-a-mlm"]], "Lab: Korean Text Processing": [[142, "lab-korean-text-processing"]], "Lab: Lexicon-based Sentiment Analysis": [[136, "lab-lexicon-based-sentiment-analysis"]], "Lab: ML-based Sentiment Classification": [[137, "lab-ml-based-sentiment-classification"]], "Lab: Pretraining LMs - CLM": [[112, "lab-pretraining-lms-clm"]], "Lab: Pretraining LMs - MLM": [[113, "lab-pretraining-lms-mlm"]], "Lab: Tokenization and Pre-processing": [[143, "lab-tokenization-and-pre-processing"]], "Lab: Tomotopy": [[153, "lab-tomotopy"]], "Lab: Topic Coherence": [[150, "lab-topic-coherence"]], "Lab: Topic Modeling": [[151, "lab-topic-modeling"]], "Lab: Training Tokenizers": [[104, "lab-training-tokenizers"]], "Lab: Word Similarity": [[156, "lab-word-similarity"]], "Labeling": [[60, "labeling"]], "Language Models": [[100, "language-models"], [132, "language-models"]], "Large Guidance Weight Samplers": [[11, "large-guidance-weight-samplers"]], "Large Language & Foundational Models": [[60, "large-language-foundational-models"]], "Large Language Models": [[48, "large-language-models"], [99, "large-language-models"]], "Large Language Models?": [[50, "large-language-models"]], "Latent Dirichlet Allocation (LDA)": [[152, "latent-dirichlet-allocation-lda"]], "Layout for GitHub pages": [[183, "layout-for-github-pages"]], "Learning Goals": [[48, "learning-goals"], [162, "learning-goals"]], "Learning Objectives": [[71, "learning-objectives"]], "Learning Objectives:": [[88, "learning-objectives"]], "Learning Outcomes": [[38, "learning-outcomes"]], "LectureBot for \u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1.\u03ac\u03b9": [[1, "lecturebot-for"]], "Legal Issues in Web Crawling": [[122, "legal-issues-in-web-crawling"]], "Lexical Semantics": [[157, "lexical-semantics"]], "Lexicon-Based Methods": [[138, "lexicon-based-methods"]], "Lightweight mask decoder": [[89, "lightweight-mask-decoder"]], "Limitations & Challenges of Large Language Models": [[50, "limitations-challenges-of-large-language-models"]], "Limitations of Traditional Models": [[41, "limitations-of-traditional-models"]], "Limitations of base LLMs": [[56, "limitations-of-base-llms"]], "Limitations of the Bag of Words Model": [[154, "limitations-of-the-bag-of-words-model"]], "Linguistic (Grammatical) Classification": [[141, "linguistic-grammatical-classification"]], "Linguistic Knowledge": [[140, "linguistic-knowledge"]], "List Containers": [[62, "list-containers"]], "List Images": [[62, "list-images"]], "Load Calendar": [[24, "load-calendar"]], "Load Economic Indices": [[24, "load-economic-indices"]], "Load FOMC Corpus": [[31, "load-fomc-corpus"]], "Load FOMC class": [[24, "load-fomc-class"], [25, "load-fomc-class"]], "Load FOMC corpus": [[25, "load-fomc-corpus"]], "Load Market Data": [[24, "load-market-data"]], "Load a corpus": [[16, "load-a-corpus"]], "Load a dataset": [[153, "load-a-dataset"]], "Load a feature set": [[30, "load-a-feature-set"], [36, "load-a-feature-set"]], "Load company code info": [[15, "load-company-code-info"], [16, "load-company-code-info"], [22, "load-company-code-info"]], "Load data": [[20, "load-data"], [22, "load-data"]], "Load data to predict": [[15, "load-data-to-predict"]], "Load datasets": [[32, "load-datasets"], [33, "load-datasets"]], "Load preprocessed data": [[26, "load-preprocessed-data"], [27, "load-preprocessed-data"], [28, "load-preprocessed-data"]], "Load the mC4 dataset": [[95, "load-the-mc4-dataset"]], "Loading the Data": [[150, "loading-the-data"]], "Loading the Dataset": [[56, "loading-the-dataset"], [137, "loading-the-dataset"]], "Loading the Model": [[113, "loading-the-model"]], "Loading the Pretrained Model and Tokenizer": [[111, "loading-the-pretrained-model-and-tokenizer"]], "Loss Computation": [[108, "loss-computation"]], "Losses": [[89, "losses"]], "Low-Rank Adaptation and Sparse Fine-Tuning": [[51, "low-rank-adaptation-and-sparse-fine-tuning"]], "MARGE": [[96, "marge"]], "MDM: Human Motion Diffusion Model": [[7, "mdm-human-motion-diffusion-model"]], "MLOps Level 0": [[72, "mlops-level-0"]], "MLOps Level 1": [[72, "mlops-level-1"]], "MLOps Level 2": [[72, "mlops-level-2"]], "MLOps Project": [[76, "mlops-project"]], "MMLU (51 tasks; see Chinchilla paper for results):": [[99, "mmlu-51-tasks-see-chinchilla-paper-for-results"]], "MPQA Subjectivity Lexicon": [[138, "mpqa-subjectivity-lexicon"]], "Machine Learning Systems Design": [[71, "machine-learning-systems-design"]], "Machine Learning and Statistical Methods": [[140, "machine-learning-and-statistical-methods"]], "Machine Learning-Based Methods": [[139, "machine-learning-based-methods"]], "Main idea": [[129, "main-idea"]], "Managing Complexity": [[164, "managing-complexity"]], "Markdown": [[174, "markdown"]], "Masked Language Modeling": [[100, "masked-language-modeling"]], "Maximum Matching Algorithm": [[146, "maximum-matching-algorithm"]], "Mean": [[148, "mean"]], "Measuring Economic Policy Uncertainty": [[120, "measuring-economic-policy-uncertainty"]], "Mecab": [[142, "mecab"]], "Mechanism and Adaptation": [[54, "mechanism-and-adaptation"]], "Median": [[148, "median"]], "Meet the Camelids: A Family of LLMs": [[84, "meet-the-camelids-a-family-of-llms"]], "Merge Operations": [[102, "merge-operations"]], "Merge commits": [[178, "merge-commits"]], "Merge with fed rate data": [[32, "merge-with-fed-rate-data"]], "Merging branches": [[181, "merging-branches"]], "Merging the Best Pair": [[109, "merging-the-best-pair"]], "Method 1: Language Model Based Approaches": [[91, "method-1-language-model-based-approaches"]], "Method 2: Statistical Methods": [[91, "method-2-statistical-methods"]], "Method 3: Curvature-Based Approaches": [[91, "method-3-curvature-based-approaches"]], "Method 4: Human Evaluation": [[91, "method-4-human-evaluation"]], "Methodologies": [[13, "methodologies"], [99, "methodologies"]], "Methods for Detecting Machine-Written Texts": [[91, "methods-for-detecting-machine-written-texts"]], "Methods of Tokenization": [[103, "methods-of-tokenization"]], "Migrating from pass to passage": [[80, "migrating-from-pass-to-passage"]], "Missing Values": [[27, "missing-values"], [28, "missing-values"]], "Model": [[105, "model"]], "Model Hallucination": [[58, "model-hallucination"]], "Model Initialization": [[108, "model-initialization"]], "Model Monitoring and Maintenance": [[75, "model-monitoring-and-maintenance"]], "Model Optimization": [[108, "model-optimization"]], "Model Safety": [[60, "model-safety"]], "Model Save and Load": [[153, "model-save-and-load"]], "Model Supervision / AI Observability": [[60, "model-supervision-ai-observability"]], "Modifying the Model for Sentiment Analysis": [[111, "modifying-the-model-for-sentiment-analysis"]], "Monetary Policy Shocks": [[35, "monetary-policy-shocks"]], "Monitoring and Logging:": [[66, "monitoring-and-logging"], [161, "monitoring-and-logging"]], "Morphemes and Morphs": [[140, "morphemes-and-morphs"]], "Morphemes: Stems and Affixes": [[140, "morphemes-stems-and-affixes"]], "Morphological Analysis (Part of Speech Tagging)": [[141, "morphological-analysis-part-of-speech-tagging"]], "Morphological Analysis in Korean": [[141, "morphological-analysis-in-korean"]], "Motion Capture and Motion Synthesis": [[7, "motion-capture-and-motion-synthesis"]], "MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model": [[7, "motiondiffuse-text-driven-human-motion-generation-with-diffusion-model"]], "Motivation": [[151, "motivation"]], "Multi-Task Learning": [[118, "multi-task-learning"]], "Multi-head Attention": [[114, "multi-head-attention"]], "Multi-head attention": [[117, "multi-head-attention"]], "Multilingual datasets": [[94, "multilingual-datasets"]], "Multimodal Machine Learning": [[117, "multimodal-machine-learning"]], "N-Grams and Probability Estimation": [[133, "n-grams-and-probability-estimation"]], "N-gram Language Models": [[133, "n-gram-language-models"]], "N-gram Models and Markov Assumption": [[133, "n-gram-models-and-markov-assumption"]], "N-grams for Tokenization": [[144, "n-grams-for-tokenization"]], "N-grams in Tokenization": [[144, "n-grams-in-tokenization"]], "N-grams, Dimensionality, and Managing Vocabulary": [[144, "n-grams-dimensionality-and-managing-vocabulary"]], "NLP Application - Chatbot": [[131, "nlp-application-chatbot"]], "NLP Application - Machine Translation": [[131, "nlp-application-machine-translation"]], "NLP Application - OpenAI CODEX": [[131, "nlp-application-openai-codex"]], "NLP Application - OpenAI GPT-3": [[131, "nlp-application-openai-gpt-3"]], "NLP Application - Text to Image Generation": [[131, "nlp-application-text-to-image-generation"]], "NLP Application - Virtual Assistants": [[131, "nlp-application-virtual-assistants"]], "NLP Applications": [[119, "nlp-applications"]], "NLP in Low-Resource Languages": [[131, "nlp-in-low-resource-languages"]], "NLP in the Korean Language": [[131, "nlp-in-the-korean-language"]], "NLP \u201cBias\u201d is statistical bias": [[138, "nlp-bias-is-statistical-bias"]], "NMF Applications": [[151, "nmf-applications"]], "NMF using scikit-learn": [[151, "nmf-using-scikit-learn"]], "Naive Recursive Algorithm": [[146, "naive-recursive-algorithm"]], "National Institute of Korean Language\u2019s Everyone\u2019s Corpus": [[122, "national-institute-of-korean-languages-everyones-corpus"]], "Necessity and Benefits": [[42, "necessity-and-benefits"]], "Need for SDLC": [[167, "need-for-sdlc"]], "Negative sampling": [[129, "negative-sampling"], [129, "id6"]], "Neural Language Models": [[128, "neural-language-models"]], "Neural Nets for NLP": [[131, "neural-nets-for-nlp"]], "Neuro-Symbolic AI and Q-Star": [[55, "neuro-symbolic-ai-and-q-star"]], "New Data Sources": [[41, "new-data-sources"]], "Next": [[66, "next"], [67, "next"], [69, "next"], [75, "next"], [81, "next"], [92, "next"], [94, "next"], [99, "next"], [103, "next"], [117, "next"], [119, "next"], [123, "next"], [127, "next"], [132, "next"], [135, "next"], [140, "next"], [149, "next"], [155, "next"], [161, "next"]], "Next Contents": [[45, "next-contents"], [47, "next-contents"], [51, "next-contents"], [54, "next-contents"]], "Next-word attention pattern": [[115, "next-word-attention-pattern"]], "Noise-contrastive estimation": [[129, "noise-contrastive-estimation"]], "Non-Functional Requirements Categories:": [[166, "non-functional-requirements-categories"]], "Non-negative Matrix Factorization (NMF)": [[151, "non-negative-matrix-factorization-nmf"], [152, "non-negative-matrix-factorization-nmf"]], "Nonconflicted commits to the same file": [[178, "nonconflicted-commits-to-the-same-file"]], "Nonconflicting changes": [[178, "nonconflicting-changes"]], "Normalization": [[105, "normalization"]], "Normalized Pointwise Mutual Information": [[148, "normalized-pointwise-mutual-information"]], "Nothing to see here": [[175, "nothing-to-see-here"]], "Numbers": [[147, "numbers"]], "Objective": [[76, "objective"]], "Objectives": [[173, "objectives"]], "Obtaining a colleague\u2019s code": [[178, "obtaining-a-colleagues-code"]], "Obtaining the Vocabulary": [[107, "obtaining-the-vocabulary"]], "Offline Batch Serving": [[74, "offline-batch-serving"]], "Offline Data": [[122, "offline-data"]], "One-shot learning:": [[101, "one-shot-learning"]], "Open Korean Text (Okt)": [[142, "open-korean-text-okt"]], "OpenAI": [[53, "openai"]], "Optimizing for the best quality responses": [[56, "optimizing-for-the-best-quality-responses"]], "Orchestration Layer / Application Frameworks": [[60, "orchestration-layer-application-frameworks"]], "Other Approaches to Enhancing LLM Performance": [[47, "other-approaches-to-enhancing-llm-performance"]], "Other Korean Tokenizers": [[142, "other-korean-tokenizers"]], "Other Tasks": [[131, "other-tasks"]], "Our first commit": [[175, "our-first-commit"]], "Out-of-Vocabulary Words (OOV) for N-grams": [[144, "out-of-vocabulary-words-oov-for-n-grams"]], "Outcomes": [[76, "outcomes"]], "Outline": [[173, "outline"]], "Output:": [[147, "output"]], "Overfitting and Underfitting Challenges": [[51, "overfitting-and-underfitting-challenges"]], "Overview": [[86, "overview"], [110, "overview"], [140, "overview"], [152, "overview"], [152, "id1"], [172, "overview"]], "Overview of Agile Project Management": [[172, "overview-of-agile-project-management"]], "Overview of AlphaGo": [[54, "overview-of-alphago"]], "Overview of PEFT Techniques": [[51, "overview-of-peft-techniques"]], "Overview of PRMs": [[54, "overview-of-prms"]], "PEFT + \ud83e\udd17 Accelerate": [[52, "peft-accelerate"]], "PEFT Techniques Overview": [[53, "peft-techniques-overview"]], "PEFT for LLMs": [[53, "peft-for-llms"]], "PEFT in Conjunction with Emerging AI Technologies": [[51, "peft-in-conjunction-with-emerging-ai-technologies"]], "PEFT in HuggingFace Libraries": [[52, "peft-in-huggingface-libraries"]], "PEFT\u2019s Impact on Large-Scale Models": [[51, "pefts-impact-on-large-scale-models"]], "PMI": [[148, "pmi"]], "PMI and Smoothing": [[158, "pmi-and-smoothing"]], "Paradigms of Software Development": [[165, "paradigms-of-software-development"]], "Parameter Efficient Tuning of Diffusion Models": [[52, "parameter-efficient-tuning-of-diffusion-models"]], "Parameter Efficient Tuning of LLMs for RLHF components such as Ranker and Policy": [[52, "parameter-efficient-tuning-of-llms-for-rlhf-components-such-as-ranker-and-policy"]], "Parameter-Efficient Fine-Tuning (PEFT)": [[51, "parameter-efficient-fine-tuning-peft"]], "Part 1: Understanding Tokenization": [[143, "part-1-understanding-tokenization"]], "Part 2: Different Types of Tokenization with Examples": [[143, "part-2-different-types-of-tokenization-with-examples"]], "Part 3: Pre-processing Steps in NLP": [[143, "part-3-pre-processing-steps-in-nlp"]], "Part 4: Tokenization in Different Languages with Examples": [[143, "part-4-tokenization-in-different-languages-with-examples"]], "Part-of-Speech Tagging and Parsing": [[145, "part-of-speech-tagging-and-parsing"]], "Performing sentiment analysis using AFINN": [[136, "performing-sentiment-analysis-using-afinn"]], "Performing sentiment analysis using TextBlob": [[136, "performing-sentiment-analysis-using-textblob"]], "Performing sentiment analysis using VADER": [[136, "performing-sentiment-analysis-using-vader"]], "Permutation Language Modeling": [[100, "permutation-language-modeling"]], "Perplexity": [[133, "perplexity"]], "Perplexity Sampling": [[96, "perplexity-sampling"]], "Perplexity\u2019s Relation to Entropy": [[133, "perplexitys-relation-to-entropy"]], "Phase-Functioned Neural Networks for Character Control": [[7, "phase-functioned-neural-networks-for-character-control"]], "Physics-based Human Motion Estimation and Synthesis from Videos": [[7, "physics-based-human-motion-estimation-and-synthesis-from-videos"]], "Pining Topics using Word Priors": [[153, "pining-topics-using-word-priors"], [153, "id2"]], "Plan-Driven vs Agile Processes": [[173, "plan-driven-vs-agile-processes"]], "Playground Tools": [[57, "playground-tools"]], "Playing with GitHub": [[177, "playing-with-github"]], "Plot impulse response functions": [[35, "plot-impulse-response-functions"]], "Plot rate decision count": [[26, "plot-rate-decision-count"]], "Plot the results and compare to the economical uncertainty / systemic risk periods": [[33, "plot-the-results-and-compare-to-the-economical-uncertainty-systemic-risk-periods"]], "Plot the sentiment scores": [[33, "plot-the-sentiment-scores"]], "Pointwise Mutual Information": [[144, "pointwise-mutual-information"]], "Pointwise Mutual Information (PMI)": [[156, "pointwise-mutual-information-pmi"], [158, "pointwise-mutual-information-pmi"]], "Policy Neural Network Adaptation": [[54, "policy-neural-network-adaptation"]], "Popular NLP Datasets": [[123, "popular-nlp-datasets"]], "Popular Traditional Machine Learning Algorithms": [[139, "popular-traditional-machine-learning-algorithms"]], "Positive Pointwise Mutual Information (PPMI)": [[158, "positive-pointwise-mutual-information-ppmi"]], "Post-processing": [[105, "post-processing"]], "Postprocess FOMC corpus": [[25, "postprocess-fomc-corpus"]], "Postprocess metadata": [[25, "postprocess-metadata"]], "Postprocessing": [[105, "postprocessing"]], "Potential and Implications": [[54, "potential-and-implications"]], "Practical Issues in N-gram Models": [[133, "practical-issues-in-n-gram-models"]], "Practical example - Team up!": [[179, "practical-example-team-up"]], "Practice": [[156, "practice"]], "Pre-processing: The Art of Text Analysis": [[147, "pre-processing-the-art-of-text-analysis"]], "Pre-tokenization": [[105, "pre-tokenization"], [109, "pre-tokenization"]], "Pre-training": [[114, "pre-training"]], "Pre-training and Fine-tuning": [[114, "pre-training-and-fine-tuning"]], "Predetermined Number of Unique Tokens": [[106, "predetermined-number-of-unique-tokens"]], "Predict polarities": [[15, "predict-polarities"], [22, "predict-polarities"]], "Predict sentiments and aggregate scores with a pipeline": [[31, "predict-sentiments-and-aggregate-scores-with-a-pipeline"]], "Predict sentiments of sentences": [[31, "predict-sentiments-of-sentences"]], "Predict sentiments with the LM sentiment analyser": [[31, "predict-sentiments-with-the-lm-sentiment-analyser"]], "Predict sentiments with the T5": [[31, "predict-sentiments-with-the-t5"]], "Predict sentiments with the finbert": [[31, "predict-sentiments-with-the-finbert"]], "Predicting ESG Categories and Polarities": [[20, "predicting-esg-categories-and-polarities"]], "Predicting Sentiments of FOMC Corpus": [[31, "predicting-sentiments-of-fomc-corpus"]], "Predicting categories": [[15, "predicting-categories"], [20, "predicting-categories"], [22, "predicting-categories"]], "Predicting polarities": [[20, "predicting-polarities"]], "Predicting the next decisions with tones": [[36, "predicting-the-next-decisions-with-tones"]], "Preparation": [[124, "preparation"]], "Prepare an environment": [[16, "prepare-an-environment"]], "Prepare esg_polarity_kr dataset": [[17, "prepare-esg-polarity-kr-dataset"]], "Prepare esg_topics_improved dataset": [[17, "prepare-esg-topics-improved-dataset"]], "Preparing Numerical Data": [[24, "preparing-numerical-data"]], "Preparing Textual Data": [[25, "preparing-textual-data"]], "Preparing active learning data": [[22, "preparing-active-learning-data"]], "Preparing additional polarity data": [[15, "preparing-additional-polarity-data"]], "Preparing esg_polarity_kr dataset": [[23, "preparing-esg-polarity-kr-dataset"]], "Preparing esg_topics dataset": [[18, "preparing-esg-topics-dataset"]], "Preparing esg_topics_improved dataset": [[23, "preparing-esg-topics-improved-dataset"]], "Preparing invalid topic data": [[15, "preparing-invalid-topic-data"]], "Preparing the Dataset": [[111, "preparing-the-dataset"], [112, "preparing-the-dataset"], [113, "preparing-the-dataset"]], "Preparing the Environment": [[111, "preparing-the-environment"], [112, "preparing-the-environment"], [113, "preparing-the-environment"]], "Preparing training datasets": [[21, "preparing-training-datasets"]], "Prerequisites": [[38, "prerequisites"], [71, "prerequisites"]], "Prerequisites:": [[82, "prerequisites"], [88, "prerequisites"]], "Prerequisites: Before Diving into Simple MLOps Pipeline": [[81, "prerequisites-before-diving-into-simple-mlops-pipeline"]], "Pretrained Language Models": [[100, "pretrained-language-models"], [100, "id1"]], "Pretraining": [[110, "pretraining"]], "Probabilistic Latent Semantic Analysis (pLSA)": [[152, "probabilistic-latent-semantic-analysis-plsa"]], "Problems with the Transformer architecture": [[117, "problems-with-the-transformer-architecture"]], "Process-Supervised Reward Models (PRMs) in Large Language Models": [[54, "process-supervised-reward-models-prms-in-large-language-models"]], "Program vs. Software": [[165, "program-vs-software"]], "Programming and documents": [[174, "programming-and-documents"]], "Project Overview": [[76, "project-overview"]], "Project Proposal": [[5, "project-proposal"], [169, "project-proposal"]], "Project Proposal Template": [[171, "project-proposal-template"]], "Project Templating Tools": [[70, "project-templating-tools"]], "Project Title:": [[171, "project-title"]], "Projecting the Future of PEFT in AI and ML": [[51, "projecting-the-future-of-peft-in-ai-and-ml"]], "Prompt Chaining": [[58, "prompt-chaining"]], "Prompt Engineering": [[58, "prompt-engineering"], [98, "prompt-engineering"], [101, "prompt-engineering"]], "Prompt Engineering and In-Context Learning": [[50, "prompt-engineering-and-in-context-learning"]], "Prompt encoder": [[89, "prompt-encoder"]], "Prompt-based and Adapter-based Methods": [[51, "prompt-based-and-adapter-based-methods"]], "Prompting on LLMs": [[101, "prompting-on-llms"]], "Prompts and Queries": [[57, "prompts-and-queries"]], "Proposal Components": [[168, "proposal-components"]], "Proprietary datasets": [[94, "proprietary-datasets"]], "Pros": [[116, "pros"]], "Prototype Model": [[167, "prototype-model"]], "Public datasets": [[94, "public-datasets"]], "Publishing branches": [[181, "publishing-branches"]], "Pull Request": [[179, "pull-request"]], "Pull an Image": [[62, "pull-an-image"]], "Punctuation": [[147, "punctuation"]], "Putting Everything Together": [[148, "putting-everything-together"]], "Putting them together in a pipeline": [[15, "putting-them-together-in-a-pipeline"]], "PyTorch": [[74, "pytorch"]], "Python Code Examples": [[159, "python-code-examples"]], "Q-Learning": [[54, "q-learning"]], "Q-Learning in AI": [[54, "q-learning-in-ai"]], "Q-Star (Q*)": [[55, "q-star-q"]], "Quality Management": [[164, "quality-management"]], "Question Answering Systems": [[50, "question-answering-systems"]], "Question Answering on SQuAD 1.1": [[131, "question-answering-on-squad-1-1"]], "Quick Start": [[124, "quick-start"]], "Quick Transformer Review": [[53, "quick-transformer-review"]], "RAD Model": [[167, "rad-model"]], "Rationale and Advantages": [[42, "rationale-and-advantages"]], "Real-World Applications of Large Language Models": [[50, "real-world-applications-of-large-language-models"]], "Real-world applications of NLP": [[131, "real-world-applications-of-nlp"]], "Rebase vs merge": [[184, "rebase-vs-merge"]], "Rebasing pros and cons": [[184, "rebasing-pros-and-cons"]], "Recap: What is Software Engineering?": [[173, "recap-what-is-software-engineering"]], "Recurrent Neural Networks (RNN)": [[139, "recurrent-neural-networks-rnn"]], "Reference Books": [[130, "reference-books"]], "References": [[0, "references"], [3, "references"], [7, "references"], [8, "references"], [11, "references"], [37, "references"], [57, "references"], [58, "references"], [60, "references"], [68, "references"], [74, "references"], [84, "references"], [86, "references"], [89, "references"], [100, "references"], [115, "references"], [116, "references"], [118, "references"], [134, "references"], [146, "references"]], "References and Further Reading": [[54, "references-and-further-reading"]], "Referencing remotes": [[186, "referencing-remotes"]], "Referencs": [[91, "referencs"]], "Referring to changes with HEAD and ~": [[176, "referring-to-changes-with-head-and"]], "Reinforcement Learning from Human Feedback (RLHF)": [[47, "reinforcement-learning-from-human-feedback-rlhf"]], "Reinforcement Learning with Human Feedback (RLHF)": [[93, "reinforcement-learning-with-human-feedback-rlhf"]], "Rejected push": [[178, "rejected-push"]], "Related Areas of NLP": [[131, "related-areas-of-nlp"]], "Relationship between containerd and Kubernetes": [[61, "relationship-between-containerd-and-kubernetes"]], "Remotes": [[177, "remotes"]], "Remove a Container": [[62, "remove-a-container"]], "Remove an Image": [[62, "remove-an-image"]], "Reparameterization-Based Methods": [[53, "reparameterization-based-methods"]], "Repeating the Process": [[109, "repeating-the-process"]], "Requirement Engineering Process": [[166, "requirement-engineering-process"]], "Requirements": [[76, "requirements"]], "Requirements Engineering (RE)": [[166, "requirements-engineering-re"]], "Research Part I": [[120, "research-part-i"]], "Research Part II": [[121, "research-part-ii"]], "Research, Infrastructure & Limitations:": [[86, "research-infrastructure-limitations"]], "Resetting the working area": [[176, "resetting-the-working-area"]], "Resolving ambiguity": [[89, "resolving-ambiguity"]], "Resolving conflicts": [[178, "resolving-conflicts"]], "Resources": [[71, "resources"]], "Responsible AI Principles": [[75, "responsible-ai-principles"]], "Results": [[116, "results"]], "Results and Analysis": [[11, "results-and-analysis"]], "Retrieval Augmented Generation (RAG)": [[56, "retrieval-augmented-generation-rag"], [58, "retrieval-augmented-generation-rag"]], "Retrieval Problems": [[56, "retrieval-problems"]], "Retrieval process": [[56, "retrieval-process"]], "Retrieving Passwords": [[80, "retrieving-passwords"]], "Reverting": [[176, "reverting"]], "Review of changes": [[175, "review-of-changes"], [176, "review-of-changes"]], "Review of status": [[175, "review-of-status"]], "Rewriting history": [[176, "rewriting-history"]], "RoBERTa": [[100, "roberta"]], "Robot Drawing System": [[8, "robot-drawing-system"]], "Robust Cascaded Diffusion Models": [[11, "robust-cascaded-diffusion-models"]], "Roles and Ceremonies in Scrum": [[172, "roles-and-ceremonies-in-scrum"]], "SAM: A generalized approach to segmentation": [[89, "sam-a-generalized-approach-to-segmentation"]], "SFV: Reinforcement Learning of Physical Skills from Videos": [[7, "sfv-reinforcement-learning-of-physical-skills-from-videos"]], "SOTA Comparisons": [[118, "sota-comparisons"]], "SSH in Git and GitHub Operations": [[77, "ssh-in-git-and-github-operations"]], "SSH keys and GitHub": [[186, "ssh-keys-and-github"]], "SSH, GPG, and AGE": [[77, "ssh-gpg-and-age"]], "Safety & Alignment:": [[86, "safety-alignment"]], "Sampling": [[98, "sampling"]], "Sampling From a Trained DALL-E": [[9, "sampling-from-a-trained-dall-e"]], "Sampling Sentences from a Language Model": [[134, "sampling-sentences-from-a-language-model"]], "Save Data": [[27, "save-data"], [28, "save-data"]], "Save compute and storage even for medium and small models": [[52, "save-compute-and-storage-even-for-medium-and-small-models"]], "Saving Models as BentoML Artifacts": [[73, "saving-models-as-bentoml-artifacts"]], "Saving and Loading the Model": [[111, "saving-and-loading-the-model"], [112, "saving-and-loading-the-model"], [113, "saving-and-loading-the-model"]], "Saving and loading a model object": [[125, "saving-and-loading-a-model-object"]], "Saving the Model": [[113, "saving-the-model"]], "Saving the re-labelled dataset": [[18, "saving-the-re-labelled-dataset"]], "Scalability": [[164, "scalability"]], "Scaling": [[118, "scaling"]], "Scaling Agile Methods": [[172, "scaling-agile-methods"]], "Scaling and Computational Efficiency": [[51, "scaling-and-computational-efficiency"]], "Scikit-learn": [[74, "scikit-learn"]], "Scope": [[174, "scope"]], "Second Iteration": [[107, "second-iteration"]], "Sections": [[14, "sections"], [40, "sections"], [49, "sections"], [59, "sections"], [163, "sections"], [169, "sections"], [173, "sections"], [187, "sections"]], "Secure Shell (SSH)": [[77, "secure-shell-ssh"]], "Security Management": [[79, "security-management"]], "Security and Compliance": [[75, "security-and-compliance"]], "Segment Anything": [[89, "segment-anything"]], "Segment Anything Data Engine": [[89, "segment-anything-data-engine"]], "Segmenting 1 billion masks": [[89, "segmenting-1-billion-masks"]], "Segmenting Text into Sentences and Paragraphs": [[147, "segmenting-text-into-sentences-and-paragraphs"]], "Selective Methods": [[53, "selective-methods"]], "Self-Attention Mechanism": [[53, "self-attention-mechanism"]], "Self-Supervised Learning vs Supervised Fine-Tuning": [[47, "self-supervised-learning-vs-supervised-fine-tuning"]], "Semantic Web Technologies": [[42, "semantic-web-technologies"]], "Semiconductors, Chips, Cloud Hosting, Inference, Deployment": [[60, "semiconductors-chips-cloud-hosting-inference-deployment"]], "Sentence Tokenization": [[143, "sentence-tokenization"]], "Sentence Tokenization in Korean": [[141, "sentence-tokenization-in-korean"]], "SentencePiece": [[104, "sentencepiece"]], "SentencePiece Tokenizer": [[106, "sentencepiece-tokenizer"]], "SentiWordNet": [[138, "sentiwordnet"]], "Sentiment Ambiguity and Context": [[138, "sentiment-ambiguity-and-context"]], "Sentiment Analysis": [[135, "sentiment-analysis"]], "Serve the App Locally": [[73, "serve-the-app-locally"]], "Server Setup & Usage": [[82, "server-setup-usage"]], "Serving the application in a highly scalable and available manner": [[56, "serving-the-application-in-a-highly-scalable-and-available-manner"]], "Setting up a Bare Metal System": [[65, "setting-up-a-bare-metal-system"], [160, "setting-up-a-bare-metal-system"]], "Setting up a GitOps workflow": [[65, "setting-up-a-gitops-workflow"], [160, "setting-up-a-gitops-workflow"]], "Setting up somewhere to work": [[174, "setting-up-somewhere-to-work"]], "Setting up the environment": [[95, "setting-up-the-environment"]], "Setup": [[136, "setup"]], "Setup with Password-Protected Key": [[80, "setup-with-password-protected-key"]], "Setup with age-plugin-yubikey": [[80, "setup-with-age-plugin-yubikey"]], "Sharing your work": [[177, "sharing-your-work"]], "Shortcomings of classical algorithms for decomposition:": [[151, "shortcomings-of-classical-algorithms-for-decomposition"]], "Shortcomings of traditional NLP pipelines": [[131, "shortcomings-of-traditional-nlp-pipelines"]], "Sidestepping the NLP pipeline": [[131, "sidestepping-the-nlp-pipeline"]], "Simple MLOps Pipeline": [[81, "simple-mlops-pipeline"]], "Simple Setup": [[80, "simple-setup"]], "Singular Value Decomposition (SVD)": [[151, "singular-value-decomposition-svd"]], "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale": [[8, "sketch-generation-with-drawing-process-guided-by-vector-flow-and-grayscale"]], "Skip-gram model": [[129, "skip-gram-model"]], "Smoothing": [[134, "smoothing"]], "Snorkel LabelModel": [[21, "snorkel-labelmodel"]], "So why are transformers so powerful?": [[117, "so-why-are-transformers-so-powerful"]], "Soft-Prompts": [[53, "soft-prompts"]], "Softmax": [[129, "softmax"]], "Software Development Life Cycle (SDLC)": [[167, "software-development-life-cycle-sdlc"]], "Software Development Life Cycle Models": [[167, "software-development-life-cycle-models"]], "Software Engineering": [[162, "software-engineering"]], "Software Engineering Proposal Guideline": [[168, "software-engineering-proposal-guideline"]], "Software Engineering?": [[164, "software-engineering"]], "Software Process Descriptions": [[173, "software-process-descriptions"]], "Software Process Models": [[165, "software-process-models"], [173, "software-process-models"], [173, "id1"]], "Software Processes": [[165, "software-processes"]], "Solo work": [[174, "solo-work"]], "Solutions and Emerging Techniques": [[58, "solutions-and-emerging-techniques"]], "Solving Manually": [[185, "solving-manually"]], "Solving automatically": [[185, "solving-automatically"]], "Some Common Pre-processing Techniques": [[147, "some-common-pre-processing-techniques"]], "Some Considerations": [[179, "some-considerations"]], "Some new content": [[177, "some-new-content"]], "Sources and Transmission of Country Risk": [[120, "sources-and-transmission-of-country-risk"]], "Sparsity": [[131, "sparsity"]], "Specialized domains": [[94, "specialized-domains"]], "Spelling variants, typos, etc.": [[140, "spelling-variants-typos-etc"]], "Spiral Model": [[167, "spiral-model"], [173, "spiral-model"]], "Spiral Model Benefits": [[173, "spiral-model-benefits"]], "Spiral Model Problems": [[173, "spiral-model-problems"]], "Spiral vs Waterfall vs Iterative Model": [[173, "spiral-vs-waterfall-vs-iterative-model"]], "Split corpus into sections": [[25, "split-corpus-into-sections"]], "Split sections into chunks": [[25, "split-sections-into-chunks"]], "Split sections into sentences": [[25, "split-sections-into-sentences"]], "Splitting Words into Characters": [[109, "splitting-words-into-characters"]], "Spotlight on Key Techniques: BitFit, LoRA, and More": [[51, "spotlight-on-key-techniques-bitfit-lora-and-more"]], "Squashing": [[184, "squashing"]], "Stage 1: Planning and Requirement Analysis": [[167, "stage-1-planning-and-requirement-analysis"]], "Stage 2: Defining Requirements": [[167, "stage-2-defining-requirements"]], "Stage 3: Designing the Software": [[167, "stage-3-designing-the-software"]], "Stage 4: Developing the Project": [[167, "stage-4-developing-the-project"]], "Stage 5: Testing": [[167, "stage-5-testing"]], "Stage 6: Deployment": [[167, "stage-6-deployment"]], "Stage 7: Maintenance": [[167, "stage-7-maintenance"]], "Staging a file to be included in the next commit": [[175, "staging-a-file-to-be-included-in-the-next-commit"]], "Staging changes": [[175, "staging-changes"]], "Standard Autoregressive Language Modeling": [[100, "standard-autoregressive-language-modeling"]], "Standard Fine-Tuning vs. PEFT": [[53, "standard-fine-tuning-vs-peft"]], "Start Services": [[62, "start-services"]], "Stashing changes": [[182, "stashing-changes"]], "Static Thresholding": [[11, "static-thresholding"]], "Static and Dynamic Data Collection": [[122, "static-and-dynamic-data-collection"]], "Static vs. Dynamic Web Pages": [[122, "static-vs-dynamic-web-pages"]], "Stemming/Lemmatizing": [[147, "stemming-lemmatizing"]], "Step 0: Prepare the data": [[129, "step-0-prepare-the-data"]], "Step 1: Define a function to create a context and a target word": [[129, "step-1-define-a-function-to-create-a-context-and-a-target-word"]], "Step 1: Indexing the words.": [[128, "step-1-indexing-the-words"]], "Step 1: Install Necessary Libraries and Set Up AutoTrain": [[46, "step-1-install-necessary-libraries-and-set-up-autotrain"]], "Step 1: Install necessary libraries": [[104, "step-1-install-necessary-libraries"]], "Step 1: Setting target and context variable": [[129, "step-1-setting-target-and-context-variable"]], "Step 2: Build the model": [[129, "step-2-build-the-model"]], "Step 2: Building the model": [[129, "step-2-building-the-model"]], "Step 2: Building the model.": [[128, "step-2-building-the-model"]], "Step 2: Load the dataset": [[104, "step-2-load-the-dataset"]], "Step 2: Prepare Dataset and Define Task": [[46, "step-2-prepare-dataset-and-define-task"]], "Step 3: Loss and optimization function": [[129, "step-3-loss-and-optimization-function"]], "Step 3: Loss and optimization function.": [[128, "step-3-loss-and-optimization-function"], [129, "id2"]], "Step 3: Prepare Your Dataset": [[46, "step-3-prepare-your-dataset"]], "Step 3: Prepare the text": [[104, "step-3-prepare-the-text"]], "Step 4: Train the tokenizers": [[104, "step-4-train-the-tokenizers"]], "Step 4: Training the model": [[129, "step-4-training-the-model"]], "Step 4: Training the model.": [[128, "step-4-training-the-model"], [129, "id3"]], "Step 4: Training with AutoTrain": [[46, "step-4-training-with-autotrain"]], "Step 5: Compare the tokenizers": [[104, "step-5-compare-the-tokenizers"]], "Step 5: Evaluation and Deployment": [[46, "step-5-evaluation-and-deployment"]], "Step-by-Step Lab: Fine-Tuning Falcon-7B on OpenAssistant": [[46, "step-by-step-lab-fine-tuning-falcon-7b-on-openassistant"]], "Steps in Software Engineering Projects": [[170, "steps-in-software-engineering-projects"], [170, "id1"]], "Stewardship and Protection": [[39, "stewardship-and-protection"]], "Stock Prices and Markov Assumption": [[133, "stock-prices-and-markov-assumption"]], "Stop Services": [[62, "stop-services"]], "Stop a Container": [[62, "stop-a-container"]], "Stopwords": [[147, "stopwords"]], "Subword Regularization in NMT": [[106, "subword-regularization-in-nmt"]], "Subword Sampling": [[107, "subword-sampling"]], "Subword Tokenization": [[103, "subword-tokenization"], [107, "subword-tokenization"]], "Subword Tokenization for Sequence Models": [[147, "subword-tokenization-for-sequence-models"]], "Subword regularization and BPE-dropout": [[106, "subword-regularization-and-bpe-dropout"]], "Summary": [[86, "summary"], [98, "summary"], [128, "summary"], [134, "summary"], [136, "summary"], [150, "summary"], [166, "summary"], [167, "summary"]], "Summary and Alternative Considerations": [[42, "summary-and-alternative-considerations"]], "Summary of Key Points": [[172, "summary-of-key-points"]], "Summary of the Lecture": [[56, "summary-of-the-lecture"]], "Super-Resolution Models": [[11, "super-resolution-models"]], "Supervised Learning": [[139, "supervised-learning"]], "Supervised and Unsupervised Methods": [[139, "supervised-and-unsupervised-methods"]], "Supported Languages": [[96, "supported-languages"]], "Supported PEFT Methods": [[52, "supported-peft-methods"]], "Surface and Deep Structure": [[140, "surface-and-deep-structure"]], "Surrounding Issues": [[99, "surrounding-issues"]], "Synchronization tools:": [[67, "synchronization-tools"]], "Synsets and Relations": [[138, "synsets-and-relations"]], "Synthesizing the Discussion": [[51, "synthesizing-the-discussion"]], "Synthetic Data": [[60, "synthetic-data"]], "T5": [[100, "t5"]], "T5: Text-To-Text Transfer Transformer": [[118, "t5-text-to-text-transfer-transformer"]], "T5: Text-to-Text Framework": [[118, "t5-text-to-text-framework"]], "TF-IDF Model": [[159, "tf-idf-model"]], "Table of Contents": [[88, "table-of-contents"], [171, "table-of-contents"]], "Tackling the Challenges: The Strategies": [[140, "tackling-the-challenges-the-strategies"]], "Tagging": [[182, "tagging"]], "Target FED Rate": [[24, "target-fed-rate"]], "Task Details": [[137, "task-details"]], "Technical Breakthroughs": [[54, "technical-breakthroughs"]], "Technical Challenges": [[39, "technical-challenges"]], "Technical highlights": [[106, "technical-highlights"]], "Techniques for Sentiment Analysis": [[135, "techniques-for-sentiment-analysis"]], "Tell git about the new file": [[177, "tell-git-about-the-new-file"]], "Telling Git about the File": [[175, "telling-git-about-the-file"]], "TensorFlow and Keras": [[74, "tensorflow-and-keras"]], "Terminology": [[58, "terminology"]], "Text Data Collection": [[122, "text-data-collection"]], "Text Data Collection Overview": [[122, "text-data-collection-overview"]], "Text Data Collection Types": [[122, "text-data-collection-types"]], "Text Encoder": [[11, "text-encoder"]], "Text Encoder: T5": [[11, "text-encoder-t5"]], "Text Generation Across Multiple Formats": [[50, "text-generation-across-multiple-formats"]], "Text Summarization": [[50, "text-summarization"]], "Text and Image: Interdisciplinary Techniques for NLP": [[131, "text-and-image-interdisciplinary-techniques-for-nlp"]], "Text length distribution": [[95, "text-length-distribution"]], "Text to Image Generation Models": [[6, "text-to-image-generation-models"]], "Text-Based Network Industries and Endogenous Product Differentiation": [[120, "text-based-network-industries-and-endogenous-product-differentiation"]], "Text-to-Image Models": [[12, "text-to-image-models"]], "Text-to-image model": [[11, "text-to-image-model"]], "TextBlob": [[136, "textblob"]], "Textbook": [[38, "textbook"], [71, "textbook"]], "Textual Analysis of FOMC contents": [[37, "textual-analysis-of-fomc-contents"]], "Textual analysis": [[119, "textual-analysis"]], "The Advent of Transformers": [[50, "the-advent-of-transformers"]], "The All-Important Data Layer": [[57, "the-all-important-data-layer"]], "The Architecture of BERT": [[114, "the-architecture-of-bert"]], "The Bad": [[140, "the-bad"]], "The ChatWrapper Utility Class": [[73, "the-chatwrapper-utility-class"]], "The Creative Partnership": [[3, "the-creative-partnership"]], "The Dataset": [[137, "the-dataset"]], "The Diffusion of Disruptive Technologies": [[121, "the-diffusion-of-disruptive-technologies"]], "The Distributional Hypothesis": [[157, "the-distributional-hypothesis"]], "The Good": [[140, "the-good"]], "The Intricacies of Tokenization": [[140, "the-intricacies-of-tokenization"]], "The Key Concept of Model Generalization": [[51, "the-key-concept-of-model-generalization"]], "The Legislative Influence Detector": [[121, "the-legislative-influence-detector"]], "The Levels of Git": [[175, "the-levels-of-git"], [178, "the-levels-of-git"]], "The Long Tail of Tokenization: Zipf\u2019s Law": [[140, "the-long-tail-of-tokenization-zipfs-law"]], "The Model": [[118, "the-model"]], "The Origin of Query and Key Vectors": [[114, "the-origin-of-query-and-key-vectors"]], "The Pros And Cons Of ByT5": [[116, "the-pros-and-cons-of-byt5"]], "The Results": [[116, "the-results"]], "The Role of Process in Software Engineering": [[173, "the-role-of-process-in-software-engineering"]], "The Role of Word Embeddings": [[50, "the-role-of-word-embeddings"]], "The Scrum Framework": [[172, "the-scrum-framework"]], "The Significance of Efficient Fine-Tuning": [[51, "the-significance-of-efficient-fine-tuning"]], "The Software Crisis": [[165, "the-software-crisis"]], "The Software Process": [[173, "the-software-process"]], "The Stages of SDLC": [[167, "the-stages-of-sdlc"]], "The State of LLMs Today": [[94, "the-state-of-llms-today"]], "The Technical Details": [[116, "the-technical-details"]], "The Ugly": [[140, "the-ugly"]], "The Zero-Shot Machine-Generated Text Detection Problem": [[85, "the-zero-shot-machine-generated-text-detection-problem"]], "The eKorpkit Corpus": [[122, "the-ekorpkit-corpus"], [131, "the-ekorpkit-corpus"]], "The gh-pages branch": [[183, "the-gh-pages-branch"]], "The levels of Git": [[180, "the-levels-of-git"]], "The problem": [[151, "the-problem"]], "The revision Graph": [[180, "the-revision-graph"]], "The staging area": [[175, "the-staging-area"]], "The struggles of unCLIP": [[10, "the-struggles-of-unclip"]], "Third Iteration": [[107, "third-iteration"]], "Three Data Must-Haves for NLP": [[94, "three-data-must-haves-for-nlp"]], "TimeSformers": [[117, "timesformers"]], "Timeline of ML Art": [[6, "timeline-of-ml-art"]], "Timestamp distribution": [[95, "timestamp-distribution"]], "Timestep Conditioning": [[11, "timestep-conditioning"]], "Timing comparison": [[151, "timing-comparison"]], "Token Examples:": [[147, "token-examples"]], "Token Extraction": [[102, "token-extraction"]], "Tokenization": [[103, "tokenization"], [108, "tokenization"], [140, "tokenization"]], "Tokenization Pipeline": [[105, "tokenization-pipeline"]], "Tokenization in French": [[143, "tokenization-in-french"]], "Tokenization in Korean": [[141, "tokenization-in-korean"], [143, "tokenization-in-korean"]], "Tokenizing Text": [[109, "tokenizing-text"]], "Tokenizing and Formatting the Data": [[111, "tokenizing-and-formatting-the-data"]], "Tools for Dotfiles Management": [[67, "tools-for-dotfiles-management"]], "Tools for Interpretability": [[41, "tools-for-interpretability"]], "Top-K Sampling": [[98, "top-k-sampling"]], "Top-p (nucleus) sampling": [[98, "top-p-nucleus-sampling"]], "Topic Coherence": [[148, "topic-coherence"]], "Topic Coherence Measures": [[148, "topic-coherence-measures"]], "Topic Modeling": [[139, "topic-modeling"], [148, "topic-modeling"], [149, "topic-modeling"]], "Topic Modeling Methodologies": [[152, "topic-modeling-methodologies"]], "Traditional Machine Learning Techniques": [[139, "traditional-machine-learning-techniques"]], "Traditional NLP Pipelines": [[131, "traditional-nlp-pipelines"]], "Train LabelModel And Generate Probabilistic Labels": [[21, "train-labelmodel-and-generate-probabilistic-labels"]], "Train an invalid classficiation model": [[17, "train-an-invalid-classficiation-model"]], "Train and evaluate esg_cv_polarity_kr dataset": [[17, "train-and-evaluate-esg-cv-polarity-kr-dataset"]], "Train and evaluate esg_cv_topics_kr dataset": [[17, "train-and-evaluate-esg-cv-topics-kr-dataset"]], "Training": [[89, "training"]], "Training Classifiers for ESG Ratings": [[23, "training-classifiers-for-esg-ratings"]], "Training FastText": [[125, "training-fasttext"]], "Training GloVe": [[126, "training-glove"]], "Training Language Models": [[110, "training-language-models"]], "Training Objectives": [[100, "training-objectives"]], "Training Tokenizers for GPT, BERT, and T5": [[104, "training-tokenizers-for-gpt-bert-and-t5"]], "Training a category classficiation model with esg_topics_improved dataset": [[23, "training-a-category-classficiation-model-with-esg-topics-improved-dataset"]], "Training a polarity classficiation model with esg_polarity_kr dataset": [[23, "training-a-polarity-classficiation-model-with-esg-polarity-kr-dataset"]], "Training an invalid topic classifier": [[15, "training-an-invalid-topic-classifier"]], "Training and Improvement Loop": [[54, "training-and-improvement-loop"]], "Training and Self-Play": [[54, "training-and-self-play"]], "Training from Raw Sentences": [[106, "training-from-raw-sentences"]], "Training further on the additional polarity data": [[15, "training-further-on-the-additional-polarity-data"]], "Training further on the additional topic data": [[15, "training-further-on-the-additional-topic-data"]], "Training the Model": [[111, "training-the-model"], [112, "training-the-model"], [113, "training-the-model"], [137, "training-the-model"]], "Tranformer Architecture": [[117, "tranformer-architecture"]], "Transfer Learning: Basics and Relevance": [[51, "transfer-learning-basics-and-relevance"]], "Transformer Architecture and PLMs": [[100, "transformer-architecture-and-plms"]], "Transformer Block Structure": [[53, "transformer-block-structure"]], "Transformer Networks": [[139, "transformer-networks"]], "Transformer in Transformer": [[117, "transformer-in-transformer"]], "Transformers": [[117, "transformers"]], "Translation": [[131, "translation"]], "Translation Services": [[50, "translation-services"]], "Transparency and Deliberation Within the FOMC": [[121, "transparency-and-deliberation-within-the-fomc"]], "Treasury Yield": [[24, "treasury-yield"]], "Triangular Matrix": [[146, "triangular-matrix"]], "Truncated SVD": [[151, "truncated-svd"]], "Two models": [[129, "two-models"]], "Types of Alternative Data": [[13, "types-of-alternative-data"]], "Types of Chatbots": [[92, "types-of-chatbots"]], "Types of Datasets": [[123, "types-of-datasets"]], "Types of Sentiment Analysis": [[135, "types-of-sentiment-analysis"]], "Types of Software Engineering Projects": [[170, "types-of-software-engineering-projects"]], "Uncertainty in the Posterior": [[9, "uncertainty-in-the-posterior"]], "Uncertainty of word boundaries": [[146, "uncertainty-of-word-boundaries"]], "Understanding": [[131, "understanding"]], "Understanding Cosine Similarity": [[148, "understanding-cosine-similarity"]], "Understanding Model Parameters and Architectures": [[51, "understanding-model-parameters-and-architectures"]], "Understanding N-grams": [[144, "understanding-n-grams"]], "Understanding Pointwise Mutual Information": [[148, "understanding-pointwise-mutual-information"]], "Understanding Q-Star (Q*)": [[55, "understanding-q-star-q"]], "Understanding texts": [[131, "understanding-texts"]], "Understanding the Basics": [[147, "understanding-the-basics"]], "Unicode Normalization": [[105, "unicode-normalization"]], "Unified Input & Output Format": [[118, "unified-input-output-format"]], "Unigram": [[104, "unigram"]], "Unigram - T5": [[104, "unigram-t5"]], "Unigram Language Model": [[107, "unigram-language-model"]], "Unigram Step-by-Step Implementation": [[108, "unigram-step-by-step-implementation"]], "Unix Password Managers": [[80, "unix-password-managers"]], "Unknown Words": [[134, "unknown-words"], [146, "unknown-words"]], "Unknown representation": [[131, "unknown-representation"]], "Unlabeled Dataset Sizes": [[118, "unlabeled-dataset-sizes"]], "Unlabeled Datasets": [[118, "unlabeled-datasets"]], "Unmodeled variables": [[131, "unmodeled-variables"]], "Unstaged changes": [[175, "unstaged-changes"]], "Unsupervised Learning Techniques": [[139, "unsupervised-learning-techniques"]], "Unsupervised Objective": [[118, "unsupervised-objective"]], "Updating Passwords": [[80, "updating-passwords"]], "Usage": [[80, "usage"], [106, "usage"], [115, "usage"]], "Usage of Copier": [[70, "usage-of-copier"]], "Usage of Language Models": [[134, "usage-of-language-models"]], "Use Cases": [[52, "use-cases"]], "Use a Volume in a Container": [[62, "use-a-volume-in-a-container"]], "Use rubrix to find potential label errors": [[18, "use-rubrix-to-find-potential-label-errors"]], "Use-Cases": [[13, "use-cases"]], "User Stories and Timeboxing": [[172, "user-stories-and-timeboxing"]], "Using AGE": [[77, "using-age"]], "Using Copier CLI": [[70, "using-copier-cli"]], "Using Copier as a Library": [[70, "using-copier-as-a-library"]], "Using FastText": [[125, "using-fasttext"]], "Using FortiClient for VPN Connectivity": [[83, "using-forticlient-for-vpn-connectivity"]], "Using GPG": [[77, "using-gpg"]], "Using GloVe": [[126, "using-glove"]], "Using SSH": [[77, "using-ssh"]], "Using SSH, GPG, and AGE: A Practical Guide": [[77, "using-ssh-gpg-and-age-a-practical-guide"]], "Using mC4 Dataset with Hugging Face Datasets Library": [[96, "using-mc4-dataset-with-hugging-face-datasets-library"]], "Using rebase to squash": [[184, "using-rebase-to-squash"]], "Using reset to rewrite history": [[176, "using-reset-to-rewrite-history"]], "Using the extension:": [[1, "using-the-extension"]], "V-Model": [[167, "v-model"]], "V-model": [[173, "v-model"]], "V-model Benefits": [[173, "v-model-benefits"]], "V-model Problems": [[173, "v-model-problems"]], "V. Challenges and Limitations": [[51, "v-challenges-and-limitations"]], "V. Conclusion": [[78, "v-conclusion"]], "V. Developing an Advanced Robotic Drawing System": [[8, "v-developing-an-advanced-robotic-drawing-system"]], "V. Scaling and Serving the Application": [[56, "v-scaling-and-serving-the-application"]], "VADER": [[136, "vader"]], "VATT: Transformers for Multimodal Self-Supervised Learning": [[117, "vatt-transformers-for-multimodal-self-supervised-learning"]], "VI. Current Trends and Future Directions": [[51, "vi-current-trends-and-future-directions"]], "VI. Evaluation and Performance Optimization": [[56, "vi-evaluation-and-performance-optimization"]], "VI. Practical Applications": [[78, "vi-practical-applications"]], "VICU\u00d1A": [[84, "vicuna"]], "VII. Conclusion": [[51, "vii-conclusion"]], "VII. Future Trends and Challenges": [[78, "vii-future-trends-and-challenges"]], "VII.Conclusion": [[56, "vii-conclusion"]], "VPN Connectivity": [[83, "vpn-connectivity"]], "VQ-VAE": [[9, "vq-vae"]], "Validating the Model": [[111, "validating-the-model"], [112, "validating-the-model"], [113, "validating-the-model"]], "Value Neural Network in LLM Context": [[54, "value-neural-network-in-llm-context"]], "Variational Autoencoders (VAE)": [[9, "variational-autoencoders-vae"]], "Vector Databases": [[60, "vector-databases"]], "Vector Representation": [[155, "vector-representation"]], "Vector Semantics": [[157, "vector-semantics"]], "Vector Similarity: Cosine": [[158, "vector-similarity-cosine"]], "Vector Space Models": [[155, "vector-space-models"]], "Version Control Systems": [[187, "version-control-systems"]], "Version Control:": [[66, "version-control"], [161, "version-control"]], "Version control systems:": [[67, "version-control-systems"]], "Virtual Assistants": [[50, "virtual-assistants"]], "Vision Transformer Architecture": [[117, "vision-transformer-architecture"]], "Vision Transformers": [[117, "vision-transformers"]], "Visualization": [[156, "visualization"]], "Visualize Features": [[29, "visualize-features"], [34, "visualize-features"], [34, "id1"]], "Visualizing Features": [[29, "visualizing-features"]], "Visualizing Internal and External Structure": [[9, "visualizing-internal-and-external-structure"]], "Visualizing Perspective and Three-Dimensionality": [[9, "visualizing-perspective-and-three-dimensionality"]], "Visualizing the Coherence Scores": [[150, "visualizing-the-coherence-scores"]], "Visualizing the embeddings": [[129, "visualizing-the-embeddings"], [129, "id4"]], "Vocabulary Initialization": [[108, "vocabulary-initialization"], [109, "vocabulary-initialization"]], "Waterfall Model": [[167, "waterfall-model"], [173, "waterfall-model"]], "Waterfall Model Drawbacks": [[173, "waterfall-model-drawbacks"]], "Waterfall Model Phases": [[173, "waterfall-model-phases"]], "Web Crawling": [[122, "web-crawling"], [122, "id1"]], "Web Crawling vs. Web Scraping": [[122, "web-crawling-vs-web-scraping"]], "What Are Large Language Models?": [[50, "what-are-large-language-models"]], "What Exactly is Tokenization?": [[140, "what-exactly-is-tokenization"]], "What Is A Token In Machine Learning?": [[116, "what-is-a-token-in-machine-learning"]], "What Is ByT5?": [[116, "what-is-byt5"]], "What are Large Language Models?": [[99, "what-are-large-language-models"]], "What are word embeddings?": [[127, "what-are-word-embeddings"]], "What can you do with NLP?": [[131, "what-can-you-do-with-nlp"]], "What does BERT actually learn?": [[115, "what-does-bert-actually-learn"]], "What does it take to understand the text?": [[131, "what-does-it-take-to-understand-the-text"]], "What is Bag of Words Model?": [[154, "what-is-bag-of-words-model"]], "What is GitOps?": [[65, "what-is-gitops"], [160, "what-is-gitops"]], "What is Morphological Analysis?": [[141, "what-is-morphological-analysis"]], "What is NLP?": [[131, "what-is-nlp"]], "What is POS Tagging?": [[145, "what-is-pos-tagging"]], "What is Reinforcement Learning?": [[93, "what-is-reinforcement-learning"]], "What is SentencePiece?": [[106, "what-is-sentencepiece"]], "What is Subword Tokenization?": [[107, "what-is-subword-tokenization"]], "What is TF-IDF?": [[159, "what-is-tf-idf"]], "What is Tokenization?": [[103, "what-is-tokenization"], [147, "what-is-tokenization"]], "What is a \u2018context\u2019?": [[158, "what-is-a-context"]], "What is fine-tuning?": [[47, "what-is-fine-tuning"]], "What is tomotopy?": [[153, "what-is-tomotopy"]], "What is version control? (Team version)": [[174, "what-is-version-control-team-version"]], "What\u2019s version control?": [[174, "whats-version-control"]], "When Words Sweat": [[121, "when-words-sweat"]], "When to use the skip-gram model and when to use CBOW?": [[129, "when-to-use-the-skip-gram-model-and-when-to-use-cbow"]], "Whitespace as a Basic Symbol": [[106, "whitespace-as-a-basic-symbol"]], "Who Uses PEFT?": [[53, "who-uses-peft"]], "Why BentoML?": [[74, "why-bentoml"]], "Why Do We Need POS Tagging?": [[145, "why-do-we-need-pos-tagging"]], "Why Large Language Models (LLMs) use Reinforcement Learning": [[93, "why-large-language-models-llms-use-reinforcement-learning"]], "Why NLP is more difficult in Korean?": [[131, "why-nlp-is-more-difficult-in-korean"]], "Why Software Engineering?": [[164, "why-software-engineering"]], "Why Subword Tokenization?": [[107, "why-subword-tokenization"]], "Why do we need language models?": [[132, "why-do-we-need-language-models"]], "Why do we need neural networks for word embeddings?": [[127, "why-do-we-need-neural-networks-for-word-embeddings"]], "Why do we need transformers?": [[117, "why-do-we-need-transformers"]], "Why does MLOps matter?": [[72, "why-does-mlops-matter"]], "Why is Imagen Better than DALL-E 2?": [[11, "why-is-imagen-better-than-dall-e-2"]], "Why is NLP hard?": [[131, "why-is-nlp-hard"]], "Why is Tokenization Important?": [[103, "why-is-tokenization-important"]], "Why should we segment words?": [[146, "why-should-we-segment-words"]], "Why study or research NLP?": [[131, "why-study-or-research-nlp"]], "Why use DeepLabCut?": [[7, "why-use-deeplabcut"]], "Why use N-grams?": [[144, "why-use-n-grams"]], "Why use version control?": [[174, "why-use-version-control"]], "Word Embeddings": [[127, "word-embeddings"], [127, "id1"], [139, "word-embeddings"], [155, "word-embeddings"]], "Word Encoding": [[108, "word-encoding"]], "Word Formation Processes": [[140, "word-formation-processes"]], "Word Segmentation": [[146, "word-segmentation"]], "Word Segmentation and Association": [[146, "word-segmentation-and-association"]], "Word Segmentation for Korean": [[146, "word-segmentation-for-korean"]], "Word Segmentation in Practice": [[146, "word-segmentation-in-practice"]], "Word Similarity": [[156, "word-similarity"], [158, "word-similarity"]], "Word Tokenization": [[103, "word-tokenization"], [143, "word-tokenization"]], "Word-Level Tasks": [[116, "word-level-tasks"]], "Word-Word Matrix": [[158, "word-word-matrix"]], "Word2Vec": [[129, "word2vec"], [155, "word2vec"]], "WordNet": [[138, "wordnet"]], "WordNet Supersenses": [[138, "wordnet-supersenses"]], "WordNet in NLP and Sentiment Analysis": [[138, "wordnet-in-nlp-and-sentiment-analysis"]], "WordPiece": [[104, "wordpiece"], [107, "wordpiece"]], "WordPiece - BERT": [[104, "wordpiece-bert"]], "WordPiece Step-by-Step Implementation": [[109, "wordpiece-step-by-step-implementation"]], "Words aren\u2019t just defined by blanks": [[140, "words-arent-just-defined-by-blanks"]], "Workflow for a Simple MLOps Pipeline Project": [[82, "workflow-for-a-simple-mlops-pipeline-project"]], "Working with multiple files": [[177, "working-with-multiple-files"]], "Working with news article samples": [[146, "working-with-news-article-samples"]], "Writing Labeling Functions": [[21, "writing-labeling-functions"]], "Writing a Thesis": [[90, "writing-a-thesis"]], "Writing the Thesis": [[90, "writing-the-thesis"]], "XGBoost and LightGBM": [[74, "xgboost-and-lightgbm"]], "XLM": [[96, "xlm"]], "XLM-R": [[96, "xlm-r"]], "XLNet": [[100, "xlnet"]], "Yaml Frontmatter": [[183, "yaml-frontmatter"]], "Zero Shot and Few Shot Learners": [[101, "zero-shot-and-few-shot-learners"]], "Zero Shot and Prompt Engineering": [[101, "zero-shot-and-prompt-engineering"]], "Zero-Shot Reasoners and Chain-of-Thought Prompting": [[101, "zero-shot-reasoners-and-chain-of-thought-prompting"]], "Zero-shot classification with CLIP": [[10, "zero-shot-classification-with-clip"]], "Zero-shot learning:": [[101, "zero-shot-learning"]], "age": [[77, "age"]], "containerd": [[61, "containerd"]], "mBART": [[96, "mbart"]], "mBERT": [[96, "mbert"]], "mC4 Dataset": [[96, "mc4-dataset"]], "mC4 Dataset and Perplexity Sampling": [[96, "mc4-dataset-and-perplexity-sampling"]], "mC4 Sampling": [[96, "mc4-sampling"]], "\u267e\ufe0f\u00a0Learning Goals": [[5, "learning-goals"], [97, "learning-goals"], [130, "learning-goals"]], "\ud83c\udfb2 Whole Game of NLP": [[97, "whole-game-of-nlp"], [130, "whole-game-of-nlp"]], "\ud83c\udfc6 Grading": [[97, "grading"], [130, "grading"]], "\ud83d\udcd2 Lecture Notes": [[97, "lecture-notes"]], "\ud83d\udcda Textbook": [[130, "textbook"]], "\ud83d\udcdc Course Description": [[5, "course-description"], [97, "course-description"], [130, "course-description"]], "\ud83d\uddd3\ufe0f\u00a0Table of Contents": [[5, "table-of-contents"], [71, "table-of-contents"], [97, "table-of-contents"], [130, "table-of-contents"]], "\ud83e\udde0 Term Project": [[5, "term-project"], [97, "term-project"], [130, "term-project"]]}, "docnames": ["about/index", "about/lecture-bot", "index", "lectures/aiart/aiart/index", "lectures/aiart/brave/index", "lectures/aiart/index", "lectures/aiart/intro/index", "lectures/aiart/motion-capture-and-synthesis/index", "lectures/aiart/robot/index", "lectures/aiart/text-to-image/dalle1", "lectures/aiart/text-to-image/dalle2", "lectures/aiart/text-to-image/imagen", "lectures/aiart/text-to-image/index", "lectures/dsecon/cb/altdata", "lectures/dsecon/cb/index", "lectures/dsecon/esg-ratings/all_in_one_pipeline", "lectures/dsecon/esg-ratings/build_news_corpus", "lectures/dsecon/esg-ratings/cross_validate_datasets", "lectures/dsecon/esg-ratings/improve_datasets", "lectures/dsecon/esg-ratings/index", "lectures/dsecon/esg-ratings/predict_esg_classes", "lectures/dsecon/esg-ratings/prepare_datasets", "lectures/dsecon/esg-ratings/prepare_datasets_for_labeling", "lectures/dsecon/esg-ratings/train_classifiers", "lectures/dsecon/fomc/01_numerical_data", "lectures/dsecon/fomc/02_textual_data", "lectures/dsecon/fomc/03_EDA_numericals1", "lectures/dsecon/fomc/03_EDA_numericals2", "lectures/dsecon/fomc/04_training_datasets", "lectures/dsecon/fomc/05_features", "lectures/dsecon/fomc/06_AutoML", "lectures/dsecon/fomc/07_predict_sentiments", "lectures/dsecon/fomc/08_EDA_sentiments1", "lectures/dsecon/fomc/08_EDA_sentiments2", "lectures/dsecon/fomc/09_visualize_features", "lectures/dsecon/fomc/10_monetary_shocks", "lectures/dsecon/fomc/11_AutoML_with_tones", "lectures/dsecon/fomc/index", "lectures/dsecon/index", "lectures/dsecon/intro/challenges", "lectures/dsecon/intro/index", "lectures/dsecon/intro/introduction", "lectures/dsecon/intro/methods", "lectures/llms/agents/autogen", "lectures/llms/agents/autoscraper", "lectures/llms/agents/index", "lectures/llms/finetune/autotrain", "lectures/llms/finetune/index", "lectures/llms/index", "lectures/llms/intro/index", "lectures/llms/intro/llms", "lectures/llms/peft/index", "lectures/llms/peft/peft-hf", "lectures/llms/peft/peft-llms", "lectures/llms/q-learning/index", "lectures/llms/q-learning/qstar", "lectures/llms/rag/index", "lectures/llms/stack/app", "lectures/llms/stack/architecture", "lectures/llms/stack/index", "lectures/llms/stack/infra", "lectures/mlops/containerization/containerd", "lectures/mlops/containerization/docker", "lectures/mlops/containerization/index", "lectures/mlops/devops/devsecops", "lectures/mlops/devops/gitops", "lectures/mlops/devops/index", "lectures/mlops/dotfiles/index", "lectures/mlops/github/fork-pull", "lectures/mlops/github/index", "lectures/mlops/github/template", "lectures/mlops/index", "lectures/mlops/intro", "lectures/mlops/llmops/bentochain", "lectures/mlops/llmops/bentoml", "lectures/mlops/llmops/index", "lectures/mlops/project", "lectures/mlops/security/age-gpg-ssh", "lectures/mlops/security/auth-enc-sign", "lectures/mlops/security/index", "lectures/mlops/security/pass", "lectures/mlops/simple-pipeline/index", "lectures/mlops/simple-pipeline/server", "lectures/mlops/simple-pipeline/vpn", "lectures/nlp_advances/gpt/camelids", "lectures/nlp_advances/gpt/detectGPT", "lectures/nlp_advances/gpt/gpt4", "lectures/nlp_advances/gpt/index", "lectures/nlp_advances/index", "lectures/nlp_advances/sam/index", "lectures/nlp_advances/thesis", "lectures/nlp_deep/chatbots/detectGPT", "lectures/nlp_deep/chatbots/index", "lectures/nlp_deep/chatbots/rlhf", "lectures/nlp_deep/datasets/index", "lectures/nlp_deep/datasets/lab-eda", "lectures/nlp_deep/datasets/mc4", "lectures/nlp_deep/index", "lectures/nlp_deep/llms/decoding", "lectures/nlp_deep/llms/index", "lectures/nlp_deep/llms/plms", "lectures/nlp_deep/llms/zeroshot", "lectures/nlp_deep/tokenization/bpe", "lectures/nlp_deep/tokenization/index", "lectures/nlp_deep/tokenization/lab-train-tokenizers", "lectures/nlp_deep/tokenization/pipeline", "lectures/nlp_deep/tokenization/sentencepiece", "lectures/nlp_deep/tokenization/subword", "lectures/nlp_deep/tokenization/unigram", "lectures/nlp_deep/tokenization/wordpiece", "lectures/nlp_deep/training/index", "lectures/nlp_deep/training/lab-finetune-mlm", "lectures/nlp_deep/training/lab-pretrain-clm", "lectures/nlp_deep/training/lab-pretrain-mlm", "lectures/nlp_deep/transformers/bert", "lectures/nlp_deep/transformers/bertviz", "lectures/nlp_deep/transformers/byt5", "lectures/nlp_deep/transformers/index", "lectures/nlp_deep/transformers/t5", "lectures/nlp_intro/apps/index", "lectures/nlp_intro/apps/research1", "lectures/nlp_intro/apps/research2", "lectures/nlp_intro/datasets/corpus", "lectures/nlp_intro/datasets/index", "lectures/nlp_intro/datasets/lab-dart", "lectures/nlp_intro/embeddings/fasttext", "lectures/nlp_intro/embeddings/glove", "lectures/nlp_intro/embeddings/index", "lectures/nlp_intro/embeddings/nlm", "lectures/nlp_intro/embeddings/w2v", "lectures/nlp_intro/index", "lectures/nlp_intro/intro/index", "lectures/nlp_intro/lm/index", "lectures/nlp_intro/lm/ngram", "lectures/nlp_intro/lm/usage", "lectures/nlp_intro/sentiments/index", "lectures/nlp_intro/sentiments/lab-lexicon", "lectures/nlp_intro/sentiments/lab-ml", "lectures/nlp_intro/sentiments/lexicon", "lectures/nlp_intro/sentiments/ml", "lectures/nlp_intro/tokenization/index", "lectures/nlp_intro/tokenization/korean", "lectures/nlp_intro/tokenization/lab-korean", "lectures/nlp_intro/tokenization/lab-tokenization", "lectures/nlp_intro/tokenization/ngrams", "lectures/nlp_intro/tokenization/pos", "lectures/nlp_intro/tokenization/segmentation", "lectures/nlp_intro/tokenization/tokenization", "lectures/nlp_intro/topic/coherence", "lectures/nlp_intro/topic/index", "lectures/nlp_intro/topic/lab-coherence", "lectures/nlp_intro/topic/lab-methods", "lectures/nlp_intro/topic/methods", "lectures/nlp_intro/topic/tomotopy", "lectures/nlp_intro/vectorization/bow", "lectures/nlp_intro/vectorization/index", "lectures/nlp_intro/vectorization/lab-similarity", "lectures/nlp_intro/vectorization/semantics", "lectures/nlp_intro/vectorization/similarity", "lectures/nlp_intro/vectorization/tf-idf", "lectures/softeng/devops/gitops", "lectures/softeng/devops/index", "lectures/softeng/index", "lectures/softeng/intro/index", "lectures/softeng/intro/introduction", "lectures/softeng/intro/processes", "lectures/softeng/intro/requirements", "lectures/softeng/intro/sdlc", "lectures/softeng/proposal/guidelines", "lectures/softeng/proposal/index", "lectures/softeng/proposal/steps", "lectures/softeng/proposal/template", "lectures/softeng/spm/agile", "lectures/softeng/spm/index", "lectures/softeng/vcs/00_introduction", "lectures/softeng/vcs/01_solo_work_with_git", "lectures/softeng/vcs/02_fixing_mistakes", "lectures/softeng/vcs/03_publishing", "lectures/softeng/vcs/04_collaboration", "lectures/softeng/vcs/05_fork_and_pull", "lectures/softeng/vcs/06_git_theory", "lectures/softeng/vcs/07_branches", "lectures/softeng/vcs/08_advanced_git_concepts", "lectures/softeng/vcs/09_github_pages", "lectures/softeng/vcs/10_rebasing", "lectures/softeng/vcs/11_debugging_with_git_bisect", "lectures/softeng/vcs/12_multiple_remotes", "lectures/softeng/vcs/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "about/lecture-bot.md", "index.md", "lectures/aiart/aiart/index.md", "lectures/aiart/brave/index.md", "lectures/aiart/index.md", "lectures/aiart/intro/index.md", "lectures/aiart/motion-capture-and-synthesis/index.md", "lectures/aiart/robot/index.md", "lectures/aiart/text-to-image/dalle1.md", "lectures/aiart/text-to-image/dalle2.md", "lectures/aiart/text-to-image/imagen.ipynb", "lectures/aiart/text-to-image/index.md", "lectures/dsecon/cb/altdata.md", "lectures/dsecon/cb/index.md", "lectures/dsecon/esg-ratings/all_in_one_pipeline.ipynb", "lectures/dsecon/esg-ratings/build_news_corpus.ipynb", "lectures/dsecon/esg-ratings/cross_validate_datasets.ipynb", "lectures/dsecon/esg-ratings/improve_datasets.ipynb", "lectures/dsecon/esg-ratings/index.md", "lectures/dsecon/esg-ratings/predict_esg_classes.ipynb", "lectures/dsecon/esg-ratings/prepare_datasets.ipynb", "lectures/dsecon/esg-ratings/prepare_datasets_for_labeling.ipynb", "lectures/dsecon/esg-ratings/train_classifiers.ipynb", "lectures/dsecon/fomc/01_numerical_data.ipynb", "lectures/dsecon/fomc/02_textual_data.ipynb", "lectures/dsecon/fomc/03_EDA_numericals1.ipynb", "lectures/dsecon/fomc/03_EDA_numericals2.ipynb", "lectures/dsecon/fomc/04_training_datasets.ipynb", "lectures/dsecon/fomc/05_features.ipynb", "lectures/dsecon/fomc/06_AutoML.ipynb", "lectures/dsecon/fomc/07_predict_sentiments.ipynb", "lectures/dsecon/fomc/08_EDA_sentiments1.ipynb", "lectures/dsecon/fomc/08_EDA_sentiments2.ipynb", "lectures/dsecon/fomc/09_visualize_features.ipynb", "lectures/dsecon/fomc/10_monetary_shocks.ipynb", "lectures/dsecon/fomc/11_AutoML_with_tones.ipynb", "lectures/dsecon/fomc/index.md", "lectures/dsecon/index.md", "lectures/dsecon/intro/challenges.md", "lectures/dsecon/intro/index.md", "lectures/dsecon/intro/introduction.md", "lectures/dsecon/intro/methods.md", "lectures/llms/agents/autogen.md", "lectures/llms/agents/autoscraper.md", "lectures/llms/agents/index.md", "lectures/llms/finetune/autotrain.md", "lectures/llms/finetune/index.md", "lectures/llms/index.md", "lectures/llms/intro/index.md", "lectures/llms/intro/llms.md", "lectures/llms/peft/index.md", "lectures/llms/peft/peft-hf.md", "lectures/llms/peft/peft-llms.md", "lectures/llms/q-learning/index.md", "lectures/llms/q-learning/qstar.md", "lectures/llms/rag/index.md", "lectures/llms/stack/app.md", "lectures/llms/stack/architecture.md", "lectures/llms/stack/index.md", "lectures/llms/stack/infra.md", "lectures/mlops/containerization/containerd.md", "lectures/mlops/containerization/docker.md", "lectures/mlops/containerization/index.md", "lectures/mlops/devops/devsecops.md", "lectures/mlops/devops/gitops.md", "lectures/mlops/devops/index.md", "lectures/mlops/dotfiles/index.md", "lectures/mlops/github/fork-pull.md", "lectures/mlops/github/index.md", "lectures/mlops/github/template.md", "lectures/mlops/index.md", "lectures/mlops/intro.md", "lectures/mlops/llmops/bentochain.md", "lectures/mlops/llmops/bentoml.md", "lectures/mlops/llmops/index.md", "lectures/mlops/project.md", "lectures/mlops/security/age-gpg-ssh.md", "lectures/mlops/security/auth-enc-sign.md", "lectures/mlops/security/index.md", "lectures/mlops/security/pass.md", "lectures/mlops/simple-pipeline/index.md", "lectures/mlops/simple-pipeline/server.md", "lectures/mlops/simple-pipeline/vpn.md", "lectures/nlp_advances/gpt/camelids.md", "lectures/nlp_advances/gpt/detectGPT.md", "lectures/nlp_advances/gpt/gpt4.md", "lectures/nlp_advances/gpt/index.md", "lectures/nlp_advances/index.md", "lectures/nlp_advances/sam/index.md", "lectures/nlp_advances/thesis.md", "lectures/nlp_deep/chatbots/detectGPT.md", "lectures/nlp_deep/chatbots/index.md", "lectures/nlp_deep/chatbots/rlhf.md", "lectures/nlp_deep/datasets/index.md", "lectures/nlp_deep/datasets/lab-eda.ipynb", "lectures/nlp_deep/datasets/mc4.md", "lectures/nlp_deep/index.md", "lectures/nlp_deep/llms/decoding.ipynb", "lectures/nlp_deep/llms/index.md", "lectures/nlp_deep/llms/plms.ipynb", "lectures/nlp_deep/llms/zeroshot.ipynb", "lectures/nlp_deep/tokenization/bpe.ipynb", "lectures/nlp_deep/tokenization/index.md", "lectures/nlp_deep/tokenization/lab-train-tokenizers.ipynb", "lectures/nlp_deep/tokenization/pipeline.ipynb", "lectures/nlp_deep/tokenization/sentencepiece.md", "lectures/nlp_deep/tokenization/subword.md", "lectures/nlp_deep/tokenization/unigram.ipynb", "lectures/nlp_deep/tokenization/wordpiece.ipynb", "lectures/nlp_deep/training/index.md", "lectures/nlp_deep/training/lab-finetune-mlm.ipynb", "lectures/nlp_deep/training/lab-pretrain-clm.ipynb", "lectures/nlp_deep/training/lab-pretrain-mlm.ipynb", "lectures/nlp_deep/transformers/bert.ipynb", "lectures/nlp_deep/transformers/bertviz.ipynb", "lectures/nlp_deep/transformers/byt5.ipynb", "lectures/nlp_deep/transformers/index.ipynb", "lectures/nlp_deep/transformers/t5.ipynb", "lectures/nlp_intro/apps/index.md", "lectures/nlp_intro/apps/research1.md", "lectures/nlp_intro/apps/research2.md", "lectures/nlp_intro/datasets/corpus.md", "lectures/nlp_intro/datasets/index.md", "lectures/nlp_intro/datasets/lab-dart.ipynb", "lectures/nlp_intro/embeddings/fasttext.ipynb", "lectures/nlp_intro/embeddings/glove.ipynb", "lectures/nlp_intro/embeddings/index.md", "lectures/nlp_intro/embeddings/nlm.ipynb", "lectures/nlp_intro/embeddings/w2v.ipynb", "lectures/nlp_intro/index.md", "lectures/nlp_intro/intro/index.ipynb", "lectures/nlp_intro/lm/index.md", "lectures/nlp_intro/lm/ngram.ipynb", "lectures/nlp_intro/lm/usage.ipynb", "lectures/nlp_intro/sentiments/index.md", "lectures/nlp_intro/sentiments/lab-lexicon.ipynb", "lectures/nlp_intro/sentiments/lab-ml.ipynb", "lectures/nlp_intro/sentiments/lexicon.md", "lectures/nlp_intro/sentiments/ml.md", "lectures/nlp_intro/tokenization/index.md", "lectures/nlp_intro/tokenization/korean.md", "lectures/nlp_intro/tokenization/lab-korean.ipynb", "lectures/nlp_intro/tokenization/lab-tokenization.ipynb", "lectures/nlp_intro/tokenization/ngrams.md", "lectures/nlp_intro/tokenization/pos.md", "lectures/nlp_intro/tokenization/segmentation.ipynb", "lectures/nlp_intro/tokenization/tokenization.md", "lectures/nlp_intro/topic/coherence.md", "lectures/nlp_intro/topic/index.md", "lectures/nlp_intro/topic/lab-coherence.ipynb", "lectures/nlp_intro/topic/lab-methods.ipynb", "lectures/nlp_intro/topic/methods.md", "lectures/nlp_intro/topic/tomotopy.ipynb", "lectures/nlp_intro/vectorization/bow.md", "lectures/nlp_intro/vectorization/index.md", "lectures/nlp_intro/vectorization/lab-similarity.ipynb", "lectures/nlp_intro/vectorization/semantics.md", "lectures/nlp_intro/vectorization/similarity.md", "lectures/nlp_intro/vectorization/tf-idf.md", "lectures/softeng/devops/gitops.md", "lectures/softeng/devops/index.md", "lectures/softeng/index.md", "lectures/softeng/intro/index.md", "lectures/softeng/intro/introduction.md", "lectures/softeng/intro/processes.md", "lectures/softeng/intro/requirements.md", "lectures/softeng/intro/sdlc.md", "lectures/softeng/proposal/guidelines.md", "lectures/softeng/proposal/index.md", "lectures/softeng/proposal/steps.md", "lectures/softeng/proposal/template.md", "lectures/softeng/spm/agile.md", "lectures/softeng/spm/index.md", "lectures/softeng/vcs/00_introduction.ipynb", "lectures/softeng/vcs/01_solo_work_with_git.ipynb", "lectures/softeng/vcs/02_fixing_mistakes.ipynb", "lectures/softeng/vcs/03_publishing.ipynb", "lectures/softeng/vcs/04_collaboration.ipynb", "lectures/softeng/vcs/05_fork_and_pull.ipynb", "lectures/softeng/vcs/06_git_theory.ipynb", "lectures/softeng/vcs/07_branches.ipynb", "lectures/softeng/vcs/08_advanced_git_concepts.ipynb", "lectures/softeng/vcs/09_github_pages.ipynb", "lectures/softeng/vcs/10_rebasing.ipynb", "lectures/softeng/vcs/11_debugging_with_git_bisect.ipynb", "lectures/softeng/vcs/12_multiple_remotes.ipynb", "lectures/softeng/vcs/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 30, 31, 36, 38, 39, 43, 46, 47, 50, 55, 56, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 123, 124, 127, 128, 129, 130, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 166, 167, 168, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186], "0": [0, 1, 2, 10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 46, 52, 77, 78, 79, 80, 89, 95, 96, 98, 101, 102, 104, 105, 106, 108, 109, 111, 112, 113, 114, 115, 118, 120, 124, 125, 127, 128, 133, 134, 136, 137, 140, 142, 143, 146, 148, 150, 151, 153, 154, 155, 156, 157, 158, 162, 182, 185, 187], "00": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 36, 52, 95, 101, 102, 104, 105, 108, 109, 111, 112, 113, 115, 133, 136, 137, 151, 182], "000": [18, 21, 96, 104, 106, 112, 113, 120, 121, 123, 129, 140, 144, 151, 153, 168], "0000": [111, 153], "000000": [26, 27, 28, 29, 31, 34, 150], "00000000": 113, "000001": 31, "000013296724692": 153, "000020": 15, "0001": 153, "00020": 10, "000270": [16, 22], "00027956522535532713": 153, "0004308223724365": 153, "0004752098843655948": 109, "000523405953129051": 15, "0006194999520653675": 15, "000642749081254596": 22, "000660": [15, 16, 22], "00070333480835": 153, "00082": 22, "0009028980666769455": 20, "0009417470597143389": 20, "00096": 22, "0009765625": 36, "000977778226698302": 20, "000km": 142, "001": 128, "0010": 153, "0010000319093906645": 15, "0010086221579924967": 20, "001021931625316696": 20, "001043796539307": 153, "0010603860605236683": 15, "0010913496344655172": 20, "0011111111108024763": 153, "0011744614247291812": 20, "0012780994727015953": 20, "0013324": 15, "0013614120427519083": 153, "0013657693473079205": 17, "0013807213841885606": 20, "001460": [32, 34], "0015103125334617502": 20, "001511": 34, "0015561782752413472": 30, "001653071269117536": 20, "001680": 15, "0017191542850923725": 153, "001750": 15, "0017750745406374334": 153, "001785838507319488": 36, "0018075713776912943": 22, "0018410125274279446": 17, "001962865950724563": 15, "001974979448829106": 17, "002": 22, "0020": 153, "00200496373839086": 20, "002177574671804905": 153, "0022369285449255986": 15, "0022407311684219168": 153, "002255635923122306": 15, "0022622254938860858": 20, "002297": 29, "002322": 26, "002442110228841302": 20, "0024603015855481497": 15, "002513": 35, "0025242881090182714": 15, "002576": 26, "0026033215690404177": 153, "002610116498544812": 153, "00277139162106223": 18, "0028065557235574324": 17, "0028207603159319233": 17, "002900": 15, "0029720626114525e": 109, "003": [84, 101], "0030": 153, "00303316": 15, "0030561790387218834": 18, "0031223123848645212": 153, "0031752510759462086": 153, "003179272280394612": 17, "0031880621893694222": 18, "003234388916771163": 20, "0032603326981582993": 36, "0033662562749769104": 20, "00349": [0, 7], "003495981109249": 153, "0035235610749915036": 20, "003535776093569": 153, "003550": [15, 22], "003586996406117": 153, "0035985502573076407": 18, "003644": 31, "003709836775138507": 18, "0037565036432219917": 18, "003873849489889034": 20, "003903": 29, "003973197078848794": 20, "003998241574432772": 17, "0040": 153, "004097158461809159": 153, "004175689859563079": 20, "004244009032845497": 153, "004376": 34, "004414455632531461": 17, "004594": 29, "004619": 34, "00476169941298804": 20, "004797083325684071": 153, "004800": 15, "004940841001211258": 18, "0050": 153, "0050339171614286": 153, "005058959626738143": 18, "005107979290187359": 153, "005134203936904669": 153, "005179156956969719": 20, "005238": 26, "005380": [15, 22], "005563": 26, "005687928438936715": 17, "005930": [15, 16, 22, 124], "0060": 153, "006023058667778969": 153, "006048532224020738": 15, "006059555336833": 153, "006127732509048656": 153, "00613": 17, "006324527770306708": 153, "0063391125479737": 153, "006360": 15, "006392374888576145": 18, "006400": 16, "006568645592778921": 153, "006612077821046114": 153, "006677545399021065": 17, "006743854005870231": 18, "006800": 15, "0068541975270435635": 18, "0070": 153, "007283565733168": 153, "007356486366026932": 153, "00741acc0": 17, "00756032345816": 109, "007591910869623802": 20, "007777777778395056": 153, "00795168713418085": 20, "0080": 153, "008004610426723957": 153, "008025267011382514": 153, "00806919950991869": 153, "00813735": 15, "008233696222305298": 153, "0082930761066575": 153, "00830205250531435": 153, "008475089073181": 153, "008636128157377243": 153, "008640003204346": 153, "0088": 22, "008809642893568226": 146, "00884969377797024": 18, "0089258432388306": 153, "009": [112, 113], "0090": 153, "0092657830980087": 153, "00931412617366345": 18, "009382950059241718": 153, "0095133185386658": 153, "0095287438501144": 146, "009533638447234705": 146, "009662": 26, "009830": 20, "00997748374939": 153, "01": [15, 16, 20, 21, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 46, 101, 104, 108, 111, 113, 124, 129, 133, 136, 137, 151, 153], "010050335853248927": 153, "010081577114760876": 153, "01008585398667492": 153, "0101010100755026": 153, "01011066196727523": 17, "010744794691714028": 18, "011200": [15, 22], "0112442822962447": 36, "011248100661326789": 18, "011560071259737015": 153, "011562358220107061": 17, "011695269495248795": 153, "011743": 31, "01194334": 15, "011977991797623686": 18, "012048": 26, "012195": 31, "012386607937514782": 153, "01250313787700796": 18, "012528997457076856": 17, "012756952526979148": 153, "012959": 21, "013": 121, "01312994262040823": 153, "013202836861213048": 153, "013203505426645279": 153, "013333333333796271": 153, "013559697485632367": 153, "013620396947472472": 153, "013667368888855": 153, "013953080879420869": 153, "01406999584287405": 153, "014297901652753353": 153, "014444444443209914": 153, "014493": 26, "0145052969455719": 153, "014599558897316456": 153, "0146991021827692": 153, "014707": 31, "014792973524635432": 17, "01481068": 15, "014815865084528923": 153, "014847449427987967": 153, "014918585307896137": 153, "015": 108, "015165": 35, "01545220130427584": 36, "015463637164793908": 153, "01563472938407527": 17, "01574835695205985": 153, "015801263126963696": 153, "0158730158556815": 153, "016037708872722253": 153, "01643266061982747": 153, "016438758864791857": 153, "016495274379849434": 153, "016666666666203728": 153, "016816": 34, "016895": 34, "017217755317688": 153, "01723609397849675": 153, "017405643466831665": 153, "017433559522032738": 153, "017537753614771317": 20, "017544": 31, "017550497874617578": 153, "017670": 16, "01771484687924385": 153, "017766": [24, 26, 27, 28], "017770": 34, "017965496318325943": 17, "01802913252790635": 153, "018248": 32, "01824960671365261": 153, "0182683509407169": 153, "018339197296235295": 153, "0183959249407053": 153, "018634909763932228": 153, "018678518012166023": 153, "018686016335820517": 17, "01871933601796627": 153, "018888888888503125": 153, "01890910230576992": 153, "018917387394747708": 18, "01894244": 15, "019077003002166748": 153, "019143888726830482": 153, "01916022039949894": 153, "019347166642546654": 153, "019481932744383812": 153, "019782157614827156": 153, "019804658368229866": 153, "019806118682026863": 153, "019809621816311e": 109, "019880": 26, "019986823201179504": 153, "01it": [24, 108], "02": [15, 16, 23, 24, 29, 31, 32, 33, 34, 111, 112, 113, 153], "020155129954218864": 153, "020184030756354332": 153, "02019628696143627": 153, "020287929102778435": 153, "020313935354351997": 153, "02036337": 15, "020408": 34, "020490463474": 133, "020539406687021255": 153, "020595964044332504": 153, "02060607075691223": 153, "0207321961720783": 153, "02100101": [15, 16, 20, 22], "02100201": 20, "02100311": 15, "02100374549627304": 153, "02100601": 15, "02100801": 15, "02100851": [15, 16, 20, 22], "0210167169570923": 153, "02111111111080248": 153, "021120237186551094": 153, "02119298093020916": 153, "021272389449621617": 20, "021280916407704353": 153, "021316067016847247": 20, "021318": 31, "02133885601942893": 153, "02134801261126995": 153, "02141981518103": 153, "021457767114043236": 153, "02149142511188984": 153, "02169227972626686": 153, "021697456017136574": 153, "021834025159478188": 153, "022079596295952797": 153, "02217409573495388": 153, "022201931104063988": 153, "022236647084355354": 153, "022253897041082382": 153, "022261105477809906": 153, "02227860502898693": 153, "02233187196252402": 153, "02241339161992073": 153, "022453": 29, "022487830370664597": 153, "022489816357847303": 153, "022510839439928532": 153, "02255701646208763": 153, "0226049423217773": 153, "02260943448636681": 153, "022615865571424365": 153, "022687014192342758": 153, "022817134857178": 153, "022828377783298492": 153, "022918909788131714": 153, "022921955212950706": 153, "022962426766753197": 153, "023013164289295673": 153, "023077810183167458": 153, "02316347137093544": 153, "0231639385223": 153, "023214666172862053": 153, "02322317101061344": 153, "023243363946676254": 153, "023304933682084084": 153, "023332816548645496": 153, "023429": 35, "023488366399701": 153, "023508427664637566": 153, "02365320026874542": 153, "023677445948123932": 153, "02375788427889347": 153, "023782242089509964": 153, "0238032303750515": 153, "023804608383215964": 153, "02384454943239689": 153, "023845259100198746": 153, "023860113695263863": 153, "02389199184771213": 153, "024": [112, 113, 118], "02400804781354964": 153, "02401486597955227": 153, "024027807638049126": 153, "024034013971686363": 153, "024058369919657707": 153, "024081824347376823": 153, "024181541055440903": 153, "02420790456235409": 153, "02428392320871353": 153, "0244444444452932": 153, "02444641850888729": 153, "0244805496186018": 153, "02454484812915325": 153, "02457650564610958": 153, "02460562437772751": 153, "024725638329982758": 153, "02484716847538948": 153, "024903977289795876": 153, "024928677827119827": 153, "02492894046008587": 153, "02493913657963276": 153, "024973296327516437": 153, "025011882465332747": 153, "025206705555319786": 153, "025228777900338173": 153, "025230159983038902": 153, "02524220570921898": 153, "02526998706161976": 153, "025288190692663193": 153, "025354486890137196": 153, "025373382633551954": 153, "025386424735188484": 153, "025460125878453255": 153, "02547328919172287": 153, "025610920041799545": 153, "025642": 31, "025644585490226746": 153, "02566142504931324": 153, "025746019068962": 153, "025783058255910873": 153, "02582348883152008": 153, "025920337066054344": 153, "025927245616912842": 153, "02594492956995964": 153, "026018": 35, "026059428229928017": 153, "026072914712131023": 153, "026073369197547436": 153, "026153041049838066": 153, "026178": 34, "026188": 29, "026242190320044757": 153, "02626017779111862": 153, "026280250067218697": 36, "02633865411626175": 153, "02641656994819641": 153, "026466488419100643": 153, "02654256857931614": 153, "026647305116057396": 153, "026666666667592542": 153, "026684165000915527": 153, "026686497032642365": 153, "02672146074473858": 153, "026755": 26, "026795502159956852": 146, "026795591191855372": 146, "026850566267967224": 153, "026877814903855324": 153, "026973506435751915": 153, "027046818286180496": 153, "027050886303186417": 153, "0271761390897964": 153, "027197375893592834": 153, "027241162955760956": 153, "027269362611696123": 153, "02731814980506897": 153, "027319354936480522": 153, "027335839346051216": 153, "02735506788144294": 153, "027357084676623344": 153, "027406617300584912": 153, "02745734713971615": 153, "027459732769057155": 153, "027603846043348312": 153, "027608619537204504": 153, "027665": [24, 26, 27, 28], "027751151472330093": 153, "027780745178461075": 153, "0277860090136528": 153, "027872106507937942": 153, "027872290462255478": 153, "02792251281400827": 17, "02802048809826374": 153, "028032733127474785": 153, "02806585220969282": 153, "028169": 32, "028173299506306648": 153, "02820960246026516": 153, "028326774704166585": 153, "02842774987220764": 153, "028549600392580032": 153, "028627438470721245": 153, "028639836236834526": 153, "028658824041485786": 153, "02873232145793736": 153, "0287358143354586": 153, "028818044811487198": 153, "028845202177762985": 153, "02884882315993309": 153, "028888888887808717": 153, "028942884877324104": 153, "028995145112276077": 153, "029011488535021748": 153, "029026644304394722": 153, "02905316837131977": 153, "02907869778573513": 153, "029129577800631523": 153, "029139023562897312": 153, "029142240062355995": 153, "029163892567157745": 153, "0292171910405159": 153, "029225243255496025": 153, "029246959519878154": 153, "029274040833115578": 153, "029338866472244263": 153, "029340967535972595": 153, "029363089614303225": 15, "029365785916646": 153, "029437027871608734": 153, "029484260827302933": 153, "029630": 32, "02966911531984806": 153, "029726402834057808": 153, "029766265489161014": 153, "029785138120253882": 153, "029884984716773033": 153, "029916903004050255": 153, "029923668410629035": 153, "029941071485324454": 153, "029972150921821594": 153, "03": [16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 101, 113, 153, 181], "030025072395801544": 153, "03004241": 15, "03012196607887745": 153, "030123389098379347": 153, "030131986364722252": 153, "030200": [15, 16], "030228495597839355": 153, "030345": 31, "030352376401424408": 153, "030426261946558952": 153, "030493": 35, "030516": 32, "030516041442751884": 153, "030535": 31, "030551111325621605": 153, "030552612939532587": 153, "030564147979021072": 153, "03076649084687233": 153, "030864188447594643": 153, "03088119998574257": 153, "031085219234228134": 153, "031132448464632034": 153, "031142": [31, 32], "031166594645543": 153, "031186800450086594": 153, "0312153663442274": 153, "03131523355841637": 153, "03131694346666336": 153, "03131acc0": 18, "031389358546584846": 153, "031448664028519": 153, "031500": 113, "031501518096774817": 153, "03156481310725212": 153, "031568868551403284": 153, "0316469706594944": 153, "031746": 31, "031786": 31, "03186766803264618": 153, "0319025032222271": 153, "03197": 30, "0319740312759507": 153, "032018862664699554": 153, "03206848353147507": 153, "03223659098148346": 153, "032240718603134155": 153, "03229295266792178": 153, "03233479708433151": 153, "03239099182925808": 153, "03240770846605301": 153, "03240897646173835": 153, "032470062375068665": 153, "0325390866647164": 153, "03259826738194377": 17, "032640": [16, 22], "0326758299022913": 153, "032683": 31, "0327024": 153, "03280625864863396": 153, "032836": [31, 32, 33], "03286190703511238": 153, "032879263162612915": 153, "0328834131360054": 153, "03296476975083351": 153, "03297409042716026": 153, "033039854077990205": 153, "03306887298822403": 153, "03312114253640175": 153, "03322892263531685": 153, "03328896686434746": 153, "03329444641454352": 153, "03331481292843819": 153, "033356454223394394": 153, "033435314893722534": 153, "03352180868387222": 153, "033560678362846375": 153, "033568563591688874": 153, "033586286008358": 153, "033591731259473": 153, "03393064513802528": 153, "03395622838288546": 153, "03396281599998474": 153, "03412267193198204": 153, "03413750594481826": 153, "034152742475271225": 153, "03415900468826294": 153, "034208785742521286": 153, "034220": 15, "0342683307826519": 153, "03433660753071308": 153, "034375499933958054": 153, "03439800813794136": 153, "03440142671690969": 153, "034425731748342514": 153, "034443046897649765": 153, "03455743566155434": 153, "03465194166637957": 153, "03467543050646782": 153, "034866993991498695": 153, "034915": [24, 27, 28, 34], "035085": 31, "03519437834620476": 153, "03524043411016464": 153, "03524777293205261": 153, "03525979816913605": 153, "03527016192674637": 153, "03532205522060394": 153, "0353222293274311": 153, "035352912605204": 153, "03537106513977051": 153, "03553271293640137": 153, "03558255136013031": 153, "03560185059905052": 153, "035720": [15, 20, 22], "035866402089595795": 153, "0360838046297431": 153, "036092985421419144": 153, "03615150600671768": 153, "03624275326728821": 153, "0362650513648988": 153, "03629786572368363": 153, "0364886112511158": 153, "036522": 26, "03659551963210106": 153, "03666666666620372": 153, "03667616244336371": 153, "0367746576666832": 153, "036792658269405365": 153, "03695906326174736": 153, "036980945616960526": 153, "03702234849333763": 153, "03704646974802017": 153, "037085410207509995": 153, "03708771616220474": 153, "03715534880757332": 153, "037185147404670715": 153, "037264298647642136": 153, "037384": 31, "03739694920368493": 153, "03740504011511803": 153, "03744939017575551": 153, "037468": [32, 34], "037500": 26, "03761112979716725": 153, "037681630812585354": 153, "037783720856532456": 153, "037908248603343964": 153, "0379212737083434": 153, "037974949926137924": 153, "038024842739105225": 153, "0381862111389637": 153, "03821370052173734": 153, "03821662440896034": 153, "03824062645435333": 153, "03839759901165962": 153, "038398": 29, "03842049837112427": 153, "038427666574716565": 153, "03844364359974861": 153, "03862296789884567": 153, "0386896597014532": 153, "03873555362224579": 153, "03876843675971031": 153, "03908383771777153": 153, "03914311155676842": 153, "039243023842573166": 153, "03926002438804054": 153, "03927813754417002": 153, "039304": 25, "039339987812046374": 153, "03935941681265831": 153, "039440584182739": 153, "03948744013905525": 153, "03952961415052414": 153, "0395844394243032": 153, "03959364909679": 108, "0397439002990723": 153, "03974424544721842": 153, "039814376831055": 153, "039873": 31, "03989723877360423": 153, "03999999999930559": 153, "03b8b76ad005950d86fc5494546cd5435a47cbbd": 185, "04": [16, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 112, 113, 122, 124, 129, 131, 153, 185], "040": [112, 113], "040083497762680054": 153, "04015165230052339": 153, "04019220173358917": 153, "04020649939775467": 153, "040207725101047": 153, "040301863104104996": 153, "040338192135095596": 153, "04037995636463165": 153, "04037998989224434": 153, "04045604541897774": 153, "040502": 6, "040554215712472794": 153, "04059769585728645": 153, "040606487262994054": 153, "04062372690273656": 153, "040644481778144836": 153, "040741": 32, "04088243441656232": 153, "040907684969454": 153, "041033096611499786": 153, "041048262268304825": 153, "0410723001576519": 36, "041128822967099646": 153, "04115924602374434": 153, "041293028742074966": 153, "04134495183825493": 153, "041367638669908044": 153, "04136773571372032": 153, "04142872244119644": 153, "04160774126648903": 153, "04161144886165857": 153, "041638": 31, "041691072285175323": 153, "04180443454533815": 153, "04182005319744349": 153, "041860342708726725": 153, "04198075830936432": 153, "041999999999236134": 153, "0421593233011663": 153, "04218817502260208": 153, "04219204559922218": 153, "042206212878227234": 153, "042256352533198": 153, "04248927906155586": 153, "0425521619617939": 153, "042552653700113297": 153, "042555006747717": 153, "04282868843939569": 153, "042941": 31, "0429912454491495": 153, "04299420490860939": 153, "04308585688704625": 153, "0431044512324863": 153, "0431815385818481": 153, "04332808777689934": 153, "04337195058696024": 153, "043400": 113, "04347703978419304": 153, "04348974861204624": 153, "0435190349817276": 153, "043523017317056656": 153, "0435703825950624": 153, "043652": 24, "0437235832214355": 153, "04376556184142828": 153, "043880258593708275": 153, "043887220323085785": 153, "043929": [31, 32, 33], "043969": 31, "0440474362578243": 153, "044164396822452545": 153, "044276900589466095": 153, "0446071389131248": 153, "04467113250866532": 153, "044734448194503784": 153, "044760": 31, "04491093009710312": 153, "044969458132982254": 153, "045": 46, "04500359818339348": 153, "0452619935102012": 153, "04534463584423065": 153, "045420831647486": 153, "045456701517105": 153, "04555992891405496": 153, "04572408273816109": 153, "045795440673828125": 153, "04585271701216698": 153, "046022": [31, 32, 33], "04605297315865755": 153, "04606": 0, "04618659242987633": 153, "04619699716567993": 153, "046242620795965195": 153, "04624945670366287": 153, "04631739230826497": 153, "04635542135098983": 153, "046620383858680725": 153, "0466287637129426": 153, "04666666666620373": 153, "046844959259033": 153, "04695010185241699": 153, "046988748013973236": 153, "046a712": 178, "0471317321062088": 153, "04714265819638967": 153, "0471946001052856": 153, "047503143548965454": 153, "047546323388814926": 153, "04757720679044723": 153, "047584916590858485": 153, "047667736559903": 153, "047727540135383606": 153, "04774315282702446": 153, "047887738794088364": 153, "04791494831442833": 153, "048015411863000027": 153, "04805": [0, 100], "048109": [31, 32, 33], "04815902188420296": 153, "04842308908700943": 153, "04861912131309509": 153, "04869697988033295": 153, "0487590491771699": 153, "048796920694947676": 153, "04880514014512301": 153, "048889391124248505": 153, "048939090222120285": 153, "04913739860057831": 153, "04916006557067793": 153, "04944229": 15, "04944303259253502": 153, "0494534604589918": 153, "04950031088665128": 153, "04950055712210693": 153, "049778604507447": 153, "049841899424791336": 153, "04d": [128, 129], "04k": 137, "05": [11, 15, 16, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 109, 112, 113], "050000001652027934": 153, "050000002527070084": 153, "05000000283627202": 153, "05001222868822": 153, "05003134906291962": 153, "050040": [32, 34], "050143": 34, "050156839191913605": 153, "05027374318626243": 153, "05030542407184839": 153, "050360": 32, "05052750938504081": 153, "05055555552748148": 153, "050565505400300026": 153, "0506262369453907": 153, "05068816989660263": 153, "0507568078530312": 153, "05091230198740959": 153, "05105343088507652": 153, "0510625998179117": 153, "05109086260199547": 153, "05130905658006668": 153, "05131297558546066": 153, "05132152512669563": 153, "051404965808615": 108, "05140705183148384": 153, "05157728120684624": 153, "0516876": 15, "051863204687833786": 153, "05191": 21, "051910": [16, 20], "05201324075460434": 153, "05208738949149847": 153, "05211600113348184": 153, "0523207476362586": 153, "05246623436214254": 153, "0524930655956268": 153, "05270737037062645": 153, "05273476496545805": 153, "05276763825159934": 153, "05279702693223953": 153, "052807": 26, "05304856225848198": 153, "0531478464603423": 153, "0532445145272019": 153, "05335765704512596": 153, "05336632952094078": 153, "05343955382704735": 153, "053497942380003": 153, "0536433339118956": 153, "05369899049401283": 153, "05395232513546944": 153, "054": [112, 113], "054033324122428894": 153, "0541820205768704": 153, "05443309042602777": 153, "0545852929353714": 153, "05464784428477287": 153, "05478229746222496": 153, "05491440370678902": 153, "05498626958578825": 153, "055276": 29, "05537626892328262": 153, "055410385131836": 153, "0554541110992433": 153, "05555555555401248": 153, "055851222156576": 153, "05589492991566658": 153, "05605816841125488": 153, "05610727518796921": 153, "0561725080013276": 153, "056442486308515075": 153, "056498335860669616": 153, "05666666666620372": 153, "05681043490767479": 153, "05693256855011": 153, "056963336705747575": 153, "05730922520160675": 153, "05733166371": 153, "0574597492814064": 153, "057496074587106705": 153, "05758258327841759": 153, "057847213745116": 153, "057878735731085e": 109, "058177": 26, "058474055491387844": 153, "058518886566162": 153, "0585608153294": 153, "058706": 26, "05875986196674117": 153, "058775322056478924": 153, "05886959284543991": 153, "058919": 29, "058977754372689456": 153, "0590": 111, "059253980701517626": 153, "05933672775478992": 153, "059524": 32, "05999999999930558": 153, "06": [15, 16, 22, 24, 25, 29, 31, 32, 34, 35, 109, 111, 175, 182], "0600": 185, "0600609116256237": 153, "060093": 26, "0602086759498055": 153, "0602213962001406": 153, "0603746697306633": 153, "06049309560718636": 153, "06070328131318092": 153, "06072566285729408": 153, "0609850883483887": 153, "06104483656365321": 153, "0611329078674316": 153, "06120393336750567": 153, "061224": 34, "06129385158419609": 153, "0613703462812636": 153, "061376765367417": 153, "061396408081055": 153, "06160355731844902": 153, "06175": 0, "061836": 26, "06188205188243753": 153, "061896": 34, "06258307859733529": 31, "06273228777572512": 153, "0628127242821375": 153, "06283593": 23, "06285469895228743": 153, "06290167171715035": 153, "0629795470195091": 153, "063": 121, "063014969574606": 153, "06369": 36, "06374088437782353": 153, "06379114091396332": 153, "06384652107954025": 153, "064255": 31, "064286": [31, 32, 33], "06496669764682236": 153, "0649914529938123": 153, "06522314250469208": 153, "06546416910010913": 153, "06546416910128068": 153, "065532997859911e": 109, "065586157143116": 153, "06580013204365968": 153, "0658064484596252": 153, "066192412128051": 153, "06621104702854534": 153, "06624470394148856": 153, "06624612605006143": 153, "066570": [15, 16, 22], "06666666666689813": 153, "06671895980835": 153, "06674521416425705": 153, "06689acc0": 18, "067133665084839": 153, "06713514820217745": 153, "0674062106758356": 153, "0674881803803146": 153, "06765787499025464": 153, "067962": 34, "0679799139499664": 153, "06800140934064984": 153, "06803527064621448": 153, "0681": 52, "06814": 0, "068241": 34, "068247": 31, "068270": [15, 22], "0683930441737175": 153, "06870913652399192": 153, "068759411375146": 153, "06888888888919752": 153, "0690041290183774": 153, "069079": [31, 32], "06931471814989455": 153, "069550": 26, "06970649": 153, "06it": 24, "07": [15, 22, 23, 24, 25, 31, 32, 33, 34], "07005497813224792": 153, "0702972412109375": 153, "070304331514571": 153, "0703579567372798": 153, "0705": 52, "0706554651260376": 153, "07073431462049484": 153, "070774345681312": 153, "071053": 31, "0716267079114914": 153, "07163909580558539": 153, "071650528907776": 153, "0716905148356126": 153, "0717117115855217": 153, "0717879543080926": 153, "07214492559432983": 153, "07240752719538407": 153, "07241": 36, "072464": 32, "0726400837302208": 153, "07271983586251736": 153, "0727551": 15, "072848": 31, "073038898727946": 153, "07305517047643661": 153, "073345": 24, "07337620109319687": 153, "07352436": 15, "0735806226730347": 153, "07362334430217743": 153, "07364538814872504": 153, "073981": 129, "0741924165627901": 153, "07421420821920037": 153, "0743200851811303": 153, "074328": 31, "07485087784007191": 153, "07499999996833334": 153, "07528742959158059": 17, "075441": [31, 32, 33], "07553057372570038": 153, "0755555555547068": 153, "07565984372007947": 153, "075712": 31, "07601101696491241": 153, "07616382919974851": 153, "0762025992076": 153, "0766732692718506": 153, "076698": [24, 27, 28, 34], "07670099985772799": 153, "07671117782592773": 153, "07682": 0, "076924": 31, "07696104113489391": 153, "07696104113545482": 153, "07696104113551105": 153, "07707776129245758": 153, "07714912438359542": 153, "07718963869055703": 153, "07719137948006391": 153, "077381": [31, 32, 33], "07745150006893609": 153, "077500": 113, "077572684817844": 153, "07778486348171201": 153, "07785352234183011": 153, "07799616557442479": 153, "07816842701577136": 153, "0783161667403813": 153, "078522": 34, "07859469803599864": 153, "0787838399410248": 153, "07897601045720357": 153, "07899330457052": 153, "07902201265096664": 153, "079199": 31, "07952811568975449": 153, "07984513494496544": 153, "07990583777427673": 153, "08": [15, 16, 20, 22, 23, 24, 29, 31, 32, 33, 34, 95], "080": [112, 113], "08003168953582644": 153, "08016": 36, "08017025142908096": 153, "08020481467247009": 153, "0802469135719117": 153, "08055725886583803": 153, "0805715151131153": 153, "080851": [31, 32], "08109336085617543": 153, "08112683892250061": 153, "08211303852897013": 153, "08212855363470023": 153, "08222222222229938": 153, "08224359766491388": 153, "08237": 0, "0824157815953828": 153, "082498407363891": 153, "08279434137253297": 153, "08322348445653915": 153, "0832902544281549": 153, "08349631540477276": 153, "08358242362737656": 153, "0837298682696807": 153, "083737": 26, "08373983587039549": 153, "08384250849485397": 153, "084": 104, "0848464209397464": 153, "08486": 17, "08486acc0": 17, "085580": 26, "085714": [32, 34], "0858306884765625": 153, "08589823905593837": 153, "08622435480356216": 153, "086359": [32, 34], "0866086959839": 153, "08704tn12tp21train_loss0": 17, "0871577113866806": 153, "08725816011428833": 153, "087292": 31, "087374": 29, "08748222142457962": 153, "087583": [31, 32, 33], "0880317687988281": 153, "0882180836465625": 153, "088255": 26, "08831321989894252": 153, "0883911517599014": 153, "088608": 31, "08869124026872062": 153, "0887713264147822": 153, "08897302425204513": 153, "089": 113, "08923283219337463": 153, "08960569": 15, "089616": 24, "089678": 35, "089881": 31, "089989948272705": 153, "08epoch": 21, "09": [15, 16, 20, 23, 24, 25, 29, 31, 32, 34, 35, 112, 113, 115, 153, 176, 185], "090": [112, 113], "0900": [175, 176, 181, 185], "09002556798255278": 153, "090069": 29, "09027235209941864": 153, "09045128077268601": 153, "090534558147192": 153, "09055597260594368": 153, "09055873945737": 153, "09059121534228325": 153, "09068491533398629": 153, "09069322496652603": 153, "09069855883717537": 153, "09070029854774475": 153, "09071093946695327": 153, "09071410968899726": 153, "09071683958172798": 153, "09078982919454574": 153, "09079249650239944": 153, "0907941222190857": 153, "09080255255103112": 153, "0908067338168621": 153, "0908079169690609": 153, "09081626906991005": 153, "09081744477152824": 153, "09082573726773262": 153, "09082677140831948": 153, "09082993492484093": 153, "09083370342850686": 153, "09083639308810235": 153, "09083664193749427": 153, "09083719700574874": 153, "09083746895194053": 153, "09084171429276466": 153, "09084264189004898": 153, "09084642007946968": 153, "0908469520509243": 153, "09084771491587165": 153, "09084807336330414": 153, "0908483773469925": 153, "09085014089941978": 153, "09085262939333916": 153, "09085730984807014": 153, "090857744961977": 153, "09085912853479386": 153, "09086524546146393": 153, "09086695313453674": 153, "09087031185626984": 153, "090873122215271": 153, "090873484313488": 153, "09087421372532845": 153, "09087632820010186": 153, "09087948873639107": 153, "09088162183761597": 153, "09088353589177131": 153, "0908846378326416": 153, "09088497683405876": 153, "09088974744081497": 153, "0908934824168682": 153, "09089420288801194": 153, "09089943617582322": 153, "09097979786909288": 153, "09104066548170522": 153, "091042": 35, "09166838228702545": 153, "09188440488661437": 146, "09200627624264193": 153, "092051823536552": 153, "0921587586402892": 153, "09219684": 15, "092324829101562": 153, "09246942280151692": 153, "0927255153656006": 31, "0928826": 178, "0928990066051483": 153, "09301305944100022": 153, "09312676191329956": 153, "09320585189982214": 153, "0935552358627318": 153, "09380713850259781": 153, "094": 104, "094256": [29, 34], "09476642608642": 153, "09485439706542012": 153, "094891": 32, "094900": 113, "094924": [24, 26, 27, 28], "095": 120, "095663": [31, 32, 33], "09569137090713614": 153, "096": 118, "0963026087731123": 153, "09631062974767758": 153, "09641246907413006": 153, "096552": 32, "09687": 54, "09694586040870846": 153, "09718930795788765": 153, "0972980260848999": 153, "097304": 26, "097561": [32, 34], "09788931234235808": 153, "09800404": 15, "09812190169672579": 153, "0981799298690425": 153, "0986122886678875": 153, "0987323746085167": 153, "098829": 24, "0991808899374273": 146, "0991838201880455": 153, "09923006594181061": 153, "09936678409576416": 153, "09945592378764523": 146, "09971871227025986": 153, "09972630068659782": 153, "09973392114043236": 153, "09973965883255005": 153, "09975052047520876": 153, "099774": 34, "09977788031101227": 153, "09982802346348763": 153, "09983752146363259": 153, "09984949454665185": 153, "09989505112171174": 153, "09995957762002945": 153, "09997299909591675": 153, "09997679015000661": 153, "09997731372714043": 153, "09997882321476936": 153, "09998270869255066": 153, "09999998137354851": 153, "09999998435378074": 153, "09999998658895493": 153, "09999998882412911": 153, "09999999105930328": 153, "09999999180436134": 153, "09999999329447747": 153, "09999999403953552": 153, "09999999478459358": 153, "09999999552965164": 153, "09999999627470971": 153, "09999999635644484": 153, "09999999701976776": 153, "09999999776482582": 153, "09999999831161985": 153, "09999999850988388": 153, "09999999925494193": 153, "09999999938123459": 153, "0m": [18, 23, 31, 133, 136, 137, 142, 151], "0ma": [133, 136, 137, 151], "0mcc0": [17, 18, 23], "0x7f0abf7043a0": 31, "0x7f0abf86c1f0": 31, "0x7f0abf86c820": 31, "0x7f0abf86c8b0": 31, "0x7f0abf86cc10": 31, "0x7f0faefeb040": 16, "0x7f0faefeb160": 16, "0x7f0faefeb670": 16, "0x7f0faefebe50": 16, "0x7f1029331f70": 20, "0x7f28e2df51f0": 17, "0x7f29d1221ee0": 17, "0x7f29d1225310": 17, "0x7f29d12254c0": 17, "0x7f29d12260d0": 17, "0x7f2afb9328b0": 17, "0x7f2afb932ca0": 17, "0x7f2afb932e50": 17, "0x7f2afb939a60": 17, "0x7f2e20d95a60": 22, "0x7f4a921d7ca0": 34, "0x7f4a921e43a0": 34, "0x7f4a921e4af0": 35, "0x7f4a924ba1f0": 34, "0x7f5538032dc0": 21, "0x7f553803b1f0": 21, "0x7f553803bf70": 21, "0x7f6b4a296820": 24, "0x7faa65df1ee0": 20, "0x7fc2a666c820": 25, "0x7fc2a666c940": 25, "0x7fc2a666cb80": 25, "0x7fc2a666cd30": 25, "0x7fc2a666cf70": 25, "0x7fc2a666d550": 25, "0x7fd4706e7280": 29, "0x7fd4706e7670": 29, "0x7fd4706e8310": 29, "0\uc2dc\ubd80\ud130": 16, "1": [0, 1, 2, 5, 7, 10, 11, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 43, 52, 53, 54, 60, 80, 95, 98, 100, 101, 102, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 125, 126, 127, 133, 134, 136, 137, 138, 140, 144, 146, 149, 150, 151, 152, 153, 154, 155, 156, 158, 162, 176, 177, 178, 181, 182, 183, 184, 185, 186, 187], "10": [0, 2, 7, 10, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 43, 44, 48, 52, 71, 95, 96, 97, 101, 102, 104, 105, 106, 108, 109, 111, 112, 113, 115, 116, 118, 120, 121, 123, 127, 129, 130, 133, 137, 138, 140, 142, 146, 148, 150, 151, 152, 153, 156, 162, 187], "100": [7, 18, 21, 24, 25, 31, 44, 52, 70, 89, 95, 96, 98, 99, 101, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 123, 129, 131, 137, 143, 146, 150, 152, 153, 182], "1000": [16, 25, 31, 36, 95, 102, 108, 109, 112, 113, 121, 127, 128, 136, 153, 185], "10000": [113, 129], "100000": [31, 129], "1000000": [104, 106], "10000000": 104, "10000000074505806": 153, "10000000116725759": 153, "10000000149011612": 153, "10000000165202796": 153, "10000000223517418": 153, "10000000252707009": 153, "10000000283627201": 153, "10000000298023223": 153, "10000000359045096": 153, "1000000037252903": 153, "10000000447034836": 153, "10000000521540642": 153, "10000000596046447": 153, "10000000670552253": 153, "1000000074505806": 153, "10000000819563866": 153, "10000000820064922": 153, "10000000894069672": 153, "10000000968575477": 153, "10000001043081283": 153, "10000001266598701": 153, "10001244082020401": 153, "1000454425811768": 153, "1000bce700c": [112, 113], "10029054445525011": 153, "1003419572424118": 153, "1004": 0, "1004699": 104, "100644": [175, 176, 177, 178, 181, 182, 186], "1009": 136, "100x": 116, "100\ud638": 16, "101": [10, 15, 105, 112, 113], "1010": 105, "101183821270789": 153, "10120457": 15, "101289": [24, 27, 28, 34], "1013101627858306": 153, "10145181030060889": 153, "1014644532": 153, "1017326507876506": 153, "10176142491400242": 153, "102": [15, 23, 105, 109], "102048": 24, "1022": 153, "1023": 36, "102319": 29, "1024": [9, 10, 11, 46, 112, 146], "1024x1024": [10, 11, 89], "1024x1204": 11, "10254788": 15, "1026": 31, "1027": 153, "10274352580308914": 153, "1029": 105, "102985": 21, "10300765294167731": 153, "10306088653936361": 153, "1031": 102, "1033524638471561": 153, "10335524227573639": 153, "1036258339881897": 153, "10370859429506546": 153, "104": [29, 30, 96, 112, 113], "104004": 25, "1041": 17, "1045511960983276": 153, "10489286482334137": 153, "10490": 15, "105": [112, 113], "10500": 113, "10500000000000002": 153, "10536051565597443": 153, "1053605156572708": 153, "10544469070737": 108, "10548304048522066": 153, "10556810678833571": 153, "1056187907799229": 153, "10573": 130, "106": [112, 113], "1061245305061154": 153, "10622589196313859": 153, "10646723646540263": 153, "10646782095923937": 153, "10650250803827695": 153, "10655201971530914": 153, "1066": 31, "10666666666550928": 153, "1067636013031006": 153, "10694603919983": 153, "107": 96, "1070": 153, "107119": 29, "1071468107418276": 153, "10722655288680988": 153, "1074": 153, "10741": 10, "1076": 153, "10762037602072623": 153, "10762037602072624": 153, "1076842308044434": 153, "107685": 146, "10785636231303215": 153, "10792532227933407": 153, "10795782655477523": 153, "108": [96, 112, 113], "10802": 17, "108056": 21, "108198": 21, "10834079577106827": 153, "10859449952840805": 153, "108675": 22, "1088065505027771": 153, "109": [104, 113], "1090194": 20, "109033560752868": 153, "1090506": 20, "1090535": [16, 20], "1090566": [16, 20], "1090615": [16, 20], "1090653": 16, "1090654": 16, "1090655": 16, "1090656": 16, "1090657": 16, "1090658": 16, "109110": 104, "1092": [102, 108], "10959": 0, "109789": 21, "10_000": [112, 113], "10m": 131, "10mb": 101, "10min": 151, "10mw": 15, "10\ub144": [15, 17], "10\uc5ec\uac1c": 21, "10\uc6d4": [16, 20], "10\uc6d4\uc5d4": 16, "10\uc870\uc6d0\uc774": 20, "11": [2, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 89, 95, 101, 104, 105, 106, 112, 113, 115, 118, 120, 129, 137, 146, 150, 153, 162, 182, 187], "110": [112, 113, 114, 148], "11000": 113, "110000": 129, "11000000": 104, "11019136048853398": 153, "1103284968522937": 153, "11050952574565061": 153, "11054": [15, 17], "1106": 23, "110689": 15, "11086780652403831": 153, "11087922155857086": 153, "11093106865882874": 153, "110kb": 104, "111": 136, "11100999661663936": 153, "11101613159001103": 153, "11109846010804177": 153, "111111": [32, 34, 150], "111111111090535": 153, "1111111111049383": 153, "11112882122397423": 153, "11113375052809715": 153, "1111360877752304": 153, "11113841906189918": 153, "11113927066326142": 153, "11114718317985535": 153, "11115459278225899": 153, "11115589812397957": 153, "11116116121411324": 153, "1111651249229908": 153, "11117018386721611": 153, "11117456331849099": 153, "11117525771260262": 153, "111176498234272": 153, "11118221059441566": 153, "11118842512369156": 153, "11119341179728508": 153, "1111955966303746": 153, "11119996532797813": 153, "11120561137795448": 153, "11120680719614029": 153, "11121246218681335": 153, "11122014597058297": 153, "11122125610709191": 153, "11122472137212754": 153, "11122925654053688": 153, "11123602688312531": 153, "11124122738838196": 153, "11124403774738312": 153, "1112450510263443": 153, "1112453892827034": 153, "11124621704220772": 153, "11125476285815239": 153, "11126035824418068": 153, "1112654909491539": 153, "11128147840499877": 153, "11129455417394638": 153, "11129547506570817": 153, "11129894480109215": 153, "11130044609308243": 153, "11130479648709297": 153, "11132487207651139": 153, "11136268749833107": 153, "11138427332043647": 153, "111412935305373": 153, "11141293530537302": 153, "11147894263267517": 153, "11148354113101959": 153, "11148485541343689": 153, "1115": 153, "11150938868522645": 153, "11151184756308793": 153, "11153265833854675": 153, "11153553343618199": 153, "11162484937707866": 153, "1117858462035656": 153, "1118": 153, "112051": [32, 34], "1123": 153, "1123066107432047": 153, "112403": [31, 32], "1125": 153, "11258613327854435": 153, "112740": 34, "11289855823852121": 153, "113": [15, 109, 112, 113], "1130": 153, "11305": 0, "1131181314587593": 153, "1131498378701508": 153, "113286": 146, "1133245636868838": 153, "113375616073609": 153, "1137": 0, "11390028382623481": 153, "1139546632766724": 153, "11397136410118747": 153, "114": [31, 146], "11403226852417": 153, "11403467499327492": 153, "1141510665416718": 153, "11457271110266447": 153, "1145889222621919": 153, "11479310813952832": 153, "11479531228542328": 153, "114829": [31, 32, 33], "1149206195026636": 153, "11495007860163847": 153, "11499179378151894": 153, "11500": 113, "11524808398723353": 22, "115277": 29, "1153": 21, "11532": [0, 7], "1154": [21, 153], "11541": [0, 7], "1155": [0, 21], "1156": 21, "115685820579529": 153, "1157": 21, "115784": 22, "1158": 21, "116": [112, 113], "1160": 17, "116052": [31, 32, 33], "1162": 0, "11647273153066635": 153, "11648": 15, "11651808135211468": 153, "11670115184194098": 153, "11676363675255017": 153, "116800": 113, "11688710": 104, "1169": 15, "11692": 100, "117": [17, 104], "117091": 34, "117156": 31, "1172": 104, "117343": 24, "11745118766041761": 153, "117647": 34, "1177": 153, "11778303566220273": 153, "11778303566258155": 153, "1177830356663694": 153, "117794": [31, 32, 33], "1178646906898124": 153, "11790130382631658": 153, "118": [15, 109], "11807400994002819": 153, "11827787994978789": 153, "1183098679418264": 153, "11832280151689759": 153, "1184": 153, "1187": 24, "1188280272579738": 153, "1190": 24, "11903": 54, "11921977251768112": 153, "11929": 0, "1193269466817144": 153, "11934": 0, "11935449063389972": 153, "11942": 100, "1196": 24, "11964958906173706": 153, "1198": 24, "11983944773489327": 153, "1198775447601903": 153, "11b": 118, "11gb": 52, "11it": 24, "11th": [112, 113], "11\uc2dc": 15, "11\uc6d4": [16, 20], "11\uc77c": 142, "12": [0, 2, 10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 101, 112, 113, 114, 118, 120, 129, 137, 146, 151, 153, 162, 187], "120": [112, 113], "12000": 113, "120000": [31, 32, 129], "12000000": 104, "1200600191950798": 153, "1201": 24, "120119": 25, "1202": 24, "1204": 153, "1204772697554695": 153, "12054447084665298": 153, "120547": 31, "1206": 24, "1207": 24, "12075710296631": 153, "1208": 24, "12080522253006873": 153, "1209": 24, "12092": 9, "12095094119498716": 153, "120\uc6d0\uc758": 15, "121": [112, 113], "1211": 24, "12119": 17, "1215004357264235e": 109, "12162": 153, "1218401308467869": 153, "122": [104, 153], "1220": 153, "12248752611724914": 153, "122680844925344": 153, "12268777150029593": 153, "122763804824756": 153, "12283456255415204": 153, "123": [17, 21, 29, 151], "1231940608": 52, "1232157862403148": 153, "1233790211540655": 153, "1234": [102, 108, 109], "12345": [17, 21], "1235": 15, "12379411570727825": 153, "1238": 24, "124": [0, 104, 185], "12404205043696695": 153, "124668386247423": 153, "124735": 29, "12495710347546096": 153, "125": 104, "1250": 153, "12500": 113, "125000": [24, 26, 27, 28, 34], "1251": 17, "125100": 113, "12513122278003186": 153, "12525155174080282": 153, "125443935394287": 153, "125461": [31, 32, 33], "125470572564088": 153, "12559629707700676": 153, "12563702444193925": 153, "1257": 153, "1258461538435896": 153, "125968885421752": 153, "1259989069056579": 153, "12601786963641642": 153, "126036": 22, "12661959749425444": 153, "12661959749425447": 153, "126984": 34, "127": [104, 153], "12733350574271754": 153, "1274": 15, "12773477082244225": 153, "128": [15, 111, 112, 129, 151, 153], "1280": 10, "12805647044959995": 153, "1281": [0, 7], "12815": 26, "12840020135045052": 153, "128420652449131": 153, "128683": 21, "12868913731679366": 153, "1289": [0, 7], "1290": 15, "129101": 25, "129102": 25, "129103": 25, "129104": 25, "129105": 25, "129114331246837": 153, "12911488191024367": 153, "129140": 25, "1293100118637085": 153, "1293967353327041": 153, "12939673533270415": 153, "12968221306800842": 153, "1298573174048215": 153, "1299620866775513": 153, "12999999999861117": 153, "12b": [9, 52], "12gb": 52, "12k": 121, "12th": [112, 113], "12\ub144\ub798": 15, "12\uba85": 20, "12\uc6d4": [21, 22], "12\uc6d4\uae4c\uc9c0": 16, "12\uc77c": 142, "13": [0, 7, 15, 17, 18, 21, 22, 23, 24, 25, 29, 31, 32, 34, 36, 95, 104, 105, 112, 113, 129, 140, 151, 153, 156], "13000": 113, "130000": [129, 137], "13000000": 104, "1300905320340664": 153, "13014": 26, "13018": 26, "130361": 26, "130552": 146, "1305689513683319": 153, "13059370080526506": 153, "1307": 15, "1307074": 153, "13091368600726128": 153, "1309658679251207": 153, "131": 0, "1310": 15, "1313131313048466": 153, "13141210740238118": 153, "13170": 31, "13183": 26, "1319174081261988": 153, "132": [112, 113], "1320184853341844": 153, "13213661321516457": 153, "1323": 15, "13246155834246956": 153, "1324615583424696": 153, "1325481235208962": 153, "13267237772233784": 153, "1329829118": 15, "133": 0, "133255": 146, "133333333284741": 153, "1333530227472592": 153, "133499290822854": 153, "1336003900525302": 153, "13375353018989322": 153, "133837": 31, "133938": 25, "134": [0, 15, 17, 25], "1340019846351324": 153, "13402051515877247": 153, "13437245786190033": 153, "13441046": 104, "13449855148792267": 153, "13461": 100, "134921": 31, "1349883197180439": 153, "13498831971804393": 153, "13500": 113, "13506944700263662": 146, "1351874610643829": 153, "135217": [24, 27, 28, 34], "135226": [32, 34], "1352714304941603": 153, "13535699248313904": 153, "1354": 153, "13548263442620365": 153, "13561280071735382": 153, "13565862607035908": 153, "1359732747077942": 153, "136": [112, 113], "136097": 34, "13616": [15, 17, 21, 23], "13626v1": 0, "13628447167575358": 153, "1363": 104, "136319494247436": 153, "13632233440876007": 153, "136364": [32, 34], "13657896220684052": 153, "13661738585142094": 153, "1367816093": 153, "136832": 108, "1369": 9, "13699999999999998": 153, "13749557": 104, "13758843340302507": 22, "13777777777700623": 153, "1378050723416717": 153, "13799999999999998": 153, "137b": 99, "138": 153, "13809": 20, "1382298469543457": 153, "1384310316397912": 153, "13852907791733743": 153, "13852acc0": 17, "13862943620078907": 153, "1386294362007891": 153, "1388888888878087": 153, "1388972859829664": 153, "139": [24, 112, 113], "139000": 26, "13940305217600987": 153, "139480": 22, "139555": 34, "1397846799755621": 153, "139gwh\uc5d0\uc11c": 17, "13b": [52, 84, 99], "13th": [112, 113], "14": [0, 7, 10, 15, 17, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 43, 52, 89, 99, 104, 105, 112, 113, 121, 129, 134, 146, 151, 153, 185], "140": [0, 21], "14000": 113, "140000": 129, "14003336653113366": 153, "14061422869563103": 153, "1406386292203226": 153, "1406825812533498": 153, "1408": 18, "1409227941185236": 153, "1411447": 23, "141286": 26, "14129233918696021": 153, "14141440639117112": 153, "14153379789657064": 153, "1415460109710693": 31, "14165": 54, "14169538021087646": 153, "14175311097344043": 153, "1419625983771921": 153, "142": 15, "1420": 153, "142012": 32, "14201988305441238": 146, "1420887517385103": 153, "1423": 0, "1423875130712986": 153, "142442607879639": 153, "14265440707643529": 153, "14265440707643534": 153, "1428330622962676": 153, "142857": [27, 28, 34, 150], "143": [112, 113, 120], "14334851156873857": 153, "143526641437244": 153, "143695": 32, "1439800856751984": 20, "144": [114, 153], "1440933644771576": 153, "14425460236335147": 153, "14438456296920776": 153, "14451706111431123": 153, "1446": 25, "144712": 35, "1447671800851822": 153, "145": [15, 104, 153], "14500": 113, "145001": 24, "14501": 24, "1450238458686197": 146, "14511": 24, "145480": 104, "1456": 31, "146": [0, 106], "14605848491191864": 153, "1461": [104, 153], "14618251017493344": 153, "146271950006485": 153, "14648936986923217": 153, "1465": 0, "14652348": 15, "1468": 136, "14699623237570955": 153, "147": [112, 113], "14727157354354858": 153, "14733463600277902": 153, "14767602767328883": 153, "14769100063500679": 153, "1477519493550062": 153, "1479509949684144": 153, "148": 113, "1480": 136, "148148": [32, 34], "14824682586212107": 153, "148436403274538": 153, "14900000000000002": 153, "14916": [0, 7], "1492": [22, 153], "1493610416512177": 153, "14943984682775205": 153, "14944404510495848": 153, "14944404510495854": 153, "14953625": 23, "14987410993346564": 153, "1499894857406616": 153, "149kb": 115, "14gb": 52, "14th": [112, 113], "14x14": 89, "15": [0, 7, 15, 16, 17, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 48, 52, 95, 99, 101, 104, 105, 111, 112, 113, 118, 120, 129, 137, 146, 150, 153, 156, 185], "150": [106, 112, 113, 121], "1500": 113, "15000": 113, "150000": 129, "15001": [0, 7], "15017744898796082": 153, "150223": 26, "1503982663154602": 153, "1508254329363505": 153, "151": 20, "151172319776523": 153, "1512319143641574": 153, "15124760381877422": 153, "1514": 24, "151474952697754": 153, "15148071944713593": 153, "1515486269045268": 146, "15163": 31, "151697635650635": 129, "151900": 113, "15196374676500757": 153, "15206043846975117": 153, "15212869114346": 153, "15242108698649745": 153, "1524210869864975": 153, "15254030227661133": 153, "152613": 35, "1526490034069866": 153, "1532": 0, "15321893766522407": 153, "15333333333240745": 153, "15341": 20, "15389785915613174": 153, "1539": [112, 113], "154": [112, 113], "1540": [112, 113], "15412284717444524": 153, "15412284717444538": 153, "1543": 0, "1547659635543823": 153, "155": [112, 113], "15500": 113, "15523123741149902": 153, "155331552028656": 153, "155797079205513": 153, "155838": 16, "15587535132395897": 153, "156": [23, 31], "15602947": 95, "15648258888424163": 153, "15648258888424169": 153, "1567": 17, "15673434886460502": 153, "1567399942720877": 153, "156780": 22, "157": [15, 121], "15709031459299314": 153, "15716274566948413": 153, "1572": 104, "1574074073806158": 153, "15769056713778093": 153, "15769056713778107": 153, "15771": 95, "15781": 26, "157895": 34, "157958984375": 153, "157th": [112, 113], "158": 25, "15803": 31, "1588389619937186": 153, "15883896199371866": 153, "158wduud": 17, "158wduudsync": 17, "159": [15, 153], "15908": 0, "15919": 0, "1593": 0, "159873457471698": 153, "15w": 113, "16": [0, 10, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 46, 52, 89, 104, 105, 106, 108, 109, 111, 112, 113, 114, 116, 137, 142, 144, 153, 176, 181], "160": [112, 113, 146], "1600": [112, 113], "16000": 113, "1600587368011475": 153, "1603544473648073": 153, "160582": [16, 20], "160583": [16, 20], "160584": [16, 20], "160585": [16, 20], "160586": [16, 20], "160587": [16, 20], "160682597425249": 153, "1607": 0, "1607390195131302": 153, "16078982": 15, "1610017": 153, "16112": 106, "1612120151519776": 153, "161248": 29, "1613579988479614": 153, "16138075318276104": 153, "1613907128572464": 153, "16158807": 15, "16175": 31, "1617922072094629": 153, "16194646654918554": 146, "162": 0, "1621559621911957": 153, "16218523657111322": 153, "16222103513433575": 153, "162235": 35, "16227": 26, "16263582197968346": 153, "162m": 104, "163": [15, 112, 113], "163235473632813": 153, "16333380341529846": 153, "163337": [24, 27, 28, 34], "16347259391720095": 153, "16353459524120556": 153, "1635345952412056": 153, "1636": 0, "1637": [112, 113], "1639": 102, "1639196932315827": 153, "163955656922057": 153, "16396880149841309": 153, "164": 31, "164078": 34, "16409189701080323": 153, "164179": 31, "1642": [112, 113], "164209136644416": 153, "1647925543989872": 153, "16486529111142117": 153, "16486529111142129": 153, "1648890905082226": 153, "165": [112, 113], "16500": 113, "165061561514934": 153, "1653": 15, "16545448899269105": 153, "1656944416877297": 153, "165961": [24, 26, 27, 28], "16637061934840555": 153, "1664350771921802": 153, "16646547615528107": 153, "166540891263221": 153, "16657824232760404": 153, "166667": [31, 32, 33], "1667372226715087": 153, "16681005880236627": 153, "166822": 34, "167": [17, 112, 113, 153], "167014": [31, 32, 33], "16762497072759863": 153, "1676352471113205": 153, "167743": 24, "16778857356312876": 153, "167826": [32, 34], "16785973124959508": 153, "168": 141, "16820714620311472": 20, "168405532836914": 153, "1684190336359297": 153, "16845434930938016": 153, "16879": 31, "168929786103597": 108, "1689504559035084": 153, "16895263698810598": 153, "16911812126636505": 153, "169238": 34, "1693682083627209": 153, "16950989984821221": 153, "16957532687520144": 153, "169595": 146, "1696420858601588": 153, "1698986291885376": 153, "1698990367823524": 153, "16989903679013044": 153, "16gb": 52, "16k": 106, "16min": 151, "16th": [112, 113], "16x": 89, "16x16": [0, 10, 117], "16\uc77c\uae4c\uc9c0": 21, "17": [0, 15, 17, 20, 21, 22, 24, 25, 29, 30, 31, 32, 33, 36, 52, 112, 113, 136, 137, 151, 153, 175, 176, 182], "17000": 113, "17005307972431183": 153, "1702": [112, 113], "1703": [112, 113], "170363187789917": 153, "170499539375307": 153, "1705422348446317": 153, "170billion": [112, 113], "1711": [112, 113], "1715": 0, "171642": 31, "171646059376813": 153, "1716517610327064": 153, "17172210053023365": 153, "171814935737186": 153, "171992": [31, 32, 33], "172": [15, 23, 25], "17203156054019927": 153, "1722": 32, "17222144025044": 153, "172414": 29, "1725": 0, "172619": 32, "172840": 34, "17291411757469177": 153, "173": 15, "17328171317695196": 153, "17329260855913162": 153, "1736": 153, "173666": 16, "17374768014997244": 153, "17386418557316": 153, "173913": 29, "174": 104, "1740421": 16, "174046516418457": 153, "17405880215656602": 153, "17405880215656605": 153, "17419189085101458": 153, "1741918908510146": 153, "1743314877152443": 153, "17435338714266152": 153, "1746": 15, "174603": [31, 32], "1747": [112, 113], "175": [17, 94], "17500": 113, "1752": 153, "1753449941255123": 146, "17555796836192408": 153, "17559212082902823": 153, "1756": [112, 113], "17570182084653996": 153, "1759595423936844": 153, "1759731325287265": 153, "175b": 99, "176": 15, "1760": [112, 113], "176087": [32, 34], "1761984825134277": 153, "1763": [112, 113], "17642224971204995": 153, "1764544": 23, "176471": 34, "1766937747568545": 153, "1767": [112, 113], "17674943804740906": 153, "17691": 31, "177": [104, 106, 153], "1770": [112, 113], "17719": 106, "177700": 113, "177724838256836": 153, "17777777777550618": 153, "177\uba85\uc758": 17, "178": 137, "17823": 106, "1783": [112, 113], "1784573495388031": 153, "17857569058736164": 153, "178878515958786": 153, "17892": 106, "178947": [32, 34], "179": 151, "1790": [112, 113], "17917594700983888": 153, "179317": 29, "1795732287232441": 146, "1795986601151526": 153, "179676280419033": 153, "179702": [31, 32, 33], "179741581835933": 153, "1798": [112, 113], "17994302767120876": 153, "1799878992578683": 22, "17kb": 115, "17m": 121, "17t09": 95, "17\uac1c": 16, "17\uc77c": 21, "18": [0, 7, 15, 16, 17, 21, 22, 24, 25, 29, 30, 31, 32, 34, 36, 52, 105, 112, 113, 118, 129, 131, 151, 153, 176, 181, 185], "180": [15, 112, 113, 153], "1800": 108, "18000": 113, "1801": 153, "1804": [0, 112, 113], "1805": 23, "18050": 113, "180569440788693": 153, "1808": [112, 113], "1808038353919983": 153, "1808829307556152": 153, "1809": [112, 113], "1809079928504717": 153, "181": [106, 112, 113], "1810": [0, 100, 112, 113], "1812": [112, 113], "1813": [112, 113], "18150741010904312": 153, "1816014": 16, "1816015": 16, "1816016": 16, "1816017": 16, "1816018": 16, "1816019": 16, "1817": [112, 113], "18184349636236827": 153, "1819": [112, 113], "182": [25, 31, 101], "1820": [112, 113], "18208635": 23, "1821878125947856": 153, "182338": [31, 32], "1825": [112, 113], "1826": [112, 113], "18260028518696703": 153, "18260028518696708": 153, "18271050453186": 153, "1828": 153, "18297020494937896": 15, "1829920572622323": 153, "183": 104, "1830": [112, 113], "18330565243959426": 153, "1833403348922729": 153, "1833910": [15, 22], "1835544238487878": 153, "1836": [112, 113], "183600": 113, "1836213392910842": 153, "18367815044046804": 153, "1838964819908142": 153, "18399974912e": 111, "1840": [112, 113], "18403090427713625": 153, "1842": [112, 113, 153], "1844": [112, 113], "1846": [112, 113], "1847": [112, 113], "1848": [112, 113], "1849": [112, 113], "185": [112, 113], "1850": [112, 113], "1851": [112, 113], "1851851851687243": 153, "1851851851779427": 153, "18527317950462321": 153, "1852731795046233": 153, "1852ebc": 175, "1855150594204762": 153, "185616": 26, "1856236656572445": 153, "18564963340759277": 153, "18592197238293587": 153, "18595886": 15, "186": [112, 113], "1860": [112, 113], "1861": [112, 113], "1864": [15, 112, 113], "1865": [112, 113], "1865225060661841": 153, "18653": 0, "1867": [112, 113], "18675": 20, "1868": [112, 113], "1869": 15, "1870": [112, 113], "187050": [32, 34], "18708438146379341": 153, "18708438146379353": 153, "1871": [112, 113], "1872": [112, 113], "1874": [112, 113], "1875": [112, 113], "18751066848635672": 153, "1876": [31, 32, 33], "1880": [112, 113], "188141": [24, 26, 27, 28], "1884039598180809": 153, "1884751": 15, "18859166279435158": 153, "1887": 15, "18870800407669353": 153, "1887080040766936": 153, "1887123200628493": 153, "188889": [31, 32, 33], "188892364501953": 153, "1889": [112, 113], "18890943971152108": 153, "188m": 104, "1890": [112, 113], "1890276476740837": 153, "18903659284114838": 153, "18904": 21, "1891": [112, 113], "1891543977169527": 153, "18927": 21, "18929": 21, "1893": 23, "18931": 106, "1896": [112, 113], "1897\ub144": 15, "18980654629698515": 153, "18980654629698537": 153, "18it": 25, "18th": [6, 112, 113, 130], "18\uc77c": 21, "18\uc870\uc6d0\uc774": 20, "19": [0, 15, 16, 17, 20, 21, 22, 24, 25, 29, 30, 31, 34, 101, 105, 111, 112, 113, 121, 129, 130, 153, 175], "190": [15, 122, 131], "1900": [15, 112, 113, 120], "19002137333154678": 153, "19004649233998394": 153, "19009": 106, "1901": [112, 113], "1902236282755808": 153, "1903": [112, 113], "19030399062256848": 153, "1904761904604435": 153, "1906": 0, "1907": 100, "19086722037431578": 153, "1909": 100, "191": 31, "1910": [100, 112, 113], "19106": 21, "1911": [112, 113], "1911078766376401": 153, "1913": [112, 113], "191378": 35, "1914": [15, 112, 113], "1915": [112, 113], "19151053100118282": 52, "19152449071407318": 153, "19153348461822214": 153, "1916": 52, "191633939743042": 153, "1919059753418": 153, "19198": 21, "192": 141, "1920": [112, 113], "1921": [112, 113], "1921483874320984": 153, "192296480531112": 153, "19242175789761945": 153, "19242175789761948": 153, "1925": [112, 113], "19258639": 23, "1926": [112, 113], "1928": [112, 113], "1929": [112, 113], "19295595935546": 109, "193": [15, 23, 153], "1930": [0, 120], "1931": 120, "19323829": 15, "1935215424746275": 153, "1936": [112, 113], "1937": [112, 113], "1938": [112, 113], "1939": [112, 113], "193974": 104, "1940": [112, 113], "1941": [112, 113], "19411": 52, "1943": [112, 113], "1945": [112, 113], "19457": 106, "1945817530155182": 153, "1946": 35, "19466acc0": 17, "1947": 35, "19470537423940926": 153, "194737": 32, "19478": [24, 26, 27, 28], "1948709785938263": 15, "1950": [50, 112, 113], "1951710104942322": 153, "1954": [0, 24, 112, 113, 157], "1955": [0, 6, 112, 113], "19555555557": 153, "1956": [112, 113], "1957": [0, 157], "19584": 17, "1960": [112, 113, 120], "1961": [112, 113], "1962": [112, 113], "19620483368635178": 15, "19628": 21, "1963": [112, 113], "1964": [112, 113], "1965": [35, 112, 113], "19650192408718997": 153, "19650308787822723": 153, "1966": [112, 113], "1967": 153, "1967119961977005": 153, "196754": 29, "1967\ub144": 16, "196m": 137, "1970": [0, 112, 113, 121, 146], "1970\ub144": 16, "1972": [112, 113], "197224577329997": 153, "1973": [6, 112, 113], "19735": [24, 26, 27, 28], "1974": [112, 113], "197402000427246": 153, "1975": [112, 113, 153], "1976": 121, "19767125672509347": 153, "1976712567250935": 153, "197674": 32, "1976\ub144": 16, "1977\ub144\uc5d4": 16, "1978583": 153, "197859": 29, "1979": [24, 112, 113], "198": [15, 17], "1980": [50, 112, 113], "19806": [24, 26, 27, 28], "1981": [112, 113], "1981\ub144": 16, "1982": [24, 25, 26, 27, 28, 32, 34, 52, 112, 113], "19823": 21, "1983": [24, 25, 26, 27, 28, 32, 34], "1984": [112, 113, 129], "198534": 20, "198538": 20, "198592": 20, "198596": 20, "198598": 16, "198599": 16, "1986": [112, 113], "198600": 16, "198601": 16, "198602": [16, 20], "198603": 16, "19868": 21, "1987": [24, 112, 113], "19888888888711426": 153, "1989": 29, "19890510874489944": 153, "1989105820655823": 153, "1989564895629883": 153, "1990": [31, 32, 33, 35, 112, 113], "19907079886438117": 153, "19907247605216172": 153, "1990\ub144\uc744": 22, "1992": [112, 113], "19926": 21, "1993": [31, 112, 113, 121, 151], "19939": 21, "1994": [112, 113, 121], "1995": 35, "1997": [29, 130], "19972720742225647": 153, "19976201755926012": 153, "199784937807312": 109, "1997\ub144": 16, "1998": [29, 32, 112, 113], "199893": 21, "1998\ub144": 16, "1999": [32, 33, 34, 35, 112, 113, 124, 152], "1999\ub144": [16, 21], "19mb": 52, "19th": [112, 113], "19\uc2dc": 142, "1b": [89, 99], "1e": [29, 31, 52, 113], "1f": [113, 129], "1f354j2g": 17, "1f354j2gsync": 17, "1gb": 52, "1gss34v9": 17, "1gss34v9sync": 17, "1h": 15, "1m": [18, 23, 31, 113, 131, 133, 136, 137, 142, 151], "1m0b7bee": 17, "1m0b7beesync": 17, "1m5majkn": 17, "1m5majknsync": 17, "1mb": [101, 104], "1min": [15, 151], "1mwandb": [18, 23, 31], "1r3nk1yw": 18, "1r3nk1ywsync": 18, "1s5a57gq": 17, "1s5a57gqsync": 17, "1st": [130, 137], "1sxdb0f": 18, "1sxdb0fssync": 18, "1t": 118, "1trwr7nn": 17, "1trwr7nnsync": 17, "1x0zsmyr": 17, "1x0zsmyrsync": 17, "1x1": 89, "1ym4z9wq": 17, "1ym4z9wqsync": 17, "1yqr3hin": 17, "1yqr3hinsync": 17, "1\ub144\uc5d0": 15, "1\uc2dc": 142, "1\uc2dc\uac04\ub9c8\ub2e4": 17, "1\uc6d4": 16, "1\uc6d4\ubd80\ud130": 16, "1\uc77c": [15, 16, 20], "1\uc77c\ubd80\ud130": [16, 20], "1\uc8708000\uc5b5\uc6d0\uc774": 20, "1\uc8fc\ub2f9": 15, "2": [0, 1, 2, 5, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 36, 52, 60, 78, 79, 89, 95, 96, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 123, 125, 126, 131, 133, 134, 136, 137, 138, 139, 140, 144, 146, 149, 150, 151, 152, 153, 154, 156, 158, 162, 175, 178, 181, 182, 183, 185, 187], "20": [0, 7, 10, 15, 16, 17, 20, 21, 22, 24, 26, 27, 28, 29, 31, 36, 88, 89, 102, 104, 105, 112, 113, 116, 133, 137, 142, 151, 153, 168, 176], "200": [7, 16, 25, 29, 52, 96, 112, 113, 134, 151, 153, 168, 171], "2000": [31, 33, 34, 106, 108, 109, 112, 113, 128, 130, 136], "20000": 129, "200000": 31, "2000000": 104, "20003": 26, "2000\ub144": 16, "2001": [112, 113], "2001\ub144": 21, "2002": [29, 112, 113, 120, 121], "2002883156967014": 153, "2003": [0, 112, 113, 123, 128, 153], "20039150988062224": 153, "2003\ub144": 15, "2004": [0, 6, 29, 104, 112, 113, 146], "20041acc0": 17, "2004\ub144": 16, "2005": [54, 112, 113, 129], "20050": 54, "200595378875732": 153, "2006": [0, 24, 112, 113, 146], "2007": [29, 112, 113, 121], "2008": [24, 29, 34, 112, 113], "200829": 21, "2008336848682828": 153, "2009": [34, 112, 113, 136, 153], "200905406979172": 153, "200m": 121, "200\ubc30": 21, "200\ud638\uc5d0": 16, "201": [102, 106, 112, 113, 146], "2010": [0, 34, 112, 113, 121], "2011": [29, 112, 113, 120, 122, 131, 136, 153], "2012": [37, 112, 113, 122], "2012\ub144": 16, "2013": [0, 112, 113, 129, 185], "201319": 21, "2014": [0, 6, 24, 25, 31, 111, 112, 113, 126], "201426": 34, "2015": [0, 25, 29, 31, 72, 102, 112, 113, 148], "20158361": 153, "2016": [0, 24, 54, 88, 102, 106, 107, 112, 113, 120, 121, 125], "201600": 21, "2017": [0, 7, 15, 50, 54, 98, 102, 105, 112, 113, 114, 117, 130], "20179854333400726": 153, "2018": [0, 7, 24, 34, 54, 96, 100, 102, 106, 107, 112, 113, 114, 120, 121, 130], "201831": 21, "20184": 113, "2018\ub144": [15, 16, 17, 21], "2019": [0, 7, 11, 95, 96, 98, 100, 102, 112, 113, 118, 120, 121, 130], "2019\ub144": 17, "2020": [0, 7, 15, 16, 20, 22, 54, 94, 96, 98, 100, 112, 113, 116, 117, 118, 120, 121, 137, 142], "20200101001103001": 22, "20200101001253001": 22, "20200101001855001": 22, "20200101040159002": 22, "20200101040200001": [15, 16, 22], "20200101040200002": [15, 16, 22], "20200101040201001": [15, 22], "20200101040202001": [16, 22], "20200101040206003": 22, "20200101060214001": 22, "20200101183234001": 22, "20200101184423001": 22, "20200101_20200115": 16, "20200102040158002": 20, "20200102080234001": 20, "20200103000814001": 20, "20200108092412001": 20, "20200108160505001": 15, "20200224163725001": 15, "20200320001516001": 15, "20200323170208001": 20, "20200326172754001": 15, "20200421102241001": 15, "20201101060124001": 16, "20201101082723001": 16, "20201101090150001": 16, "20201101090515001": 16, "20201101092641001": 16, "20201101113442001": [16, 20], "20201101125903001": [16, 20], "20201101130118001": [16, 20], "20201102114419001": 20, "20201231110236001": 22, "20201231111427001": 22, "20201231132917001": 22, "20201231140203001": 15, "20201231141813001": 15, "20201231164457001": [15, 22], "20201231171734001": 15, "20201231204324001": [15, 22], "202050316333771": 153, "2020a": 96, "2020b": 96, "2020\ub144": 17, "2020\ub144\uc740": 22, "2021": [0, 7, 15, 21, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 54, 112, 113, 116, 117, 120, 121, 133, 136, 142], "20210101002609003": 15, "20210101002610001": 15, "20210101002615001": 15, "20210101040137001": 15, "20210101040138001": 15, "20211116142132001": 15, "20211123210051001": 15, "20211201094104001": 15, "20211209160337001": 15, "20211222141644001": 15, "20211231104409001": 15, "20211231112402001": 15, "20211231112403001": 15, "20211231115157001": 15, "20211231143447001": 15, "20211231150933001": 15, "20211231181802001": 15, "20211231182324001": 15, "20211231210909001": 15, "202195": 29, "2021\ub144": [15, 20], "2022": [0, 7, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 35, 54, 96, 99, 113, 116, 117, 124, 133, 153, 182], "20220101002520005": [15, 22], "20220224155144001": 20, "20220228050135001": 20, "20220228093428001": [16, 20], "20220228103653001": [16, 20], "20220228154344001": [16, 20], "20220228184928001": 16, "20220228190438002": 16, "20220228193736001": 16, "20220228205136001": 16, "20220228223323001": 16, "20220301": [112, 113], "20220308000798": 124, "20220527101334001": 20, "20220527154429001": 20, "20220531091955001": 20, "20220531112630001": 20, "20220531150108001": 16, "20220531154303001": [16, 20], "20220701_020155": 31, "20220816001711": 124, "20220905_company50": 16, "20220906_071028": 18, "20220906_071142": 18, "20220906_071214": 18, "20220906_071333": 18, "20220906_071403": 18, "20220906_071523": 18, "20220906_071554": 18, "20220906_071712": 18, "20220906_071742": 18, "20220906_071900": 18, "20220919_090235": 17, "20220919_092838": 17, "20220919_092902": 17, "20220920_005201": 17, "20220920_010015": 17, "20220920_010205": 17, "20220920_010232": 17, "20220920_010421": 17, "20220920_010448": 17, "20220920_010633": 17, "20220920_010700": 17, "20220920_010846": 17, "20220920_010913": 17, "20220920_011101": 17, "20220920_021330": 17, "20220920_021512": 17, "20220920_022059": 17, "20220920_022233": 17, "20220920_022302": 17, "20220920_022431": 17, "20220920_022500": 17, "20220920_022632": 17, "20220920_022703": 17, "20220920_022833": 17, "20220920_022901": 17, "20220920_023029": 17, "20220920_024031": 17, "20220920_024240": 17, "20221001": 104, "20221215_115806": 23, "20221215_120145": 23, "20221216_003124": 23, "20221216_003453": 23, "2023": [0, 15, 46, 54, 85, 101, 113, 136, 137, 142, 175, 176, 181, 185], "2024": 105, "20244873": 15, "202692": 150, "2027769971690658": 153, "20281956968249237": 153, "20281956968249248": 153, "2030": 153, "2030\ub144": 17, "2030\uc744": 16, "20324": 21, "20325": 21, "20325291559000797": 153, "20326": 21, "20327": 21, "20327777777305223": 153, "20328": 21, "20333": 21, "20334": 21, "20335": 21, "20336": 21, "20337": 21, "2034": 151, "2034636748385512": 153, "20347139984369278": 153, "203739": 26, "20374327898025513": 153, "203924": 16, "20406588969959": 153, "20446": 106, "20447": 106, "2048": 10, "20483024": 153, "2049560397863388": 31, "2050\ub144\uc774\ub2e4": 22, "2056": 0, "20602956772264508": 153, "20622534751892": 153, "20629671216011047": 153, "20632": 15, "206367": 34, "206845": 22, "206995": 29, "207386240153904": 153, "207419": 26, "207547": 31, "20784": 153, "207940": 20, "208333": 34, "20854200422763824": 153, "20906424522399902": 153, "20915542462219794": 153, "209552": [31, 32, 33], "209571909913137": 153, "20newsgroup": 150, "20th": [112, 113], "20\ub144": 21, "21": [0, 7, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 101, 102, 104, 108, 109, 111, 112, 113, 115, 131, 137, 153], "21000": 112, "21000000000000002": 153, "2101934199945794": 153, "2102": 9, "2103": 10, "2105": 0, "210568908088681": 153, "21072103130978853": 153, "21077627": 153, "2108678847586545e": 109, "210945653270672": 153, "2109678855560513": 153, "211": 153, "21100983675569296": 153, "21118": 29, "2112": 10, "2113": 153, "211580514907837": 153, "21183": 106, "212": 15, "212170": 25, "21217251856446653": 20, "2125246165440904": 153, "2127181026670668": 153, "2129": 105, "212986089077653": 36, "213010": [31, 32, 33], "21341": 106, "21346006609706414": 153, "2135": 0, "2137": 15, "213700": 113, "213922": 29, "21400000000000002": 153, "2140641365107059": 153, "21452752351760865": 153, "2146502597464455": 153, "21479199138056074": 153, "2150": 153, "215196074379815": 153, "215686": 31, "215800": 113, "216": 25, "2163301201716118": 153, "2163301201716119": 153, "21656668186187744": 153, "2167186163365841": 153, "216783": [31, 32], "21728213826815287": 15, "21751579642295837": 153, "217525332521506e": 109, "21764491": 23, "2178465873003006": 153, "2179": [21, 23], "2180174231529235": 153, "21807907607263988": 146, "2182841300964355": 153, "2183526396751403": 153, "21852376175624544": 153, "21875141391323671": 153, "219": [32, 34], "2190274": 15, "219403": [31, 32, 33], "2195909172296524": 153, "21it": 104, "21min": 151, "21st": [112, 113], "22": [0, 7, 10, 15, 16, 17, 20, 21, 24, 29, 31, 32, 33, 34, 36, 104, 112, 113, 129, 137, 151, 153], "220": [112, 113, 118, 123], "2200": 106, "2201": 54, "220126": 31, "22015353503574592": 22, "2202": 0, "2205": [0, 106], "22052617371082306": 153, "2206": 0, "2207": 0, "2207817789982073": 153, "2208": [0, 7], "22083134949207306": 153, "2208441019058227": 153, "22086668": 23, "2209": [0, 7], "2210555225610733": 153, "22110844002351862": 22, "22142546": 15, "221891": 29, "221892": 29, "222": [20, 112, 113, 129], "22205013036727905": 153, "222222": 34, "2223": 36, "222329": [24, 26, 27, 28], "222721": [32, 34], "222771860531334": 153, "222928": [24, 26, 27, 28], "223181": 22, "2232bf3": 184, "22353": 17, "2238002725221477": 153, "223855": 150, "22386": 153, "224": [112, 113], "224036483432627": 108, "224238872528076": 31, "2242692696241041": 153, "2244161333617765": 153, "224525048": 104, "2245705448013361": 22, "22467442005872726": 153, "22468823567808915": 153, "2247240034286678": 153, "22482402838833196": 153, "2249209702014923": 153, "224x224": 10, "225": 153, "2256082773208616": 153, "225806": 29, "225879836082458": 153, "226": 20, "226201621008416": 153, "2263261437416078": 153, "226467": 24, "22646935797399945": 153, "226677": 26, "227077": 20, "2272521961226583": 153, "2273": 15, "22738339269375524": 153, "22741": 106, "22745": 106, "2274680429034763": 153, "2275": 15, "2275139331817626": 153, "22767148911952972": 153, "227756137638969": 153, "228": 113, "228070": [32, 34], "2281": 104, "228681125865242": 153, "228714": 26, "22875212784856558": 153, "2288841644922892": 153, "2293009676418639": 30, "229571372270584": 153, "22974988263514307": 153, "2298": 24, "22gb": 52, "22it": 104, "22nd": [0, 112, 113], "22xgmnw8": 23, "22xgmnw8sync": 23, "22\uc77c": [15, 21], "23": [0, 15, 16, 17, 21, 24, 29, 31, 95, 101, 112, 113, 118, 136, 137, 142, 146, 151, 153, 185], "230": [16, 18, 21, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 112, 113, 153], "230078": 24, "2301": 0, "23018273615527657": 153, "2304922645497653": 153, "2305": 54, "230519461631775": 153, "2308": 54, "231": [112, 113], "231485": 24, "23162247641012074": 153, "23194885086268185": 153, "232": [15, 21], "2321656532999542": 153, "2325001955032349": 153, "23292849957942963": 153, "232k": 115, "2330": 15, "2330093636364418": 153, "233062": 24, "23333306312561": 153, "2333679087460041": 153, "2334528881435593": 153, "2335412502288818": 153, "233715": 26, "2338264191316234": 153, "2339521853385075": 153, "234047": 29, "23411971915790059": 153, "23427294194698334": 153, "234318804740906": 153, "234340": 26, "234429": 29, "234434127807617": 153, "2344785405840311": 153, "234567901196464": 153, "234650719165802": 153, "234776": 24, "2349082961678505": 153, "235": 22, "235069": 25, "235554731218934": 153, "2355661774882012": 153, "2359296": 52, "235955": 31, "236": 111, "23679817765951156": 153, "23692641034722328": 153, "23776455167163577": 153, "238": [112, 113], "23802": 153, "2380435297265649": 153, "238197326660156": 153, "2382670289940303": 153, "238576": 150, "23889190826607307": 153, "238902": 35, "238952159881592": 153, "239": [23, 109], "2390": 31, "2391": 31, "2392": 31, "23927003145217896": 153, "2393": 31, "2393397092819214": 153, "2394": 31, "2394mib": 113, "2395": 31, "239583": [31, 32], "23980206837877632": 153, "239959": 29, "23rd": [112, 113], "23\uc2dc": 142, "24": [10, 15, 16, 17, 18, 22, 23, 24, 29, 31, 32, 34, 36, 86, 104, 112, 113, 114, 118, 137, 146, 153], "240": 104, "2400": 153, "24045217": 15, "240481845103053": 153, "2404918": 146, "2405412077903748": 153, "24066539108753204": 153, "2408658489817811": 153, "24086584898178115": 153, "24092480540275574": 153, "241245746612549": 153, "241290": [32, 34], "24153346777929982": 153, "2416311651468277": 153, "2416791915893555": 153, "2417418599128722": 153, "24206": 0, "242064": 129, "24221": 0, "242317545413971": 153, "242745341360569": 153, "243": [112, 113], "243070": [32, 34], "24317131489515303": 153, "243324": 34, "243343": [32, 34], "24354935751654835": 153, "243671": 22, "243672": 22, "243673": 22, "243674": 22, "243675": 22, "244": [112, 113], "2441218301929142": 153, "24425282842966542": 153, "2442528284296655": 153, "244442932288125": 153, "2445598989725113": 153, "2447265088558197": 153, "2448540449142456": 153, "24508911790326238": 153, "245335590839386": 153, "245509": [32, 34], "246029": 29, "24603603780269623": 153, "2463554620742798": 153, "2468165174126625": 153, "247": [104, 112, 113, 120], "247149721569528": 153, "24714972156952805": 153, "2472682": 15, "2477": 136, "2477717101573944": 153, "24786447": 153, "24800": 24, "248177": 34, "2484613592937987": 153, "24863": 95, "2488": 15, "24899999999999997": 153, "249": 185, "24900000000000003": 153, "24931146192053955": 153, "249377": [24, 26, 27, 28], "24949350953102112": 153, "2499561309814453": 153, "24gb": 52, "24mb": 104, "24th": [112, 113], "25": [15, 16, 17, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32, 36, 48, 95, 96, 99, 112, 113, 118, 121, 129, 130, 137, 143, 153], "250": [10, 112, 113], "2500": 113, "25000": 111, "250000": [31, 32, 34, 150], "250046": 21, "2505337163909442": 153, "250626658245578": 153, "250735392794013": 153, "25080054998397827": 153, "25091810534198355": 153, "250m": 9, "251": [15, 24, 104], "25133133": 15, "251404": 15, "251764": 34, "25201512277126314": 153, "2521924495697023": 153, "25219999875725335": 153, "2521999987572534": 153, "2522": 31, "25237317085266": 153, "25252525251887564": 153, "2525869905948639": 153, "25280910134315493": 153, "25286320050557454": 153, "253": 153, "253649": 21, "2537673862402816": 153, "2540597200393677": 153, "254098796844483": 153, "25424020821444454": 153, "25457": 106, "25461": 106, "254611086845398": 153, "25463688023094283": 15, "25475": 106, "2548": 17, "2548acc0": 17, "2552475929260254": 153, "256": [9, 15, 17, 18, 20, 23, 31, 89, 118], "2561096668243408": 153, "2561513797552215": 153, "2562444779607984": 153, "25635379552841187": 153, "2565449684858322": 153, "25664": 17, "256899498630729": 153, "25697005": 15, "256x256": [10, 11], "2570201081641083": 153, "257080": 29, "25730": 137, "25743132426534937": 153, "2574427025423358": 153, "2575892210006714": 153, "2577278188119332": 153, "25782379508018494": 153, "258": [122, 131], "258090591430664": 153, "2581": 106, "2581733147753403": 153, "25819794668091667": 153, "2583255767822266": 153, "2584400296211242": 153, "2584603667259215": 153, "258500": 113, "258536": 22, "258537": 22, "2585714322398417": 153, "258632": 104, "2590": 31, "25913405418395996": 153, "259259": 31, "2592729784548283": 153, "25942555218935015": 153, "259526": 34, "259527": 146, "259843": 29, "25992": 137, "25999999999999995": 153, "25h": 136, "25hbuild": 136, "25hrequir": [133, 136, 137, 151], "25ldone": 136, "25min": 15, "25th": [112, 113], "25\uc77c": [15, 20], "26": [11, 15, 16, 17, 22, 24, 25, 26, 27, 28, 29, 31, 32, 34, 86, 96, 101, 108, 112, 113, 129, 143, 146, 153, 175], "260": [112, 113], "2601": 104, "260452628135681": 153, "26048": 137, "260563": 32, "2607381343841553": 31, "2607411935925484": 153, "2607489824295044": 153, "26096": 31, "26100": 137, "26130": 137, "261365": 35, "261628": 31, "261657238006592": 129, "26177132": 146, "262141": [31, 32], "26224": 106, "26241374015808105": 153, "2626262625994085": 153, "262964129447937": 153, "263": [15, 153], "263141": 24, "2635118961334229": 153, "2641089407861668": 146, "26436833": 153, "264435": 32, "264450388285885": 153, "2646642609779317": 15, "264700": 113, "26487721796664926": 153, "26491374": 153, "265": 15, "26517586410045624": 153, "2654": 52, "26574485265980285": 153, "26576": 151, "26592340022325517": 153, "26599999999999996": 153, "266217577457428": 153, "2663285652796427": 15, "2668755257019132": 153, "26687552570191325": 153, "267111": 22, "2673": 153, "26747798919677734": 153, "267557430267334": 153, "267766": [24, 26, 27, 28], "267790": 15, "26809704303741455": 153, "268116643244866": 108, "2682366371154785": 153, "268511325444344": 153, "269231": [32, 34], "269355": 20, "26945594184191995": 146, "269513": 35, "269841269819602": 153, "26\uc77c": 17, "27": [11, 15, 16, 17, 18, 22, 23, 24, 29, 31, 32, 33, 36, 52, 70, 112, 113, 118, 146, 153], "270": 153, "270096": 24, "270118": 34, "2709275364875794": 153, "2709827545409401": 153, "2715209622206862": 153, "2715209622206863": 153, "271877": 22, "27219223976135254": 153, "2724": [21, 23], "2724171280860901": 153, "272474583729167": 153, "272716283135944": 153, "27308953884575": 153, "2734027441797985": 153, "2735632185": 153, "2738": 113, "273856472969055": 153, "274": [112, 113], "274252": 106, "274359": 20, "2744368456982516": 153, "274446924376207": 156, "274910": 146, "2756188680003915": 153, "27564658059061264": 153, "276": 15, "276040": 21, "2760459780693054": 153, "27618899941444397": 153, "2762430664151907": 153, "276408004760743": 153, "27650429494678974": 153, "27655373497141733": 153, "277": 31, "277136898040773": 153, "2771944399682726": 153, "2772588723025781": 153, "2773457169532776": 153, "277665": [24, 26, 27, 28], "277778": 32, "2777975a2334c2396ccb9faf98ab149824ec465b": 185, "278": [112, 113], "278030": 146, "2780546369890838": 153, "2780742120763763e": 153, "2781986892223358": 153, "27821696095948567": 153, "278689": 29, "279": [112, 113, 153], "2793": 0, "27944541030519776": 153, "279606819152832": 153, "279688": 31, "27975747734308243": 153, "28": [15, 16, 17, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 34, 36, 112, 113, 115, 124, 153], "280": [53, 112, 113], "2802": 25, "2803": 0, "280368": 26, "28047922": 15, "280516": [31, 32], "2807204246521": 153, "280933845461242": 153, "280b": 99, "281": 25, "281398": 15, "2817": 25, "281742": 35, "28175778368280996": 153, "2817714214324951": 153, "2818": 25, "2819": 25, "282": 20, "2820": 25, "2820512820238879": 153, "2821": 25, "282110285758972": 153, "282835324932625": 153, "2829674184322357": 153, "2831": 113, "283419132232666": 153, "283658": [27, 28, 34], "283784": 34, "2840523043982159": 153, "284129": 29, "2844853401184082": 153, "2845817714929582": 153, "285": [25, 112, 113], "2850": 25, "2850092927096146": 153, "2850300274976867": 153, "2851": 25, "2851081848144532": 153, "2852": 25, "2853": 25, "2853970527648926": 153, "2854": [25, 31], "285564": [32, 34], "285714": 29, "285999862353007": 15, "286": [17, 25, 31], "2861169584095478": 153, "28614394288966066": 153, "28614394288966083": 153, "286240578111675": 153, "28673261404037476": 153, "286880": 34, "2868936721207613": 153, "287": [25, 31], "28705792129039764": 153, "28712310772271554": 153, "2874221801757812": 153, "2876820724414198": 153, "2877488086620967": 153, "2877505226455023": 153, "28775052264550244": 153, "287804": 20, "287821763753891": 153, "28789310455322265": 153, "288": [25, 31], "2883289317289988": 15, "2885": 104, "288551": 34, "288624": [27, 28, 34], "288802": 34, "289": 153, "289473260111279": 153, "2895": 153, "28970395103096963": 153, "28987571597099304": 153, "28it": 24, "28\uc77c": 16, "29": [15, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 112, 113, 118, 121, 129, 146, 151, 153], "290": [24, 26, 27, 28, 112, 113], "290000": 26, "29000000000000004": 153, "2900974750518799": 153, "29022714495658875": 153, "2903820521198213": 153, "2906177127978444": 153, "291": 0, "29130387": 15, "2915966510772705": 31, "29187180995941164": 153, "2918782234191895": 129, "2919665389931534": 153, "29211614": 153, "2927805900573732": 153, "293520": 32, "293573": 20, "2936119906": 153, "29369887570285214": 153, "293700": 113, "2937325588117043": 153, "293935": 26, "2939641773700714": 153, "294": 104, "2941": 106, "2957142441467513": 153, "295765495300293": 153, "29584785221336524": 153, "295981720050152": 153, "296": 153, "2960053444307032": 153, "29600534443070325": 153, "2960137814283371": 15, "29665989984447755": 153, "2967510416892118e": 109, "297": 133, "2972231205811517": 153, "2974543133079955": 153, "29756946355149305": 153, "297673": 34, "2978416590213351": 153, "2978416590213352": 153, "2978954613208771": 153, "298": [31, 133], "29808357678767705": 153, "2981277704238892": 153, "2988475929530144": 153, "29894404822132653": 153, "29911605285273657": 153, "2993130683898926": 153, "2994259119033815": 153, "29996280868848163": 153, "29c": 113, "29it": 25, "29\uc77c": [15, 22], "2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec": [102, 104, 108, 109], "2a59bqsm": 17, "2a59bqsmsync": 17, "2a74d89": 184, "2bclip": 10, "2ceyf1n4": 17, "2ceyf1n4sync": 17, "2d": [7, 127], "2e": 46, "2e7jflgg": 18, "2e7jflggsync": 18, "2f": [26, 32], "2fa": [78, 79], "2h04jfx6": 23, "2h04jfx6sync": 23, "2k": [133, 136, 137, 151], "2min": 151, "2m\uc758": 142, "2ngg0tpm": 17, "2obg8t98": 18, "2oivm1t2": 17, "2oivm1t2sync": 17, "2s63fdzf": 17, "2s63fdzfsync": 17, "2vv0hewt": 18, "2vv0hewtsync": 18, "2x": [89, 116, 118], "2yq3mw4j": 17, "2yq3mw4jsync": 17, "2zt1qpx2": 17, "2zt1qpx2sync": 17, "2\u00b2\u2075": 118, "2\uacf5\uc7a5": 21, "2\ub144": 21, "2\ub300": 16, "2\ub9cc": 21, "2\ubd84\uae30\uc5d0": 17, "2\uc2dc": 142, "2\uc6d4": 16, "2\uc6d4\ubd80\ud130": 16, "2\ucc28\uc804\uc9c0": 21, "3": [0, 2, 6, 9, 10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 43, 48, 50, 52, 56, 62, 75, 84, 93, 94, 98, 99, 101, 102, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 133, 134, 136, 137, 140, 144, 146, 147, 150, 151, 152, 153, 162, 175, 176, 181, 182, 185, 187], "30": [0, 4, 7, 15, 17, 22, 23, 24, 25, 31, 32, 33, 34, 35, 36, 71, 88, 97, 101, 104, 112, 113, 130, 140, 146, 151, 153, 162], "300": [10, 112, 113, 151], "3000": [113, 128], "30000": [104, 111, 113, 129], "3000000": 104, "300007": 24, "3000326329631926": 153, "30006176233291626": 153, "300k": 121, "300m": 10, "300w": 113, "300\ud638": 16, "301": 104, "301071643829346": 153, "30110509278196973": 153, "3012711354385487": 153, "3019773": 146, "3027957253985933": 153, "30285680294036865": 153, "3028968002392749": 20, "302897": 20, "303": [112, 113], "3035161207119624": 153, "3037643601664413": 153, "303969": 26, "303\uc5b5\uc6d0\uc744": 15, "304293155670166": 153, "305": 121, "30500775774319966": 15, "3050496578216553": 153, "30523637334505715": 153, "305328941345215": 153, "3054954707622528": 153, "305556": 31, "3058826974593103": 153, "30588778853416443": 153, "3059754371643066": 153, "306": [0, 15, 29, 35], "3061930537223816": 153, "3062569569796324": 153, "3063109305169847": 153, "3065742522854": 153, "3066": [31, 32, 33], "3066542577943232": 30, "307": [29, 112, 113], "3072": 113, "3075068242847919": 153, "307692": 34, "30779310458650194": 153, "3078935027122498": 153, "30799426429340176": 153, "308": 29, "3080440490": 153, "3081002600491047": 153, "30811312794685364": 153, "3081607738509774": 153, "308204": 29, "30842970315780904": 153, "308485984802246": 153, "308928": 34, "3089823722839355": 153, "309": 29, "309001147774482": 153, "30900114777448207": 153, "3091985285282135": 153, "3093050652080112": 153, "30939303582741157": 153, "309474611282349": 153, "309476": 34, "309712243080139": 153, "30_000": 113, "30e0ccb": 184, "30k": 147, "30min": 15, "30tb": 118, "30th": [24, 112, 113], "30\ub144": 22, "30\ubd84": 15, "31": [15, 23, 24, 25, 31, 32, 33, 35, 112, 113, 133, 136, 137, 141, 142, 151, 153, 185], "310": 29, "31062971577048304": 153, "311": 29, "31138": 31, "311434030532837": 31, "3115": 0, "3119921805544": 153, "312158226966858": 153, "3124418258666992": 153, "3125058130824736": 153, "3125091246325367": 153, "3126": 15, "3126117847152092": 153, "3128114342689514": 153, "3128788981690175": 153, "313": 153, "31315051799433097": 153, "31341073": 153, "31365885996615045": 153, "3136588599661505": 153, "3136667526430554": 153, "314": [104, 112, 113], "3143009778112173": 153, "3143158": 15, "314413": 34, "314837": 146, "3149481895897124": 153, "314956903457642": 153, "31518845558166503": 153, "3152145147323608": 153, "31562480330467224": 153, "315789473664974": 153, "3160255074501037": 153, "316108": 20, "316640100991759": 153, "31665071715186865": 153, "317": 23, "317378": 129, "317392498254776": 153, "317460": [31, 32, 33], "317580962181091": 153, "318096989863972": 153, "318610280752182": 153, "318708": 26, "31882762478330307": 153, "3188276247833031": 153, "3191691594567949": 146, "3196": 23, "319663143157959": 153, "31979130793668337": 153, "3197913079366835": 153, "31m100": 133, "31m12": 137, "31m17": 136, "31m27": 133, "31m4": 136, "31m54": 151, "31\uc77c": [15, 21], "32": [0, 9, 10, 15, 17, 18, 20, 23, 29, 31, 46, 52, 104, 112, 113, 133, 136, 137, 142, 151], "32000": 104, "32006070017814636": 153, "320284903049469": 153, "3204577164651875": 153, "3204577164651876": 153, "320464": 20, "3205361928480367": 153, "321096407409169": 153, "32126699541178017": 153, "32146450877189636": 153, "321642255783081": 153, "32200417": 153, "32208251953125": 153, "322135237242685": 153, "3222507753641843": 153, "322421": 129, "3225314312924941": 153, "3226379733532667": 153, "32292348": 15, "32296014": 15, "32307078506564724": 153, "32323366": 153, "32332706451416016": 153, "32402369379997253": 153, "32440507411956787": 153, "3245970745918638": 146, "324700": 26, "3247616750": 15, "325226652622223": 153, "3254g": 17, "32550658281478617": 153, "32555586099624634": 153, "325581": 34, "32564": 17, "32564acc0": 17, "326": [109, 120], "326329428785377": 153, "32647931506198496": 146, "3269": 109, "326970": 150, "327": [104, 112, 113], "327033519744873": 31, "32708": 15, "3272883892059326": 153, "327325": 34, "3275638867650108": 146, "3276653647422791": 153, "32767": 153, "3279976915096982": 153, "328208327293396": 153, "32832280118185425": 153, "3284517904122671": 153, "3284977972507477": 153, "3285024154428924": 153, "3285040669655546": 153, "3295": 23, "3299575706066555": 153, "3299575706066556": 153, "32gb": 52, "32k": 106, "32m1": 133, "32m298": 133, "32m461": 137, "32m52": 136, "32m636": 136, "32m9": 151, "32x32": 10, "33": [15, 16, 24, 25, 26, 27, 28, 31, 34, 36, 95, 104, 116, 129, 146, 151], "330156": 22, "33036327": 23, "330709": [32, 34], "33076155450609": 153, "331": [104, 112, 113], "33127416269768944": 30, "332": 153, "3320080794477474": 153, "33214378356933594": 153, "33243343234062195": 153, "332493": 34, "332501": 29, "33317976239575325": 153, "3331964910030365": 153, "333333": [31, 34], "3333333333185187": 153, "3333333333333333": 109, "33338644554217656": 153, "3335316630287303": 153, "3336375951766968": 153, "333913": 150, "334075": 146, "3343541645341449": 153, "33436": 21, "334601": 34, "3346821069717407": 153, "3347507417201996": 153, "3348137766122818": 153, "3349212914705276": 153, "33493686": 15, "334940": 26, "335": [112, 113], "335063934326172": 31, "335245": 34, "3353415497716667": 153, "3353415497716672": 153, "33574057": 15, "33578805923463": 153, "336": 10, "3360": 109, "336600": 113, "3367249697446823": 153, "33679577708244324": 153, "33695": 153, "3369654417037964": 153, "336px": 10, "336x336": 10, "33701446652412415": 153, "3370403753386603": 153, "337079": 31, "3371551722288132": 153, "3373492727159626": 153, "3376509308815003": 153, "3378403186798096": 153, "3379381071100026": 146, "338": [112, 113], "33805098533630373": 153, "33813833362526363": 153, "33828441947698595": 153, "33854187": 15, "338881254196167": 153, "338889": [31, 32, 34], "339": 15, "3390489612188604": 153, "3392370343208313": 153, "33925": 108, "33999999999999997": 153, "33b": 84, "33mentelecheia": [18, 23, 31], "33mwarn": 23, "34": [0, 15, 21, 22, 23, 25, 34, 112, 113, 133, 136, 137, 142, 151], "340": 10, "340121": 31, "34047603607177734": 153, "34076554398569797": 153, "340982913970947": 153, "341": 25, "34112692": 15, "34122953414917": 153, "34148": 21, "34197703417804504": 153, "342000": 26, "342065739466084": 153, "3421005010604858": 153, "34213744625449183": 153, "34244710206985474": 153, "3426904241243998": 153, "342701804637909": 153, "3428099542940226": 153, "342919707298279": 153, "343": [15, 153], "34311446903531895": 17, "3434767007827757": 153, "3435245777160014": 153, "3435245777160023": 153, "34372544288635254": 153, "343837": [32, 34], "34388906210660936": 153, "3440860214933326": 153, "3440898985369131": 153, "3441504937079218": 153, "3442993678090223": 153, "34469854469854466": 36, "344843": 104, "344844": 104, "34486544132232666": 153, "3453836627304554": 153, "34551202019469607": 153, "3457771937052409": 153, "34588676674498453": 153, "346": 15, "34609341621398926": 153, "346154": 34, "34623068273067475": 153, "346372310677454": 153, "34645339846611023": 153, "3465757022785438": 146, "3465827856780583": 146, "3465828747099568": 146, "347": 16, "3473098207303265": 153, "34796334778269133": 153, "348": 15, "348135626366958": 153, "3484": 104, "34844744205474854": 153, "348837": 31, "3489603996276855": 153, "3493381023406983": 153, "349479913711548": 31, "3496905752250248": 146, "349789": 34, "34979259967803955": 153, "349943590164184": 153, "3499656090752427": 146, "34b": 118, "34it": 24, "34k": 104, "34m": [18, 23, 31], "35": [0, 15, 17, 21, 22, 23, 25, 29, 31, 32, 33, 34, 35, 112, 113, 118, 121, 151, 153], "350": [25, 106], "3500": 113, "35029977937018786": 153, "35036173462867737": 153, "350831": [32, 34], "35086887776851655": 153, "351": 104, "35133889416853586": 153, "351351351341206": 153, "351438074447317": 153, "35168678990791136": 153, "3516867899079114": 153, "3517324017228247": 153, "3519227033342969": 146, "35195610448718073": 153, "35200": 104, "352100": 113, "3522205935672775": 153, "3526109635829926": 153, "352829": 34, "35304332": 15, "353139877319336": 153, "353173": 34, "35347050428390503": 153, "353698372840881": 153, "3542680740356445": 153, "3544959825168774": 20, "3547240469054427": 153, "3548059927092658": 153, "355": [15, 129], "3552114872225542": 153, "355417": [24, 26, 27, 28, 34], "3555277672078874": 153, "3557": 31, "35570975244045255": 153, "355847175203072": 153, "3558471752030721": 153, "356": 129, "3561165131571915": 146, "35636063549253677": 153, "3563797414302826": 153, "356613": [31, 32, 33], "3566843113861978": 153, "3568": 31, "35685782028959667": 153, "357": 153, "357664": 32, "357745": 31, "358087": 34, "3589421510696411": 153, "359": [112, 113], "35903206546025535": 146, "359375": 34, "35945": 153, "359515190124512": 153, "35952309105131364": 153, "35959198474884035": 153, "3597119006845686": 153, "359891652097845": 153, "35gb": 52, "35lxag5u": 18, "35lxag5usync": 18, "36": [0, 7, 16, 20, 31, 32, 33, 34, 36, 98, 104, 112, 113, 136, 151], "3607129294011328": 153, "3609868586063385": 153, "36101144552230835": 15, "36161744594573975": 153, "361705": 26, "3618507874508699": 153, "3619428873062134": 153, "36196450125426055": 153, "362": [112, 113], "362140": 34, "3624002845095718": 153, "362400284509572": 153, "3624297085720154": 153, "3631428241729737": 153, "36342382": 153, "3635103702545166": 153, "3636": [102, 108, 109], "363636": 34, "36375135481357573": 153, "36392": 17, "363974618911743": 153, "364": 15, "3643739732810193": 153, "364447": 29, "36449912190437317": 153, "3645357459783554": 153, "36455040506811603": 153, "3650163412094116": 153, "36521188616752626": 153, "3652218150352202": 153, "36558184027671814": 153, "3656056709587574": 153, "3656192421913147": 153, "365789": 35, "3659698486328125": 153, "366": [15, 17], "36605697870254517": 153, "36646339164839853": 153, "3664802716837989": 153, "366501808166504": 153, "367": [17, 153], "367011500419014": 153, "367028": [32, 34], "3673328459262848": 153, "3679927587509155": 153, "368": 17, "3680855777528551": 153, "368122": 35, "3683128794034322": 153, "368441152572633": 153, "3687988817691803": 153, "3688957737551795": 153, "369": [17, 21, 104], "3694": [31, 32, 33], "3698277353097963": 153, "3698390002038444": 153, "36983900020384447": 153, "3698685281806522": 153, "36it": 24, "36m": [101, 105], "36m0": [133, 136, 137, 151], "36mb": 137, "36min": 15, "36o0ldih": 17, "36o0ldihsync": 17, "36th": [112, 113], "36\ub9cc\uba85": [15, 17], "37": [0, 7, 15, 16, 20, 23, 29, 31, 32, 33, 112, 113, 143, 146], "370": 17, "3700122098128001": 153, "3701383246947222": 153, "37013832469472235": 153, "37045379281044005": 153, "37084027417004106": 153, "371": 17, "3710936218500137": 153, "37123751640319824": 153, "37124642729759216": 153, "3712513309499346": 153, "3712513309499348": 153, "371429": 34, "3717052936553955": 153, "3719": 26, "3721025586128235": 153, "37295582954090467": 153, "373": 104, "3731122314929962": 153, "37316074293080925": 153, "3733553886413574": 31, "37337837686991365": 146, "373465908815218": 153, "373670": 23, "373675": 26, "373858": 26, "3738812698258294": 153, "374244": [32, 34], "3743484366": 153, "3744139075279236": 153, "374700": 113, "3747661471366883": 153, "37483677003118726": 153, "3748432844877243": 153, "37495": 22, "374973249435424": 153, "3751106262207031": 153, "3753472553359138": 153, "375461806191338": 153, "37554": 21, "37595123052597046": 153, "375999981840818": 153, "375m": 104, "3762440251916417": 153, "376811": 32, "37728322446346285": 153, "3776": 26, "377622": [31, 32], "3777039244822744": 153, "377871535718441": 153, "378": 104, "3780543494180079": 153, "378238": 29, "3783985793590546": 153, "3785300427012973": 153, "3785381019115448": 153, "378788": 34, "378911566734314": 153, "37897453": 15, "37927": 17, "37927acc0": 17, "3795117437839508": 153, "379622534248564": 153, "379629": 32, "37u4j5w8": 23, "38": [15, 16, 21, 30, 31, 34, 112, 113, 129, 180], "380": [104, 112, 113], "380187131961186": 153, "380282": 32, "380702": 129, "380952": 34, "381": [104, 112, 113], "38110026717185974": 153, "381295": 34, "381300": 31, "38130316138267517": 153, "38168871533125637": 153, "38170992": 104, "3822804285420312": 153, "382299": [24, 34], "3824710249900818": 153, "3825223781996303": 153, "3826148182153702": 153, "382623314857483": 153, "3826446420616574": 153, "382657": 24, "382716": 32, "3827680640750461": 153, "383": [112, 113], "383234": 34, "383309006690979": 153, "3833363808691502": 153, "3837": 31, "383765": 34, "384": [31, 114], "38405901193618774": 153, "3842": 109, "3842966556549072": 31, "3844850063323975": 153, "38452149331569674": 153, "384615": [32, 34], "3846781253814697": 153, "384912": 35, "385": 15, "3850690140078465": 153, "3852004334330559": 153, "385281375197048": 153, "385310": 20, "38542279601097107": 153, "38552218191325666": 153, "385724": 20, "38578488296932645": 153, "3859741806983947": 153, "3862943611186682": 153, "386536": 26, "386676873022225": 108, "38686257": 104, "386983186006546": 153, "387": [112, 113], "387025356292725": 153, "3875945382648044": 153, "387800": 29, "387810": 20, "387900710105896": 153, "388298433356816": 153, "3885018050670626": 153, "3885394036769867": 153, "3887": 31, "38872024416923523": 153, "38887887398401894": 153, "3888888888567388": 153, "388889": 34, "389381": 34, "3893874883651733": 31, "38939291536808013": 153, "389438509941101": 153, "39": [11, 15, 18, 21, 22, 23, 31, 34, 36, 112, 113, 129, 133, 136, 137, 142, 151, 153], "3900874853134155": 153, "39013231322169306": 153, "39027324233514565": 153, "3904047669635879": 153, "390883": 34, "3908944098485841": 153, "3914314246426026": 153, "391977071762085": 31, "3921151995658874": 153, "3921919425328573": 153, "3922": 106, "3922528200679355": 153, "3923": 106, "39233422146903146": 153, "39261747068829006": 153, "39262569": 15, "3927939838833279": 153, "3928699791431427": 153, "3929948170979816": 153, "3932976722717285": 31, "3934319317340851": 153, "39356791619211434": 153, "39377264669165013": 153, "393870": 20, "394514090485043": 153, "39463675022125244": 153, "394920063018799": 153, "3952705932988061": 153, "39533209800720215": 153, "3953467755295613": 153, "395349": 34, "3954794108867645": 153, "395555": [27, 28, 34], "39561948031187055": 153, "395788433154424": 153, "3958378553390502": 153, "3962100613862276": 153, "39698004722595215": 153, "3970118880271911": 153, "3972": 31, "3972317576408386": 31, "3972695622179243": 153, "397472381591797": 153, "3976234495639801": 153, "39764": 133, "3977": 109, "397855": 31, "397952": 24, "3980284184217453": 153, "3981026129370882": 153, "3981595748000675": 153, "39835565818680657": 153, "398488": 21, "3986912210782369": 153, "3987556591183646": 17, "39895099401474": 153, "3989551968872547": 153, "399": [0, 31], "3991887867450714": 153, "3993108928203584": 153, "3993554711341858": 153, "399375": 26, "3994131624698639": 153, "39it": 24, "3a6e16220649c10b4cd5b3ca2aa3ac50b9e5b24f322be56bbed0737c3feefaaa": 136, "3aj4gdmk": 17, "3aj4gdmksync": 17, "3b": [52, 118], "3b106lwn": 17, "3bpaphe7": 17, "3bpaphe7sync": 17, "3bx0elnp": 18, "3bx0elnpsync": 18, "3d": [0, 4, 9, 121, 149, 151], "3d_studio": 150, "3f340121f0986bf8": 113, "3fyvrvgf": 31, "3gb": 52, "3jgaq9xx": 17, "3jgaq9xxsync": 17, "3kb": 101, "3m": 142, "3mb": 104, "3min": [15, 23, 151], "3q97kspe": 23, "3rd": 130, "3upm5zw": 17, "3upm5zwesync": 17, "3w3bkjug": 17, "3w3bkjugsync": 17, "3x3": [11, 89], "3\uac1c": 15, "3\uacf5": 21, "3\ub2e8\uacc4\ub85c": 20, "3\ubd84\uae30": 22, "3\uc6d4": [20, 142], "3\uc870500\uc5b5\uc6d0\uc73c\ub85c": 22, "3\uc870\uc6d0\ub300\uc5d0": 22, "4": [0, 2, 7, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 52, 54, 60, 80, 84, 87, 88, 98, 99, 101, 102, 109, 112, 113, 114, 115, 116, 117, 118, 123, 133, 134, 136, 137, 140, 142, 144, 146, 150, 151, 152, 153, 162, 175, 176, 177, 181, 182, 185, 187], "40": [15, 16, 17, 18, 20, 21, 22, 23, 30, 36, 80, 104, 112, 113, 140, 152, 153, 168], "400": [10, 27, 28, 112, 113], "4000": [113, 128], "40000": 129, "4000000": 104, "4003549336881114": 153, "4003549336881116": 153, "4005433334244622": 153, "400621": 26, "4009397059679031": 153, "40094903": 153, "400million": [112, 113], "400x": 89, "400\ud638\uc5d4": 16, "4010718471474118": 153, "40120257437229156": 153, "4021126025252872": 153, "4021384835243225": 153, "40265536": 15, "40278589725494385": 153, "403": [112, 113, 153], "4033030778169632": 153, "4035642951726913": 153, "403571": [31, 32], "4036736488342285": 153, "4040002981821695": 153, "4040156900882721": 153, "404229": 150, "4044821739196777": 153, "40465158224105835": 153, "40471704192459584": 153, "4048138054696502": 153, "4048138054696506": 153, "4049933248096043": 153, "4051099667946498": 153, "4051308393478394": 153, "405797": 34, "4058368131518364": 153, "405919623374939": 153, "406": [17, 106], "4061099": 95, "40612800121307374": 153, "406149": 150, "4062464237213135": 153, "40634281262755395": 153, "4064190685749054": 153, "40643646253479854": 153, "40655995971626707": 153, "4067401882674959": 153, "406873881816864": 153, "407": [104, 111, 113], "40712885856628": 153, "40721428394317627": 153, "4073": 104, "407407": 34, "4074074078": 153, "408": 0, "408242": [31, 32], "40851979123221505": 153, "408884": 26, "408889": 32, "4089191257953644": 153, "4092903137207031": 153, "40978858404689367": 153, "4098752948972914": 153, "4098756572162499": 153, "4098756572162503": 153, "40\ubd84": 142, "40\uc8fc\ub144": 16, "41": [15, 16, 20, 21, 112, 113], "410": [112, 113], "4100": 31, "4100873610433413": 153, "41012402772903445": 153, "410384": 24, "41051129": 153, "411": [18, 112, 113], "411004638671875": 153, "4111373096704483": 153, "4112602941691875": 153, "4116775261031257": 153, "41183939278125764": 153, "41185176": 15, "4119377543528875": 153, "4121724492973752": 153, "412215": [32, 34], "4124165214598179": 153, "4125315": 146, "41257696": 104, "4127258360385895": 15, "41280580": 104, "412947": [31, 32], "4129498998324075": 153, "4129695691956162": 153, "41296956919561634": 153, "4129734568297863": 153, "413279": 31, "41351083368062974": 153, "413581609725952": 153, "4138374083571964": 153, "41399666402075025": 153, "414": [24, 26, 104], "414474": 34, "41461974952117087": 153, "41476214": 15, "415": [24, 25, 26, 27, 28, 29, 32, 34], "41501474380493164": 153, "4150846584": 109, "415362": [24, 26, 27, 28], "415459543466568": 153, "41551544395307993": 153, "415961": [24, 26, 27, 28], "4160135120153427": 153, "416100": 113, "4163795210421085": 153, "416620707511902": 153, "4166274363483794": 153, "4172645108567344": 153, "417581510543823": 153, "4178920825322469": 153, "41815333664417265": 153, "41826743086179097": 153, "41831708": 15, "41851362850930957": 153, "418568": 35, "419": 31, "4192": [104, 106], "41927905082701": 153, "4195118091144356": 17, "4195900823409209": 15, "41982099413871765": 153, "419857": [32, 34], "41k": 137, "42": [9, 15, 21, 31, 34, 36, 104, 112, 113, 137], "420": [112, 113], "4202008843421936": 153, "42043137550354004": 153, "42045146226882935": 153, "420680743983702": 153, "420690": 34, "420939": [24, 26, 27, 28], "421": 31, "4212134650598962": 153, "42121727665782804": 153, "4213864803314209": 153, "4214225709438324": 153, "422": [106, 112, 113], "4222222221898273": 153, "42227031141519544": 153, "4223848611116409": 153, "422535": 24, "42268345": 153, "42272013458940716": 153, "423": 104, "4230997562408447": 153, "4232210506374636": 153, "42326092951827576": 153, "423400950431824": 153, "4234406484497918": 153, "4234808087348938": 153, "4235381631689017": 153, "423538163168902": 153, "4236492501364814": 153, "4237": 111, "42373811536365086": 153, "4240686010569334": 153, "424300": 113, "4244162026935911": 153, "4244162026935918": 153, "4248759551503945": 153, "42487595515039467": 153, "425000": 26, "4250685731569926": 153, "425499": 20, "425627151255806": 153, "426230": 29, "426261": 26, "427": [24, 106], "4277962": 153, "428": [0, 15, 104], "428054": 24, "4285337212423949": 153, "428571": [31, 34], "42867404222488403": 153, "4286973774433136": 153, "4288": 106, "4293242484331131": 153, "4296712492948265": 153, "429940": 26, "43": [15, 21, 23, 25, 36, 112, 113, 116, 129, 137, 153, 180], "430223838157124": 153, "430280049641927": 153, "430436897277833": 153, "43046212": 15, "430772896633587": 153, "430983": 31, "431": [25, 112, 113], "431002": 31, "4310186803340912": 153, "4311": 109, "4311494575606452": 153, "431169271469116": 153, "4313059644566642": 153, "43137869": 104, "43142897": 104, "4322194457054138": 153, "43249382376670836": 153, "432632": 25, "43278515": 15, "432800473204122": 153, "43283358": 153, "4329821487267812": 153, "43306236075249366": 153, "4330623607524941": 153, "4331acc0": 17, "433401": [32, 34], "433544445037843": 153, "43378524780273436": 153, "4340397599847348": 153, "4344255328178406": 153, "43455282": 15, "4346828691661358": 153, "43473703985412915": 153, "435": [0, 109, 112, 113], "4352289259433746": 153, "4354722201824188": 153, "4355814456939697": 153, "435728073120117": 153, "435897": 31, "4366700": 146, "437": 15, "43703860640525816": 153, "437147": [27, 28, 34], "4375795140862465": 153, "43763422667980195": 153, "437892961502075": 153, "4379139787207047": 153, "43815643": 153, "4383622705936432": 153, "438971": 129, "439": 15, "4390567261732707": 153, "439142453324124": 153, "4393458787279667": 153, "4393939393939394": 36, "439508193554606": 153, "4396458": 153, "4397713": 146, "4398733735084535": 153, "43987542390823364": 153, "43it": 24, "44": [7, 15, 22, 29, 30, 34, 36, 99, 104, 112, 113, 136, 153], "440": 24, "4402464628219604": 153, "440559": 24, "44068923592567444": 153, "440m": 115, "441048": [32, 34], "44132310152053833": 153, "4414571046829223": 153, "4415394": 146, "44182train_loss0": 17, "44183275227507113": 153, "442": [112, 113], "44212474822998": 153, "442171192169189": 153, "442327070236207": 153, "44272010181254395": 153, "4428694": 146, "44289947897195814": 153, "4432090878486634": 153, "4432110205292702": 153, "44326648849528": 109, "4437849283218385": 153, "4438908696174622": 153, "4439284801483154": 153, "443945384025575": 153, "444": [112, 113], "4440085932612419": 153, "44401636720738": 153, "4440664765834577": 153, "44434": 18, "444409430027008": 153, "444444": [31, 32, 34], "444444444320989": 153, "44444444443950626": 153, "4446329014792689": 17, "4447674": 153, "445079586075412": 153, "4453229010105133": 153, "4454398795410999": 153, "44544156491756437": 153, "44572acc0": 17, "44621886669153665": 153, "446\ub9cc": 15, "4475": 109, "448": [122, 131], "4480247225281728": 153, "448127388954163": 153, "4481358230113983": 153, "448412187894186": 153, "4489587392133696": 153, "44914649901267": 146, "4493477040020368": 153, "4493477040020373": 153, "44940024614334106": 153, "449900817871094": 153, "449915270805356": 153, "45": [15, 16, 21, 25, 31, 34, 36, 108, 112, 113, 120, 121, 123, 137, 153, 175], "4500": 113, "450000374764204": 153, "4500\uc5b5\uc6d0\uc5d0": 21, "4506096941108505": 153, "45086624": 104, "45087203": 104, "4509164703468697": 146, "451": [112, 113], "4511": 104, "451196633776029": 153, "45179317759142984": 153, "4518": 31, "451961803479181": 153, "451961803479182": 153, "452": 31, "45200169": 15, "4520202020110353": 153, "45229148864746094": 153, "452699175145891": 153, "45332501977682116": 153, "4535639047622682": 153, "4536": 104, "453f5bc": [175, 177, 178, 180], "453f5bcf1cfe7616ded061ca2b1cf1e910351824": [175, 176], "454": 104, "45409396290779114": 153, "4542298316955566": 153, "45446985446985444": 36, "45448160244462393": 153, "454545": 34, "45504247943560283": 153, "4551342276028461": 153, "45518324": 153, "455663": 26, "455730713128055": 153, "456012099981308": 153, "4561": 31, "456199": [24, 34], "456348": 24, "45656153485178946": 153, "45673076672987506": 111, "456747": 34, "456k": 101, "457": [112, 113], "457221": 20, "457412910461425": 153, "458333": 34, "458417229904026": 153, "458484387397766": 153, "4585": 109, "45877": 15, "4589559988355822": 17, "459": [112, 113], "4590431611053646": 153, "4592802584171295": 153, "459355": 34, "45938059820069205": 153, "4595166444778442": 153, "45972611324043794": 146, "459748269058764": 153, "459793": 104, "45it": 25, "46": [15, 26, 30, 34, 36, 112, 113, 129, 185], "46030": 104, "460480": 104, "4607523679733276": 153, "460900": 113, "461": 137, "461368560791016": 153, "4615187886617018": 153, "461538": [31, 34], "4615578651428223": 153, "4616": 153, "46163train_loss0": 17, "461669683456421": 153, "46167train_loss0": 17, "462396": 20, "462459": 128, "462811": 128, "4629502296447754": 153, "4631067621441408": 17, "463171": 20, "4632687270641327": 153, "4634987852639622": 153, "463683": 128, "4636900547983257": 15, "46394": 17, "46394acc0": 17, "464567": 34, "46470": 20, "46471": 20, "46475": 20, "46477": 20, "46478": 20, "4648455142974854": 153, "4648907739423103": 153, "4650069460272789": 153, "4650723061795412": 153, "4650723061795419": 153, "465864181518555": 153, "46617349055078294": 153, "466667": 34, "466801": 128, "466k": 115, "467": 153, "46723321235772747": 20, "46726287": 104, "46726298": 104, "4674039426777098": 153, "46882564": 153, "4688612878322601": 153, "468966903707212": 153, "4691283585240593": 15, "469300": 35, "46934685": 153, "46940648555755615": 153, "46946394741535186": 153, "4699": 104, "46mb": 105, "46\uc870\uc6d0\ub300\ub85c": 20, "47": [15, 16, 17, 20, 31, 32, 36, 52, 113, 115, 129, 137], "47000362923358285": 153, "4702285533016523": 17, "4705633774399757": 153, "47071945667266846": 153, "470860": 26, "4709807678063713": 153, "471": 0, "47115384615384615": 30, "471545": 34, "471698": 31, "4717846617102623": 153, "47215969661434976": 36, "472329": [24, 26, 27, 28], "47249train_loss0": 17, "472539": 26, "472998": 20, "473": 113, "4734817637337579": 153, "4736030129460684": 153, "47376230359077454": 153, "47384417057037354": 15, "474": 15, "4742779970169066": 153, "474656": [24, 27, 28, 34], "474820": 34, "47492": 15, "475418": 26, "47543461829176115": 15, "47551360925038655": 153, "47579583078622817": 153, "475884": 26, "4760036665014923": 153, "47610455825924874": 153, "476190": 31, "476552414894104": 153, "476596": 34, "476814": [27, 28, 34], "4770257814062966": 153, "4770597591996193": 153, "4770723730325699": 153, "477493": [32, 34], "47778acc0": 18, "4778187870979309": 153, "4781847609413994": 153, "47851452": 153, "4785268584887186": 153, "47856080532073975": 153, "479": 15, "4790469151291808": 23, "479205131530762": 153, "4793075716122985": 153, "4798": 25, "47998train_loss0": 17, "4799913730886247": 153, "48": [15, 21, 22, 23, 24, 34, 36, 102, 108, 111, 112, 113, 137, 153], "4801769256591797": 153, "48035172671079635": 153, "4804173162407261": 153, "4804653570495008": 153, "480899": 35, "4816522326806949": 146, "481953": 34, "48196596": 104, "48196650": 104, "4820239801682076": 153, "48242614923472477": 153, "4825298238545656": 153, "48266232311725615": 153, "48268745514815": 156, "482846216572118": 153, "4828462165721186": 153, "4828745499253273": 153, "483": 153, "4832791": 153, "4833": 109, "4837201237678528": 153, "4837617874145508": 153, "4839033007621765": 153, "484": [15, 17, 54], "4841044306755067": 153, "4842275597155094": 153, "4843333332497222": 153, "48480454087257385": 153, "484906649778778": 153, "485": 15, "48553305864334106": 153, "48568335771560667": 153, "486": 153, "4864306248476107": 153, "4865640806034207": 153, "48694471889678254": 153, "4869715571403503": 153, "48717684911357034": 153, "487200": 113, "48731302552753025": 153, "4875531804415069": 153, "4876408100128176": 153, "4878202319145202": 153, "48795462530517447": 153, "488": 15, "4880732536315917": 153, "488254": 128, "4883527679034347": 153, "48875993937253953": 153, "489": [31, 32, 33, 54], "489119": 31, "48919835686683655": 153, "489818": 29, "4899999999999998": 133, "48t": 21, "49": [15, 16, 17, 29, 34, 95, 104, 129, 153], "49076725275249233": 23, "4909617304801941": 153, "491": 106, "4910168096423149": 153, "49140mib": 113, "4914559665787048": 153, "4914559665787055": 153, "4916548767501645": 153, "4917181432247162": 153, "4918918490409851": 153, "492": 15, "493": 22, "493088": 29, "49328284449875354": 153, "4937671720981598": 153, "494": 112, "4945665955543518": 153, "4947402609719171": 153, "4950372223947054": 15, "4954831686284807": 153, "4955023588736858": 153, "495761942863464": 153, "49591032415628433": 153, "496": [112, 113], "49621543": 104, "49621655": 104, "496300": 113, "496824312210083": 153, "497": 121, "4971213": 146, "49714879393577577": 153, "497177": [24, 26, 27, 28], "49732834100723267": 153, "497915780544281": 153, "4982015788555145": 153, "4987923622131347": 153, "499": 185, "499377": [24, 26, 27, 28], "49960836470127107": 153, "4996921420097351": 153, "4998456843197346": 153, "49999310076236725": 153, "49it": 25, "49m": [133, 136, 137, 142, 151], "49m23": [133, 136, 137, 142, 151], "49mnotic": [133, 136, 137, 142, 151], "49mpip": [133, 136, 137, 142, 151], "49\ubd84\uacbd\uc5d0": 142, "4b4edc1": 181, "4b4edc115e87629b853fc5084931350348909663": 181, "4f": 111, "4fa39c8": [177, 178, 180, 181], "4fb2ed8": [181, 182], "4gb": 52, "4m": 142, "4min": 23, "4th": [112, 113, 129, 130], "4x": [10, 118], "4\uc2dc": 21, "4\uc6d4\uae4c\uc9c0": 20, "4\ucc28": 15, "5": [0, 2, 10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 44, 48, 80, 84, 95, 98, 99, 101, 102, 105, 106, 107, 109, 112, 113, 115, 118, 123, 125, 129, 133, 134, 137, 140, 142, 143, 146, 150, 151, 153, 156, 162, 175, 176, 178, 181, 182, 183, 185, 187], "50": [7, 10, 15, 16, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 88, 89, 95, 98, 101, 104, 106, 109, 112, 113, 116, 121, 127, 129, 137, 143, 151, 153, 181, 185], "500": [4, 101, 111, 113, 137, 168, 185], "5000": [113, 128, 137], "50000": [104, 129], "500000": 26, "5000000": 104, "500013296804193": 153, "5002365076418617": 153, "5003574252128602": 153, "5005275414844204": 153, "500527541484421": 153, "50078015327453": 153, "5008124589920044": 153, "5009278669953346": 153, "500km": 142, "500\uc5b5\uc6d0\uc5d0": 21, "500\ud638": 16, "5010495139285922": 153, "501081607511474": 153, "5011142507195473": 153, "502": [112, 113], "50212365": 96, "502124309539795": 153, "50256": 101, "50257": 112, "5026": 104, "5026300244861179": 153, "50299999993": 153, "5030347108840942": 153, "503096": 32, "5032047": 153, "5036019414663313": 153, "504": 108, "5040773967745518": 153, "5042677521705627": 153, "5044889359683212": 153, "504613733026627": 153, "5049610137939453": 153, "5055979818105698": 153, "5057655387454565": 153, "5058705645390194": 153, "506": 25, "5060144066810608": 153, "506538450345397": 153, "5066773494084676": 15, "506885": [32, 34], "507": 106, "507101": 26, "507366928259525": 153, "5079365079314689": 153, "5083285570144653": 153, "508752492070198": 153, "5088331699371338": 153, "5088414877653122": 153, "5090053081512451": 153, "509185202916463": 153, "5096372005012301": 153, "5096396565437318": 153, "509806": [31, 32], "509990119934082": 153, "50it": 24, "50\uc5ec": 142, "51": [15, 16, 17, 22, 23, 29, 31, 34, 36, 129, 137], "510": [112, 113], "5102350264787674": 153, "510292598605156": 153, "51032940": 104, "51033150": 104, "5105727970600128": 153, "5107786150136963": 153, "5108256237575629": 153, "510870265960694": 153, "5109133243560791": 153, "5109996477762858": 153, "511": [0, 30, 113], "5117599874734878": 153, "512": [9, 10, 15, 17, 18, 20, 22, 31, 52, 111, 113, 115, 116], "5121": 18, "5122612968087197": 153, "5123818334583414": 23, "51238train_loss0": 23, "5128358319401741": 153, "513354111031174": 153, "5134019255638123": 153, "513688063621521": 153, "5139": 153, "514085": 34, "51426acc0": 17, "5144984575880421": 146, "5146351165241665": 153, "5148299932479858": 153, "514854": 22, "5148541733920216": 22, "515099125438266": 153, "5151218771934509": 153, "5151515151132535": 153, "5152": [0, 7], "5154653616249562": 153, "5159353629304713": 153, "5159353629304715": 153, "5160080606117845": 153, "5161": [0, 7], "5162451863288879": 153, "51649958": 15, "5168040946125985": 153, "5169796407222748": 153, "51699698": 15, "5173569798469544": 153, "517410898208619": 153, "5177711397409439": 153, "518": [15, 112, 113], "5182306855916977": 153, "518519": 32, "5187976956367493": 153, "5193201501853764": 153, "519595": 29, "519921213326355": 153, "51aafd": 22, "51it": 31, "51z": 95, "52": [15, 21, 23, 29, 31, 34, 104, 136, 137], "520": [112, 113], "5203056308598093e": 153, "5204781480063937": 146, "5205207884311676": 153, "520790159702301": 153, "5211324095726013": 153, "5211626291275024": 153, "521296923625839": 153, "521429": [31, 32, 33], "5216344833374": 153, "522": 22, "522379159927368": 153, "522638": 35, "5229": 31, "522965590300311": 153, "523": 17, "5232": 106, "5234188318252564": 153, "52346754": 15, "5237525105476379": 153, "5238095237835223": 153, "523898": 26, "5243439616039047": 153, "524343961603905": 153, "5244248604016497": 153, "5245177417993545": 153, "52461838722229": 153, "52469102": 104, "52470264": 104, "5248393416404724": 153, "525": [112, 113, 153], "5250355693505371": 146, "525151567988925": 153, "5251638889312744": 153, "5256941318511963": 153, "525729": 35, "5260767102241516": 153, "5262686189508873": 153, "5262686189508876": 153, "5264039039611816": 153, "5266369490971852": 153, "5266369490971856": 153, "526721": 153, "5269137233495712": 153, "527": 15, "5272161457273695": 153, "527260013181598": 153, "5273105978965758": 153, "527514": 35, "5275579690933228": 153, "5277079284191132": 153, "5280389": 153, "5281": 0, "5283": 106, "528441429138184": 153, "528532": [24, 26, 27, 28], "5289": 15, "529": [54, 153], "529236": [32, 34], "5295765637523598": 153, "5297322273254395": 153, "529771": 17, "52gb": 52, "53": [15, 23, 25, 29, 31, 34, 104, 109, 112, 113, 175], "530": [94, 113], "5302295088768005": 153, "530694967508316": 153, "5307975": 153, "53091334684587": 153, "5311867952346803": 153, "531340": [32, 34], "531536": 129, "5316045413682643": 153, "5319959935158121": 153, "5321281790733337": 153, "5323186298211415": 153, "53267826826777": 109, "5326852523605549": 153, "532685252360555": 153, "533": 18, "5334630190756529": 153, "5334633": 146, "533753": 35, "5338767528533935": 153, "533890": 34, "53430": 136, "5347955226898193": 153, "535612565287408": 153, "536": 106, "5360476672649384": 153, "5361560556566348": 136, "536394": 96, "5364161756303575": 153, "536606056036479": 153, "5367234945297241": 153, "5368331864793847": 153, "536893": 17, "5369794368743896": 153, "537": 104, "5373274594545364": 153, "5375698208808899": 15, "5379707217216492": 153, "538": 31, "5381382368505001": 153, "5382207289094766": 153, "538284": 35, "5383680820465088": 153, "538462": [31, 32, 34], "53867435": 15, "539": 108, "5391488671302795": 153, "5391562134027481": 153, "5393182039260864": 153, "5394160777330399": 153, "539497": [31, 32, 33], "53971634": 104, "53972222": 104, "5399529510350565": 153, "54": [15, 21, 22, 29, 34, 95, 104, 108, 112, 113, 136, 175], "540": 94, "5402519106864929": 153, "5405859769669961": 153, "54073486328125": 153, "540b": 99, "541044": 17, "541075611114502": 153, "541123934836883": 153, "5415724128422639": 153, "541761589050293": 153, "5419433057308197": 153, "5420901507139206": 153, "5421510398387909": 153, "542485": 17, "542485316149969": 17, "542900": 113, "543": [112, 113, 146], "5434947": 153, "5435505": 153, "5438662767410278": 153, "544": 15, "5440375487491753": 153, "5441355347633362": 153, "545": 21, "5451": 106, "5454545454545454": 36, "545455": 34, "5455716252326965": 153, "545708": 129, "5459191679954529": 153, "5463879113428052": 153, "5463879113428056": 153, "5469": 106, "5469532": 153, "547": 106, "547535": [26, 29], "547619": [31, 32], "548": 104, "548355": [32, 34], "548855": 26, "548975944519043": 153, "5497331604361534": 153, "54fa40f": [178, 180, 181], "54it": 24, "54th": 0, "55": [15, 22, 23, 95, 108, 112, 113, 136, 153, 185], "5500": 113, "5503150254487992": 153, "5509150475263596": 153, "551013136": 104, "5512014642357826": 153, "5514543205499649": 153, "551981115341187": 153, "552": 20, "5522102773189544": 153, "5522374004125595": 153, "5524925": [178, 180, 181], "5525827613141802": 153, "5532432510658585": 153, "5533533722162247": 153, "55349142": 104, "55349925": 104, "5537001609802246": 153, "553kb": 101, "5543202757835388": 153, "5553434246116215": 153, "555367": 17, "555486556628476": 23, "55549global_step546lr0": 23, "5555555554864204": 153, "5555555555382716": 153, "5555555555452675": 153, "555556": [31, 32], "555858987569809": 153, "556": [31, 32, 33], "55624": 18, "5564370689820499": 153, "556589663028717": 153, "557": 106, "557279497385025": 153, "5574072420597076": 153, "557561": 15, "5576": 104, "5579301101135489": 153, "558": [104, 106], "5580196784602272": 153, "5581017136573792": 153, "5583333332497221": 153, "558351": 34, "558923": 15, "558927": 20, "5589282512664795": 153, "559": 104, "5593037558926477": 153, "5595276564359665": 153, "559653": 34, "5597643057419147": 153, "559828281402588": 153, "559892": 22, "5599215030670166": 153, "5599398672580719": 153, "55eval_loss0": 17, "55k": 137, "56": [0, 15, 21, 22, 23, 25, 29, 120, 136, 137, 141, 153], "560198": 34, "560365": 25, "5603938579559327": 153, "560866": 129, "5612490766722223": 23, "561801": 26, "562": 15, "562641906738282": 153, "5631718": 23, "5632155805826187": 153, "564": 153, "5640980223814647": 153, "564110": [32, 34], "5642764568328857": 153, "5644107758998871": 153, "56441368063523": 153, "5645034700632096": 153, "5646324700779385": 153, "5649130344390869": 153, "565": [112, 113], "565062618255617": 153, "5658087696202627": 153, "566": 153, "5661": 104, "5664587616920471": 153, "5668640611007268": 153, "5672577619552612": 153, "567363": 26, "5674934085458517": 153, "5676436835382548": 153, "5677988529205322": 153, "5678": 34, "5680274128913879": 153, "568219244480133": 153, "5683780044317246": 153, "568400": 113, "568863": 24, "5692125529050827": 153, "56gb": 52, "57": [0, 15, 17, 23, 27, 28, 29, 34, 101, 137], "570": 115, "570048": 34, "570948": [24, 26, 27, 28, 34], "571": [15, 153], "5710591435432434": 153, "5710992306470871": 153, "571429": [32, 34], "5716313332319259": 153, "57164252": 15, "571946": 24, "5719722": 153, "5720635890960692": 153, "572295": [29, 34], "5725445315241814": 153, "5730520486831665": 153, "5734125177065531": 15, "57356196641922": 153, "5736709266901017": 153, "573951": 24, "5744902908802032": 153, "574614330098895": 153, "574704": 25, "57484370470047": 153, "574969": 15, "575033": 15, "575039": 15, "57536414488468": 153, "5755005634088165": 153, "576": 21, "57634037733078": 153, "5763556361198425": 153, "5766310691833496": 153, "5768337538468736e": 153, "5768337677246613e": 153, "5769483402371407": 153, "5770901381969452": 153, "577428936958313": 153, "577716016769409": 153, "5777320265769958": 153, "577781380712986": 153, "577867": 26, "5779075": 15, "577968": 26, "5779788494110107": 153, "578": [112, 113], "5785669237375259": 153, "578618": 35, "5786906272172928": 153, "578860592842102": 153, "5791655408011542": 153, "579313": 26, "5795": 106, "5796": 17, "579674": [32, 34], "5796759605407715": 153, "57it": 95, "57\ubd84\uacbd\uc5d0\ub294": 142, "58": [24, 26, 27, 28, 34, 54, 112, 113], "580046021938324": 153, "5803": 15, "5804461449384689": 153, "580488": 17, "5806098580360413": 153, "5806891532275694": 153, "580752494931221": 153, "581": 21, "58103942871094": 153, "5812047616908983": 153, "58121748691968": 153, "5813835948705673": 153, "58142": 31, "5815661487686965": 153, "5820300175084008": 153, "5820991456508636": 153, "582206": [32, 34], "5826810441083398": 153, "583": 15, "5830207": 153, "583333": 34, "5835189384228876": 153, "5842362410492368": 153, "58426094": 153, "5844497149251596": 153, "5844844531181247": 23, "5845632533232371": 153, "58469": 20, "58470": 20, "5849519714713096": 153, "58601504691836": 153, "5870785329076978": 153, "58709": 25, "587413": [31, 32, 33], "5877866648873042": 153, "5877866649030966": 153, "5881895881895881": 36, "588553": 21, "5886256409357892": 153, "5889425377361477": 153, "589": [112, 113], "589239579596395": 153, "5893126898341708": 153, "5894590816212744": 153, "589626": 153, "59": [15, 22, 23, 29, 31, 34, 36, 112, 113, 121, 129, 146], "590": [18, 106], "590156": 129, "590201": 31, "5902392476797104": 153, "5904256105422974": 153, "5904481410980225": 153, "5904821053147316": 153, "591": [24, 104], "591088530421257": 153, "5913944244384766": 153, "591490375995636": 153, "5916098952293396": 153, "5916839916839918": 36, "59204630851745": 153, "5926": 106, "5926167368888855": 153, "593": 121, "593023756146431": 153, "5931995581448133": 146, "5933": [0, 7], "593594": 150, "5936046262814404": 153, "594": [112, 113], "5940357313858171": 36, "5940763026475906": 153, "5942": [0, 7], "59450996": 153, "594681": 34, "594924": [24, 26, 27, 28], "5951818227767944": 153, "595236301422119": 153, "596": 106, "5964958867020723": 36, "596500": 113, "5969623416662216": 153, "597": 104, "5970727115869522": 153, "5971336365555293": 153, "5972": 104, "5972039008306133": 153, "5980050881703696": 153, "59833586": 15, "599": 18, "5997474747474748": 36, "5997911095619202": 153, "5999829795625473": 153, "5999999999795558": 153, "5b": [10, 52], "5billion": [112, 113], "5d99c3aa2cd1b79db65583bd456136cd9fbbcc4": 185, "5g": 15, "5gb": 52, "5th": [24, 112, 113], "5x": [89, 116], "5\ub144\uac04": 20, "5\uc5b8": 141, "5\uc6d4": 16, "5\uc6d4\uc5d4": [15, 16, 17], "6": [0, 2, 7, 10, 15, 16, 17, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 44, 52, 86, 89, 95, 98, 102, 104, 105, 107, 109, 112, 113, 115, 118, 128, 129, 133, 136, 137, 140, 146, 150, 151, 153, 162, 185, 186, 187], "60": [17, 21, 23, 26, 27, 28, 29, 30, 34, 36, 48, 71, 95, 97, 112, 113, 118, 129, 130, 136, 152, 153, 162], "600": [81, 112, 113, 116], "6000": 113, "60000": 129, "6000000": 104, "60023": 109, "6002833247184753": 153, "6004": 17, "6004041439294816": 153, "6005045566293928": 153, "60077": 153, "6009999999": 153, "600million": [112, 113], "600\ud638": 16, "600\ud638\ub97c": 16, "600\ud638\uc5d0": 16, "6010507076978684": 153, "6011057376861573": 153, "601244": 17, "601322603225707": 153, "6013480097055435": 153, "6014356017112732": 153, "6014894707978905": 153, "6015325670498084": 36, "601659": 34, "601905071735382": 153, "601953": 35, "6024388074874878": 153, "602978": 34, "6035295695066452": 153, "6037357442080975": 153, "604": 153, "604038265559883": 153, "60404": 153, "6040872625385721": 153, "6044882446527481": 153, "6045406103134154": 153, "6046907782554627": 153, "6047012209892273": 153, "6048533856868744": 153, "6051172554492951": 153, "6054804116487503": 153, "6056559213265249": 146, "6060932964086533": 153, "607": [104, 106], "6070075160927243": 153, "60709da": 184, "6076949115341027": 153, "6079433553160218": 153, "607943355316022": 153, "6079999999150001": 153, "608": 104, "6087498277425766": 153, "609": 153, "609109103679657": 153, "609438": 35, "6096499741077424": 153, "60it": [21, 24], "61": [20, 23, 26, 29, 30, 31, 34, 136, 153], "610": 108, "6100264191627502": 153, "6103616148233414": 153, "6107279777526857": 153, "61077201": 15, "6109052265588026": 36, "611": 15, "611111": 31, "61125920481152": 153, "6113076812691158": 153, "6113331038327985": 153, "6116340756416321": 153, "6116812": 153, "611814": 34, "611842": 34, "6118693023920059": 153, "612057495117187": 153, "612063941028383": 153, "61211": 25, "61222103497842": 153, "6122414320707321": 153, "6123547405004501": 153, "6135365962982178": 153, "6136944791990455": 153, "61374": 104, "613909": 35, "613999999915": 153, "6142416": 15, "6143026351928711": 153, "6145224": 153, "615": 153, "6151176895973893": 36, "6152072912602486": 153, "615207291260249": 153, "615226": 26, "615385": [27, 28, 32, 34], "615502": 29, "6157705187797546": 153, "6158387660980225": 153, "615917": 31, "6159706115722656": 153, "615\ub9cc": 15, "616": [7, 15], "6160316441204637": 146, "6161861394167182": 153, "616191": 34, "6163566360309041": 153, "6163956195116043": 153, "6165847301483156": 153, "616803": 26, "616857": 26, "6169759377837181": 153, "617": 108, "617283950607758": 153, "617461": 129, "6175571918487549": 153, "6177343167893081": 153, "6178307306435373": 153, "6179495543241501": 153, "617981": 35, "6180178427067431": 17, "618018": 17, "618385820918613": 153, "6185740262269974": 153, "6187533557415008": 153, "618890": 150, "6189156651496888": 153, "619035180409749": 153, "6192097634077072": 153, "619234496642365": 153, "6193571090698242": 153, "6194979637861252": 153, "62": [15, 17, 29, 30, 36, 52, 112, 113, 136, 137, 185], "6202": 17, "6207689881324768": 153, "6211654329045517": 153, "6211654329045535": 153, "6211802777111816": 136, "6212121212121212": 36, "6213171839714051": 153, "6215577125549316": 153, "621722": [32, 34], "621732091903686": 153, "6218": 15, "62188": 153, "6219": 15, "6219531387090683": 153, "622": 15, "62214136": 23, "6222955": 153, "622478": 29, "6226463794708252": 153, "622821": 29, "623": [104, 153], "6232512129677668": 153, "62350": 15, "6235321164131165": 153, "623534759879209e": 109, "6239841527409024": 153, "6241": 109, "624865765838529": 146, "625000": [32, 34], "6251657009124756": 153, "6251761059453366": 30, "625310": 29, "625587": 153, "625640649927987": 153, "6261020600795746": 153, "626347541809082": 129, "6266018450260162": 153, "627": 15, "62717399597168": 153, "6278219133615494": 153, "6282": 104, "628229808807372": 153, "628378": 34, "6288093000650405": 153, "629": 108, "629476198554039": 153, "6296296296115227": 153, "62it": 102, "63": [10, 15, 23, 29, 30, 120, 136, 146, 153], "6300692686554132": 153, "6300975859165192": 153, "630240973830223": 153, "6302479207515717": 153, "6306056916713715": 153, "6306196133295695": 153, "6306696415194301": 15, "631": [15, 104], "631021115928547": 153, "6310879856348037": 153, "6312766671180725": 153, "6316824167966842": 153, "6318665146827698": 153, "6319933338297739": 153, "632": [10, 15], "6320065855979919": 153, "6320095574554566": 153, "63207": 29, "63225589900849": 153, "6327709509266746": 153, "633": 104, "63322": 106, "633373832702638": 153, "6333910822868347": 153, "6335693955421448": 153, "6338666": 153, "634": [112, 113], "634419396519661": 153, "6346445910731934": 153, "6346445910731939": 153, "634724": 153, "6348272562026978": 15, "6348734751343728": 153, "635": 136, "635204005241394": 153, "635240": 35, "63527436653773": 153, "635549034012687": 153, "6356056213378907": 153, "635912299156189": 153, "636": [112, 113, 136], "6362178372900401": 153, "6363498419523239": 153, "636364": 34, "636558": 24, "6368729309905782": 36, "637": [112, 113], "6370809895484615": 153, "6371696591377258": 153, "6371875941753388": 153, "637304": [24, 26, 27, 28], "6374659019661213": 17, "637466": 17, "6375426169484854": 153, "6379999999500001": 153, "6380366259151035": 153, "638435": 29, "6384710669517517": 153, "638696": 20, "6396074990431467": 153, "639968752861023": 153, "63g": 101, "63mb": 137, "64": [0, 9, 15, 17, 23, 36, 54, 102, 111, 112, 113, 118, 136], "640": [20, 21], "6401087": 23, "640138": 34, "6404455900192261": 153, "6405402686860826": 153, "640747": 34, "6407616078853607": 153, "6410084575414657": 153, "6410277843475343": 153, "6410729912131234": 153, "6410962343215942": 153, "6412571244580745": 153, "6414405763149261": 153, "642276": 34, "642412": 26, "6424735730344598": 15, "643": 15, "643159": 24, "643411": 29, "643467": 26, "643486": 15, "643487": 15, "643488": 15, "643489": 15, "643490": 15, "6434971481561661": 153, "6437": 109, "643700": 113, "644": 21, "644089": 15, "6441273166075167": 133, "6444204216480794": 153, "64492": 106, "645867": 112, "646": [112, 113], "646188926696777": 153, "6467330462218057": 146, "647": [112, 113], "6470509966214498": 153, "647059": [31, 34], "6470937132835388": 153, "64711train_loss0": 17, "6472298730578687": 153, "6475066512823104": 153, "6483241111040116": 153, "6483639587055553": 15, "6484619776407877": 153, "648607": 15, "6486195921897888": 153, "6490831957923042": 153, "64b": 99, "64gb": 52, "64it": 24, "64x64": [10, 11, 89], "65": [15, 23, 30, 36, 54, 102, 112, 113, 133, 136, 142, 153], "650": [10, 112, 113], "6500": 113, "65007954279483": 36, "6501025140285492": 153, "650206": 34, "6503": 113, "6503607503607504": 36, "6503789352872539": 153, "6504347576035394": 153, "6506289839744568": 153, "65080326795578": 153, "650808334350586": 153, "6511220229996575": 153, "651163": 34, "6511701941490173": 153, "6512066079510583": 153, "6514": [31, 32, 33], "6514423076923077": 30, "6515151515151515": 36, "6516749501228333": 153, "6519516706466675": 153, "65217": 23, "6522184759378433": 153, "6524575412273407": 153, "65272802": 15, "6528063505887985": 153, "653300": 113, "6533805131912231": 153, "653463": [25, 31], "653464": [25, 31], "653465": [25, 31], "653466": [25, 31], "653467": [25, 31], "653468": 31, "653502": 25, "6535684954036366": 15, "6538003087043762": 153, "654": 31, "654203474521637": 153, "6542543949045063": 153, "6549134254455566": 153, "6549388404418197": 153, "6549664517243703": 153, "655029296875": 153, "655548": 15, "6560884118080139": 15, "6563803288671706": 153, "656716": 31, "656886": 17, "6570854714462421": 136, "6575677396177281": 22, "657568": 22, "657814": 26, "6580655585685583": 136, "658124": 26, "658565005660057": 153, "658637": 15, "6594241172075271": 153, "6596688153346381": 153, "65b": 84, "65billion": [112, 113], "65it": 25, "65mb": 115, "66": [0, 15, 17, 23, 36, 52, 102, 112, 113, 136, 137], "6600303232669831": 153, "6600911617279053": 153, "66027516": 153, "6602881044149399": 153, "6603913962841034": 153, "6604177474975585": 153, "6609686613082886": 15, "661336047859807": 153, "661544": 26, "661764144897461": 153, "661946": 35, "6619628310203552": 153, "662069": 34, "662247": 96, "662407511472702": 153, "6626d56": [175, 177, 178, 180], "6626d56233bdf14ea2f9741588523c2a6d5c483d": [175, 176], "662704": 29, "66277": 106, "6632340461015701": 153, "6634315013885498": 153, "66354718208313": 153, "6637576699256897": 153, "6637577414512634": 153, "664": 136, "664210915565491": 153, "6643118752373589": 153, "6644162535667419": 153, "664599246033868": 153, "6648780703544617": 153, "665": [112, 113], "665009011942105": 156, "665362": [24, 26, 27, 28], "6657542082998488": 153, "6657921642065048": 153, "6658364466583645": 17, "6659291565418244": 153, "665962": 26, "6659841272566054": 153, "6660489351224613": 153, "666050275001261": 153, "6661734580993652": 153, "6663359231022626": 153, "6666666666516203": 153, "6666666666666666": 17, "666667": [34, 150], "666896": 29, "6669036716222765": 153, "667129993438721": 153, "6675231665372848": 153, "6675720485773954": 15, "6676555216312409": 153, "667660": 24, "667920": [31, 32, 33], "668": 17, "668090": 15, "668761": 15, "668762": 15, "668763": 15, "668764": 15, "668765": 15, "668766": 15, "668767": 15, "668768": 15, "668769": 15, "668770": 15, "6689490675926208": 153, "669206157186698": 153, "6696984320878983": 153, "67": [0, 15, 17, 23, 31, 36, 102, 112, 113], "670": 17, "6701412068472968": 153, "6701883879830325": 153, "6710249781608582": 153, "67116572068": 108, "671351": 24, "6719021423435378": 153, "672": [30, 52], "672131": 34, "6724554291746573": 15, "6727087252669864": 153, "672840": 32, "672965435185822": 36, "673": [15, 108], "673107": 26, "673938": [24, 27, 28, 34], "6741435077455309": 153, "6741549015045166": 153, "6748478": 153, "674951": 35, "674959808588028": 153, "6749999999": 153, "6749999999074999": 153, "675": [31, 32, 108, 153], "67537acc0": 18, "675995961825053": 153, "6764449241372277": 146, "6765992105007171": 153, "6766": 104, "6767237674030993": 153, "6767676767676769": 17, "676806": 34, "6769340634346008": 153, "677083": 34, "6772064924240112": 153, "677306281195746": 153, "677398823599758": 153, "6775986671447753": 153, "67766global_step549lr0": 17, "6779175245241125": 153, "6779964208602904": 153, "678051": 26, "6783880680137142": 136, "6788614100880093": 153, "67927313": 15, "6793989837169647": 153, "6796886920928955": 153, "679706026453727": 36, "67th": [112, 113], "68": [15, 17, 23, 30, 31, 101, 112, 113, 136, 137, 153], "680": 23, "680045485496521": 153, "680219697952271": 153, "680398739212089": 153, "6804": [24, 26], "6805806457996368": 153, "6806197047233582": 153, "68063global_step549lr0": 17, "680778": [24, 26, 27, 28, 34], "682016827000512": 153, "6820690483526008": 153, "6825235188007355": 153, "6826499429616061": 15, "6826923076923077": 30, "6830": 24, "6833051443099976": 153, "6842105263022469": 153, "6846902370452881": 153, "685": [106, 112, 113], "685006892681122": 153, "6851790109009271": 153, "6858244955539703": 153, "6858331813414893": 153, "686": [104, 153], "6861237555742263": 153, "6868418": 0, "687408": 24, "687473406288814": 153, "6875664088461134": 153, "6876316348711649": 153, "687737911939621": 153, "68788004": 15, "688141": [24, 26, 27, 28], "689": [112, 113], "68913eval_loss0": 17, "6893860750728183": 153, "6893939393939394": 36, "689394": 34, "6894": 31, "6894622564315795": 153, "6895470358751884": 15, "689755380153656": 153, "68978acc0": 23, "69": [15, 30, 36, 106, 136], "690": [104, 108, 112, 113], "6900": [18, 20], "690210": [24, 26, 27, 28], "6904528617858887": 153, "6908267736434937": 153, "6908912089135911": 153, "690992": 24, "691": [17, 18], "6918159127235413": 153, "6918225136640888": 146, "691886854171752": 153, "692": 153, "692289924621582": 153, "692308": [31, 34], "6925550699234009": 153, "692587971687317": 31, "693141": 24, "693147180560723": 153, "6933852344751358": 153, "6937022149562836": 153, "69395eval_loss0": 17, "694": 23, "6944896761916455": 15, "694544792175293": 153, "694598": 15, "694599": 15, "694600486755371": 153, "6948964387178421": 153, "6950854659080505": 153, "6951278984546662": 153, "6953143775463104": 153, "695652": [27, 28, 34], "695952582359315": 153, "696": 23, "6960519154866537": 153, "6964739632869893": 23, "6965884747288964": 153, "6966831141048008": 153, "696977050953278": 153, "697": [23, 106], "697141504287719": 153, "6973669797182083": 153, "6974779167686911": 153, "6979990694257948": 153, "698": 104, "69807eval_loss0": 17, "6984683573246002": 153, "69876eval_loss0": 17, "699376": 26, "699400": 113, "6996152639389037": 153, "6997313087533348": 146, "6997373965051439": 153, "6999426712671027e": 113, "699993": 24, "69c99c1f20b21cfc214b07dc630afcc52a23a3a4": 185, "6a4834d": 184, "6billion": [112, 113], "6f": [128, 129, 136], "6m": 7, "6mb": 106, "6min": 15, "6th": 10, "6\uc6d4": 16, "7": [2, 11, 15, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 44, 46, 52, 54, 70, 98, 99, 101, 102, 104, 105, 106, 109, 111, 112, 113, 114, 121, 129, 133, 137, 142, 146, 150, 151, 153, 162, 185, 187], "70": [15, 20, 23, 30, 53, 96, 104, 112, 113, 120, 146, 153], "700": [10, 81, 112, 113], "7000": 113, "70000": 129, "7000000": 104, "7002859115600586": 153, "7004050612449646": 153, "7013998627662659": 153, "70146global_step546lr0": 17, "7015290180842082": 153, "7015772461891174": 153, "701703": 26, "702": 153, "7020963006549411": 153, "702137": 150, "7021779139836629": 153, "7029999999000001": 153, "703": 153, "703344": 129, "7033872485160828": 153, "7034077525138855": 153, "703704": [29, 34], "703916822627378": 153, "704": 111, "7043274402618408": 153, "7045339941978455": 153, "7045623505630207": 153, "704906948407491": 153, "70495eval_loss0": 17, "7050536228550806": 153, "7053548276424408": 153, "7054342985153198": 153, "705539": 24, "70578fn11fp16global_step48mcc0": 17, "705882": [32, 34], "706": 108, "7062499708599514": 153, "706383": 34, "706422758102417": 153, "706954562664032": 153, "7070525884628296": 153, "707182431221009": 153, "7075881520907084": 153, "707927669262908": 153, "7079999999": 153, "7082306557231479": 153, "70836926": 15, "7084757924079895": 153, "7087128102779389": 153, "708752137868833": 153, "7090": 111, "7090898901224136": 153, "7094447016716003": 153, "709791": 35, "70b": 99, "71": [15, 23, 36, 96, 112, 113, 136, 137], "7100220680236816": 153, "7107454538345337": 153, "710816662841373": 153, "711029": 26, "7111220359802246": 153, "7112665004200405": 153, "711332082748413": 153, "7114471904726491": 153, "71160579": 23, "7119239542219374": 153, "712": 17, "7121212121212122": 36, "712603521347046": 153, "7127739984882842": 15, "71288acc0": 23, "71346global_step610lr0": 17, "713495": 35, "7135660039054023": 153, "7139965176582337": 153, "7139999999": 153, "714": 153, "7141295931091425": 153, "7141295931091431": 153, "714368814892239": 153, "7145481109619141": 153, "714690089225769": 153, "715696952078077": 153, "715895": 146, "716": 129, "7161286473274231": 153, "7162305646472507": 153, "71639": 18, "7167915105819702": 153, "7169607857863108": 153, "7170875298093867": 153, "717370119690895": 153, "7174402475357056": 153, "717613": 22, "7176932009588028": 153, "7178064083191105": 153, "7182757245169745": 153, "7183065354824066": 153, "718453": 15, "71868": 106, "719": [112, 113], "719424": 34, "7194733553462558": 153, "7199262201786041": 153, "72": [15, 23, 36, 112, 113, 136], "7202261": 181, "720238": 31, "7202866797702516": 153, "7204073071479797": 153, "72059global_step549lr0": 17, "720808560318417": 153, "72096train_loss0": 18, "72143075466156": 153, "7219855189323425": 153, "72240": 25, "7225010902553423": 136, "7227683544158936": 153, "7229824145634969": 153, "72317train_loss0": 18, "7232087903552585": 153, "723238": 104, "723309": 26, "723513": 35, "7236059308052063": 153, "723911": 25, "724138": [29, 34], "7243074602550931": 153, "7246161": 146, "7247352600097656": 153, "7249999999": 153, "7254211902618408": 153, "7254809141159058": 153, "726": 153, "7261502756012811": 153, "726335525512695": 153, "7268": 104, "727": 25, "7271": 26, "7271665891011556": 153, "7272209480976366": 153, "72731train_loss0": 18, "7275664448738097": 153, "7282691597938538": 153, "7283771634101868": 153, "7286302831437853": 153, "728865": 35, "7289518859651354": 153, "729008": 29, "729900": 113, "72mb": 137, "73": [17, 20, 23, 25, 29, 31, 112, 113, 136], "730000": 26, "731": [17, 18], "731034": 26, "73189train_loss0": 18, "732": [24, 36], "7321758026569418": 153, "7324": 106, "7327": 36, "733": 153, "733351707458496": 153, "7333948813470017": 23, "73341733": 23, "7334885597229": 153, "73375train_loss0": 18, "73376": 106, "7337837298711141": 153, "7339953780174255": 153, "734": [112, 113], "73421train_loss0": 17, "7345global_step549lr0": 17, "7352332243367302": 153, "7353357390220683": 15, "7354151606559753": 153, "7357237325774298": 153, "736": [112, 113], "7361850976943969": 153, "7365705847740174": 153, "736786593331231": 153, "736842": 34, "7368649337026808": 153, "7369999999000001": 153, "73779global_step650lr0": 17, "73782097697258": 153, "738": 31, "7384": 15, "7384365010732551": 23, "73844train_loss0": 23, "7389515042304993": 153, "739": 153, "7390028595924378": 153, "7392514573203193": 153, "739726": 34, "739937": 35, "73fbeaf": 176, "73it": 24, "74": [15, 17, 23, 31, 36, 104, 112, 113, 137, 153], "7400881057268722": 23, "7402534365717239": 153, "740259716245863": 153, "7403112888336185": 153, "7403956360287136": 153, "7404359757900238": 153, "7408284081353083": 153, "74135train_loss0": 17, "741397101149303": 23, "741414487361908": 153, "742": 153, "74201012": 23, "742234440291489": 153, "7424242424242424": 36, "7426078796386719": 153, "7430278062820435": 153, "7431858331334158": 153, "743327": 29, "743425109308362e": 153, "7436153888702393": 153, "7437359650929769": 153, "744": [112, 113], "7442686306105719": 153, "744459581375122": 153, "7445871914581467": 23, "74467025670524": 153, "7447236180904523": 23, "7448662141188256": 153, "74502105": 153, "7450411319732666": 153, "7450666628395886": 153, "745236": 35, "7452939433210036": 15, "7454": 15, "74558687210083": 153, "745588": 34, "7456": 36, "74614": 16, "746253": 35, "7466441154479981": 153, "746772848367693": 153, "7468354430379747": 15, "7469874143600463": 153, "747177": [24, 26, 27, 28], "74724train_loss0": 17, "7482755780220032": 153, "7488": 52, "749077": [31, 32, 33], "7492063492063492": 15, "749298248506891": 15, "7493083596229553": 153, "749388": 24, "749894": [24, 26, 27, 28], "74efc42": [175, 177, 178, 180], "74efc42f1": 175, "74efc42f190870df59f42e1013c8bcb766d119b9": [175, 176], "74it": 137, "75": [0, 15, 17, 24, 26, 31, 32, 33, 36, 104, 106, 112, 113], "750": [112, 113, 118, 185], "7500": 113, "7503141760826111": 153, "750612": 24, "7507988410070539": 23, "7508global_step560lr0": 23, "751225": 35, "7515979970202726": 15, "7523576293806506": 153, "752381": 34, "7525374889373779": 153, "7529": 36, "753": 153, "75302train_loss0": 17, "7531645569620253": 15, "7533559920550403": 153, "7535561919212341": 153, "7535566773749426": 23, "75356eval_loss0": 23, "753678321838379": 153, "75403train_loss0": 17, "7541576802730561": 153, "754637752793726": 153, "7549334557136301": 23, "755": 111, "7556502297443957": 153, "756": [22, 24], "7560356259346008": 153, "7561087608337402": 153, "756882642582059": 153, "756947": 26, "757": 15, "7570669054985046": 153, "75735104": 15, "7574": [0, 7], "757506": 25, "7576857016752074": 153, "7578847774437496": 23, "758": 25, "75823683": 15, "7583": [0, 7], "7586309909820557": 153, "7587": 54, "759": [112, 113], "75912": 16, "7592": 105, "759814174969991": 153, "76": [10, 15, 17, 23, 111, 112, 113], "760": [112, 113], "7601279616355896": 15, "76074743270874": 113, "7609699527422588": 153, "76133126": 15, "7614807307720184": 153, "761785608553607": 153, "762": 22, "76264271736145": 153, "7631global_step456lr0": 18, "764055218641406": 153, "76427eval_loss0": 18, "7649813916948106": 153, "765": 153, "7650192379951477": 153, "765698": 35, "7660671982418458": 15, "7668444594100311": 15, "7671eval_loss0": 18, "767606": 34, "768": [15, 16, 111, 112, 113], "768240": 29, "768800": 113, "7688843831944374": 23, "7691373178155086": 153, "7691373178155088": 153, "76936eval_loss0": 18, "76945686340332": 153, "76it": 25, "77": [15, 17, 23, 25, 31, 104, 106], "770": [112, 113, 118], "7702807784080505": 153, "77039eval_loss0": 17, "771287155151366": 153, "7713922262191772": 153, "7715571337276035": 153, "771775144744973": 15, "7724587930573358": 153, "77292global_step650lr0": 17, "7731204032897949": 15, "773810": 34, "773874": 104, "774047705334313": 15, "7742315477284243": 15, "7743260264396667": 153, "774326799710591": 153, "77445eval_loss0": 18, "7749561309814452": 153, "7749583721160889": 15, "775": [112, 113], "7757685352622061": 23, "7758243685876923": 153, "7759999999074999": 153, "776027750968933": 153, "77644eval_loss0": 17, "776516477637529": 23, "7766585350036621": 153, "77671eval_loss0": 18, "777": 52, "7773478090763093": 153, "7777777777432102": 153, "777802": 26, "7779": 104, "778532": [24, 26, 27, 28], "7788461538461539": 30, "7788773775100708": 153, "7798994974874371": 23, "7799eval_loss0": 23, "77gb": 52, "78": [15, 17, 23, 31, 36, 96, 112, 113, 137], "780": 153, "780089": 35, "780387353897094": 153, "78077936": 15, "7808": 104, "7812200784683228": 153, "78147eval_loss0": 17, "78172128538039": 153, "7823833227157593": 153, "7825global_step456lr0": 18, "783": 153, "783068783068783": 15, "7835": 17, "783784": 34, "7838737487792968": 153, "7839088670144436": 153, "783973473707835": 153, "7841405712333676": 153, "785": 104, "785336": [15, 22], "785425448417662": 153, "78543353": 15, "786": [52, 104], "7863431660657688": 153, "78634918": 15, "7866509199609911": 153, "78679global_step456lr0": 18, "787": [112, 113], "78751eval_loss0": 17, "7875376955323292": 153, "7875376955323294": 153, "787820911407472": 153, "788": 153, "7881527801250634": 15, "78852eval_loss0": 17, "788555": 26, "7892586641434904": 17, "789669513702393": 153, "78it": 24, "79": [15, 17, 23, 31, 113], "790": [112, 113], "7900076427042646": 153, "7901608188947041": 153, "7903929410806272": 153, "79063701800694e": 109, "7906828334396937": 17, "7908996045589447": 153, "790970": 129, "791655": 129, "791667": 34, "7917594692248326": 153, "792": 24, "7923396890705874": 17, "7923858074358401": 153, "7924955818388195": 153, "7925": 15, "794034": 15, "79414225": 15, "7942999": 153, "79475519657135": 153, "79481234550476": 153, "7948817253112793": 153, "794895172119141": 153, "7951": 15, "795524288275124": 153, "795838020247469": 15, "79634953": 15, "796858215332032": 153, "7968761801719666": 153, "797343": 35, "7973950795947902": 15, "79745eval_loss0": 17, "797537386417389": 153, "7978774722624216": 15, "7978934049606323": 153, "79864global_step456lr0": 18, "798841881752014": 153, "799": 104, "79cde8905e45a47f": [102, 108, 109], "7b": [52, 84, 99], "7b1": 52, "7ffd228": [182, 183], "7m7e05hu": 17, "7m7e05husync": 17, "7min": 151, "7\uc6d4\ubd80\ud130": 21, "7\uc77c": 21, "8": [2, 7, 10, 15, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 52, 62, 70, 84, 89, 99, 100, 101, 102, 104, 106, 109, 111, 112, 113, 114, 115, 116, 125, 133, 136, 137, 142, 146, 150, 151, 153, 162, 185, 187], "80": [15, 17, 18, 23, 30, 31, 36, 84, 112, 113, 116, 121, 133, 146, 151, 153], "800": [52, 112, 113, 137], "8000": 113, "80000": 129, "800000": 31, "8000000": 104, "800041675567627": 153, "8005030751228333": 153, "80069train_loss0": 17, "8009085059165955": 153, "801": 0, "80128765": 15, "80148global_step650lr0": 17, "80164global_step456lr0": 18, "802091729640961": 153, "802290514152911": 153, "8025983892937552": 153, "8025984580504936": 36, "8027013989387362": 15, "8027322625961777": 153, "802841540755959": 17, "802891": 109, "803030303030303": 36, "8035576939582825": 153, "803606": 29, "8036339667108323": 153, "803800": 113, "8041651871469286": 153, "8041757582507306": 15, "8042060041106648": 15, "8045366795366795": 15, "8046839102325267": 15, "8049886621315193": 15, "805": 29, "805270916317296": 153, "8053802145851983": 153, "805790901184082": 153, "805954927572994": 15, "8067716627733474": 15, "8069455133544075": 153, "807": 15, "8070857387586171": 146, "8073120721209749": 36, "8075026869773865": 153, "8075116052276107": 15, "807693099975586": 153, "807850": 20, "8080": [18, 21, 62], "8084240469908484": 15, "809008": 24, "809384": 31, "8094637852091993": 15, "8096889436244965": 153, "80990493381229": 153, "80gb": 52, "81": [15, 17, 23, 31, 136], "8106017713175628": 15, "810671669674209": 153, "8109302162168566": 153, "8109302162251897": 153, "811": [112, 113], "8117618": 153, "8122045384513007": 153, "812558126449585": 153, "812592": 24, "8128131628036499": 153, "813314": 29, "813571095466614": 153, "8136528134346008": 153, "8138297478357951": 153, "81464global_step650lr0": 17, "8148148151": 153, "8148745715618133": 153, "814890384674072": 153, "8153495192527771": 153, "8154245281843358": 153, "8155": 104, "8156261616282993": 153, "815864": 34, "8160": 113, "8160318732261658": 153, "8165262017090233": 153, "817": 153, "817172": 35, "817219": 153, "8174244178666009": 153, "817425860464573": 153, "817477707696492": 153, "8179838974696024": 15, "8180068135261536": 153, "8181499573919508": 153, "81818402": 15, "8182960730456528": 153, "81832": 104, "8192": [9, 146], "8194134831428528": 153, "8197667598724365": 153, "819876": 29, "8199644976192051": 153, "82": [15, 17, 23, 29, 36, 112, 113], "820743430985345": 153, "821": [112, 113], "821036100387573": 153, "821884269184537": 153, "822197030576038": 153, "8224291814698114": 153, "8229714737584194": 153, "8231304507724357": 15, "8232758620689655": 15, "82328": 153, "823284888087085": 153, "823479084407582": 15, "824": [112, 113], "824231719970703": 153, "8243044892946879": 153, "8245844": 153, "825088196727965": 153, "82520e7875fc69": 111, "82527global_step650lr0": 17, "825504": 22, "8255044887345607": 22, "8255860805511475": 153, "8257068116299219": 153, "8257713248638838": 15, "8259999998999998": 153, "8265": 15, "8269158482551573": 153, "827": 24, "8270976185798645": 153, "8275042325607501": 153, "82756757736206": 153, "8275765712628258": 15, "828204870223999": 153, "828649": 24, "82866eval_loss0": 17, "8291": 15, "8293424091943761": 153, "83": [15, 17, 23, 24, 25, 31, 122, 131, 136], "8304114023844401": 153, "8306878306878307": 15, "8310660719871521": 153, "831461": 34, "8316201654065506": 15, "831760479344262": 153, "8321995464852607": 15, "8324528217315674": 153, "8329554043839759": 15, "8330308529945554": 15, "833248193": 153, "833444407582283": 153, "833746569962225": 153, "834": 15, "834000": 26, "8340578079223633": 153, "8344671201814059": 15, "8346521258354187": 153, "8346863150596618": 153, "835": 153, "835000": 34, "8351849488988791": 15, "8351891378637732": 15, "8352229780801209": 15, "836478": 34, "8366067935289703": 153, "8370756314020869": 15, "837860183047866": 153, "839": [24, 112, 113], "8396104574203491": 153, "839826829122668": 153, "8398320378929996": 153, "839832037893": 153, "83it": [21, 31], "84": [15, 17, 23, 31, 112, 113, 118, 120], "840": [112, 113], "8405752408315796": 153, "841389800608158": 153, "8416612963899948": 15, "8416924252477069": 15, "8418636918067932": 153, "8419096206765615": 15, "8420461010091653": 15, "842105": 34, "84284": 23, "8428568844583993": 15, "8431163771644155": 153, "8431163771644157": 153, "84325": 29, "843464023537106": 153, "843712": 29, "8446215139442231": 15, "8448275862068966": 15, "845041184955173": 153, "845083717375899": 15, "84513521194458": 153, "8452358961105346": 153, "8453894654909769": 153, "8456896551724138": 17, "846154": 34, "846369": [31, 32, 33], "8465215619765862": 17, "84662264585495": 153, "847029685974121": 153, "8471301983903201": 15, "8471407045467768": 153, "8472237527370453": 153, "847674": 24, "8481564521789551": 153, "849": [112, 113], "8490943908691406": 153, "8492333903150788": 17, "8496030672556825": 153, "84gb": 52, "85": [15, 17, 23, 24, 31, 112, 113, 116], "850": [112, 113], "8500": 113, "8501870264609654": 153, "8501989907520767": 15, "8509526835547553": 153, "851": 18, "8517777272479437": 15, "8518518518232738": 153, "8520880222320557": 153, "8528951346874237": 153, "8539513349533081": 153, "854": [104, 111], "85427": 18, "854999": 24, "8551825504170523": 153, "8555574890591362": 153, "856754672889186": 153, "8568254854944017": 153, "8570949314037963": 153, "8571844696998596": 153, "8576761537128025": 153, "8582547346750895": 153, "858469": 101, "858684": 31, "8589930772781371": 153, "859194891827816": 153, "85934401": 15, "8595886193597174": 15, "8598122": 15, "85\ub144": 16, "86": [15, 17, 21, 23, 112, 113, 151], "860287052386768": 153, "8611091058190008": 153, "8613271713256836": 153, "8615469124582079": 153, "8617703727076175": 153, "8617703727076176": 153, "8617791864607067": 153, "8618583679199219": 153, "8620413064956665": 153, "8622870445251465": 153, "862912118434906": 153, "863": 52, "8631192445755005": 153, "8631575107574463": 153, "8633557140827179": 153, "8633925139904022": 153, "863442": 24, "864": 15, "8641168276468912": 153, "8644108938029865": 15, "8644522918595208": 153, "86489": 25, "8649173259735108": 153, "865800": 113, "866727590560913": 153, "8671932220458984": 153, "8675100591447619": 153, "8678891599178314": 153, "8680202687611864": 153, "8683999688876635": 153, "8684459182951185": 153, "8691527287165324": 153, "8691604139030074": 153, "87": [15, 17, 23, 112, 113, 122, 131], "870": [0, 15, 153], "8707619605792893": 153, "8707838190926446": 153, "870980441570282": 153, "871009826660156": 153, "871084690093994": 153, "8713": [21, 23], "871394": 35, "871484327316284": 153, "871793395280838": 153, "87184global_step790lr0": 17, "872": 104, "87225178": 96, "8728516340255738": 153, "872867226600647": 153, "8731648921966553": 153, "873382854368536": 153, "873748779296875": 153, "8740266468789842": 153, "87408849234339e": 153, "8743": 15, "874766953786214": 153, "874kb": 101, "875": 185, "8754242658615112": 153, "8754687373542778": 153, "8755013942718506": 153, "8755223027370869": 153, "8756595693460896": 153, "875851555821591": 153, "8764177560806274": 153, "8765435218811035": 153, "877": 153, "877087": 35, "87733449406094": 153, "878": 153, "878004424663513": 153, "8785028352814224": 153, "8786590695381165": 153, "8787878787878788": 36, "879450798034668": 153, "879700": 113, "8799245460269352": 153, "88": [15, 17, 23, 24, 89, 118], "880208917458852": 153, "8803811073303223": 153, "880466": 34, "8805878221988678": 153, "8807709": 23, "880851": 31, "88103": 106, "8818578124046326": 153, "88197": 25, "882": 0, "882071053981781": 153, "882104041841295": 153, "88246488571167": 153, "8836": 104, "8836533972493942": 153, "8838164329528808": 153, "88382": 21, "8839708745479584": 153, "88407": 21, "88413": 21, "88439": 21, "884681761264801": 153, "884779371155633": 153, "8848589893698096": 153, "885008454322815": 153, "8855": 153, "88550": 21, "8856943421893649": 153, "885801887512207": 153, "8858444094657898": 153, "8865294039249421": 153, "886792": 29, "8869431614875793": 153, "887": 0, "887304": [24, 26, 27, 28], "8874885131087566": 153, "888": 153, "888152563256316": 156, "888158": 31, "8882899284362793": 153, "888783973455429": 153, "8888888888790125": 153, "8888888888823795": 153, "8888888888827162": 153, "889": 104, "889160": 150, "8892569541931152": 31, "8896758079528808": 153, "889790": 35, "88it": 111, "89": [15, 17, 18, 36, 104, 109, 112, 113, 136], "890": 153, "890000": 26, "8905021548271179": 153, "8905305203853535": 153, "8911628544330596": 153, "8912580755021837": 153, "8913208246231079": 153, "8918190002441406": 153, "8919851157400344": 153, "892": [52, 112, 113], "8920": 109, "8924511830012004": 153, "893": [24, 26, 27, 28], "893048": 150, "8930710017681122": 153, "8931920528411865": 153, "893358": 26, "893755": 35, "8938221335411072": 153, "893900990486145": 31, "8939241734827547": 36, "8944442338413663": 153, "89454": 21, "89486acc0": 18, "895": [24, 26, 27, 28], "895180702209473": 129, "8953": 23, "8955254554748535": 153, "8955683052539826": 153, "8957698961367982": 31, "8958088377661515": 31, "8960176991150443": 31, "8960376670584083": 23, "8960786700248718": 153, "896372185813056": 153, "896465": 15, "8964992761611938": 153, "896727": 129, "896856880187988": 153, "897": 52, "8972178141276042": 153, "897441": 35, "8977bc2": 186, "898551": 29, "898655": 31, "8989042401313782": 153, "899151": 26, "8993445038795471": 153, "8995069801807404": 153, "899846577644348": 153, "8999915237636707e": 153, "899k": 101, "89d6ac597a40e29": [102, 108, 109], "8aa13df": 176, "8aa13df1fa53b03617c8b86752d442068c0ce56a": 176, "8b": 99, "8billion": [112, 113], "8gb": 52, "8k": 106, "8mb": [52, 115], "8min": 15, "8th": [112, 113], "8x8": 10, "8\uac1c": [16, 20], "8\uac1c\uc0ac\uac00": [16, 20], "8\uc6d4": 16, "8\uc6d4\uc5d0": 15, "8\uc8703000\uc5b5\uc6d0\ub300\ub85c": 20, "9": [0, 2, 7, 15, 17, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 52, 96, 100, 102, 104, 106, 107, 109, 112, 113, 118, 120, 129, 133, 136, 137, 146, 150, 151, 153, 162, 181, 185, 187], "90": [15, 18, 31, 111, 112, 113, 137, 151, 152, 153], "900": [102, 112, 113], "9000": 113, "90000": 129, "9000000": 104, "900003040065772e": 153, "9000521475110517": 153, "900067400932311": 153, "90013": 17, "9006467580795288": 153, "9011274512865044": 153, "901128": 35, "9013971149921417": 153, "901506": 26, "9017829835414887": 153, "9018328309059143": 153, "9020455718040467": 153, "902053": 31, "9023345887660981": 153, "9027936637401581": 153, "9028993308544159": 153, "903": 0, "9030599276224772": 153, "903959184885025": 153, "904638576448713": 153, "9047776937484742": 153, "905062073469162": 153, "9051498711109162": 153, "9054386794567109": 153, "905730802064189e": 109, "9058874368667602": 153, "905983": 29, "9061625897884369": 153, "9061688786978715": 153, "906697412331899": 153, "906922808788813": 153, "907007": 25, "9071476677119651": 153, "9072303771972656": 153, "90740": 21, "9074244916439056": 153, "907718539237976": 153, "90773559": 15, "9077460765838623": 153, "9077514350414276": 153, "9079844713211059": 153, "9079863071441651": 153, "908": [17, 104], "9081074988842013": 153, "908365": 26, "9083827204174466": 153, "9084170997142792": 153, "9084529221057892": 153, "9084756791591644": 153, "9086": 17, "9086551727646448": 30, "9086619794368744": 153, "9087440133094787": 153, "908799512368887e": 153, "908976": 35, "90918": 21, "9092812064780683": 153, "9093945089752844": 153, "9094338595867157": 153, "9098460018634796": 153, "90f23ec": 178, "90k": 89, "90m": [133, 136, 137, 151], "91": [15, 18, 23, 31, 151, 153], "9101777918673029": 22, "910178": 22, "9101901948451996": 153, "9103051900863648": 153, "9104019999504089": 153, "9104682432280646": 153, "9105643033981323": 153, "9105921447277069": 153, "9106474757194519": 153, "9106616199016571": 153, "9106798052787781": 153, "9106871962547303": 153, "9107547461986542": 153, "9107627511024475": 153, "910851": 35, "9109231293201446": 153, "91106196641922": 153, "9110627174377441": 153, "9110994279384613": 153, "9111285269260406": 153, "9111976206302643": 153, "9112907469272613": 153, "9114029586315155": 153, "9114533245563508": 153, "9114806866952789": 15, "9115502536296844": 153, "9116369605064392": 153, "9116515040397644": 153, "9118037780125937": 153, "9118721087773641": 153, "9118741154670715": 153, "911925446987152": 153, "9119442880153656": 153, "9119841039180756": 153, "9120813608169556": 153, "9120863258838654": 153, "9121033608913421": 153, "9121947288513184": 153, "9122909307479858": 153, "9123625040054322": 153, "9123888492584229": 153, "9125157237052918": 153, "9126778662204742": 153, "9129321826829": 153, "9129396239916484": 153, "9133953988552094": 153, "9134948909282684": 153, "9135325968265533": 153, "9136266094420601": 15, "9141834139823913": 153, "9142145872116089": 153, "9143188178539277": 153, "9146278921763101": 153, "9148176729679107": 153, "914996188879013": 153, "915027": 26, "91504776": 15, "91516358": 15, "9152511358261108": 153, "9159986495971679": 153, "91612019971099": 153, "91635215": 153, "9164608538150787": 153, "9164952185418871": 153, "9165": 106, "9166006147861481": 153, "9168468117713928": 153, "9169389188289643": 153, "916973489522934": 153, "917": 0, "9172113299369812": 153, "9174473414104023": 153, "917453050613403": 153, "9177050948143005": 153, "9177692532539368": 153, "918256985219584": 153, "9189544194716004": 153, "919250": 96, "919475555419922": 153, "9197418034076691": 153, "9197915196418762": 153, "91be346ce97972f5": 104, "92": [15, 18, 22, 23, 31, 52, 98, 112, 113, 131], "9200849056243896": 153, "9201": 111, "92010298371315": 153, "920215": 26, "9202969610691071": 153, "92046": 25, "92047": 25, "9204763114452362": 153, "92048": 25, "92049": 25, "92050": 25, "92051": 25, "920939": [24, 26, 27, 28], "9209719644652472": 153, "921": 25, "92140168": 15, "9214084148406982": 153, "9223": 104, "9223617800281911": 153, "9223808370094702": 153, "9223808370094703": 153, "923": 25, "92311429977417": 153, "9233746528625488": 153, "9234955966472626": 153, "9235683441162109": 153, "9235726594924927": 153, "9237553596496582": 153, "9238462153413554": 153, "9238621056079864": 153, "9241811692714691": 153, "9243027687072753": 153, "9244933878967375": 153, "9246693849563599": 153, "925548": 15, "9255641990237766": 153, "9256532788276672": 153, "925821": 29, "9259259259116369": 153, "9259259259181319": 153, "9259259259187814": 153, "92594481": 15, "9259529941013552": 18, "9259544157948747": 153, "926": [15, 21, 153], "9261069238185883": 153, "926681931813558": 153, "9267397880554199": 153, "9269208124816014": 15, "927": 104, "9271989339005193": 153, "9272": 111, "9281115879828327": 15, "928241": 15, "928571": 31, "929": 153, "92mb": 104, "93": [0, 15, 17, 18, 30, 112, 113, 129], "930": [23, 153], "9300058656023976": 153, "9302503347396851": 153, "930793991416309": 15, "9309146285057068": 153, "931201514160114e": 109, "9313304721030042": 15, "9315055": 153, "931628999164661": 153, "9317025850216545": 153, "932": 111, "9320395422644892": 153, "9329399141630901": 15, "932944": 34, "9329968214035034": 153, "9332154810428619": 153, "9333105725176685": 153, "933551393706223": 113, "933635026216507": 153, "9338362574577331": 153, "9338732779026031": 153, "9343199729919434": 153, "9343347639484979": 15, "934763948497854": 15, "935": 153, "9351759076118469": 153, "9353445768356323": 153, "9355605125427247": 153, "9357312977313995": 153, "935814490942164": 15, "9358580072292853e": 153, "9359890752368503": 153, "9361532661649914": 153, "9361587982832618": 15, "9366410970687866": 153, "9366952789699571": 15, "9369237124919891": 153, "937": 185, "937135538789961": 153, "937251": 26, "9372662842273712": 153, "937361064931399": 153, "937481838464737": 153, "937500": [31, 32, 33], "937843376827051": 153, "9378823009649313": 153, "938": [112, 113], "938048362731934": 153, "93838484131265": 109, "9384097099304199": 153, "93872": 21, "9388108253479004": 153, "9392126202583313": 153, "9392213821411133": 153, "9393776824034334": 15, "939386063134093": 153, "9394": 26, "939766138792038": 153, "93it": 24, "94": [15, 18, 31], "940210": [24, 26, 27, 28], "9403512413688508": 15, "9404": 52, "9404210229503303": 18, "9409192383289338": 153, "9409907221794128": 153, "9410110116004944": 153, "9414067029953003": 153, "942301": 15, "9429188728332519": 153, "943": 120, "9435745537281036": 153, "943827": 34, "944": [17, 20], "944037276506424": 153, "944045": 20, "9442847371101379": 153, "9444616088410577": 153, "9446840107440948": 153, "9447168111801147": 153, "945039": 29, "9452589069885053": 153, "9456190446093845": 153, "9458022725617946": 153, "9460621774196625": 153, "946215808391571": 153, "946848": [24, 27, 28, 34], "947": 15, "94701087474823": 153, "947089947075267": 153, "9474806981643329": 31, "947885513305664": 153, "9481481481391936": 153, "948905": 31, "9489622076240566": 153, "9491150442477876": 31, "9492060959339141": 153, "9493901491165161": 153, "9495910765330818": 31, "9496804177761078": 153, "94\ub144": 16, "95": [15, 18, 21, 31, 89, 98, 104, 112, 113], "9500": 113, "9500268008973863": 153, "950174129340383": 153, "9502161026000977": 153, "9502478659152984": 153, "950515135257185": 153, "9512531757354736": 153, "951733589172363": 153, "9522316236050686": 146, "9522718071937561": 153, "952373": 34, "952513": 34, "9525385618209838": 153, "952751": 22, "9527512959359385": 22, "9529073238372803": 153, "952\ub9cc": 15, "9533914708501714": 17, "9547281682491302": 153, "9548657298088074": 153, "9549902737140655": 153, "955": 21, "955035": 31, "955290111180942": 109, "9553639352321625": 153, "9561408758163452": 153, "9561534903362163": 153, "95617": 106, "9568761706352233": 153, "957": 106, "9570511102676391": 153, "957790600982717": 153, "957808": 31, "958100": 113, "9583303928375244": 153, "9586255116896196": 15, "9586986899375916": 31, "9587222039699554": 153, "9588610708713532": 153, "959061336517334": 153, "9597": 26, "959949502845605": 153, "9599951684474946": 153, "96": [15, 18, 20, 23, 31, 36, 112, 113, 136], "960": [0, 15], "960401701927185": 153, "960415": 29, "960746": 31, "9607468128204346": 153, "960805": 31, "9613dda": 181, "9616746664047241": 153, "9618860918242997": 153, "96235901": 23, "962483372280577": 153, "963042879104613": 153, "96359983086586": 153, "9637438952922821": 153, "96388427810584": 153, "964": [112, 113], "9645551145076752": 153, "9645883781616761": 15, "9648597265277666": 153, "964c673": [183, 186], "9657190799713135": 153, "9661835748675581": 153, "9664158940315246": 153, "966483163833619": 153, "96653938": 15, "966953155729506": 153, "967106": 31, "9675707817077637": 153, "967620": 31, "967770": 31, "967973": 31, "968": 185, "968215875053943": 153, "9689162568358742": 15, "968976": 26, "969": 153, "969531393051147": 153, "96gb": 52, "96it": 109, "97": [18, 31, 112, 113, 136], "970": 7, "9702214002609253": 153, "970297": 34, "970326895536801": 153, "97071016": 153, "970902": 15, "9712950348854065": 153, "9719110247106496": 17, "972": 153, "972270": 24, "972928": [24, 26, 27, 28], "9730925319655515": 153, "9735818028450012": 153, "9740810260175872": 153, "9747179567813873": 153, "97506": 22, "9756801762639395": 153, "975768095254898": 153, "9758998453617096": 153, "97593": 21, "976": [112, 113], "97624731": 15, "97627": 21, "97650": 21, "97667": 21, "977142": [24, 27, 28, 34], "9774350543228523": 153, "97756": 21, "977634889": 15, "9778721332550049": 153, "97797042": 15, "9780619010239433": 153, "9782684757568221": 153, "9783030668907": 38, "978488": 22, "9784880492636585": 22, "9786549585511946": 153, "9786576999558343": 153, "9787092269858242": 153, "978836": 24, "979": 153, "979167127609253": 153, "9793456785422703": 36, "9793609": [176, 177, 178, 180], "97936099145d29e1067f42a856e9aa3a41c7b50f": 176, "97gb": 52, "98": [15, 18, 31, 112, 113], "980": [0, 112, 113], "980159": 31, "980204629898072": 153, "980392": 31, "981": [112, 113], "983945485121674": 153, "984": [112, 113, 185], "9841269840876163": 153, "9853566560115524": 15, "9873750627040863": 153, "988107": 26, "9893611453220097": 153, "989784550666809": 153, "99": [15, 104, 106, 112, 113, 118, 129], "990155601501463": 153, "990185": 15, "9904": 104, "991": [29, 112, 113], "992": 185, "992185453036204": 153, "99268501437722": 153, "993": 153, "99320948": 96, "9938374519348144": 153, "9947576940059661": 153, "995413": 34, "9955683946609497": 153, "9956230812602573": 153, "996": 185, "99621": 21, "9969701210657758": 153, "9970690608024597": 153, "9972156604131": 153, "9976812325252717": 153, "998": 185, "998075495427734": 153, "9982102600171": 153, "999": [102, 185], "999072253704071": 153, "999200": 113, "9995": [104, 106], "99957": 106, "9996923130945297": 153, "9996923130945299": 153, "999894": [24, 26, 27, 28], "999999": 31, "9999990000010001": 31, "99acea4a740b4cc36e4a93a238c7de11b0ce341d65b7d37168b3b90fd64721d2": 95, "9min": 151, "9th": [112, 113], "9\ubd84": 142, "9\uc2dc\uae4c\uc9c0": 16, "9\uc6d4": 15, "9\uc6d4\uc5d4": 16, "9\ud488\uc0ac": 141, "A": [0, 2, 5, 7, 8, 9, 10, 38, 43, 46, 47, 51, 52, 53, 55, 56, 60, 61, 62, 63, 65, 66, 72, 74, 75, 79, 81, 82, 83, 87, 88, 91, 94, 96, 98, 100, 101, 106, 109, 110, 112, 113, 114, 115, 120, 121, 122, 123, 125, 127, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 151, 152, 153, 155, 157, 159, 160, 161, 164, 165, 166, 168, 173, 178, 182, 183, 184], "AT": [112, 113], "And": [25, 31, 96, 101, 109, 113, 117, 137, 140, 175, 178, 185], "As": [1, 2, 3, 6, 7, 9, 10, 24, 27, 28, 39, 42, 51, 53, 54, 56, 57, 60, 61, 78, 81, 82, 84, 89, 90, 92, 94, 98, 99, 100, 101, 111, 112, 113, 114, 115, 116, 117, 118, 121, 123, 129, 131, 133, 140, 141, 144, 145, 149, 151, 152, 156, 164, 172, 173, 174, 178], "At": [11, 12, 37, 50, 51, 53, 57, 87, 97, 98, 112, 113, 115, 116, 117, 118, 120, 143, 146, 149, 173], "BE": [112, 113], "Be": [31, 86, 90, 179], "But": [6, 118, 127, 131, 140, 144, 145, 147, 151, 153, 174, 175, 176, 177, 181, 182, 183, 184], "By": [3, 5, 7, 8, 9, 10, 11, 12, 13, 31, 38, 46, 47, 51, 53, 54, 55, 60, 61, 64, 65, 66, 67, 68, 69, 72, 75, 77, 78, 80, 81, 82, 83, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 106, 107, 110, 112, 113, 114, 115, 116, 117, 129, 130, 131, 133, 134, 135, 137, 138, 139, 146, 147, 148, 149, 150, 151, 152, 156, 158, 160, 161, 162, 168, 172, 173, 179, 182, 183], "For": [3, 5, 9, 10, 13, 31, 36, 39, 42, 43, 44, 46, 47, 50, 53, 60, 61, 65, 70, 72, 74, 77, 78, 80, 81, 82, 89, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 128, 129, 130, 131, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 151, 152, 153, 157, 158, 160, 171, 175, 177, 178, 179, 181, 182], "IN": 145, "IT": [15, 65, 66, 72, 112, 113, 160, 161], "If": [15, 31, 46, 47, 55, 69, 77, 78, 82, 85, 93, 94, 98, 101, 102, 106, 108, 109, 110, 112, 113, 115, 116, 124, 126, 127, 131, 134, 141, 144, 145, 146, 148, 153, 158, 174, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186], "In": [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 30, 36, 37, 39, 42, 43, 46, 47, 51, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 77, 78, 81, 82, 83, 84, 85, 87, 89, 90, 91, 94, 95, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 117, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 168, 169, 172, 173, 174, 175, 177, 178, 180, 181, 182, 184, 185, 186], "Into": 7, "It": [4, 6, 7, 9, 10, 11, 13, 25, 31, 37, 38, 43, 46, 47, 48, 51, 53, 54, 55, 57, 60, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 83, 84, 86, 89, 90, 92, 93, 94, 96, 97, 98, 100, 101, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 122, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 163, 165, 167, 168, 170, 172, 173, 176, 178, 179, 182, 184], "Its": [42, 54, 112, 113, 173, 182], "NO": [52, 137, 182], "NOS": [112, 113], "NOT": [15, 17, 18, 23, 31, 106, 111], "No": [15, 16, 17, 18, 20, 22, 25, 30, 36, 44, 70, 72, 75, 85, 89, 98, 100, 101, 106, 112, 113, 152, 167, 168, 174, 178], "Not": [9, 10, 70, 80, 112, 113, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "ONE": [137, 153], "OR": 184, "Of": [98, 112, 113, 145], "On": [0, 7, 10, 30, 31, 36, 43, 44, 51, 60, 61, 63, 77, 98, 112, 113, 116, 117, 120, 127, 137, 145, 152, 153, 157, 159, 173, 174, 175, 177, 179, 182, 184], "One": [6, 41, 47, 50, 51, 53, 60, 72, 91, 98, 106, 112, 113, 116, 117, 119, 120, 131, 134, 138, 139, 140, 144, 148, 154, 158, 178], "Or": [70, 125, 140], "Such": [39, 47, 50, 60, 112, 113], "THE": 174, "That": [61, 98, 102, 109, 112, 113, 131, 176, 178], "The": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 18, 29, 31, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 119, 120, 124, 125, 126, 127, 128, 129, 130, 133, 134, 136, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 164, 166, 168, 169, 170, 174, 176, 177, 179, 181, 182, 184, 187], "Their": [47, 50, 51, 53, 54, 60, 90, 99, 112, 113, 117], "Then": [10, 73, 77, 81, 89, 97, 98, 100, 101, 106, 108, 109, 112, 113, 126, 129, 130, 134, 145, 150, 154, 156, 179, 181], "There": [4, 13, 18, 51, 65, 66, 67, 71, 72, 73, 78, 92, 93, 94, 103, 105, 107, 110, 112, 113, 115, 116, 118, 121, 122, 127, 131, 132, 134, 135, 136, 138, 142, 144, 146, 147, 149, 155, 156, 157, 160, 161, 173, 174, 175, 176, 179, 180], "These": [6, 7, 8, 9, 10, 12, 13, 14, 39, 41, 42, 43, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 63, 65, 66, 67, 72, 75, 77, 78, 83, 87, 89, 90, 91, 92, 94, 96, 98, 99, 101, 104, 107, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 125, 127, 128, 129, 131, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 151, 155, 156, 157, 160, 161, 165, 166, 172, 173, 177, 180], "To": [1, 2, 7, 9, 10, 11, 15, 18, 23, 31, 46, 47, 50, 56, 60, 61, 62, 64, 65, 68, 69, 70, 72, 73, 77, 78, 79, 81, 82, 83, 84, 89, 90, 94, 95, 96, 97, 98, 99, 101, 103, 104, 106, 109, 110, 111, 112, 113, 114, 115, 117, 121, 122, 124, 127, 131, 133, 134, 136, 137, 138, 140, 142, 143, 148, 149, 151, 152, 153, 157, 158, 160, 166, 168, 175, 177, 178, 181, 182, 183, 184, 186], "Will": [26, 112, 113, 117], "With": [1, 2, 7, 10, 13, 14, 46, 50, 51, 52, 60, 65, 66, 67, 77, 82, 83, 91, 98, 107, 111, 112, 113, 117, 118, 129, 131, 134, 140, 142, 156, 160, 161, 162, 167, 168, 173, 182, 186, 187], "_": [9, 25, 85, 98, 100, 106, 108, 109, 120, 125, 127, 129, 134, 140, 144, 146, 148, 150], "_20220911": [15, 22], "_20221229": 15, "___": 114, "___________________________________________________": [15, 17, 23, 30, 31, 36, 136], "__call__": [31, 113], "__dict__": [112, 113], "__file__": 182, "__init__": [128, 129, 153], "__version__": [16, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 153], "__worker_lfs__": 21, "_annot": 21, "_ax": 24, "_blank": 153, "_category_pr": 22, "_column": 31, "_config": [15, 21, 23], "_confusion_matrix": [15, 23], "_copier_conf": 70, "_cv": 15, "_data": 35, "_date": 24, "_derj_9r": [101, 102, 104, 109, 115, 133, 136, 137, 142, 151], "_diff_prev": 24, "_diff_year": 24, "_equinox_iii": 150, "_export": [15, 21], "_finbert": 31, "_format": 24, "_func_": [16, 18, 27], "_i": 126, "_j": 126, "_keys_": 29, "_m": 148, "_method_": [17, 18, 31], "_name": 35, "_of_00020": 113, "_parms_": 29, "_partial_": [16, 18, 25], "_pipeline_": [16, 17, 20, 22, 25, 31], "_polarity_pr": 22, "_pred": [15, 21, 23], "_similar": 149, "_split": 18, "_t5": 31, "_t_sne": 29, "_target_": [16, 18, 25], "_token": 146, "_tone": 32, "_w_2": 144, "a100": [52, 84], "a319": [112, 113], "a320": [112, 113], "a321": [112, 113], "a57fa0037aa12ddd2821b0233a9d917cf821e415": 185, "a600": 143, "a6000": 113, "a7mqtfdv": 18, "a7mqtfdvsync": 18, "a936190": 185, "a93619043f8d34fc902c9968898a2690b4e504d1": 185, "a_data": 153, "a_i": 149, "a_ib_i": 149, "aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559": [112, 113], "aaa": 141, "aac": 132, "aakash": 0, "aardvark": [112, 113, 157], "aaron": [112, 113], "ab": [0, 7, 9, 10, 54, 102], "ab11": 184, "ab323ba": 184, "ab3578d6": 180, "ab3579d6": 180, "aba": [112, 113], "abandon": [50, 112, 113], "abbeel": [0, 7], "abbrevi": [7, 103, 112, 113, 140, 181], "abc": [112, 113, 116], "abcabc123\u1100\u1161\u1102\u1161\u1103\u1161": 105, "abcabc123\uac00\ub098\ub2e4": 105, "abh": [112, 113], "abil": [0, 6, 7, 9, 10, 11, 42, 43, 45, 47, 50, 51, 53, 54, 55, 56, 60, 82, 86, 87, 91, 93, 94, 101, 110, 112, 113, 114, 117, 127, 131, 135, 139, 155, 157, 164, 172, 174], "abjad": [112, 113], "abl": [5, 11, 15, 17, 18, 23, 38, 43, 48, 69, 71, 88, 91, 92, 93, 97, 101, 108, 109, 111, 112, 113, 115, 117, 118, 121, 130, 131, 138, 140, 141, 145, 147, 151, 162, 173, 177, 181], "abnorm": [112, 113], "abolish": [112, 113], "abolit": [112, 113], "abort": [112, 113, 178], "about": [1, 7, 9, 13, 36, 38, 50, 51, 52, 53, 56, 60, 64, 68, 72, 77, 78, 84, 86, 89, 90, 95, 98, 99, 101, 106, 112, 113, 117, 118, 120, 122, 124, 127, 128, 131, 135, 137, 139, 140, 145, 147, 148, 151, 152, 153, 155, 157, 168, 172, 173, 174, 176, 178, 179, 180, 186], "abov": [1, 11, 15, 52, 56, 68, 81, 90, 99, 105, 106, 111, 112, 113, 114, 118, 126, 129, 131, 142, 144, 145, 159, 175], "abraham": [112, 113], "abridg": 50, "absenc": 131, "absolut": [11, 101, 112, 113, 182], "absorb": [1, 112, 113], "absorpt": [112, 113], "abspath": 182, "abstain": 21, "abstention": [112, 113], "abstract": [12, 50, 51, 60, 61, 75, 90, 99, 115, 116, 121, 131, 140, 165, 173], "absurd": 18, "abund": [7, 131], "ac": [0, 102, 112, 113], "ac80a2f": [178, 180, 181], "academ": [84, 86, 90, 112, 113, 169], "academi": [86, 134], "academia": [50, 112, 113], "acc": [15, 17, 18, 21, 23], "acc0": 17, "acc_stat": [112, 113], "acceler": [60, 86, 89, 98, 111, 112, 113, 153], "accent": [113, 143], "accept": [112, 113, 115, 167, 170, 173, 176], "access": [1, 6, 7, 9, 13, 39, 43, 46, 47, 51, 53, 60, 61, 65, 69, 72, 73, 74, 75, 77, 78, 79, 83, 84, 85, 86, 89, 92, 94, 97, 99, 111, 112, 113, 122, 130, 131, 160, 167, 177, 186], "accessor": 0, "accommod": [13, 112, 113, 164, 167, 172, 173], "accompan": 109, "accompani": [84, 94, 109, 112, 113, 179], "accomplish": [2, 113, 115, 117, 131], "accord": [7, 9, 43, 47, 50, 60, 90, 98, 108, 112, 113, 114, 120, 131, 134, 143, 150, 152, 153, 157], "accordingli": [58, 89, 114, 138], "account": [9, 11, 68, 69, 75, 76, 77, 78, 81, 82, 93, 100, 106, 112, 113, 117, 121, 131, 138, 152, 155, 168, 172, 173, 177, 179], "accredit": [112, 113], "accumul": [7, 46], "accur": [1, 7, 8, 10, 11, 13, 41, 43, 50, 54, 56, 58, 60, 72, 74, 86, 89, 91, 94, 98, 99, 101, 112, 113, 123, 131, 132, 133, 135, 138, 142, 147, 149, 151, 152, 168, 173], "accuraci": [7, 8, 13, 15, 17, 21, 23, 26, 30, 31, 36, 39, 42, 43, 46, 51, 52, 56, 58, 60, 72, 75, 85, 91, 92, 93, 94, 106, 110, 111, 116, 117, 122, 129, 131, 132, 133, 136, 137, 138, 145, 151, 166], "accuracy_scor": 136, "accus": [112, 113, 141], "acd2b4820c0b62bd7294ddb900c498fdab6ba657": 185, "achiev": [2, 7, 11, 42, 43, 45, 50, 51, 52, 53, 56, 60, 64, 65, 66, 72, 78, 89, 92, 93, 94, 99, 103, 106, 112, 113, 114, 116, 117, 118, 129, 131, 134, 135, 137, 138, 139, 147, 148, 151, 152, 158, 160, 161, 172, 173], "acic": [112, 113], "acid": [112, 113], "ack": 102, "acknowledg": [53, 86, 99, 112, 113], "acl": 0, "aclanthologi": 0, "acm": [0, 7, 54, 90], "acquaint": 81, "acqui": 102, "acquir": [7, 43, 51, 99, 112, 113, 115, 153], "acquisit": [94, 131, 140], "acrobat": 7, "acronym": [10, 159], "across": [7, 11, 12, 13, 39, 40, 47, 49, 52, 53, 54, 56, 57, 60, 62, 63, 65, 66, 67, 72, 77, 78, 86, 89, 90, 92, 94, 96, 99, 100, 101, 112, 113, 114, 115, 116, 117, 118, 121, 128, 129, 131, 134, 135, 150, 151, 152, 155, 159, 160, 161, 172, 173], "act": [13, 41, 43, 45, 51, 53, 57, 60, 101, 112, 113, 127, 131, 173], "action": [7, 13, 41, 43, 45, 54, 55, 58, 65, 66, 76, 112, 113, 116, 117, 120, 131, 138, 143, 160, 161, 165, 168, 171], "activ": [2, 7, 13, 19, 38, 43, 45, 53, 70, 72, 78, 83, 89, 98, 101, 112, 113, 115, 117, 118, 120, 127, 128, 129, 131, 134, 141, 164, 165, 167, 170, 171, 172, 173], "activation_function1": 129, "activist": [112, 113, 121, 153], "actor": [7, 79, 150], "actual": [11, 46, 53, 65, 67, 89, 98, 104, 106, 112, 113, 129, 137, 144, 148, 151, 160, 165, 167, 170, 172, 173, 186], "ad": [7, 9, 10, 11, 15, 16, 21, 23, 29, 51, 53, 77, 82, 89, 102, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 127, 128, 131, 133, 134, 140, 141, 146, 147, 151, 153, 167, 173, 175, 176, 178, 179, 182, 184, 186], "adalora": [52, 53], "adalora_linear": 53, "adam": [0, 110, 112, 113, 128, 129], "adamik": 8, "adamw": [89, 111, 113], "adapt": [1, 2, 7, 8, 10, 11, 43, 46, 47, 50, 53, 55, 56, 57, 58, 66, 72, 78, 79, 84, 85, 89, 90, 92, 98, 99, 101, 110, 112, 113, 114, 117, 118, 123, 131, 135, 142, 152, 161, 164, 166, 167, 170, 172, 173], "adaption_prompt": 53, "add": [1, 10, 26, 27, 28, 53, 56, 61, 62, 68, 69, 70, 77, 80, 81, 98, 100, 101, 105, 107, 109, 111, 115, 116, 117, 118, 133, 134, 140, 141, 146, 147, 150, 153, 156, 158, 167, 168, 173, 174, 176, 177, 178, 179, 180, 181, 183, 186], "add_available_latest": [24, 32], "add_corpu": 153, "add_decisions_to_calendar": 24, "add_dictionari": 142, "add_doc": 153, "add_dummy_prefix": [104, 106], "add_prefix_spac": 112, "add_special_token": 105, "add_unconventionals_to_calendar": 24, "addict": 137, "addit": [5, 6, 7, 8, 9, 10, 11, 13, 37, 43, 47, 51, 52, 61, 65, 66, 67, 72, 77, 78, 89, 92, 93, 94, 98, 99, 101, 105, 106, 112, 113, 114, 116, 117, 118, 121, 123, 124, 126, 131, 134, 137, 139, 141, 144, 152, 160, 161, 172, 177, 178, 179, 181], "addition": [2, 7, 10, 13, 47, 50, 53, 67, 72, 78, 89, 94, 104, 106, 112, 113, 115, 116, 124, 131, 138, 167, 170, 173], "address": [1, 2, 7, 13, 38, 39, 48, 50, 51, 53, 54, 56, 58, 60, 61, 64, 68, 75, 78, 79, 82, 83, 84, 86, 89, 90, 94, 96, 98, 99, 103, 107, 112, 113, 116, 117, 118, 131, 134, 137, 138, 139, 146, 148, 152, 158, 159, 166, 171, 172, 173, 174], "addus": [81, 82], "adept": [43, 47, 55, 92], "adequ": [39, 72, 84, 96, 112, 113], "aderholt": [112, 113], "adhd": [112, 113], "adher": [2, 7, 44, 47, 70, 78, 90, 112, 113, 122, 166, 167, 168, 172], "adhes": [112, 113], "adi": [112, 113, 125], "adin": 108, "aditya": 0, "adj": 145, "adjac": [115, 139, 152], "adject": [112, 113, 139, 140, 141, 145], "adjust": [0, 10, 13, 43, 47, 51, 53, 56, 75, 89, 96, 98, 99, 107, 110, 112, 113, 138, 145, 156, 172, 173], "adm": 10, "administ": [112, 113], "administr": [77, 82, 83, 94, 112, 113, 120], "admir": [112, 113], "admiss": [112, 113], "admit": [112, 113], "ado": [112, 113], "adob": 170, "adolesc": [112, 113], "adopt": [13, 42, 50, 51, 56, 64, 65, 66, 75, 78, 86, 99, 112, 113, 121, 160, 161, 171, 172], "adp": 145, "adtran": [112, 113], "adult": [112, 113, 137, 140], "adulthood": [112, 113], "adv": 145, "advanc": [0, 1, 2, 3, 6, 7, 9, 10, 12, 13, 38, 39, 42, 43, 45, 46, 47, 48, 50, 53, 56, 58, 60, 61, 73, 74, 78, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 99, 110, 112, 113, 117, 123, 127, 130, 131, 134, 140, 152, 153, 155, 157, 162, 166, 187], "advantag": [6, 7, 10, 47, 50, 51, 52, 53, 55, 58, 74, 97, 99, 110, 112, 113, 116, 117, 121, 130, 133, 135, 139, 148, 152, 155, 167, 173], "advent": [13, 14, 43, 45, 58, 87, 98, 112, 113], "adventur": [112, 113], "adverb": [139, 141, 145], "advers": 60, "adversari": [6, 7, 10, 12, 60, 78, 86, 131], "advertis": [9, 12, 112, 113, 120, 131], "advic": [31, 86, 119], "advis": 43, "advisori": 50, "advoc": [51, 112, 113], "ae": [78, 79, 112, 113], "aerat": 143, "aeroplex": [112, 113], "aerosol": [112, 113], "aerospac": [112, 113], "aeschylu": [112, 113], "aesthet": [3, 8, 112, 113], "af": [96, 102], "affair": [112, 113, 168], "affect": [10, 11, 60, 68, 69, 72, 107, 110, 112, 113, 116, 120, 121, 131, 133, 134, 138, 158, 175], "affel": 100, "affero": 182, "affili": [112, 113, 121, 122, 137], "affin": [112, 113], "affix": 141, "afford": [7, 112, 113], "afforest": [112, 113], "afn": 136, "afraid": 131, "african": [112, 113], "afrikaan": 96, "after": [4, 7, 9, 11, 18, 46, 53, 61, 68, 69, 83, 88, 89, 96, 98, 99, 100, 102, 105, 106, 109, 110, 111, 112, 113, 114, 116, 118, 120, 121, 124, 127, 129, 137, 139, 140, 141, 145, 146, 151, 152, 153, 154, 155, 167, 172, 173, 175, 176, 178, 179, 183, 184, 185], "aftermath": 64, "afternoon": [25, 112, 113], "afterthought": 64, "afterward": [112, 113, 143], "ag": [2, 13, 67, 71, 78, 79, 81, 82, 89, 91, 98, 99, 102, 112, 113, 149], "again": [101, 107, 112, 113, 115, 116, 146, 175, 178, 182], "against": [7, 10, 51, 54, 55, 58, 60, 78, 96, 112, 113, 129, 131], "age1": [112, 113], "age1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx": 77, "age_kei": 77, "agenc": [60, 112, 113], "agenda": [112, 113], "agent": [0, 2, 48, 55, 73, 99, 112, 113, 131], "agentless": [65, 160], "agg_func": 18, "agglom": 149, "aggrav": [112, 113, 137], "aggreg": [54, 120, 122, 135, 139], "aggregate_info": 18, "aggregate_scor": 31, "aggress": [112, 113], "agi": [2, 101], "agil": [2, 47, 65, 66, 160, 161, 162, 166, 168, 170, 171], "agnost": [13, 74, 106], "ago": [112, 113, 131], "agrarian": [112, 113], "agre": 168, "agreement": [70, 78, 122], "agricultur": [89, 112, 113], "ah": 102, "ahead": [46, 51, 78, 102, 129, 153, 176, 183, 186], "ahm": [0, 73], "ai": [1, 2, 4, 6, 7, 9, 15, 17, 18, 23, 41, 42, 47, 48, 56, 59, 72, 79, 84, 86, 89, 91, 94, 97, 98, 99, 102, 117, 123, 131, 135, 140, 142, 155, 167, 169, 170, 171, 186], "aid": [13, 51, 54, 56, 60, 99, 112, 113, 137, 145, 173], "aidan": 0, "aie": [46, 177, 178, 179, 181, 182, 183, 184, 185, 186], "aim": [7, 12, 13, 37, 38, 39, 42, 43, 45, 47, 49, 50, 51, 53, 54, 55, 56, 58, 60, 64, 65, 66, 76, 77, 78, 81, 84, 86, 89, 90, 94, 96, 101, 103, 106, 107, 112, 113, 116, 117, 131, 139, 148, 149, 151, 152, 157, 160, 161, 164, 166, 168, 169, 171, 172, 173, 187], "ainer": 108, "ainsworth": [112, 113], "air": [112, 113, 134], "airbu": [112, 113], "aircraft": [112, 113], "airflow": [57, 72], "airless": [112, 113], "airlin": [112, 113], "airmen": [112, 113], "airplan": 118, "airport": [112, 113], "aiva": 3, "ajunew": 16, "ak": 102, "aka": [112, 113, 180], "akbari": [0, 117], "akin": [47, 54, 157], "al": [0, 7, 8, 53, 54, 72, 85, 96, 98, 99, 100, 102, 106, 107, 108, 112, 113, 114, 116, 117, 118, 120, 121, 125, 126, 128, 129, 130, 146, 148], "al15qitl": 0, "alabahmu": [112, 113], "alabama": [112, 113], "alabamian": [112, 113], "alabamo": [112, 113], "alabamu": [112, 113], "alain": 0, "alan": [24, 31, 32, 187], "alat": 57, "albama": [112, 113], "albanian": 96, "albedo": [112, 113], "albert": [110, 118], "alcohol": [112, 113, 157], "alebamon": [112, 113], "alec": 121, "aleph": [112, 113], "alert": [66, 72, 161], "alex_delvecchio": 150, "alexa": [50, 131], "alexand": [0, 7, 112, 113], "alexandra": 0, "alexei": [0, 7], "alfredo": [112, 113], "algebra": [112, 113, 152], "algorithm": [2, 3, 6, 7, 8, 13, 36, 39, 40, 41, 50, 51, 54, 55, 56, 60, 72, 74, 77, 78, 79, 81, 85, 89, 92, 94, 98, 103, 104, 105, 106, 108, 109, 121, 123, 126, 127, 130, 131, 137, 138, 141, 142, 148, 152, 153, 154, 155, 157, 167, 168, 170, 171], "algorithmia": 72, "ali": [102, 108], "alibam": [112, 113], "alibama": [112, 113], "alibamu": [112, 113], "alic": 121, "alien": [112, 113], "align": [2, 7, 10, 11, 43, 47, 51, 54, 55, 56, 60, 64, 90, 94, 98, 106, 121, 123, 126, 129, 131, 165, 168, 171, 173], "alik": [50, 64], "all": [0, 4, 7, 9, 10, 11, 24, 37, 42, 44, 46, 47, 51, 52, 53, 54, 56, 62, 64, 65, 67, 71, 72, 73, 74, 76, 77, 81, 82, 83, 89, 90, 94, 96, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 118, 120, 121, 122, 124, 126, 127, 128, 129, 131, 134, 137, 138, 139, 141, 142, 143, 146, 147, 148, 150, 151, 152, 154, 155, 156, 158, 160, 167, 168, 169, 170, 172, 173, 174, 175, 177, 178, 179, 180, 181, 184, 185, 186, 187], "all_coherence_scor": 150, "all_word": 102, "alleg": [112, 113], "allegedli": [112, 113], "allegro": 72, "allei": [112, 113], "alleng": 109, "allergi": [112, 113], "allevi": [42, 51, 168], "alli": [112, 113], "allibam": [112, 113], "alloc": [51, 52, 56, 75, 133, 139, 149, 153, 167, 168, 170, 173], "allomorph": 140, "allow": [1, 3, 7, 9, 10, 12, 13, 39, 41, 43, 47, 50, 51, 52, 53, 54, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 85, 86, 89, 90, 92, 94, 96, 97, 98, 99, 101, 103, 104, 106, 107, 110, 112, 113, 114, 117, 122, 123, 125, 127, 130, 132, 133, 135, 137, 138, 139, 143, 145, 146, 148, 149, 152, 153, 156, 159, 160, 161, 164, 165, 167, 168, 172, 173, 175, 177, 179, 182], "allow_whitespace_only_piec": [104, 106], "allyn": 130, "almost": [91, 112, 113, 115], "alo": [0, 7], "alon": [7, 11, 89, 112, 113, 117, 138, 140], "along": [10, 37, 46, 53, 73, 74, 107, 111, 112, 113, 115, 117, 127, 137, 145, 151, 156, 174, 181], "alongsid": [112, 113], "alpha": [33, 53, 106, 112, 113, 134, 153], "alphabet": [104, 106, 109, 112, 113, 140], "alpin": [61, 62], "alreadi": [18, 50, 52, 60, 77, 98, 101, 110, 112, 113, 133, 134, 136, 137, 142, 143, 151, 156, 177, 181, 182, 184, 186], "also": [2, 3, 6, 7, 9, 10, 11, 12, 13, 25, 39, 42, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 65, 67, 70, 71, 72, 73, 74, 78, 79, 81, 84, 87, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 103, 104, 105, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 124, 128, 129, 131, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 147, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 164, 166, 168, 172, 173, 174, 175, 176, 178, 179, 181, 182, 186, 187], "alston": [112, 113], "alt": [118, 151], "altaic": 141, "alter": [47, 51, 55, 78, 86, 112, 113, 140, 173], "altern": [2, 7, 9, 10, 14, 38, 41, 46, 47, 53, 61, 77, 98, 112, 113, 121, 129, 132, 133, 134, 139, 140, 148, 152, 166], "alternate_sign": 144, "although": [10, 51, 53, 54, 67, 70, 89, 112, 113, 114, 125, 148, 152, 155, 183], "alti": 102, "altogeth": 176, "altruist": [112, 113], "aluminum": 153, "alwai": [26, 65, 66, 67, 72, 80, 98, 105, 107, 108, 109, 111, 112, 113, 119, 131, 133, 137, 144, 148, 151, 160, 161, 172, 173, 179, 186], "am": [96, 98, 102, 121, 131, 133, 138, 140, 147, 175, 176, 177, 178, 181, 182, 183, 186], "amalgam": 43, "amateur": [7, 131], "amaz": 137, "amazon": [39, 50, 60, 122, 153], "ambigu": [56, 58, 92, 106, 132, 135, 145, 166], "amen": [42, 137], "amend": [112, 113, 184], "amer": 102, "america": [112, 113], "american": [0, 84, 102, 112, 113, 121, 123], "amhar": 96, "ami": 0, "amid": 153, "amit": [0, 7, 60], "amodei": 100, "among": [41, 43, 53, 61, 65, 76, 84, 87, 98, 99, 102, 106, 112, 113, 121, 123, 145, 148, 150, 152, 160, 165, 168, 172, 173], "amorph": [112, 113], "amort": 116, "amount": [3, 9, 11, 13, 47, 53, 54, 72, 78, 92, 93, 94, 96, 99, 101, 110, 112, 113, 114, 117, 118, 122, 125, 127, 129, 131, 133, 134, 135, 140, 145, 146, 157], "amp": [15, 21, 109], "amper": 3, "amphibian": [112, 113], "ampicillin": 143, "ampl": 53, "amplif": 110, "amplifi": [54, 93, 131], "amtrak": [112, 113], "amus": [112, 113], "an": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 25, 38, 39, 42, 43, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 186], "anachron": 99, "anali": 102, "analog": [47, 54, 60, 99, 116], "analogi": [117, 126, 157], "analys": [32, 112, 113, 131, 136], "analysi": [0, 2, 7, 10, 38, 39, 40, 41, 42, 48, 50, 51, 54, 56, 60, 66, 72, 74, 76, 89, 90, 94, 96, 97, 99, 101, 110, 112, 113, 114, 120, 121, 122, 123, 124, 127, 130, 131, 133, 139, 142, 144, 146, 149, 151, 154, 155, 157, 161, 168, 172, 173], "analyst": [102, 112, 113, 120, 121, 129], "analyt": [2, 38, 40, 54, 66, 99, 147, 161, 164, 166, 168, 171, 173], "analyz": [2, 3, 6, 9, 10, 13, 24, 38, 39, 42, 50, 58, 66, 88, 90, 91, 92, 98, 99, 112, 113, 117, 119, 121, 122, 124, 127, 131, 133, 135, 138, 139, 141, 142, 144, 148, 149, 152, 155, 161, 166, 167], "anarch": [112, 113], "anarcha": [112, 113], "anarchi": [112, 113], "anarchism": [112, 113], "anarchist": [112, 113], "anarcho": [112, 113], "anarkhia": [112, 113], "anc": 102, "ancestor": [112, 113, 181], "ancestri": [112, 113], "anchor": 60, "ancient": [2, 112, 113], "ancillari": 75, "andiron": [112, 113], "andrea": 0, "andreessen": 57, "andrew": [112, 113], "android": [121, 170], "anecdot": [112, 113], "anew": 47, "ang": 109, "angel": 120, "anger": [109, 112, 113, 135], "angjoo": [0, 7], "angl": [9, 10, 112, 113, 127, 148, 149, 158], "anglo": [112, 113], "angri": [4, 131], "angular": [112, 113, 125], "ani": [1, 4, 7, 10, 11, 13, 39, 52, 57, 60, 61, 62, 65, 66, 74, 80, 89, 90, 92, 96, 98, 99, 100, 101, 103, 105, 106, 107, 111, 112, 113, 115, 116, 117, 118, 121, 122, 127, 129, 131, 133, 134, 136, 137, 140, 144, 146, 151, 153, 154, 157, 160, 161, 167, 168, 171, 173, 175, 182, 186], "anim": [6, 7, 9, 101, 112, 113, 118, 138, 144, 150], "ann": [42, 102], "annals_cirp": 150, "anniston": [112, 113], "annot": [15, 17, 18, 20, 21, 33, 56, 60, 89, 94, 123, 129, 131, 137, 138, 147], "annot_arg": 33, "annot_id": 21, "annotation_ag": [15, 17, 18, 20], "announ": 102, "announc": [13, 24, 94, 102, 112, 113], "annual": [0, 112, 113, 123, 124, 153], "annul": [112, 113], "anomali": [13, 78, 112, 113], "anonym": [39, 94, 112, 113], "anoth": [6, 8, 10, 11, 15, 17, 18, 23, 41, 50, 51, 52, 53, 60, 65, 66, 67, 68, 72, 74, 82, 85, 91, 98, 99, 101, 105, 106, 107, 111, 112, 113, 114, 117, 127, 131, 132, 133, 134, 135, 138, 140, 141, 144, 146, 148, 151, 153, 156, 157, 158, 160, 161, 172, 176, 177, 178, 180, 181, 184], "ansibl": [66, 161], "ansuz": [112, 113], "answer": [1, 43, 52, 54, 58, 60, 70, 87, 90, 93, 94, 99, 101, 110, 114, 115, 116, 117, 123, 132, 137, 155], "answer_text": 101, "answers_fil": 70, "ant": 102, "antarct": [112, 113], "antarctica": [112, 113], "antebellum": [112, 113], "anthrop": 60, "anthropogen": [112, 113], "anthropologi": [112, 113], "anthropologist": [112, 113], "anti": [112, 113], "anticip": [51, 53, 112, 113, 114], "anticipatori": 86, "anticonvuls": [112, 113], "antidepress": [112, 113], "antigon": [112, 113], "antipathet": [112, 113], "antipod": 148, "antipsychot": [112, 113], "antiqu": [112, 113], "antithet": [112, 113], "antonym": [138, 157], "antspeak": 116, "anxieti": [112, 113], "anyon": [7, 78, 137, 151, 184], "anyth": [2, 8, 88, 112, 113, 115, 156, 183], "anywher": [112, 113, 182], "aonach": 181, "ap": [102, 106, 146], "apach": [39, 72, 89], "apache_beam": 113, "apart": [72, 112, 113, 117, 144], "api": [13, 21, 43, 46, 47, 57, 60, 61, 62, 65, 72, 73, 74, 78, 86, 90, 101, 113, 124, 136, 160], "api_kei": [101, 124], "apk": 61, "apm": 172, "apocalypt": [112, 113], "apologi": 131, "aporia": 60, "app": [2, 6, 18, 48, 59, 62, 78, 92, 103, 107, 108, 109, 131], "appalachian": [112, 113], "appar": [112, 113, 184], "apparatu": [112, 113], "apparel": [112, 113], "appeal": [53, 112, 113], "appear": [7, 10, 58, 98, 109, 112, 113, 115, 118, 121, 129, 131, 132, 133, 134, 137, 138, 140, 148, 151, 152, 157, 158, 159, 177, 178, 179, 183], "appel": [112, 113], "append": [24, 26, 27, 28, 32, 33, 51, 78, 98, 102, 107, 109, 116, 128, 129, 134, 136], "appl": [50, 52, 60, 103, 106, 108, 109, 128, 131, 134, 140, 146], "appli": [7, 8, 9, 10, 13, 15, 16, 17, 20, 21, 22, 25, 29, 31, 34, 35, 37, 38, 39, 42, 47, 50, 51, 53, 55, 56, 58, 60, 65, 67, 72, 78, 82, 88, 89, 96, 97, 98, 99, 100, 101, 105, 106, 109, 111, 112, 113, 114, 116, 117, 118, 120, 127, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 144, 148, 149, 151, 152, 156, 157, 158, 160, 162, 165, 168, 172, 173, 178, 181, 182], "applic": [0, 2, 6, 7, 8, 9, 12, 38, 39, 43, 45, 46, 47, 48, 49, 52, 53, 55, 57, 59, 61, 62, 63, 65, 66, 67, 71, 72, 74, 75, 79, 83, 84, 86, 87, 89, 90, 92, 94, 95, 97, 98, 101, 103, 106, 110, 112, 113, 117, 121, 122, 123, 127, 130, 133, 134, 141, 145, 146, 148, 149, 155, 156, 160, 161, 163, 164, 170, 171, 172, 173, 187], "apply_to": [16, 31], "apply_worker_lf": 21, "appoint": 50, "apport": [112, 113], "appreci": [81, 98, 112, 113], "approach": [0, 7, 8, 9, 10, 11, 12, 24, 39, 41, 42, 43, 50, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 68, 70, 81, 84, 85, 90, 93, 94, 96, 97, 98, 100, 101, 103, 106, 107, 110, 112, 113, 116, 117, 118, 119, 120, 121, 122, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 147, 148, 149, 151, 152, 155, 157, 158, 160, 164, 165, 166, 167, 170, 172, 173, 176, 186, 187], "appropri": [7, 10, 15, 23, 46, 47, 50, 53, 54, 56, 61, 67, 72, 73, 77, 81, 82, 83, 90, 92, 95, 101, 110, 112, 113, 117, 131, 138, 141, 152, 157, 178, 185], "approv": [68, 69, 112, 113, 122, 167, 168], "approx": [100, 114, 133, 134, 152], "approxim": [8, 9, 10, 53, 96, 106, 112, 113, 120, 129, 133, 134, 139, 152, 157], "apr": 10, "april": [10, 112, 113, 118, 153], "apt": [61, 65, 80, 81, 82, 112, 160], "aqua": [112, 113], "aquacultur": [112, 113], "aquat": 4, "ar": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 23, 25, 31, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 125, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 166, 167, 168, 170, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186], "arab": [96, 131], "arai": [112, 113], "arbitrari": [7, 112, 113, 118, 131, 158, 185], "arc": [112, 113, 122], "arcelormitt": [112, 113], "archaeolog": [112, 113], "archiei": [112, 113], "architect": [43, 50], "architectur": [2, 6, 7, 8, 10, 12, 13, 15, 17, 18, 23, 39, 43, 47, 48, 49, 56, 59, 60, 65, 72, 85, 87, 88, 89, 94, 98, 99, 110, 111, 112, 113, 128, 131, 139, 155, 160, 167, 169, 170, 173], "archiv": [16, 61, 73, 112, 113, 122], "arctic": [112, 113], "ard": 102, "area": [2, 8, 9, 13, 50, 51, 53, 55, 60, 64, 72, 78, 85, 89, 90, 94, 99, 112, 113, 121, 135, 168, 172, 173, 178, 179, 180, 182], "aren": [98, 167, 175, 186], "arg": [16, 21, 25, 31, 111, 112, 113], "argentin": [112, 113], "argentina": [112, 113], "argilla": 137, "argmax": [98, 107, 111, 129], "argo": [65, 160], "argsort": 151, "argu": [112, 113, 131], "arguabl": [90, 98], "argument": [18, 31, 90, 105, 111, 112, 113, 129, 131, 151, 153, 185], "argumentum": 151, "ari": [98, 102], "arial": 29, "arima": 13, "aripiprazol": [112, 113], "aris": [3, 9, 10, 11, 39, 51, 56, 60, 65, 90, 112, 113, 121, 131, 138, 160, 164], "arisen": 51, "aristotl": 2, "arithmet": [10, 50, 58, 99, 101, 114, 148], "ariz": 60, "arizona": 137, "arkansa": [112, 113], "arket": 108, "arkho": [112, 113], "arm": [50, 65, 102, 112, 113, 160], "armadillo": 23, "armand": 0, "armenian": [96, 112, 113], "armi": [112, 113], "arn": 108, "arni": 108, "arnin": 108, "aros": [112, 113], "around": [10, 13, 42, 52, 53, 57, 73, 84, 89, 97, 106, 112, 113, 116, 117, 118, 120, 127, 129, 131, 144, 158, 172, 177, 179], "arpa": 96, "arrai": [13, 50, 51, 60, 74, 104, 106, 112, 113, 127, 129, 133, 151, 153, 159], "arrang": [9, 58, 117], "arrest": [112, 113], "arriv": [54, 72, 101, 109], "arrow": [102, 108, 109, 111, 113], "arsen": [112, 113], "art": [2, 7, 9, 11, 12, 47, 51, 58, 86, 89, 94, 99, 109, 110, 112, 113, 114, 116, 118, 131, 135, 139, 169], "arthur": 60, "articl": [13, 31, 38, 41, 47, 50, 55, 84, 85, 90, 91, 93, 94, 98, 99, 104, 112, 113, 116, 118, 119, 120, 122, 123, 131, 135, 138, 148, 149, 152], "articlesperform": 123, "articless": 85, "articul": [112, 113, 164, 168], "artifact": [7, 10, 11, 17, 18, 23, 72, 112, 113, 116], "artifici": [2, 3, 4, 6, 7, 9, 12, 42, 45, 50, 53, 55, 60, 78, 79, 84, 88, 89, 90, 91, 92, 94, 98, 101, 112, 113, 123, 130, 131], "artist": [6, 8, 112, 113, 150], "artistri": 3, "artner": 108, "artwork": [3, 6], "arxiv": [0, 7, 9, 10, 54, 100], "as_target_token": 31, "asana": 168, "asarrai": 151, "ascet": [112, 113], "ascii": 99, "asd": [112, 113], "ase": 102, "ases": 102, "ashish": 0, "ashkenazi": [112, 113], "ashraq": [102, 108, 109], "ashraq___parquet": [102, 108, 109], "asian": 153, "asid": [112, 113, 117, 182], "ask": [1, 10, 31, 65, 101, 112, 113, 117, 137, 153, 156, 160, 179, 181], "asleep": [112, 113], "aspect": [3, 8, 10, 43, 46, 50, 51, 54, 55, 56, 58, 60, 61, 63, 66, 72, 75, 77, 78, 81, 90, 94, 96, 97, 99, 101, 107, 112, 113, 114, 117, 123, 127, 130, 134, 135, 137, 139, 140, 141, 152, 157, 161, 167, 170, 171, 172, 173], "asperg": [112, 113], "ass": 102, "assail": [112, 113], "assassin": [112, 113], "assembl": 120, "assembli": [59, 112, 113, 165, 170], "assert": [153, 173], "assess": [10, 39, 47, 54, 64, 72, 75, 86, 90, 112, 113, 121, 138, 148, 166, 167, 170, 172], "assessor": [112, 113], "asset": [1, 25, 31, 45, 78, 102, 119, 120, 129, 146, 153], "assign": [10, 38, 60, 71, 76, 91, 112, 113, 114, 115, 116, 120, 121, 127, 128, 132, 133, 134, 135, 137, 138, 141, 145, 152, 153, 155, 159, 162, 168, 172], "assimil": 47, "assist": [3, 6, 39, 43, 49, 51, 54, 60, 89, 90, 92, 99, 112, 113, 132, 144], "assistantag": 43, "associ": [0, 2, 9, 10, 11, 13, 50, 51, 53, 60, 64, 72, 75, 77, 78, 87, 93, 94, 99, 101, 106, 107, 108, 112, 113, 117, 120, 121, 123, 127, 128, 130, 135, 136, 137, 138, 140, 144, 148, 151, 152, 155, 156, 158, 170, 172], "assum": [41, 68, 73, 85, 98, 106, 131, 133, 134, 139, 152, 158, 177, 179, 182], "assumpt": [90, 112, 113, 146, 148, 152, 157, 158, 173], "assur": [13, 56, 167, 170, 171, 172, 173], "asterisk": 55, "asteroid": [112, 113], "astroblem": [112, 113], "astronom": [112, 113], "astronomi": [112, 113], "astyp": [26, 32], "asuncion": 153, "asx": 153, "asymmetr": [77, 78, 79, 153], "asymmetri": [112, 113], "ata": 102, "ate": [102, 141], "ates": 102, "atheism": 151, "atheist": 151, "athenian": [112, 113], "athlet": [60, 112, 113, 131], "ati": 102, "ating": 102, "ation": 102, "ativ": 102, "atkin": [112, 113], "atlanta": [112, 113], "atlassian": [66, 161], "atmospher": [4, 112, 113], "atom": [4, 54], "atop": 129, "atp": [112, 113], "attach": [78, 112, 113, 124, 141], "attack": [10, 53, 64, 78, 112, 113, 120], "attain": [7, 53, 93, 112, 113, 118], "attempt": [112, 113, 135, 152, 168, 176, 178], "attend": [7, 11, 53, 88, 89, 112, 113, 117, 118], "attent": [0, 2, 7, 9, 10, 11, 12, 13, 47, 54, 56, 60, 89, 90, 93, 97, 99, 101, 105, 112, 113, 116, 118, 131, 139, 155, 182], "attention_mask": [101, 105, 111, 113], "attention_probs_dropout_prob": 113, "attitud": [112, 113, 119, 137], "attngan": 12, "attornei": [112, 113], "attract": [6, 112, 113, 152], "attribut": [3, 10, 43, 44, 45, 60, 94, 99, 101, 105, 112, 113, 135, 141, 151, 166], "attun": 136, "atur": 102, "atyp": [112, 113], "au": 102, "auburn": [112, 113], "aud400": 153, "aud450": 153, "audienc": [99, 112, 113, 135, 168], "audio": [0, 10, 51, 60, 73, 117, 122, 151], "audit": [13, 65, 120, 121, 124, 160], "auditor": [112, 113], "aug": 153, "augment": [2, 3, 10, 11, 43, 47, 48, 51, 53, 89, 94, 101, 106, 121, 131, 132], "august": [0, 102, 112, 113], "augusta": 6, "auprc": 15, "auroc": 15, "aurora": 4, "austral": [112, 113], "australia": [0, 153], "authent": [2, 46, 47, 65, 71, 77, 79, 81, 83, 160], "author": [7, 10, 11, 78, 79, 85, 96, 112, 113, 116, 117, 118, 121, 175, 176, 181, 185], "authoris": 177, "authoritarian": [112, 113], "authorized_kei": [81, 82], "authorship": [3, 94], "autism": [112, 113], "autismu": [112, 113], "autist": [112, 113], "auto": [17, 18, 20, 25, 29, 43, 74, 75, 98, 99, 101, 102, 104, 109, 111, 112, 113, 115, 129, 137, 176, 178], "auto_pip_depend": 74, "autocomplet": [99, 131], "autocrat": [112, 113], "autoencod": [7, 12, 127], "autogen": [2, 48], "autogpt": [43, 45], "autoimmun": [112, 113], "autom": [7, 13, 39, 43, 45, 54, 56, 57, 61, 64, 65, 66, 67, 70, 76, 86, 94, 122, 131, 160, 161, 166, 167, 168, 170, 171, 172], "automag": 176, "automak": 153, "automat": [7, 8, 9, 31, 60, 65, 72, 74, 75, 89, 99, 105, 112, 113, 131, 135, 137, 139, 141, 142, 146, 160, 166, 175, 178, 179, 183], "automl": [2, 36, 37, 38], "automobil": [112, 113], "automodel": 115, "automodelforseq2seqlm": 52, "automot": [51, 112, 113], "autonom": [43, 45, 51, 54, 55, 60, 112, 113], "autonomi": [43, 45, 58, 112, 113], "autonotebook": [101, 102, 104, 109, 111, 112, 113, 115, 137], "autopilot": 7, "autoregress": [0, 7, 9, 10, 110, 112, 116, 118, 131], "autosc": 56, "autoscrap": [2, 45, 48], "autotoken": [105, 112, 113, 115], "autotrain": [2, 47, 48], "autotrain_project_nam": 46, "autreat": [112, 113], "aut\u00f3": [112, 113], "aux": [61, 145], "auxiliari": [9, 10, 47, 89, 101, 112, 113], "av": 146, "avail": [7, 9, 10, 13, 24, 25, 31, 37, 38, 39, 43, 47, 51, 53, 54, 60, 61, 62, 65, 66, 67, 70, 72, 77, 80, 84, 89, 90, 94, 96, 101, 105, 111, 112, 113, 115, 116, 118, 120, 121, 122, 126, 128, 131, 133, 134, 136, 137, 140, 142, 149, 151, 160, 161, 168, 170, 173, 186], "avatar": 7, "avenu": [3, 41, 53, 90], "averag": [27, 28, 85, 102, 112, 113, 114, 115, 116, 118, 120, 121, 125, 129, 133, 134, 136, 145, 146, 148, 153, 155], "average_coher": 153, "aveyron": [112, 113], "avg": [15, 17, 23, 30, 31, 36, 136, 137], "avid": 23, "avoc": [112, 113], "avoid": [7, 11, 18, 31, 50, 52, 55, 56, 90, 96, 98, 101, 103, 107, 112, 113, 117, 133, 134, 146, 182], "avx": 153, "avx2": [15, 23, 101, 153], "aw": [60, 65, 72, 160, 168, 170], "awai": [112, 113, 116, 137], "await": 179, "awaken": [112, 113], "awar": [8, 11, 13, 31, 56, 58, 64, 90, 92, 110, 112, 113, 115, 121, 131, 136, 155, 158], "awesom": 98, "ax": [24, 25, 26, 27, 28, 32, 33, 150], "ax2": [26, 33], "axessubplot": 16, "axi": [15, 32, 111, 112, 113, 137, 153, 156], "axial": 117, "axno": [24, 25, 26], "axvspan": 33, "ayb": [112, 113], "ayp": [112, 113], "ayq": 0, "az": 96, "aza": [112, 113], "azerbaijani": 96, "azur": [60, 65, 86, 160], "a\uac70\ub798\uc18c": 21, "b": [1, 10, 17, 18, 23, 52, 54, 56, 68, 69, 75, 79, 89, 98, 102, 109, 112, 113, 115, 116, 118, 120, 121, 125, 148, 149, 152, 153, 175, 176, 178, 179, 181, 183], "b101602": [178, 180, 181], "b1osgjx9": 136, "b305c5107a17618f2938a067d5ffcbb556909d82398762089": 136, "b41f869": 184, "b4befef": 176, "b63f764": 175, "b86f514977d51ee81aaea6b10573b8fd9bfd0a38": 185, "b943bed": [177, 178, 180], "b_": [120, 121, 146], "b_i": 149, "ba": [100, 102], "bab2min": 0, "babbl": [112, 113], "babel": 7, "babi": 140, "back": [6, 9, 10, 29, 47, 54, 60, 65, 72, 73, 81, 89, 102, 111, 112, 113, 120, 121, 128, 133, 134, 137, 145, 149, 153, 160, 175, 176, 178, 179, 181], "backbon": [7, 49, 52], "backend": [16, 21, 25, 31, 61, 70, 78, 80, 168, 182], "backend_pdf": 182, "backend_token": 105, "background": [48, 55, 90, 112, 113, 117, 131, 135], "backlash": 121, "backlog": [172, 173], "backpropag": [9, 89], "backtrack": 54, "backup": 174, "backward": [31, 89, 113, 117, 128, 129, 146], "bacon": [130, 159], "bacteria": [7, 143], "bad": [96, 118, 137, 176, 182, 185], "bag": [2, 112, 113, 127, 130, 139, 140, 146, 147, 151, 155, 157, 159], "bah\u00e1\u02bc\u00ed": [112, 113], "bai": [112, 113], "bake": 101, "baker": [0, 112, 113, 120], "bakeri": 140, "bakunin": [112, 113], "bakuninist": [112, 113], "balanc": [24, 26, 27, 28, 29, 42, 43, 46, 47, 53, 54, 56, 78, 89, 93, 94, 98, 103, 107, 112, 113, 116, 117, 134, 137, 168], "balanced_diff": [24, 26, 27, 28, 29, 30, 34, 36], "baldwin": [112, 113], "ballerina": 7, "ballot": 120, "bamboo": [66, 161], "ban": [102, 112, 113], "banana": [128, 134], "banc": 102, "band": [112, 113], "bang": [112, 113], "bangla": 96, "bank": [2, 37, 38, 44, 100, 102, 112, 113, 121, 131, 138, 153], "banker": 44, "bankhead": [112, 113], "bap": 131, "bapeul": 131, "baptist": [0, 112, 113], "bar": [1, 86, 102, 112, 113, 115, 129, 137, 150, 151, 156, 157], "barachia": [112, 113], "barb": [112, 113], "barbasol": [112, 113], "barber": [112, 113], "barcelona": [112, 113], "bard": [43, 50, 94], "bare": [76, 186], "bare_dir": 186, "bare_repo": 186, "barh": 156, "barret": 0, "barri": 0, "barrier": [7, 99, 116], "barsetshir": 175, "bart": [96, 98, 101], "barth": 0, "barto": 54, "barua": 0, "base": [0, 1, 2, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 39, 43, 45, 47, 50, 52, 54, 55, 57, 58, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 80, 82, 84, 85, 87, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 140, 141, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 167, 168, 170, 171, 172, 173, 174, 180], "base_dir": 31, "basebal": [97, 112, 113, 130], "baselin": [2, 37, 38, 52, 72, 170], "basenam": 182, "basesentimentanalys": 31, "basesnorkel": 21, "bash": [46, 80, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "bashag": 80, "basi": [61, 84, 89, 112, 113, 140, 154, 156, 168], "basic": [2, 5, 38, 47, 68, 76, 77, 81, 88, 93, 108, 109, 112, 113, 117, 119, 130, 131, 135, 140, 141, 145, 154, 158], "basicconfig": [24, 26, 27, 28, 29, 31, 36], "basqu": 96, "basra": [112, 113], "bass": 138, "bassett": [112, 113], "batch": [11, 16, 21, 22, 25, 31, 46, 56, 72, 89, 111, 112, 113, 129], "batch_dir": 21, "batch_siz": [46, 112, 128, 129], "batcher": [16, 17, 18, 21, 25, 31], "batr": [112, 113], "battalion": [112, 113], "battl": [112, 113, 116], "bay": [106, 135, 138, 139], "bayou": [112, 113], "bazaar": 186, "bbd16": 0, "bc": [112, 113], "bd": 148, "bdrf": [112, 113], "bdvj03": 0, "beach": [112, 113], "beacon": [178, 180, 181], "beam_output": 98, "bean": [157, 159], "bear": 157, "bearish": 129, "beat": [102, 118, 153], "beaufort": [112, 113], "beauti": [4, 141, 159], "beautifulsoup": [13, 44, 94, 122, 124], "beautifulsoup4": 124, "becam": [112, 113], "becaus": [9, 10, 11, 25, 29, 42, 54, 61, 72, 89, 91, 93, 96, 98, 100, 109, 111, 112, 113, 114, 115, 116, 117, 129, 131, 133, 137, 141, 143, 144, 146, 148, 153, 154, 173, 176, 177, 178, 179], "becom": [6, 10, 13, 42, 47, 51, 53, 54, 60, 63, 64, 65, 74, 78, 85, 89, 91, 92, 94, 98, 99, 100, 103, 107, 112, 113, 116, 117, 123, 127, 129, 131, 135, 139, 140, 141, 143, 146, 147, 153, 160, 164, 167, 173, 182], "bed": [112, 113], "bedford": [112, 113], "bedrock": [112, 113], "been": [3, 6, 7, 9, 10, 11, 12, 13, 14, 18, 42, 43, 46, 50, 54, 55, 64, 77, 78, 84, 86, 87, 91, 94, 98, 99, 100, 101, 104, 105, 107, 111, 112, 113, 116, 117, 118, 119, 121, 122, 129, 131, 134, 136, 137, 139, 142, 143, 148, 151, 152, 153, 154, 167, 172, 175, 177, 179, 181, 184, 185], "beer": 157, "befor": [8, 10, 17, 18, 23, 46, 52, 64, 65, 73, 77, 82, 83, 89, 90, 94, 98, 100, 101, 102, 105, 106, 109, 111, 112, 113, 115, 117, 118, 121, 127, 129, 133, 134, 137, 139, 140, 141, 143, 147, 148, 149, 151, 153, 155, 160, 172, 173, 175, 176, 178, 179, 182, 184], "beforehand": [106, 149], "began": [56, 112, 113, 122], "begin": [9, 25, 46, 47, 52, 53, 60, 97, 105, 109, 112, 113, 117, 126, 129, 130, 131, 137, 140, 158, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186], "begun": 57, "behalf": 43, "behav": [11, 60, 93], "behavior": [7, 13, 31, 41, 45, 47, 52, 58, 60, 62, 63, 84, 86, 92, 101, 112, 113, 115, 117, 119, 145], "behaviour": [112, 113], "behind": [10, 90, 93, 98, 99, 106, 112, 113, 117, 134, 135, 148, 151, 152, 171, 172, 186], "beigebook": 31, "being": [2, 3, 7, 9, 12, 13, 42, 43, 50, 51, 52, 53, 57, 63, 65, 72, 78, 83, 87, 89, 91, 92, 98, 112, 113, 114, 116, 117, 118, 129, 131, 133, 137, 140, 148, 150, 153, 157, 159, 160, 172, 178, 179], "beings": 131, "belarusian": 96, "belief": [42, 98, 112, 113], "believ": [25, 31, 97, 98, 112, 113, 116, 130, 131, 151], "bell": 143, "bellman": 54, "bellsouth": [112, 113], "belong": [10, 89, 117, 131, 139, 145, 151, 152], "below": [13, 43, 52, 53, 96, 112, 113, 121, 153, 174, 175], "belt": [112, 113], "beman": 156, "ben": [24, 178, 181], "benann": 11, "bench": [112, 113], "benchmark": [7, 50, 54, 60, 86, 90, 99, 100, 123, 135, 173], "bend": [112, 113], "beneath": [112, 113], "benefici": [13, 47, 53, 56, 90, 93, 104, 106, 107, 112, 113, 118, 121, 127, 144, 149, 173], "benefit": [8, 10, 50, 51, 54, 60, 61, 64, 67, 77, 84, 89, 99, 112, 113, 116, 117, 131, 151, 155, 168], "bengio": [0, 54, 128, 129], "bengio03a": 0, "benjamin": [112, 113], "bento": 73, "bentoml": [2, 71, 75], "benz": [112, 113], "ber": 102, "berkelei": [7, 84], "berlin": 0, "bermano": [0, 7], "bernank": 24, "berneri": [112, 113], "bernoulli": 133, "berri": 115, "bert": [0, 2, 10, 13, 46, 48, 54, 56, 96, 97, 99, 105, 109, 110, 111, 113, 117, 118, 127, 131, 139, 147], "bert_base_uncas": [111, 113], "bertasiu": [0, 117], "bertconfig": 113, "bertformaskedlm": [111, 113], "bertforpretrain": [15, 17, 18, 23, 111], "bertforsequenceclassif": [15, 17, 18, 23, 111], "bertin": [0, 96], "bertmodel": [113, 115], "bertnorm": 104, "bertrand": [112, 113], "berttoken": 115, "berttokenizerfast": 111, "bertviz": 115, "bertwordpiecetoken": 113, "besb": 73, "besid": [10, 112, 113], "best": [10, 25, 30, 31, 36, 46, 54, 67, 69, 71, 72, 77, 90, 92, 93, 98, 102, 104, 106, 108, 112, 113, 116, 117, 118, 123, 131, 139, 146, 147, 148, 152, 153, 156, 167, 168, 173, 183], "best_count": 102, "best_estim": [30, 36], "best_model": [15, 20, 23], "best_model_dir": 20, "best_pair": [102, 109], "best_score_at_start": [108, 109], "best_segment": [108, 109], "besta": 54, "bestow": 43, "bet": [102, 146], "beta": [6, 9, 94, 131], "beta_": 152, "beta_k": 152, "bethg": [0, 7], "better": [1, 10, 13, 29, 39, 42, 43, 47, 50, 51, 53, 54, 55, 56, 58, 63, 64, 65, 66, 72, 77, 78, 80, 81, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 104, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 126, 129, 131, 133, 134, 137, 138, 139, 144, 148, 149, 151, 152, 156, 158, 160, 161, 167, 173, 174, 184], "between": [3, 7, 8, 9, 10, 11, 12, 24, 37, 39, 43, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 60, 63, 64, 65, 66, 67, 72, 74, 75, 77, 78, 79, 83, 85, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 103, 104, 105, 107, 112, 113, 114, 115, 117, 118, 120, 121, 123, 125, 126, 127, 128, 130, 131, 133, 134, 136, 137, 138, 139, 140, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 172, 173, 178, 181, 182, 184, 186], "beverag": [112, 113], "bewild": [112, 113], "beyer": 0, "beyond": [3, 43, 47, 50, 51, 53, 55, 56, 58, 72, 89, 92, 117, 121, 127, 140, 172], "bf5c643": 181, "bg": [96, 121], "bgjm16": 0, "bgk": 0, "bgm": 150, "bhk": 0, "bhm": [112, 113], "bi": [100, 102, 112, 113], "bia": [13, 15, 17, 18, 23, 46, 48, 50, 51, 54, 56, 60, 75, 84, 86, 93, 94, 96, 111, 112, 113, 118, 127, 128, 129, 131, 133, 158], "bias": [17, 18, 23, 31, 51, 54, 56, 60, 71, 72, 75, 87, 91, 93, 94, 96, 99, 110, 121, 131, 138, 144], "bibl": [112, 113], "biblic": [112, 113], "bibliographi": 2, "bicamer": [112, 113], "bicub": 10, "bicycl": 60, "bid": [112, 113], "bidirect": [0, 2, 53, 97, 99, 100, 112, 113, 117, 131, 155], "bidirection": 113, "biederman": 98, "big": [4, 13, 14, 22, 39, 40, 42, 102, 107, 112, 113, 120, 122, 129, 137, 140, 151, 164, 177, 178, 181, 182], "bigger": [108, 109, 112, 113, 118], "biggest": [109, 140, 153], "bigram": [120, 121, 134, 139, 144, 150], "bigram_model": 134, "bigramassocmeasur": 150, "bigramcollocationfind": 150, "bigscienc": 52, "bike": 60, "bil": 102, "bilinear": [10, 137], "bill": [112, 113, 121, 145], "billion": [10, 46, 50, 53, 79, 94, 112, 113, 116, 118, 123, 131, 153], "bin": [0, 7, 16, 25, 27, 43, 61, 80, 96, 101, 113, 115, 125, 153], "binari": [15, 23, 54, 61, 85, 89, 100, 101, 112, 113, 120, 127, 129, 137, 155, 158], "bind": [9, 10], "bingl": 156, "bio": 102, "biodivers": [112, 113], "biographi": [112, 113], "bioinformat": 151, "biolog": [112, 113], "biologi": 86, "biologist": 89, "biom": [112, 113], "biomed": 94, "biometr": 79, "bipartit": 10, "birch": 0, "bird": [4, 112, 113, 130, 131], "birmingham": [112, 113], "birth": [112, 113], "bisect": [2, 162, 187], "bisect_dir": 185, "bisectdemo": 185, "bisexu": [112, 113], "bist": 118, "bit": [4, 9, 102, 133, 179], "bitbucket": [66, 77, 161], "bitcoin": 78, "bite": [112, 113], "bitstream": 29, "bitter": [112, 113], "bl": 102, "black": [41, 42, 112, 113], "blain": [112, 113], "blair": [112, 113], "blame": [112, 113], "blank": [9, 82, 118, 137], "blanket": [11, 112, 113], "blast": [112, 113], "blazer": [112, 113], "ble": 102, "bleed": [112, 113], "blei": 153, "blend": [7, 43, 45, 56, 112, 113, 169], "blendsearch": [36, 43], "bless": 121, "bleu": [56, 110], "bleuler": [112, 113], "blind": [112, 113], "blindism": [112, 113], "blo": 102, "blob": 10, "bloc": [112, 113], "block": [9, 10, 11, 60, 89, 112, 113, 117, 118, 134, 155], "block_siz": [46, 112], "blockchain": 13, "blog": [9, 10, 13, 52, 53, 54, 94, 100, 102, 135], "blogger": 121, "blogpost": 52, "bloom": [0, 98, 121], "bloomz": 52, "blue": [33, 112, 113, 114, 115, 156, 159], "blueprint": [46, 168, 170, 173], "blur": [10, 57], "blurri": 9, "bm25": 56, "bmo": 129, "bn": 96, "bo": 102, "board": [0, 54, 112, 113, 122], "boardseq": 95, "boast": [86, 112, 113], "bob": [112, 113], "bobbl": 156, "bodi": [0, 90, 112, 113, 157], "bodmin": 179, "bog": 1, "bohemian": [112, 113], "boi": [112, 113, 121], "boil": 127, "boilerpl": 70, "bojanowski": [0, 125], "bok": [121, 138], "boll": [112, 113], "bolshev": [112, 113], "bolshevik": [112, 113], "bolster": [50, 60], "bommasani": 0, "bon": [102, 108], "bonanno": [112, 113], "bond": [102, 112, 113], "bone": [112, 113], "bonsai": 7, "bonu": 141, "bonum": 141, "boo": 102, "book": [15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 50, 94, 96, 97, 98, 101, 102, 112, 113, 118, 129, 131, 140, 146, 153, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "bookcorpu": 110, "boom": [13, 185], "boost": [13, 74, 129], "bootstrap": [54, 65, 67, 70, 160], "boqe": 0, "border": [112, 113], "bore": 98, "borgeaud": 0, "borgu": [112, 113], "borisdayma": 9, "born": [112, 113], "borrow": [101, 112, 113, 121, 129], "bos_id": [104, 106], "bos_piec": [104, 106], "bos_token_id": 112, "bosma": 0, "boston": 120, "bot": [1, 50, 73, 122], "botch": [112, 113], "botchan": 106, "both": [0, 7, 8, 9, 10, 11, 41, 42, 50, 51, 53, 54, 55, 56, 58, 60, 65, 70, 72, 73, 74, 77, 78, 80, 89, 90, 92, 93, 96, 97, 98, 99, 100, 101, 106, 111, 112, 113, 115, 116, 117, 121, 127, 130, 131, 137, 139, 143, 145, 146, 148, 150, 151, 152, 155, 156, 157, 159, 160, 164, 165, 168, 171, 173, 176, 177, 178, 181, 184, 185], "bottl": 157, "bottleneck": [13, 60], "bottom": [9, 129, 149], "bought": [115, 129], "bound": [11, 89, 140, 152], "boundari": [3, 6, 8, 47, 53, 89, 96, 112, 113, 115, 131, 140, 141, 143, 154, 168], "bourgeoi": [112, 113], "bow": [139, 154], "bowl": [112, 113], "box": [25, 31, 41, 42, 52, 63, 74, 85, 89, 116, 140, 178], "boycott": [112, 113], "boyd": [112, 113], "bp": 153, "bpe": [2, 9, 97, 100, 103, 112, 116], "bpe_gpt_token": 104, "bpe_token": 104, "bpe_tokenizer_path": 104, "bpetrain": [104, 112], "br": 102, "bracket": [118, 125], "bradlei": [112, 113], "brain": [11, 50, 101, 112, 113, 117, 131], "brainard": 25, "brainstorm": 168, "branch": [0, 2, 54, 65, 112, 113, 131, 133, 134, 160, 162, 174, 175, 177, 180, 182, 184, 185, 186, 187], "branching_threshold": 146, "branchingentropytoken": 146, "brand": 135, "brandon": 0, "brassier": [112, 113], "brave": [2, 5], "brazil": [112, 113], "brdf": [112, 113], "brea": 102, "breach": [13, 64, 65, 78, 160], "breadth": [43, 98], "break": [9, 31, 54, 56, 64, 66, 72, 80, 92, 96, 99, 101, 102, 103, 104, 106, 107, 109, 112, 113, 117, 131, 137, 140, 141, 143, 144, 145, 146, 147, 154, 161, 168, 172, 185], "break_output": 185, "breakdown": [44, 112, 113, 117, 154, 170], "breakfast": 159, "breakm": 185, "breakthrough": [7, 9, 117], "brecht": 182, "brett": [112, 113], "brew": 80, "brian": [0, 7], "bridg": [45, 55, 57, 60, 64, 66, 74, 101, 112, 113, 161], "bridgeport": [112, 113], "brief": [10, 53, 101, 111, 142], "briefli": [131, 168, 171], "bright": [112, 113], "brighton": [112, 113], "brill": 0, "brillig": 184, "bring": [7, 11, 43, 99, 112, 113, 184], "britain": [112, 113], "british": [112, 113], "brittl": [9, 86], "bro": 102, "broad": [7, 47, 49, 50, 51, 53, 55, 60, 93, 112, 113, 114, 131, 158], "broadband": [112, 113], "broaden": [51, 53, 55, 56, 60, 121], "broader": [51, 54, 71, 72, 86, 89, 90, 98, 112, 113, 117, 135, 138, 165], "broadli": [75, 78, 112, 113, 127, 153], "broke": 131, "broken": [98, 105, 118, 131, 140, 141, 145, 147, 185], "brokerag": 129, "bromin": [112, 113], "brook": [112, 113, 134], "brooklei": [112, 113], "broth": 143, "brother": [112, 113, 120], "brought": [51, 84, 112, 113], "brown": [54, 112, 113, 116, 133, 143, 145, 156, 159], "brows": [1, 70, 86], "browser": [1, 89, 122, 177, 178], "bryant": [112, 113], "br\u00e9gier": [112, 113], "bs4": 124, "bsr": 10, "bu": [102, 112, 113], "bubbl": [112, 113], "bucket": [125, 144], "buddharaksa": [112, 113], "buddhism": [112, 113], "buddhist": [112, 113], "budget": [43, 50, 52, 112, 113, 169, 170, 173], "buffer": 146, "buford": [112, 113], "bug": [69, 74, 90, 99, 167, 170, 174, 179, 181, 185], "buggi": 185, "bui": [102, 129, 153], "build": [2, 4, 7, 10, 13, 18, 19, 38, 47, 50, 55, 60, 65, 66, 71, 72, 73, 74, 76, 86, 98, 99, 107, 112, 113, 114, 123, 127, 130, 131, 134, 135, 136, 140, 147, 148, 152, 160, 161, 172, 173, 178, 184], "buildctl": 61, "builder": 137, "buildkit_host": 61, "buildkitd": 61, "built": [1, 7, 21, 29, 47, 54, 61, 62, 63, 65, 66, 67, 72, 74, 75, 78, 79, 89, 106, 112, 113, 117, 122, 136, 138, 145, 160, 161, 167, 170, 182, 184], "builtin": 16, "bulgarian": [96, 116], "bulk": [112, 113], "bull": 129, "bullet": 140, "bump": 109, "bunch": [151, 182, 185], "bundl": [70, 122], "burden": [51, 53, 112, 113], "bureau": [0, 112, 113], "bureaucrat": [112, 113, 121], "burgeon": [39, 60], "burgess": [0, 121], "burial": [112, 113], "burlap": [112, 113], "burmes": 96, "burn": [112, 113, 153], "burn_in": 153, "buse": 168, "bushi": 101, "busi": [13, 46, 60, 64, 65, 66, 72, 78, 112, 113, 122, 124, 135, 153, 160, 161, 166, 170, 172, 173], "busiest": [112, 113], "butter": 47, "butterfli": 17, "button": [1, 68, 69, 73, 77, 83, 112, 113, 122, 178, 179], "bwt21": 0, "by3oe75k": 17, "by3oe75ksync": 17, "bypass": [47, 83, 112, 113], "byrn": [112, 113], "byt5": [0, 2, 97, 117], "byte": [0, 2, 10, 97, 100, 102, 106, 112, 117, 147], "byte_fallback": [104, 106], "bytelevel": 112, "bytepair": 102, "bzr": 186, "c": [0, 1, 11, 50, 52, 68, 70, 75, 79, 81, 89, 96, 98, 100, 102, 105, 106, 109, 112, 113, 116, 117, 120, 129, 133, 134, 140, 143, 146, 148, 152, 153, 156, 158, 170, 175, 182], "c3": 136, "c4": 96, "c608fbcd461a99d00c2d71d26c64bd6fb26c6c71": 185, "c626438": 101, "c_": [129, 148, 150], "c_i": 120, "c_j": 120, "c_npmi": 153, "c_uci": [150, 153], "c_v": [148, 150, 153], "ca": [79, 96, 102], "cabinet": [112, 113], "cac": 153, "cach": [15, 16, 17, 18, 20, 21, 22, 23, 25, 30, 31, 43, 56, 57, 61, 62, 95, 101, 102, 104, 108, 109, 111, 112, 113, 115, 129, 133, 136, 137, 142, 146, 151, 153, 186], "cache_dir": 18, "cached_dev_electra_256_10_2": [15, 23], "cached_dev_electra_256_2_2": 15, "cached_dev_electra_256_3_2": [15, 23], "cached_dev_electra_512_2_2": 15, "cached_path": [16, 17, 18, 20, 21, 22, 23, 25, 30, 31, 129, 146, 153], "cached_path_cache_root": [16, 17, 18, 20, 21, 22, 23, 30], "cached_train_electra_256_10_2": [15, 23], "cached_train_electra_256_2_2": 15, "cached_train_electra_256_3_2": [15, 23], "cached_train_electra_512_2_2": 15, "cacl2": 143, "cadair": [181, 182], "cadr": [112, 113], "cafe": [6, 131], "cahaba": [112, 113], "cahokia": [112, 113], "cai": [0, 7], "cairngorm": [178, 181], "cake": 101, "calcium": [112, 113], "calcul": [10, 21, 24, 25, 29, 53, 89, 95, 96, 98, 108, 109, 112, 113, 114, 115, 117, 118, 120, 128, 129, 134, 138, 140, 146, 149, 150, 151, 153, 158, 159], "calendar": 32, "calib": [112, 113], "calibr": 86, "california": 7, "call": [6, 7, 9, 10, 11, 17, 18, 20, 22, 25, 30, 31, 39, 54, 57, 60, 61, 63, 65, 73, 78, 84, 89, 96, 98, 100, 101, 102, 104, 105, 106, 112, 113, 114, 115, 117, 118, 120, 121, 125, 127, 129, 133, 137, 138, 141, 146, 147, 149, 152, 153, 154, 158, 160, 168, 171, 174, 176, 177, 179, 184], "calvert": [112, 113], "cambodia": [112, 113], "came": [6, 106, 112, 113, 153], "camel": 84, "camelcas": 146, "camelid": [2, 87, 88], "camellia": [112, 113], "camera": [7, 10], "camil": [112, 113], "camillo": [112, 113], "camouflag": [112, 113], "camp": 109, "campa": 109, "campai": 109, "campaig": 109, "campaign": [0, 109, 112, 113], "campbel": [112, 113], "campu": [112, 113], "campus": [112, 113], "can": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 18, 21, 31, 36, 39, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 166, 167, 168, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186], "canad": 102, "canada": [112, 113], "canadian": [102, 112, 113, 131], "candid": [0, 9, 31, 60, 85, 98, 109, 112, 113, 117, 121, 135], "candidate_label": 101, "canebrak": [112, 113], "cannot": [10, 15, 41, 42, 43, 58, 106, 112, 113, 121, 125, 144, 153, 154], "canon": 105, "canopi": [112, 113], "canyon": [112, 113], "cap": [60, 102, 112, 113], "capabl": [3, 6, 7, 8, 9, 10, 39, 43, 45, 46, 47, 50, 51, 53, 55, 56, 57, 58, 60, 65, 70, 72, 74, 75, 78, 84, 86, 87, 89, 92, 94, 101, 106, 113, 114, 117, 123, 131, 137, 140, 147, 155, 160], "capac": [2, 43, 50, 51, 58, 60, 101, 112, 113, 127, 164], "capit": [57, 85, 101, 102, 112, 113, 116, 120, 137, 140], "capita": [112, 113], "capitalist": [112, 113], "capitol": [112, 113], "cappuccino": 148, "capshaw": [112, 113], "caption": [9, 10, 123, 131], "captiv": [101, 127], "captur": [2, 5, 9, 10, 11, 13, 47, 50, 51, 53, 56, 60, 65, 87, 89, 92, 93, 99, 107, 110, 114, 115, 117, 121, 124, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 144, 148, 149, 151, 152, 154, 155, 158, 160, 173], "capybara": 9, "car": [47, 98, 102, 112, 113, 134, 138, 150, 153], "carbon": [112, 113], "carbonel": [0, 100], "card": [13, 41, 78, 79, 84], "cardin": 11, "care": [13, 51, 54, 56, 72, 90, 99, 102, 111, 112, 113, 137, 147, 175, 177], "career": [98, 112, 113, 131], "carefulli": [7, 46, 47, 54, 58, 98, 99, 101, 116, 118, 151, 172, 173], "caregiv": [112, 113], "caret": [112, 113], "cargo": 80, "carl": 131, "carlo": [54, 152], "carnivalesqu": [112, 113], "carol": 184, "carolin": [0, 7, 112, 113], "carollian": 184, "carpentri": 186, "carr": [112, 113], "carri": [2, 78, 112, 113, 115, 117, 122, 139, 140, 147, 151], "carrier": 153, "carv": 60, "case": [0, 9, 10, 41, 43, 46, 47, 49, 50, 53, 56, 59, 60, 65, 66, 68, 75, 77, 82, 84, 89, 90, 98, 99, 101, 106, 109, 112, 113, 114, 115, 116, 117, 118, 129, 131, 133, 134, 137, 138, 140, 141, 143, 146, 148, 151, 152, 153, 155, 158, 160, 161, 166, 168, 170, 179, 181, 184], "casein": [112, 113], "cash": [112, 113, 153], "casino": [112, 113], "cassoulet": 157, "cast": [11, 112, 113], "casualti": 153, "cat": [101, 114, 118, 127, 133, 140, 148, 150, 154, 175, 176, 177, 178, 181], "cat18": 0, "cat_preds_df": 20, "catalan": [96, 112, 113], "catalinac": [0, 121], "catalog": [112, 113], "catalyz": 51, "catastroph": 52, "catch": [65, 66, 140, 141, 160, 161], "categor": [7, 13, 75, 78, 90, 98, 99, 100, 112, 113, 131, 135, 138], "categori": [2, 10, 16, 19, 38, 43, 57, 60, 66, 75, 90, 99, 112, 113, 117, 127, 131, 134, 136, 138, 141, 144, 145, 151, 152, 161, 168], "categoris": [112, 113], "category_data": 22, "category_pr": 22, "category_preds_df": [20, 22], "category_record": 20, "cater": [53, 152], "catfish": [112, 113], "cathedr": [112, 113], "cathol": [112, 113], "catholic": [112, 113], "cattl": [112, 113], "caught": [112, 113], "caus": [10, 11, 65, 66, 93, 94, 98, 112, 113, 118, 121, 131, 144, 160, 161, 178, 185], "causal": [10, 99, 110, 112, 118], "causal_language_model": 52, "caution": [98, 148], "cavalri": [112, 113], "cave": [112, 113], "caveat": 144, "cavern": [112, 113], "caviti": [112, 113], "cb": [13, 14, 112, 113], "cbow": [125, 155], "cbow_model": 129, "cbow_test": 129, "cbspeeches_list": 44, "cc": [15, 23, 96, 101, 104, 106, 145], "cc360cb": [178, 180, 181], "ccnet": 96, "cconj": 145, "cd": [57, 65, 67, 69, 71, 72, 76, 80, 81, 82, 160, 171, 179, 186], "cd27": 184, "cdc": [112, 113], "cdd": [112, 113], "cdn": [10, 56], "cdot": [9, 85, 106, 107, 120, 127, 148, 149, 158], "ce": [102, 112, 113], "ce8bddc": 178, "ceas": [112, 113], "ceb": 96, "cebuano": 96, "cede": [112, 113], "cel": 151, "celebr": [112, 113], "cell": [30, 36, 89, 104, 112, 113, 137], "cen": 102, "censor": 121, "censorship": [83, 121], "censu": [112, 113], "census": [112, 113], "cent": 153, "center": [4, 24, 48, 57, 78, 112, 113, 120, 142, 145, 153], "centervil": [112, 113], "cento": [61, 76, 82], "centr": [112, 113], "central": [2, 11, 37, 38, 39, 44, 50, 62, 64, 66, 67, 94, 96, 99, 112, 113, 117, 121, 138, 148, 155, 161], "centralbank_analysi": 37, "centric": [56, 57, 172], "centroid": 149, "centuri": [6, 112, 113, 151], "ceo": [60, 102, 112, 113], "cere": [112, 113], "ceremoni": [112, 113], "cert": 73, "certain": [9, 11, 45, 47, 50, 51, 54, 56, 60, 72, 89, 91, 93, 94, 98, 103, 105, 107, 112, 113, 117, 118, 131, 133, 139, 141, 143, 151, 152, 158, 173, 182], "certainli": 140, "certainti": 133, "certfil": 73, "certif": [60, 78, 79, 83], "certifi": 167, "cf": 98, "cfa": [112, 113], "cfg": [15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 129, 146, 153], "cgze19": [0, 7], "ch": [102, 153], "cha": 102, "chain": [13, 43, 50, 57, 60, 75, 79, 99, 106, 133, 152], "chainforg": 58, "chair": [25, 31, 33, 131], "chairman": [25, 31], "chairperson": 33, "chalco": 153, "challeng": [2, 3, 7, 9, 10, 11, 38, 40, 43, 53, 60, 71, 75, 76, 77, 79, 84, 86, 87, 91, 96, 98, 99, 103, 107, 109, 112, 113, 116, 117, 127, 130, 131, 133, 138, 139, 141, 144, 152, 154, 157, 165, 166, 168, 171, 173], "cham": 130, "chamber": [112, 113], "champion": [54, 112, 113, 172], "championship": [112, 113, 131], "chan": [0, 7], "chanc": [98, 99, 116, 144, 148, 156, 158], "chang": [0, 2, 9, 10, 11, 13, 15, 24, 26, 29, 43, 45, 47, 51, 53, 57, 65, 66, 67, 72, 75, 77, 81, 86, 98, 104, 105, 107, 108, 109, 111, 112, 113, 120, 121, 129, 131, 133, 138, 140, 141, 145, 152, 153, 156, 160, 161, 164, 165, 166, 167, 170, 172, 173, 174, 180, 183, 184, 185, 186], "changeset": 182, "chanh": [112, 113], "channel": [10, 11, 77, 89, 117, 170], "chao": [112, 113, 167], "chaotic": 167, "chapter": [38, 72], "char": [102, 104, 106], "charact": [0, 96, 102, 104, 105, 106, 107, 108, 112, 113, 116, 123, 137, 140, 143, 144, 146, 147, 155, 175], "character": [94, 99, 112, 113, 116, 149, 152, 170, 172, 173], "character_coverag": [104, 106], "character_freq": [108, 109], "characterawar": 116, "characteris": [112, 113], "characterist": [13, 54, 72, 84, 94, 98, 106, 112, 113, 116, 121, 131, 133, 137, 147, 167], "charcoal": [112, 113], "charg": [112, 113, 140, 177], "charge_": 140, "charl": 35, "charli": 117, "chart": [24, 43, 65, 90, 112, 113, 160, 171], "chase": [60, 101], "chat": [43, 112, 113], "chataigni": [112, 113], "chatbot": [2, 47, 54, 58, 60, 71, 75, 84, 97, 99, 123], "chatdev": 43, "chatgpt": [1, 43, 47, 54, 84, 86, 93, 97], "chaudhari": 0, "chdir": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "che": 102, "cheaha": [112, 113], "cheap": 181, "check": [1, 2, 37, 38, 42, 44, 56, 61, 98, 99, 100, 111, 112, 113, 115, 121, 137, 145, 173, 174, 178, 186], "checklist": [112, 113], "checkout": [68, 69, 174, 176, 179, 181, 183, 184, 185, 186], "checkpoint": [15, 17, 18, 23, 39, 52, 98, 101, 111, 113], "cheer": 134, "cheetah": 7, "chef": [47, 65, 66, 160, 161], "chelat": [112, 113], "chelsea": 0, "chemistri": 151, "chen": [0, 100], "cheng": [0, 7], "cher": [112, 113], "cheroke": [112, 113], "cherri": 181, "chess": 43, "chezmoi": 67, "chi": [102, 109, 112, 113], "chic": 109, "chicago": [112, 113, 120, 140], "chickasaw": [112, 113], "chico": 109, "chief": [112, 113], "chiefli": [112, 113], "chil": 109, "child": [100, 112, 113, 129, 140], "childersburg": [112, 113], "childhood": [112, 113], "children": [112, 113, 137, 140, 151], "chile": 109, "chilton": [112, 113], "chin": [102, 109], "china": [102, 109, 112, 113, 121, 153], "chine": 109, "chines": [0, 50, 94, 96, 103, 106, 109, 121, 140, 141, 146, 153], "chip": [109, 129], "chipo": 109, "chipot": 109, "chipotl": 109, "chitchat": 43, "chmod": 81, "chocol": 146, "choctaw": [112, 113], "choi": [0, 7], "choic": [22, 31, 47, 53, 60, 61, 65, 77, 94, 98, 101, 103, 106, 112, 113, 126, 127, 129, 133, 134, 137, 138, 139, 145, 147, 148, 152, 157, 160, 167, 168, 171, 172, 173, 174, 175], "choices_nam": 22, "chomskyan": 140, "choos": [22, 54, 61, 63, 65, 69, 70, 76, 83, 94, 98, 103, 106, 107, 110, 111, 112, 113, 118, 130, 131, 132, 134, 141, 148, 152, 155, 157, 160, 168, 171, 175, 177, 182], "chop": 151, "chosen": [9, 11, 46, 78, 98, 110, 134, 145, 152, 168, 171, 172, 173], "chown": 81, "cho\ub294": 15, "chracter": 116, "chri": [112, 113], "christ": [112, 113], "christian": [0, 112, 113], "christiano": 35, "christoph": 0, "chroma": 60, "chromedriv": 122, "chromosom": [112, 113], "chronic": [112, 113], "chronicl": 120, "chronolog": [112, 113, 122], "chu": [46, 177, 178, 179, 181, 182, 183, 184, 185, 186], "chua": [112, 113], "chuan": [0, 7], "chuang": 0, "chunj": 0, "chunk": [16, 77, 144], "chunk_data": [15, 22], "chunk_df": 16, "chunk_id": [15, 16, 20, 22, 25], "chunk_siz": [16, 25], "church": [112, 113, 153], "ci": [57, 65, 67, 71, 72, 76, 102, 113, 160, 171, 172, 174, 178, 186], "cia": 120, "ciao": 98, "cicl": 130, "cinema": 150, "ciphertext": [78, 79], "circa": 151, "circl": [13, 112, 113], "circleci": [65, 66, 160, 161], "circuit": [112, 113], "circular": 146, "circularli": [112, 113], "circumfix": 140, "circumst": [112, 113, 121, 172], "circumv": 47, "citat": [90, 121], "cite": [90, 112, 113, 153], "citi": [4, 98, 101, 112, 113, 137, 144], "citizen": [112, 113], "civil": [112, 113], "civilis": [112, 113], "ci\ub97c": 21, "cjhutto": 136, "cjwbw": [6, 131], "ck": 102, "cl": [102, 104, 105, 109, 111, 112, 113, 115], "cla": 22, "claim": [78, 112, 113, 117, 121, 153], "clan": [112, 113], "clarif": 68, "clarifi": 56, "clariti": [56, 90, 101, 168, 173], "clark": [100, 112, 113, 116], "clash": [112, 113], "class": [9, 10, 11, 15, 16, 21, 22, 23, 29, 34, 44, 46, 47, 52, 61, 71, 74, 76, 88, 89, 101, 105, 111, 112, 113, 115, 117, 128, 129, 137, 139, 140, 141, 148, 151, 152, 153, 183], "class_data_dir": 52, "class_dir": 52, "class_prompt": 52, "classes_": 137, "classic": [9, 41, 47, 78, 112, 113], "classif": [2, 13, 15, 17, 19, 20, 21, 22, 23, 30, 31, 36, 38, 47, 51, 58, 60, 76, 81, 85, 89, 97, 98, 99, 100, 101, 110, 111, 112, 113, 117, 118, 121, 123, 125, 127, 130, 131, 135, 136, 138, 139, 144, 147, 149, 152, 154, 157], "classifi": [2, 7, 10, 17, 18, 19, 38, 47, 85, 86, 91, 99, 100, 101, 111, 112, 113, 115, 117, 118, 129, 131, 135, 141, 145, 148], "classification_model": [15, 23], "classification_report": [136, 137], "classification_t5": 31, "classification_util": [15, 23], "classlabel": 111, "classroom": 186, "claud": 60, "claw": 101, "cld3": 96, "clean": [4, 46, 72, 90, 94, 96, 111, 112, 113, 123, 139, 143, 156, 175, 184], "clean_text": 113, "cleaner": 184, "cleans": [57, 118], "cleanup": [178, 183], "clear": [6, 10, 17, 44, 46, 53, 54, 56, 64, 65, 69, 90, 101, 112, 113, 115, 137, 140, 141, 149, 150, 160, 166, 167, 168, 172, 173, 184], "clearer": [112, 113], "clearli": [90, 98, 117, 134, 164, 166, 168, 173], "clf": 151, "cli": [61, 62, 80, 81, 82], "click": [1, 68, 69, 77, 83, 89, 97, 111, 113, 122, 133, 136, 142, 177, 178, 179], "client": [25, 32, 33, 34, 35, 61, 77, 78, 79, 167, 170, 173], "clientel": 60, "climat": [112, 113], "climatologi": [112, 113], "climb": [7, 101], "clingston": [112, 113], "clinic": [112, 113, 131], "clinician": [112, 113], "clip": [7, 9, 11, 73, 89, 112, 113], "clipboard": [177, 178], "clitic": 140, "clm": [2, 97, 110], "clo": 102, "clone": [77, 81, 178, 185], "close": [0, 3, 6, 7, 9, 10, 47, 50, 60, 90, 91, 93, 102, 112, 113, 115, 116, 118, 119, 127, 129, 131, 133, 134, 137, 140, 148, 153, 157, 173], "closer": [56, 89, 98, 107, 112, 113, 127, 129], "closest": [112, 113, 149], "cloth": [112, 113], "cloud": [13, 39, 56, 57, 61, 63, 65, 66, 67, 71, 73, 78, 79, 81, 82, 112, 113, 137, 153, 160, 161, 168, 170, 177], "cloudform": [65, 160], "cls_token": [112, 113], "clue": [56, 131, 137], "cluster": [61, 63, 65, 66, 75, 76, 81, 96, 99, 120, 127, 151, 152, 160, 161], "cm": [137, 150, 153], "cm_uci": 150, "cm_umass": 150, "cmap": [26, 32], "cmd": [16, 61, 62, 80, 174], "cmu": 84, "cncf": [61, 63], "cnooc": 153, "cnt": [112, 113], "cnvrg": 72, "cny2": 153, "cny8": 153, "co": [3, 60, 96, 101, 102, 112, 113, 137, 139, 144, 148, 149, 152, 155, 156, 158, 172], "coal": [112, 113, 120], "coalit": [112, 113], "coars": 145, "coast": [112, 113], "coastal": [112, 113], "coastlin": [112, 113], "coattail": [112, 113], "cocain": [112, 113], "coco": [11, 89], "code": [1, 5, 7, 9, 10, 20, 43, 45, 46, 53, 60, 62, 65, 68, 69, 70, 72, 73, 74, 75, 78, 79, 81, 86, 96, 98, 99, 101, 111, 112, 113, 116, 120, 121, 122, 125, 131, 134, 137, 142, 144, 151, 153, 156, 160, 162, 165, 167, 168, 170, 172, 173, 174, 176, 179, 180, 181, 184, 187], "code_execution_config": 43, "code_info": [15, 16, 22], "code_info_avail": [15, 16, 20, 22], "codeag": 77, "codebas": [66, 97, 161, 167, 172], "codebook": 9, "codenam": 99, "coder": 178, "codifi": [112, 113], "coe": [112, 113], "coeffici": [112, 113], "coequal": [112, 113], "coerc": [112, 113], "coercion": [112, 113], "coerciv": [112, 113], "coexist": [112, 113, 116], "coffe": [10, 148], "cog": [6, 131], "cognit": [43, 98, 101, 112, 113, 131, 138], "cogview2": [6, 131], "coh": 153, "cohen": [0, 6, 7], "coher": [0, 2, 7, 10, 47, 49, 50, 54, 56, 60, 87, 90, 92, 93, 94, 98, 99, 100, 112, 113, 130, 131, 132, 149, 152, 167], "coherence_per_top": [150, 153], "coherence_per_topic_uci": 150, "coherence_per_topic_umass": 150, "coherencemodel": 150, "coin": [112, 113, 133], "coincid": [112, 113], "col": [15, 16, 17, 22, 27, 31, 32, 34, 35], "colab": [7, 10, 16, 18, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 98, 111, 112, 113, 124, 153, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "colab_workspac": 124, "cold": [60, 112, 113, 138, 184], "colder": [112, 113], "cole": 0, "colin": [0, 112, 113], "collabor": [2, 7, 13, 39, 43, 45, 47, 60, 64, 65, 66, 67, 69, 72, 76, 81, 82, 83, 84, 131, 151, 160, 161, 162, 170, 172, 173, 174, 181, 184, 186, 187], "collar": [112, 113], "collat": 113, "colleagu": [90, 113, 179, 184, 186], "collect": [2, 7, 8, 10, 13, 39, 43, 44, 50, 60, 66, 72, 89, 91, 96, 99, 101, 102, 108, 109, 110, 112, 113, 116, 118, 123, 130, 131, 133, 134, 136, 137, 138, 139, 148, 149, 151, 152, 153, 156, 158, 159, 161, 172], "collectiv": [112, 113], "collectivis": [112, 113], "collectivist": [112, 113], "collector": [112, 113], "colleg": [112, 113, 131], "colloc": 150, "colloqui": [131, 176], "colmenarejo": 0, "colon": [112, 113], "coloni": [4, 112, 113], "colonist": [112, 113], "color": [9, 22, 33, 60, 112, 113, 114, 115, 117, 151, 156], "coloss": [53, 96], "colour": [112, 113], "colsample_bylevel": 36, "colsample_bytre": [30, 36], "columbu": [112, 113], "column": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 53, 60, 108, 109, 111, 114, 115, 117, 120, 126, 127, 137, 146, 150, 151, 152, 158, 159], "column_info": [18, 23, 29, 34], "com": [6, 9, 10, 16, 25, 31, 54, 62, 65, 68, 69, 70, 71, 77, 80, 81, 82, 83, 84, 95, 98, 102, 113, 120, 121, 129, 131, 133, 136, 137, 142, 146, 151, 153, 160, 174, 175, 176, 177, 178, 179, 181, 182, 183, 185, 186], "combat": 153, "combin": [6, 7, 8, 9, 10, 11, 13, 15, 41, 42, 52, 53, 54, 55, 56, 57, 60, 65, 66, 72, 73, 78, 79, 89, 90, 92, 93, 96, 98, 100, 106, 107, 110, 112, 113, 114, 115, 117, 118, 122, 131, 133, 136, 137, 139, 140, 141, 143, 148, 150, 152, 153, 155, 160, 161, 162, 163, 167, 172, 173, 176, 178, 184], "come": [4, 6, 10, 47, 50, 51, 53, 54, 60, 62, 65, 90, 93, 94, 98, 99, 102, 111, 112, 113, 117, 120, 121, 122, 127, 129, 131, 137, 140, 141, 153, 155, 158, 160, 182, 184], "comet": [112, 113], "comfi": 17, "comfort": [43, 81, 143], "comma": [112, 113], "command": [1, 43, 46, 47, 52, 58, 65, 70, 73, 74, 77, 80, 81, 82, 101, 104, 106, 112, 113, 115, 125, 131, 142, 160, 174, 175, 177, 179, 182, 184, 186], "commenc": 173, "commensur": 47, "comment": [47, 68, 112, 113, 122, 135, 153, 179, 185], "commentari": 102, "commerc": [13, 60, 120, 131], "commerci": [84, 112, 113, 151, 153], "commiss": [112, 113], "commission": [112, 113], "commit": [53, 65, 77, 81, 82, 112, 113, 160, 172, 174, 176, 180, 181, 182, 183, 184, 185, 186], "committe": [31, 112, 113, 121], "commmit": 182, "common": [6, 9, 43, 47, 56, 58, 65, 66, 77, 78, 81, 89, 91, 94, 96, 98, 101, 105, 106, 107, 110, 111, 112, 113, 121, 123, 126, 127, 129, 131, 133, 134, 136, 137, 138, 139, 140, 145, 148, 149, 151, 154, 158, 159, 160, 161, 181, 184], "commonli": [2, 51, 65, 78, 79, 89, 105, 110, 112, 113, 120, 123, 140, 143, 144, 155, 160, 173], "commonmark": 182, "commonplac": [112, 113], "commun": [12, 37, 53, 54, 60, 61, 64, 65, 66, 70, 77, 78, 79, 83, 84, 88, 90, 92, 99, 102, 112, 113, 118, 121, 131, 132, 138, 160, 161, 164, 170, 172, 173], "communard": [112, 113], "communist": [112, 113], "comp": 151, "compa": 109, "compac": 109, "compact": [9, 109, 112, 113, 127], "compan": [102, 108, 109], "companhia": [112, 113], "compani": [43, 47, 57, 60, 72, 94, 98, 102, 108, 109, 112, 113, 120, 122, 133, 135, 146, 153, 157], "companion": 131, "company_by_nam": 124, "companyseq": 95, "compar": [7, 10, 56, 57, 58, 61, 63, 68, 70, 77, 78, 79, 84, 85, 86, 89, 90, 91, 96, 98, 109, 110, 112, 113, 114, 116, 117, 118, 123, 127, 129, 131, 132, 133, 134, 139, 143, 144, 148, 149, 150, 151, 159, 172, 173, 174, 179, 181], "comparison": [9, 10, 52, 55, 56, 65, 90, 98, 106, 112, 113, 160], "compass": 109, "compat": [31, 52, 60, 61, 63, 80, 105, 106, 112, 113, 114], "compel": [7, 43, 112, 113, 127, 131, 137, 168, 169], "compet": [6, 94, 120, 131], "competit": [9, 66, 84, 94, 112, 113, 116, 118, 120, 121, 161], "competitor": 120, "compil": [8, 15, 23, 101, 102, 112, 113, 123, 153, 167, 182], "complaint": [52, 137], "complement": 67, "complementari": 118, "complet": [7, 8, 9, 13, 15, 23, 31, 43, 48, 53, 61, 63, 68, 71, 72, 84, 88, 90, 91, 96, 97, 99, 101, 111, 112, 113, 114, 130, 133, 164, 167, 168, 172, 173], "complex": [6, 7, 8, 9, 10, 12, 13, 41, 42, 43, 45, 47, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 72, 77, 89, 90, 92, 93, 94, 98, 99, 101, 102, 103, 105, 106, 107, 112, 113, 114, 115, 116, 117, 122, 127, 129, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 149, 151, 152, 157, 162, 165, 167, 168, 170, 172, 173], "compli": [75, 78, 112, 113, 166], "complianc": [60, 65, 72, 94, 112, 113, 160, 170], "compliant": [60, 61, 63], "complic": [7, 112, 113, 131, 141], "compon": [8, 9, 10, 11, 13, 43, 53, 56, 57, 58, 59, 60, 63, 65, 66, 67, 69, 70, 72, 74, 78, 79, 81, 82, 89, 90, 94, 101, 103, 111, 112, 113, 114, 117, 127, 128, 131, 139, 140, 141, 148, 149, 151, 152, 159, 160, 161, 165, 169, 170], "components_": 151, "compos": [10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 61, 63, 72, 89, 109, 112, 113, 114, 117, 129, 131, 146, 148, 153, 155, 173], "compose_worker_lf": 21, "composit": [3, 9, 60, 105, 106, 112, 113, 144], "composition": 0, "compound": [50, 94, 112, 113, 136, 140, 141, 146], "comprehend": [1, 50, 53, 94, 112, 113, 114, 115, 127, 140, 143, 173], "comprehens": [1, 2, 7, 11, 13, 38, 39, 43, 46, 47, 48, 49, 51, 53, 55, 56, 59, 60, 63, 72, 74, 76, 77, 78, 79, 83, 89, 92, 99, 100, 101, 112, 113, 116, 117, 122, 131, 152, 166, 168, 170, 172, 187], "compress": [7, 9, 10, 104, 107, 116, 127, 151], "compris": [10, 47, 53, 112, 113, 114, 118, 165], "comprnfb": 35, "compromis": [13, 39, 51, 56, 78, 96, 117], "compuls": [112, 113], "compulsori": [112, 113], "comput": [0, 6, 7, 8, 9, 10, 12, 13, 14, 39, 43, 45, 46, 47, 53, 54, 55, 56, 60, 61, 63, 74, 75, 77, 79, 84, 87, 89, 90, 92, 94, 95, 98, 99, 100, 103, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 127, 129, 130, 131, 132, 133, 134, 137, 138, 140, 141, 143, 144, 146, 147, 148, 151, 152, 154, 155, 156, 158, 177, 179, 186], "computation": [47, 78, 98, 102, 127, 129, 131, 134, 135, 137, 139, 147, 152], "compute_environ": 52, "compute_loss": [108, 109], "compute_metr": 111, "compute_pair_scor": 109, "compute_scor": [108, 109], "compvi": 52, "com\ub85c": 141, "con": [15, 17, 102], "concat": 53, "concat_data": [15, 17, 18], "concaten": [7, 10, 11, 15, 16, 21, 22, 53, 102, 112, 114, 117, 150, 155], "concatenated_exampl": 112, "concentr": [2, 51, 60, 112, 113, 117, 121, 152], "concept": [2, 10, 11, 12, 38, 39, 43, 47, 50, 54, 55, 56, 58, 60, 68, 71, 76, 78, 79, 81, 83, 88, 89, 97, 101, 106, 107, 110, 112, 113, 115, 117, 119, 127, 130, 131, 133, 138, 143, 144, 148, 150, 156, 157, 158, 159, 162, 163, 168, 172, 173, 187], "conceptu": [53, 60, 99, 138, 167], "concern": [2, 13, 48, 51, 54, 56, 60, 61, 72, 75, 78, 87, 93, 94, 98, 99, 110, 112, 113, 122, 130, 131, 153, 157], "concert": [99, 150], "concis": [1, 10, 50, 56, 58, 65, 90, 99, 117, 160, 168, 171], "conclud": [108, 112, 113, 143], "conclus": [38, 63, 70, 74, 79, 98, 112, 113, 127, 129, 131, 135, 151], "concret": [50, 107], "concurr": [56, 112, 113], "conda": [29, 31, 43, 70], "condens": [50, 112, 113, 127, 148, 149, 168], "condit": [7, 9, 10, 13, 47, 51, 56, 60, 98, 106, 112, 113, 118, 133, 145, 146, 173], "condition": 139, "conditional_gener": 52, "conduc": 60, "conduct": [7, 13, 56, 101, 112, 113, 117, 162, 168, 170, 173], "cone": 140, "conecuh": [112, 113], "confcal": [24, 25, 26, 27, 28, 32], "confect": 47, "confeder": [112, 113], "confederaci": [112, 113], "confer": [0, 7, 37, 90, 112, 113, 120, 121, 130], "confid": [9, 13, 89, 96, 112, 113], "confidenti": [75, 77, 78, 79], "config": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 52, 77, 81, 82, 112, 113, 115, 129, 146, 150, 151, 153, 174, 175, 184], "config_fil": 52, "config_group": [17, 20, 22, 24, 27, 29, 30, 31, 34, 36], "config_list": 43, "config_list_from_json": 43, "configmap": 81, "configur": [46, 61, 62, 63, 70, 73, 74, 76, 77, 78, 82, 90, 111, 112, 113, 118], "confin": 56, "confirm": [25, 31, 68, 69, 72, 78, 112, 113, 118, 175, 179], "confirmmeasur": 153, "conflict": [21, 69, 112, 113, 166, 181], "conflicted_fil": 178, "confluenc": [50, 112, 113, 170], "conform": 121, "confound": 0, "confront": [39, 58, 112, 113], "confus": [1, 94, 112, 113, 137, 174], "confusion_matrix": [15, 17, 18, 23, 136, 137], "conglomer": [112, 113], "congratul": 113, "congreg": [112, 113], "congress": [112, 113, 120, 138], "congression": [112, 113], "congressmen": [112, 113], "conifer": [112, 113], "conjug": 131, "conjunct": [120, 121, 145], "conll": 123, "conneau": 96, "connect": [2, 10, 47, 53, 55, 65, 71, 77, 78, 79, 81, 89, 90, 112, 113, 117, 118, 127, 128, 129, 152, 160, 177, 178, 181], "connot": [112, 113, 157], "cono": 102, "conscienc": [112, 113], "consciou": 98, "conscious": [112, 113, 131], "consecut": [102, 107, 118, 173], "consensu": [112, 113, 129, 153], "consent": [94, 112, 113], "consequ": [2, 60, 99, 101, 112, 113, 117, 141, 179], "conserv": [51, 98, 112, 113, 121], "consid": [10, 13, 25, 26, 31, 36, 42, 47, 52, 53, 56, 64, 65, 66, 67, 70, 78, 89, 90, 94, 98, 99, 101, 104, 106, 110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 126, 127, 131, 133, 134, 137, 138, 139, 140, 141, 144, 145, 148, 150, 151, 152, 154, 155, 157, 159, 160, 161, 167, 168, 171, 172, 179], "consider": [11, 51, 53, 56, 71, 75, 87, 90, 94, 99, 110, 112, 113, 131, 147], "consist": [7, 9, 10, 39, 50, 53, 56, 57, 62, 63, 65, 66, 67, 77, 89, 90, 92, 94, 98, 100, 103, 106, 107, 112, 113, 114, 117, 118, 120, 121, 122, 123, 127, 131, 138, 140, 143, 144, 148, 150, 155, 158, 160, 161, 164, 166, 168, 172], "consol": 106, "consoli": 38, "consolid": [76, 112, 113], "conson": [112, 113], "constant": [0, 47, 52, 56, 72, 89, 112, 113, 131, 134, 146, 148, 173], "constantli": [112, 113, 131], "constel": [112, 113], "constitu": 131, "constitut": [73, 112, 113, 120, 141], "constrain": [9, 47, 50, 51, 60, 61, 63, 93, 96, 151], "constraint": [7, 10, 51, 53, 63, 72, 84, 90, 98, 101, 112, 113, 122, 151, 152, 165, 167, 168, 171, 172, 173], "construct": [7, 13, 47, 54, 58, 84, 99, 112, 113, 120, 121, 138, 140, 147, 153, 155, 168, 172], "consult": [86, 166, 167], "consum": [7, 13, 41, 47, 53, 60, 94, 102, 112, 113, 119, 145, 153, 173], "consumer": [112, 113], "consumpt": [35, 46, 51, 78, 87, 99, 112, 113, 173], "cont": 102, "contact": [7, 112, 113], "contain": [9, 10, 12, 25, 39, 46, 56, 57, 63, 65, 66, 68, 74, 81, 82, 90, 92, 94, 95, 96, 98, 99, 105, 106, 111, 112, 113, 115, 117, 118, 120, 121, 122, 123, 125, 127, 129, 131, 134, 135, 137, 138, 140, 146, 147, 148, 151, 153, 154, 156, 157, 159, 160, 161, 172, 174, 175, 176, 178, 179, 183, 184], "container": [2, 39, 56, 61, 62, 65, 71, 74, 76, 81, 160, 170], "containerd": [2, 63, 65, 71, 82, 160], "contempl": [2, 98], "contemporari": [45, 112, 113], "contend": 70, "content": [1, 2, 3, 7, 9, 12, 13, 15, 22, 25, 44, 50, 52, 56, 58, 60, 61, 77, 78, 82, 83, 86, 87, 89, 93, 94, 95, 96, 99, 101, 112, 113, 116, 117, 118, 121, 122, 123, 124, 131, 137, 140, 148, 149, 152, 168, 174, 175, 176, 178, 180, 181, 182, 183, 184, 185, 186], "content_typ": [25, 31], "contest": 131, "context": [1, 2, 7, 8, 9, 10, 13, 31, 38, 39, 42, 46, 47, 48, 51, 53, 55, 58, 60, 61, 70, 77, 78, 86, 87, 90, 92, 93, 94, 98, 99, 100, 101, 103, 108, 110, 112, 113, 114, 115, 117, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 148, 149, 154, 155, 156, 157, 168, 171, 172], "context_s": 129, "context_vector": 129, "context_word": 156, "contextu": [1, 12, 47, 50, 51, 54, 56, 58, 60, 87, 92, 98, 99, 101, 110, 114, 127, 131, 132, 139, 149], "contigu": [121, 139, 144], "contin": 102, "continent": [112, 113], "conting": [168, 171], "continu": [3, 6, 9, 10, 12, 31, 43, 47, 51, 52, 53, 54, 56, 60, 64, 65, 71, 78, 79, 80, 81, 84, 86, 92, 94, 99, 102, 107, 108, 109, 112, 113, 117, 123, 127, 131, 133, 134, 140, 141, 149, 153, 155, 160, 164, 167, 170, 173, 178, 184], "contour": 8, "contourpi": 137, "contrac": 102, "contract": [78, 112, 113, 129, 131, 140, 143, 172], "contradict": [56, 112, 113], "contradictori": [56, 112, 113], "contrail": [112, 113], "contrari": [112, 113, 151], "contrast": [7, 9, 11, 13, 14, 53, 54, 72, 96, 98, 101, 112, 113, 115, 117, 127, 137, 149, 151, 172, 173], "contribut": [7, 10, 43, 50, 51, 53, 56, 58, 60, 68, 69, 76, 78, 85, 90, 94, 99, 112, 113, 114, 116, 117, 118, 131, 142, 147, 151, 152, 153, 179], "contributor": 182, "control": [0, 2, 4, 46, 50, 53, 56, 58, 60, 65, 72, 75, 76, 78, 79, 81, 82, 90, 98, 106, 107, 112, 113, 121, 122, 153, 160, 162, 168, 170, 173, 175, 177, 182, 186], "controversi": [6, 112, 113], "convei": [2, 121, 131, 168], "conveni": [50, 77, 105, 111], "convent": [42, 47, 55, 57, 112, 113, 127, 131, 174], "converg": [29, 51, 54, 55, 57, 65, 117, 160, 182, 184], "convers": [2, 45, 47, 50, 60, 84, 93, 94, 97, 99, 106, 111, 120, 123, 127, 146, 166, 172, 179], "convert": [8, 9, 10, 11, 15, 23, 56, 60, 74, 78, 79, 89, 98, 101, 103, 105, 106, 109, 112, 113, 116, 117, 118, 120, 122, 124, 129, 131, 133, 134, 137, 139, 143, 147, 149, 156, 159], "convert_ids_to_token": 115, "convert_to_humanbyt": 18, "convert_tokens_to_id": 105, "convict": [112, 113], "convinc": [58, 86, 112, 113, 169], "convolut": [10, 11, 51, 89, 117, 173], "coo": 16, "cook": 47, "cooki": 141, "cool": [112, 113, 181], "cooler": [112, 113], "cooper": [112, 113], "coordin": [112, 113, 127, 167, 172, 173], "coosa": [112, 113], "cope": [112, 113], "copi": [15, 17, 22, 24, 25, 26, 27, 28, 31, 32, 33, 35, 62, 67, 68, 69, 77, 80, 99, 102, 108, 109, 112, 113, 121, 172, 174, 177, 178, 179, 180, 181, 186], "copilot": [50, 131], "copiou": [112, 113], "copper": 153, "coptic": [112, 113], "copyright": [94, 122, 182], "cor": 102, "cordonni": 0, "core": [4, 7, 12, 15, 16, 22, 23, 43, 45, 47, 58, 59, 60, 61, 63, 67, 69, 78, 81, 87, 94, 101, 102, 104, 105, 106, 112, 113, 114, 116, 117, 127, 138, 149, 157, 172, 173, 175], "corefer": 131, "coreweav": 60, "corn": [112, 113, 157], "cornel": 123, "corner": [1, 68, 69, 112, 113], "cornerston": [7, 51, 53, 106, 166], "corp": 102, "corpor": [102, 112, 113, 120, 131, 153], "corpora": [50, 94, 99, 100, 123, 136, 147, 149, 150, 157, 158], "corporati": 108, "corporatio": 108, "corpu": [2, 7, 13, 19, 33, 37, 38, 46, 87, 93, 94, 96, 98, 104, 106, 107, 108, 109, 110, 114, 121, 125, 126, 127, 129, 133, 136, 137, 139, 140, 143, 144, 145, 146, 147, 148, 150, 151, 152, 154, 155, 156, 157, 158, 159], "corpus_cfg": 16, "corpustext": 136, "corr": [26, 32, 120, 121], "corr_column": [26, 32], "corr_data": [26, 32], "corr_data1": 26, "corr_data2": 26, "corrado": 0, "correct": [7, 9, 10, 21, 31, 43, 50, 54, 56, 60, 65, 67, 78, 94, 96, 97, 99, 100, 105, 112, 124, 131, 132, 140, 141, 142, 144, 145, 146, 160, 166, 176, 186], "correct_ct": 129, "correctli": [46, 65, 77, 92, 100, 116, 120, 131, 137, 141, 160, 172], "correl": [2, 7, 37, 38, 39, 94, 96, 112, 113, 120, 153], "correspond": [1, 6, 7, 10, 11, 12, 47, 52, 53, 56, 89, 105, 111, 112, 113, 115, 116, 118, 122, 127, 137, 139, 140, 142, 145, 148, 151, 152, 154, 155, 156, 157, 159, 173, 182], "correspondingli": [112, 113], "corrupt": [10, 100, 112, 113, 116, 151], "corsican": 96, "cortic": [112, 113], "cosin": [10, 11, 56, 117, 120, 153], "cosmic": 17, "cosmo": 17, "cost": [10, 11, 13, 36, 46, 47, 51, 53, 56, 60, 64, 66, 72, 91, 98, 106, 110, 112, 113, 116, 118, 121, 128, 129, 147, 153, 161, 165, 167, 168, 171, 173], "costli": [7, 94, 121, 173], "cot": 101, "cot_prompt": 101, "cotton": [112, 113], "couch": 10, "cough": 93, "could": [6, 10, 11, 13, 15, 41, 42, 43, 47, 50, 51, 53, 54, 55, 60, 65, 78, 89, 90, 93, 96, 98, 103, 105, 106, 107, 112, 113, 116, 117, 118, 121, 128, 131, 137, 138, 139, 140, 144, 148, 153, 157, 160, 166, 168, 171, 174, 175, 176, 177, 178], "couldn": 178, "council": [112, 113], "count": [15, 16, 18, 22, 23, 101, 104, 106, 107, 116, 117, 120, 121, 127, 134, 137, 146, 147, 148, 151, 152, 154, 156, 157, 158, 159], "counter": [112, 113, 119, 121, 133, 134, 140], "counteract": 7, "countercultur": [112, 113], "counterpart": [84, 112, 113, 116], "counti": [112, 113], "countin": 146, "countplot": [25, 26, 137], "countri": [0, 4, 89, 112, 113, 153], "countryexposure_": 120, "countryrisk_": 120, "countrysentiment_": 120, "countvector": [127, 144, 151], "coupl": 7, "courag": 172, "cours": [44, 50, 53, 73, 112, 113, 118, 131, 140, 174, 177, 179], "coursera": 50, "court": [94, 112, 113, 153], "courtlisten": 94, "covari": 152, "cover": [10, 13, 38, 55, 61, 71, 72, 76, 82, 86, 89, 90, 94, 97, 104, 106, 112, 113, 116, 120, 121, 130, 131, 134, 151, 166, 169, 171, 187], "coverag": [21, 95, 104, 106, 112, 113, 120, 122, 129], "covid": [112, 113], "cowen": 129, "cozi": 10, "cp": [35, 153], "cp38": [137, 151], "cpi": [13, 35], "cpi_diff_prev": [26, 27, 28, 29], "cpi_diff_year": [26, 27, 28, 29], "cpiaucsl": 35, "cpu": [7, 15, 23, 52, 89, 101, 113, 151], "cpu_feature_guard": [15, 23, 101], "cr": 102, "craft": [3, 10, 47, 51, 58, 90, 93, 99, 101, 167], "craftsperson": 47, "craiyon": [6, 131], "crash": 185, "crass": [112, 113], "crater": [112, 113], "crawl": [2, 96, 123, 130, 131], "crawler": [94, 122], "crayfish": [112, 113], "cream": [140, 146], "creat": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 24, 26, 37, 38, 43, 44, 46, 48, 50, 51, 53, 54, 55, 57, 58, 60, 63, 65, 66, 67, 72, 73, 74, 76, 77, 79, 80, 83, 84, 86, 87, 89, 90, 91, 94, 95, 96, 98, 101, 108, 111, 116, 117, 122, 124, 127, 133, 134, 136, 137, 138, 140, 147, 148, 150, 151, 152, 153, 154, 155, 156, 159, 160, 161, 163, 168, 170, 172, 174, 175, 178, 181, 182, 183, 184, 186], "create_ngram_model": 134, "create_project": 22, "create_records_from_cv_pr": [17, 18, 20], "creation": [2, 7, 43, 47, 51, 54, 56, 60, 63, 64, 89, 99, 112, 113, 122, 148, 154, 165, 166, 167, 170], "creativ": [6, 9, 10, 12, 43, 54, 56, 86, 87, 89, 98, 99, 112, 113, 120, 133, 167], "creator": [3, 6, 10, 89, 131, 138], "creatur": [4, 101], "credenti": [65, 77, 78, 79, 82, 83, 112, 113, 160], "credibl": [56, 131], "credit": [13, 37, 39, 41, 60, 112, 113, 121], "credoai": 60, "creek": [112, 113], "creep": [167, 173], "crenshaw": [112, 113], "crescent": [112, 113], "crespo": 0, "crf": 145, "cri": 61, "crime": [4, 112, 113], "crimin": [112, 113], "crimson": [33, 112, 113], "crise": [13, 41, 120], "crisi": 153, "criteria": [0, 44, 94, 112, 113, 141, 146, 167, 168, 170], "criterion": [85, 128, 129, 146], "critic": [0, 8, 11, 15, 23, 38, 43, 47, 48, 51, 53, 56, 60, 61, 64, 72, 75, 78, 86, 88, 90, 94, 99, 101, 112, 113, 114, 117, 123, 131, 132, 140, 164, 166, 170, 173], "criticis": [112, 113], "critiqu": [5, 88, 90, 112, 113], "critu": 151, "crop": [7, 10, 13, 89, 112, 113], "cross": [2, 9, 11, 19, 38, 56, 58, 66, 70, 89, 94, 96, 100, 110, 112, 113, 117, 120, 123, 128, 129, 161, 186], "cross_val_predict": [15, 17, 18], "crossentropyloss": [128, 129], "crossov": [112, 113], "crouch": 131, "crow": [112, 113], "crowdfund": 121, "crowdsourc": 52, "crucial": [6, 7, 8, 9, 11, 13, 39, 41, 42, 46, 47, 51, 53, 54, 55, 56, 60, 65, 72, 74, 77, 78, 79, 81, 89, 90, 93, 94, 96, 99, 103, 106, 107, 112, 113, 117, 123, 132, 133, 134, 135, 137, 138, 139, 141, 143, 144, 145, 147, 148, 149, 152, 158, 160, 166, 167, 168, 173], "crush": [112, 113], "crutch": 11, "cruz": [112, 113], "cryptocurr": 78, "cryptograph": [39, 77, 78, 79], "cryptographi": [77, 78, 79], "cryptosystem": 79, "crystal": 153, "crystallin": [112, 113], "css": [122, 170], "csv": [24, 46, 74], "ct": [72, 102], "ctmodel": 153, "ctor": 102, "ctrl": [98, 100], "ctype": 25, "cu": 102, "cu118": 46, "cuda": [46, 52, 113], "cuda_device_ord": [16, 18, 25, 32, 33, 34, 35, 153], "cuda_visible_devic": [16, 18, 25, 32, 33, 34, 35, 153], "cue": [112, 113], "cui": 0, "cuisin": 47, "culinari": 47, "culmin": 13, "cultiv": [112, 113], "cultur": [64, 65, 66, 94, 99, 112, 113, 131, 133, 135, 138, 143, 160, 161, 172], "cumberland": [112, 113], "cumbersom": 124, "cumbria": [177, 178], "cumul": [55, 93, 98, 112, 113], "cup": [112, 113], "curat": [47, 56, 57, 58, 94, 99], "cure": [112, 113], "curi": [0, 7], "curiou": 183, "curl": [61, 81], "curli": 118, "curr_sv": 53, "currenc": [112, 113, 120, 153], "current": [10, 18, 23, 31, 37, 50, 55, 56, 61, 62, 64, 72, 77, 78, 79, 89, 90, 94, 98, 112, 113, 121, 128, 129, 130, 131, 133, 152, 153, 164, 166, 168, 174, 175, 176, 181, 185], "current_ngram": 134, "current_word": 134, "curriculum": 7, "curs": [50, 127, 134, 144, 149], "cursiv": [112, 113], "curtail": 51, "curv": [78, 79, 112, 113], "curvatur": [0, 85], "custom": [8, 9, 10, 42, 43, 46, 51, 53, 54, 60, 61, 62, 63, 65, 66, 67, 72, 75, 78, 83, 89, 92, 93, 94, 99, 112, 113, 122, 131, 135, 138, 139, 149, 153, 160, 161, 165, 166, 167, 172, 173], "custom_inventori": [65, 160], "customis": 179, "customiz": [43, 61, 106], "cut": [26, 27, 28, 29, 30, 34, 36, 43, 47, 99, 102, 112, 113, 119, 129, 149], "cute": 148, "cv": [15, 17, 18, 159, 174, 178, 186], "cv_matrix": 159, "cv_pred": [17, 18], "cv_preds_inv": 15, "cv_preds_new": 17, "cv_preds_top": 15, "cvf": [0, 7], "cw": [112, 113], "cxhxw": 89, "cy": [96, 102], "cyber": [50, 78], "cybersecur": 86, "cycl": [2, 7, 15, 43, 61, 64, 72, 162, 163, 172, 173], "cycler": 137, "cyclic": [121, 172, 173], "cynic": [112, 113], "cyril": [112, 113], "czech": 96, "d": [0, 1, 15, 17, 18, 23, 25, 38, 54, 60, 68, 75, 80, 81, 85, 100, 101, 102, 106, 107, 109, 112, 113, 114, 116, 120, 125, 129, 130, 137, 140, 141, 143, 147, 148, 151, 152, 153, 158, 176, 181, 182, 183], "d14": 0, "d2b4434": [177, 178, 180, 181], "d55c9d": 22, "d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0": 111, "d6ed38f9b76acdb2c76ae773f15031c42b9fbdb": 185, "d_": [9, 121], "d_w": 148, "da": [96, 102, 124], "dad": 172, "daemon": [61, 62], "dai": [0, 13, 24, 32, 66, 84, 89, 100, 102, 112, 113, 121, 129, 137, 153, 161, 172], "daili": [24, 47, 92, 112, 113, 131, 172], "daily_treasury_yield_curv": 24, "daisyworld": [112, 113], "dakota": [112, 113], "dali": 6, "dall": [2, 5, 12, 60, 131], "dalla": [112, 113, 120], "dalle2": 10, "damag": [11, 112, 113], "damp": 109, "dan": 0, "danawa": 95, "danc": [0, 184], "dancer": 7, "dang": 109, "danger": [109, 176, 186], "dani": 0, "daniel": [0, 7], "danish": 96, "dark": [4, 17, 112, 113], "darkblu": 33, "darken": [112, 113], "darker": [112, 113], "darkest": [112, 113], "darktrac": 50, "dart": [2, 123, 130], "dart_api_kei": 124, "dartmoor": 179, "dash": 183, "dashboard": 83, "data": [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 17, 18, 19, 23, 29, 30, 31, 34, 35, 37, 40, 43, 44, 46, 47, 48, 50, 51, 54, 55, 58, 59, 61, 62, 64, 65, 66, 71, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 86, 87, 92, 93, 97, 99, 100, 101, 102, 104, 106, 107, 108, 109, 110, 114, 116, 117, 118, 119, 120, 121, 123, 125, 127, 128, 130, 131, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 152, 153, 154, 157, 159, 160, 161, 165, 166, 168, 170, 171, 186], "data_col": [34, 113], "data_column": 18, "data_dir": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 124, 153], "data_fil": [15, 17, 18, 20, 21, 22, 23, 25, 29, 31, 34, 46], "data_files_modifi": [18, 23, 29], "data_inv": 15, "data_inval_cv": 15, "data_kei": [15, 16, 22], "data_path": [46, 182], "data_pol_merg": 15, "data_sourc": [15, 16, 22], "data_topic_cv": 15, "databas": [7, 13, 39, 47, 57, 58, 79, 90, 94, 117, 121, 122, 131, 138], "databrick": [57, 60], "datacollatorforlanguagemodel": [112, 113], "datadog": [65, 66, 160, 161], "dataflow": 165, "datafram": [15, 16, 21, 22, 23, 24, 25, 29, 31, 74, 124, 137, 150], "dataframe_to_predict": 22, "dataframeinput": 74, "dataiku": 72, "dataload": 112, "datano": [25, 26], "datarobot": 72, "dataset": [2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 26, 27, 29, 30, 31, 34, 36, 37, 38, 47, 50, 52, 53, 54, 60, 74, 75, 76, 85, 89, 90, 91, 97, 99, 107, 110, 114, 117, 120, 121, 122, 126, 129, 130, 131, 133, 135, 136, 139, 140, 148, 150, 151, 156], "dataset_build": [17, 21], "datasetdict": [95, 137], "datasetinfo": 18, "date": [1, 6, 16, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 56, 67, 69, 79, 90, 94, 112, 113, 120, 124, 131, 133, 134, 143, 151, 156, 175, 176, 177, 181, 182, 185, 186], "datetim": [18, 23, 29, 33], "datetime64": 29, "dateutil": [137, 142], "daunt": 94, "davi": [0, 112, 113], "david": [0, 97, 112, 113, 130], "davinci": [84, 101], "davydov": 0, "dax": 153, "db": [16, 20, 65, 160], "db1": [65, 160], "dbeorlf123": 16, "dbk": 0, "dbow": 155, "dbscan": [139, 149], "dcl21": 0, "dclt18": 0, "dc\uc5d0\uc11c": 21, "ddim": 10, "de": [0, 52, 78, 79, 96, 102, 112, 113], "de73": 184, "de82": 184, "deactiv": [43, 98], "dead": 100, "deadlin": 171, "deadlock": 18, "deal": [10, 39, 50, 51, 54, 57, 58, 64, 90, 94, 102, 112, 113, 117, 127, 134, 137, 139, 140, 144, 148, 153, 157, 172, 178], "deali": [112, 113], "dean": [0, 156], "death": [112, 113], "deb": 81, "debat": [112, 113], "debian": 80, "debit": 41, "debt": [0, 102, 116, 153], "debug": [2, 43, 59, 99, 162, 167, 168, 173, 187], "debut": 131, "decad": [7, 50, 112, 113, 121, 131], "decai": [46, 89, 111], "decatur": [112, 113], "decemb": [112, 113, 153], "decenni": [112, 113], "decent": [137, 150], "decentr": [39, 77, 78], "decentralis": [112, 113], "decid": [7, 11, 37, 53, 58, 98, 106, 107, 112, 113, 129, 137, 145, 146, 147, 176, 178], "decidu": [112, 113], "decimet": [112, 113], "deciph": [0, 103], "decis": [2, 10, 13, 25, 28, 31, 37, 38, 40, 45, 50, 51, 54, 55, 58, 60, 64, 65, 77, 86, 92, 95, 99, 107, 112, 113, 119, 120, 121, 131, 139, 160, 179], "decker": [112, 113], "decl": 102, "declar": [65, 66, 67, 102, 112, 113, 160, 161], "declin": [112, 113, 120, 121, 152, 153], "decod": [2, 8, 13, 96, 97, 99, 100, 101, 111, 112, 116, 131, 140], "decompos": [56, 58, 133, 151, 152, 164], "decomposit": [43, 53, 105, 133, 166], "deconstruct": 115, "decoupl": 116, "decreas": [9, 96, 98, 107, 112, 113, 146], "decri": 156, "decrypt": [77, 78, 79, 80], "dedic": [7, 65, 72, 160], "deduct": [112, 113], "dedupl": [56, 96, 118, 129], "deed": [112, 113], "deem": [78, 127], "deep": [0, 2, 7, 12, 13, 15, 18, 23, 41, 42, 47, 51, 54, 55, 60, 72, 74, 86, 87, 88, 89, 92, 94, 98, 99, 100, 103, 112, 113, 114, 117, 119, 129, 131, 132, 135, 137, 138, 155, 171], "deepart": 3, "deepcopi": [108, 109], "deepdeep": 18, "deepdream": 3, "deepen": [112, 113], "deeper": [10, 53, 56, 74, 90, 107, 113, 114, 131], "deepercut": 7, "deeplabcut": 0, "deepli": [46, 55, 112, 113], "deepmind": 54, "deepnlp": 46, "deepspeed_config": 52, "def": [21, 27, 33, 35, 53, 74, 101, 102, 108, 109, 111, 112, 113, 116, 125, 128, 129, 133, 134, 136, 137, 146, 151, 153, 182], "default": [0, 13, 15, 18, 20, 25, 29, 50, 61, 65, 67, 70, 80, 81, 82, 83, 89, 101, 113, 121, 125, 151, 153, 160, 176, 178, 181, 182, 183], "defaultdict": [102, 108, 109, 133, 134, 156], "defeat": [54, 112, 113, 137], "defect": [66, 112, 113, 161, 173], "defenc": [112, 113], "defend": [112, 113], "defens": 120, "defi": [112, 113], "defiantli": [112, 113], "defici": 165, "deficit": [112, 113, 120, 138], "defin": [0, 2, 7, 8, 9, 17, 18, 20, 22, 30, 51, 53, 58, 62, 63, 64, 65, 67, 70, 72, 73, 74, 76, 85, 96, 98, 99, 100, 104, 107, 108, 109, 111, 115, 117, 121, 128, 131, 133, 134, 136, 137, 141, 144, 146, 148, 151, 155, 156, 158, 159, 160, 165, 168, 169, 171, 172, 173], "definit": [73, 79, 112, 113, 120, 140, 145, 158, 167, 172, 175, 176, 177, 181, 183], "deflat": 35, "deforest": [112, 113], "degrad": [10, 118, 173], "degre": [43, 112, 113, 117, 131, 141, 148, 173], "dehghani": 0, "dejavu": 29, "del": [112, 113], "delai": [7, 64, 112, 113, 165, 173], "deleg": [112, 113], "delegitimis": [112, 113], "delet": [20, 80, 82, 100, 112, 113, 116, 175, 176, 177, 178, 181, 182, 183], "delete_project": 22, "delhi": [112, 113, 130], "deliber": [0, 60, 65, 160], "delic": [47, 117], "delin": [53, 57, 112, 113], "deliv": [65, 66, 72, 81, 112, 113, 117, 160, 161, 171, 172, 173], "deliver": [48, 173], "deliveri": [56, 65, 81, 160, 165, 172, 173], "delug": 17, "delus": 82, "delusion": 151, "delv": [3, 40, 45, 50, 51, 55, 60, 90, 101, 107, 112, 113, 143, 168, 170, 173, 187], "demand": [1, 11, 13, 47, 51, 53, 54, 56, 60, 65, 66, 94, 99, 112, 113, 123, 153, 160, 161, 170, 172, 173], "demo": [7, 52, 84], "democraci": [112, 113, 151], "democrat": [0, 51, 53, 60, 72, 84, 112, 113, 121, 151], "demograph": [112, 113, 121], "demonstr": [7, 9, 43, 50, 51, 52, 54, 74, 84, 86, 90, 94, 98, 99, 101, 102, 112, 113, 114, 116, 117, 121, 131, 151, 173], "demopoli": [112, 113], "den": 102, "dendrogram": 149, "deng": 0, "deni": 186, "denim": 17, "denni": [0, 112, 113], "dennison": 0, "denois": [7, 10, 11, 99, 100, 118], "denomin": [112, 113, 144], "denormalizer_spec": [104, 106], "denot": [9, 54, 55, 96, 112, 113, 120, 127, 134, 138, 141, 146, 148, 152], "dens": [15, 17, 18, 23, 89, 111, 118, 128, 129, 139, 155], "dense_predict": [15, 17, 18, 23], "denser": [127, 159], "densif": 56, "densiti": [56, 112, 113, 149], "dental": [112, 113], "dentistri": [112, 113], "dep": 145, "depart": [112, 113, 172], "depend": [1, 9, 10, 11, 41, 42, 43, 46, 47, 50, 53, 54, 62, 63, 65, 70, 72, 73, 74, 76, 87, 89, 90, 94, 98, 99, 100, 101, 103, 104, 106, 107, 110, 112, 113, 114, 115, 116, 117, 129, 131, 133, 134, 137, 138, 139, 140, 141, 143, 146, 147, 148, 151, 152, 155, 157, 158, 160, 165, 172, 173, 175, 176, 177, 183], "depict": [4, 43, 60, 112, 113], "deploi": [2, 42, 46, 47, 56, 58, 60, 62, 63, 65, 66, 71, 72, 74, 75, 76, 81, 86, 87, 93, 98, 99, 110, 131, 160, 161, 167, 173, 177], "deploy": [50, 51, 54, 56, 61, 63, 64, 65, 66, 71, 72, 73, 76, 81, 84, 86, 93, 99, 160, 161, 162, 170, 171, 172, 173], "deposit": 100, "deprec": [23, 31, 111, 113], "depress": [112, 113], "depriv": [112, 113], "depth": [0, 10, 13, 42, 48, 51, 56, 69, 71, 88, 97, 112, 113, 116, 154, 166, 168, 170, 173], "der": [0, 102, 148], "derail": 168, "derang": 151, "derek": 0, "deri": [0, 7], "deriv": [13, 15, 53, 60, 96, 106, 112, 113, 114, 116, 129, 137, 138, 140, 143, 148, 158, 172], "descart": [112, 113], "descend": [102, 112, 113, 125], "descent": [112, 113, 152], "describ": [7, 9, 10, 11, 26, 50, 61, 65, 69, 82, 89, 90, 97, 112, 113, 117, 131, 140, 152, 154, 160, 165, 166, 168, 171], "descript": [6, 7, 9, 10, 11, 12, 13, 18, 60, 68, 69, 72, 83, 89, 94, 101, 112, 113, 120, 121, 131, 146, 168, 172, 174, 177], "desegreg": [112, 113], "desert": [112, 113], "deserv": 137, "deshuffl": 118, "desiderata": 131, "design": [2, 6, 7, 8, 10, 11, 12, 42, 43, 44, 47, 51, 53, 54, 60, 61, 63, 72, 74, 75, 77, 78, 81, 86, 89, 90, 91, 92, 94, 96, 98, 99, 101, 104, 106, 112, 113, 114, 115, 116, 117, 118, 123, 124, 131, 137, 139, 152, 164, 166, 168, 170, 172, 173], "desir": [9, 43, 45, 47, 53, 56, 58, 65, 67, 77, 82, 93, 96, 98, 101, 107, 109, 117, 122, 131, 134, 148, 149, 152, 160, 166, 173], "desktop": [62, 170], "desoto": [112, 113], "despit": [6, 10, 11, 39, 50, 51, 54, 56, 60, 87, 92, 102, 110, 112, 113, 116, 127, 131, 133, 140, 152, 154, 173], "destigmat": [112, 113], "destin": [67, 68, 70, 112, 113], "destroi": [11, 112, 113], "destruct": [112, 113], "det": 145, "detach": [78, 129, 178], "detail": [6, 7, 8, 13, 31, 43, 46, 53, 54, 56, 58, 68, 77, 78, 84, 90, 97, 100, 101, 105, 108, 112, 113, 117, 120, 130, 131, 145, 153, 167, 168, 171, 173, 178, 183], "detect": [0, 7, 13, 15, 18, 22, 25, 32, 33, 34, 35, 39, 47, 50, 51, 56, 60, 65, 66, 75, 78, 79, 96, 99, 100, 112, 113, 117, 121, 123, 131, 135, 139, 141, 148, 160, 161, 173], "detectgpt": [0, 2, 87, 88, 91], "detector": [0, 7], "determin": [8, 10, 11, 37, 43, 53, 56, 65, 90, 92, 98, 101, 103, 105, 107, 111, 112, 113, 114, 115, 117, 118, 131, 133, 135, 136, 137, 138, 139, 140, 141, 145, 146, 148, 158, 160, 173], "determinist": [7, 10, 98, 125, 144], "deterr": 121, "detoken": 106, "detox": [112, 113], "detriment": [98, 118], "dev": [15, 18, 21, 23, 29, 34, 66, 72, 136, 161, 182], "dev50": 18, "dev57": [17, 20, 21, 23], "dev58": 22, "dev67": 15, "dev7": 153, "dev_siz": [15, 17, 21], "devast": [112, 113], "develop": [1, 2, 3, 6, 7, 10, 12, 13, 42, 43, 47, 48, 50, 51, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 77, 78, 79, 84, 85, 86, 87, 88, 89, 92, 93, 94, 97, 98, 99, 110, 112, 113, 114, 117, 120, 121, 122, 123, 131, 132, 133, 137, 138, 139, 142, 144, 152, 153, 155, 157, 160, 161, 162, 163, 164, 166, 168, 169, 170, 171, 174, 177, 179, 181, 187], "development": [50, 112, 113], "deviat": [24, 29, 96, 113, 133], "devic": [50, 51, 52, 72, 74, 77, 78, 79, 83, 112, 113, 121], "devis": 11, "devlin": [0, 96, 100, 113, 114], "devoid": [60, 166], "devop": [2, 57, 71, 74, 81, 162, 170], "devot": 120, "devsecop": [2, 66, 71], "devset": 133, "df": [39, 74, 137], "df618e0": 184, "dfd": 166, "dfedtar": 24, "dfedtaru": 24, "dff": 24, "dff_30": 24, "dg": 108, "dhariwa": 11, "dharma": [112, 113], "dhn": [112, 113], "di": [6, 102, 131, 140, 146], "diabet": [112, 113], "diacrit": [112, 113], "diagnos": [110, 112, 113, 157], "diagnosi": [50, 93, 112, 113], "diagnost": [50, 51, 112, 113], "diagon": 151, "diagram": [114, 165, 166, 168, 170, 171, 175, 176, 177], "dialect": [50, 94, 99, 112, 113, 131], "dialog": [80, 98, 123, 131], "dialogu": [43, 47, 54, 92, 98, 99, 123, 132], "diam": 102, "diamet": [112, 113], "dic": 142, "dice": [89, 153], "dichotomi": [112, 113], "dick": 140, "dict": [15, 16, 18, 21, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "dict_kei": 102, "dictat": [112, 113], "dictatorship": [112, 113], "dictionari": [31, 32, 44, 56, 105, 109, 111, 112, 113, 121, 125, 127, 136, 140, 145, 146, 147, 150, 157, 166], "did": [98, 108, 109, 111, 112, 113, 117, 118, 131, 174, 184], "didn": [10, 21, 52, 89, 176], "diego": 84, "diet": [112, 113], "dietmar": 0, "diff": [10, 24, 175, 176, 178, 181, 186], "differ": [1, 5, 6, 7, 8, 10, 11, 13, 38, 42, 43, 50, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 65, 67, 72, 73, 74, 75, 77, 78, 79, 83, 85, 89, 90, 92, 94, 96, 98, 99, 100, 101, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 127, 129, 131, 132, 134, 135, 137, 138, 139, 141, 142, 145, 146, 148, 149, 150, 151, 152, 153, 157, 158, 160, 165, 167, 170, 173, 174, 175, 178, 181, 184, 186], "differenti": [0, 7, 85, 94, 112, 113, 137], "differential_privacy_clipping_threshold": [104, 106], "differential_privacy_noise_level": [104, 106], "difficult": [13, 27, 28, 93, 94, 100, 101, 110, 112, 113, 115, 122, 127, 135, 138, 141, 148, 149, 152, 167, 173], "difficulti": [7, 112, 113, 117, 131, 173, 186], "diffus": [0, 6, 53, 112, 113, 131], "dig": 102, "digit": [1, 7, 13, 15, 56, 60, 64, 77, 79, 90, 94, 99, 112, 113, 131, 149], "digraph": [112, 113], "dilemma": [51, 127], "dillard": [112, 113], "dilut": [112, 113], "dim": [53, 112, 113], "dimc": 60, "dimens": [3, 10, 39, 42, 50, 53, 56, 60, 89, 93, 114, 117, 120, 127, 129, 139, 147, 148, 149, 155, 157, 158], "dimension": [7, 10, 42, 50, 56, 57, 60, 100, 114, 116, 121, 127, 128, 134, 137, 148, 151, 152, 154, 155, 157, 158], "diminish": [51, 89, 112, 113], "din": 125, "diner": [112, 113], "ding": 102, "dioxid": [112, 113], "dip": 153, "diphthong": [112, 113], "dir": [16, 20, 62, 140, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "direct": [10, 47, 50, 53, 56, 57, 90, 99, 100, 101, 106, 112, 113, 114, 115, 129, 146, 158, 172], "directli": [7, 54, 56, 58, 60, 61, 67, 70, 104, 105, 106, 112, 113, 116, 117, 121, 122, 124, 131, 139, 145, 153, 157, 175], "director": [134, 150], "directori": [15, 61, 62, 65, 67, 81, 111, 112, 113, 124, 136, 160, 174, 175, 176, 177, 178, 179, 180, 181, 183, 185, 186], "dirglielo": 140, "dirichlet": [139, 149, 153], "dirk": 0, "dirnam": 182, "dirti": [24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 112, 113, 118], "disabl": [18, 61, 111, 112, 113], "disadvantag": [50, 148, 173], "disagr": [112, 113], "disagre": [112, 113], "disambigu": [131, 132, 138, 143, 154, 158], "disappear": [112, 113], "disappoint": 137, "disast": [13, 112, 113], "disc": [112, 113], "discard": [15, 17, 22, 56, 98, 118, 147, 154, 175, 177, 182], "discern": [56, 94, 148], "disciplin": [72, 112, 113, 121, 163, 164, 167, 172, 173], "disclos": 53, "disco": [6, 112, 113, 131], "disconnect": 72, "discours": [131, 137, 141, 175, 176, 177, 178, 180], "discov": [54, 98, 99, 101, 117, 131, 139, 149, 151, 152, 153], "discoveri": [0, 3, 50, 98, 121, 131, 152], "discrep": [65, 85, 156, 158, 160], "discret": [10, 43, 53, 127, 149, 157, 165], "discrimin": [15, 17, 18, 23, 100, 112, 113, 138, 139], "discriminator_predict": [15, 17, 18, 23], "discriminatori": 131, "discuss": [3, 5, 13, 56, 58, 64, 73, 77, 78, 80, 81, 85, 88, 90, 97, 98, 107, 112, 113, 114, 120, 121, 124, 131, 141, 151, 156, 159, 166, 168, 171, 173], "diseas": [50, 93, 112, 113], "disenfranchis": [112, 113], "disentangl": 135, "disfranchis": [112, 113], "disgrac": 140, "disgracefulli": 140, "dish": [47, 157], "disinform": [86, 91, 99], "disintegr": [112, 113], "disjoint": 74, "disk": [80, 111, 112, 113, 178], "dislik": 146, "dismal": [112, 113], "dismember": [112, 113], "dismiss": [112, 113], "disobei": [112, 113], "disord": [112, 113], "disp": 113, "dispar": [112, 113], "dispers": [115, 120], "displaci": 145, "displai": [44, 62, 73, 82, 92, 112, 113, 114, 122, 143, 146, 150, 151, 153, 156, 179], "dispos": [112, 113], "disproportion": 60, "disproven": [112, 113], "disput": [112, 113], "disregard": 139, "disrupt": [0, 78, 112, 113, 115], "dissect": [43, 57], "dissemin": [60, 112, 113], "dissimilar": 148, "dist": [1, 111, 112, 113], "distanc": [112, 113, 127, 149], "distant": [117, 129], "distict": 115, "distil": 75, "distilbert": [100, 109], "distinct": [8, 11, 47, 51, 72, 78, 112, 113, 114, 115, 117, 120, 122, 127, 131, 138, 140, 146, 148, 157, 172, 173], "distinctli": [112, 113], "distinguish": [10, 43, 53, 91, 100, 107, 112, 113, 116, 127, 129, 141], "distort": 9, "distress": [112, 113], "distri": 102, "distribut": [0, 7, 9, 13, 39, 41, 47, 52, 55, 56, 60, 61, 63, 66, 73, 74, 75, 76, 77, 79, 81, 84, 96, 98, 100, 112, 113, 114, 117, 121, 128, 129, 131, 133, 134, 137, 139, 140, 147, 148, 149, 152, 153, 155, 156, 159, 161, 177], "distributed_typ": 52, "district": [112, 113], "disturb": [112, 113], "ditto": 151, "div": 44, "dive": [56, 74, 102, 111, 112, 114, 136, 139, 171], "diverg": [8, 9, 58, 112, 113, 152, 184], "divers": [0, 8, 9, 10, 11, 12, 39, 41, 43, 46, 47, 50, 51, 53, 54, 55, 56, 60, 84, 89, 94, 98, 99, 101, 110, 112, 113, 117, 122, 123, 131, 145], "diversifi": [13, 14, 84, 106, 112, 113, 117], "divi": 102, "divid": [11, 57, 76, 109, 110, 112, 113, 115, 117, 120, 133, 138, 139, 140, 141, 143, 144, 148, 152, 158, 164, 165, 168, 172, 173], "dividen": 102, "dividend": [102, 153], "divin": [112, 113], "divis": [112, 113, 141, 168], "dixi": [112, 113], "django": 168, "dlc": 7, "dlcrnet": 7, "dlerror": 15, "dlopen": 15, "dlrpv": 0, "dlt": 78, "dm": 155, "dmrmodel": 153, "dn": 81, "dna": [112, 113], "dnn": 98, "do": [6, 7, 10, 25, 31, 43, 54, 60, 70, 78, 80, 89, 98, 100, 101, 102, 103, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 129, 133, 134, 137, 140, 143, 148, 151, 152, 153, 158, 159, 165, 166, 168, 170, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186], "do_lower_cas": 115, "do_sampl": [98, 112], "doc": [17, 18, 23, 31, 36, 62, 81, 136, 137, 145, 153], "doc_inst": 153, "doc_length": 153, "doc_topic_dist": 153, "docker": [2, 43, 56, 61, 63, 65, 66, 71, 73, 76, 160, 161, 170], "dockerd": 62, "dockerfil": [2, 67, 71], "doctor": [112, 113, 137, 157], "doctrin": [112, 113], "document": [16, 25, 31, 37, 43, 47, 48, 50, 56, 65, 74, 77, 78, 94, 96, 99, 112, 113, 120, 121, 122, 126, 127, 131, 135, 138, 139, 145, 147, 148, 151, 152, 154, 156, 157, 158, 159, 160, 165, 166, 167, 168, 170, 172, 173, 179, 183], "document_al": 124, "documentlist": 44, "doe": [7, 10, 11, 47, 51, 53, 56, 78, 82, 91, 98, 100, 101, 106, 107, 112, 113, 114, 116, 117, 122, 126, 127, 139, 140, 141, 144, 149, 151, 152, 155, 157, 158, 159, 172, 173, 175, 181, 184], "doesn": [10, 53, 85, 86, 93, 98, 106, 113, 117, 133, 134, 137, 140, 141, 158, 178], "dog": [52, 98, 112, 113, 114, 116, 117, 127, 138, 143, 144, 145, 148, 150, 154, 159], "dogecoin": 102, "doha": 0, "doi": 0, "dollar": [131, 153], "domain": [7, 9, 12, 18, 39, 40, 41, 43, 46, 47, 54, 55, 56, 58, 60, 66, 75, 85, 86, 87, 89, 90, 92, 99, 101, 110, 117, 118, 122, 123, 131, 135, 138, 139, 142, 145, 146, 161, 164, 167, 170], "domest": [112, 113, 120], "domin": [60, 112, 113, 115, 117, 121, 139, 140], "don": [4, 24, 25, 60, 65, 73, 77, 94, 98, 113, 114, 116, 127, 129, 131, 137, 140, 143, 147, 153, 154, 156, 160, 175, 176, 177, 178, 179, 182, 186], "donald": 0, "donat": [112, 113, 120], "done": [9, 53, 65, 72, 80, 93, 100, 104, 105, 106, 109, 110, 112, 113, 117, 127, 133, 160, 172, 173, 177, 179, 184], "dong": [0, 117], "door": 145, "doppler": [2, 67, 71], "dosovitskii": [0, 117], "dot": [10, 53, 67, 71, 114, 117, 126, 127, 148, 181], "dotdrop": [2, 67, 71], "dotenv": 124, "dotenv_path": 124, "dotfil": [2, 65, 71, 160], "dothan": [112, 113], "doubl": [10, 54, 112, 113, 135, 181], "doubli": [0, 117], "doubt": 184, "dow": 102, "down": [1, 7, 9, 10, 15, 17, 18, 23, 54, 61, 62, 64, 66, 90, 92, 98, 101, 102, 103, 104, 105, 106, 107, 111, 112, 113, 114, 116, 117, 118, 127, 129, 131, 140, 141, 144, 145, 147, 153, 154, 161, 168, 170, 178], "downcast_bf16": 52, "downg": 108, "downgr": 108, "downgra": 108, "downgrad": [102, 108], "download": [16, 21, 46, 60, 61, 62, 73, 78, 96, 101, 104, 105, 112, 115, 122, 125, 126, 129, 133, 134, 136, 137, 140, 143, 145, 151, 156], "downscal": 89, "downstream": [50, 100, 110, 111, 112, 113, 114, 115, 118, 127, 147], "downtim": [66, 161], "downtown": [112, 113], "downturn": 13, "downward": 172, "downweight": 126, "dozen": 141, "dozier": [112, 113], "dpg": 95, "dpg\ub294": 95, "dqn": 54, "dr": [105, 137], "draft": [43, 60, 90, 121, 168], "dragon": 17, "dragonfli": [112, 113], "dramat": [60, 96, 116, 120], "draw": [2, 5, 38, 47, 54, 90, 98, 112, 113, 117, 131, 137, 141], "drawback": [98, 117, 120, 152], "drawbench": 11, "drawn": [117, 148], "dream": 18, "dreambooth": 52, "dreamlik": 3, "dress": [112, 113], "drew": [112, 113], "dri": 102, "drift": [60, 65, 66, 75, 120, 160, 161], "drill": 129, "drink": 157, "drive": [51, 53, 55, 56, 66, 67, 90, 94, 98, 112, 113, 117, 123, 124, 140, 161, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "drive_dir": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "driven": [0, 10, 17, 38, 43, 45, 53, 55, 64, 70, 72, 94, 104, 106, 131, 167, 170], "driver": [112, 113], "drone": 13, "drool": [112, 113], "drop": [10, 11, 15, 16, 22, 89, 106, 112, 113, 118, 120, 131, 147, 153], "drop_dupl": 16, "drop_index": [16, 17, 21, 25], "dropbox": 67, "dropdown": 113, "droplet": [112, 113], "dropna": [32, 35], "dropout": [113, 141], "drosophila": 7, "drought": 13, "droz": 6, "drug": [50, 112, 113], "drunk": 157, "dry": [112, 113], "ds_cfg": [17, 18, 23, 31], "ds_inval": 15, "ds_pol": 15, "ds_tp": 15, "ds_tp_merg": 15, "ds_tp_predict": 15, "ds_tp_valid": 15, "ds_zero3_cpu": 52, "dsa": 79, "dsl": [66, 161], "dsm": [112, 113], "dso_load": 15, "dsp": [112, 113], "dt": [33, 145], "dtmodel": 153, "dtype": [15, 16, 22, 26, 29, 111, 113, 129, 151], "du": [102, 118], "dual": 86, "ducharm": 0, "duck": 131, "dudlei": [25, 31], "due": [6, 7, 9, 10, 39, 47, 50, 51, 53, 60, 63, 65, 70, 72, 78, 84, 85, 98, 99, 112, 113, 117, 129, 131, 133, 134, 135, 138, 139, 141, 142, 143, 144, 145, 148, 149, 152, 153, 154, 157, 160, 165, 168, 173], "duel": 54, "duke": 120, "dummi": [10, 127], "dump": [112, 113], "duolingo": 86, "dup": 102, "duplic": [53, 99, 112, 113, 118, 182], "durabl": 153, "durat": [30, 36, 51, 53, 112, 113, 122, 168, 172], "dure": [6, 8, 9, 10, 11, 47, 51, 52, 53, 54, 55, 78, 79, 89, 90, 98, 99, 101, 107, 110, 111, 112, 113, 114, 116, 117, 118, 120, 134, 137, 141, 143, 146, 151, 152, 153, 172, 173], "dust": [112, 113], "dustri": 108, "dutch": 96, "duti": [112, 113], "dvae": 9, "dvc": 71, "dw2008\uc744": 15, "dwindl": 56, "dx": 15, "dy": 102, "dyer": 100, "dynam": [0, 3, 13, 15, 39, 41, 42, 47, 50, 51, 53, 55, 56, 58, 60, 72, 75, 89, 90, 92, 98, 100, 112, 113, 142, 153, 168, 172, 173], "dynamo_backend": 52, "dysfunct": [112, 113], "dysmorph": [112, 113], "dysphoria": [112, 113], "dysregul": [112, 113], "e": [0, 1, 2, 5, 12, 13, 15, 17, 18, 20, 22, 23, 46, 54, 56, 60, 61, 65, 66, 68, 75, 76, 79, 80, 83, 85, 89, 94, 96, 98, 100, 101, 102, 103, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 121, 124, 127, 129, 131, 133, 134, 138, 139, 140, 143, 144, 146, 147, 148, 149, 153, 154, 157, 160, 161, 168, 171, 172, 175, 176, 178, 181, 182, 184], "e2": 6, "e4bb8ea": 176, "e5451fd": [178, 180, 181], "e61909": [0, 7], "e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf": 137, "ea15": 184, "eac": [112, 113], "each": [6, 7, 9, 10, 11, 13, 21, 24, 37, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 56, 60, 61, 66, 72, 73, 74, 76, 77, 78, 81, 82, 84, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 165, 167, 170, 171, 173, 175, 180, 181, 182, 183], "ead": 125, "eagach": 181, "eager": 17, "ear": 102, "earli": [13, 41, 50, 58, 64, 65, 66, 112, 113, 140, 160, 161, 167, 172, 173], "earlier": [10, 46, 54, 82, 89, 114, 115, 117, 153, 156, 173, 177, 179, 184], "earliest": [112, 113, 173], "early_stop": 98, "earn": [102, 112, 113, 120, 121, 129, 153], "earnest": 17, "earni": 108, "earnin": 108, "earth": [84, 89, 112, 113], "earthshin": [112, 113], "earthworm": [112, 113], "eas": [7, 56, 66, 67, 77, 161], "easi": [60, 63, 65, 67, 70, 72, 73, 75, 80, 98, 103, 111, 112, 113, 124, 133, 137, 141, 147, 157, 160, 177, 181, 182], "easier": [9, 10, 65, 66, 67, 74, 75, 84, 92, 99, 100, 112, 113, 114, 122, 131, 138, 151, 152, 160, 161, 164, 167, 173], "easili": [7, 9, 52, 67, 72, 73, 74, 113, 125, 146, 148, 151, 153, 173], "east": [112, 113], "eastern": [112, 113], "eat": [101, 103, 112, 113, 127, 131, 133, 140], "ebner": 0, "ebook": 118, "ec": [142, 143], "ecc": [78, 79, 113], "ecdsa": 79, "echo": [80, 81, 112, 113, 174, 177, 178, 186], "echolal": [112, 113], "echolalia": [112, 113], "echota": [112, 113], "eckert": 130, "eclect": [112, 113], "ecolog": [112, 113], "ecologi": 7, "econ_col": [34, 35, 36], "econ_data": [24, 26, 27, 28, 35], "econ_data2": [24, 26, 27, 28], "econ_data_pivot": 35, "econ_ind": 24, "econ_news_code_info_20220905": 16, "econ_news_code_info_available_20220905": [16, 20], "econ_news_code_info_available_20220911": 22, "econ_news_code_info_available_20221229": 15, "econ_news_filt": 20, "econ_news_filtered_202201229": 15, "econ_news_filtered_20220905": [16, 20], "econ_news_filtered_20220911": 22, "econ_news_kr": [2, 15, 19, 20, 22, 38], "econ_news_kr_chunk": [16, 22], "econ_news_kr_chunks_": [15, 22], "econ_news_kr_chunks_2020_code_20220911": 22, "econ_news_kr_chunks_2020_code_20221229": 15, "econ_news_kr_chunks_2022_code_20220911": 22, "econ_news_kr_chunks_2022_code_20221229": 15, "econ_seri": 24, "econ_train_larg": [27, 28, 29], "econ_train_smal": [27, 28, 29, 34], "econo": 102, "econom": [0, 2, 37, 39, 40, 86, 112, 113, 119, 121, 138, 166], "econometr": 42, "economi": [0, 13, 14, 98, 102, 112, 113, 120, 138], "economist": 120, "ecor": [112, 113], "ecosystem": [2, 7, 48, 59, 60, 61, 63], "ed": [102, 130, 140], "ed25519": 77, "eda": [2, 37, 38, 72, 94, 97], "edg": [47, 51, 54, 60, 61, 72, 74, 99, 112, 113, 119, 153], "edit": [0, 10, 65, 80, 89, 90, 160, 174, 175, 176, 179, 184], "editor": [174, 176], "edmundson": [112, 113], "edouard": 0, "edu": [130, 151], "eduardo": 0, "educ": [8, 9, 43, 49, 64, 93, 112, 113, 130, 177], "edward": [112, 113], "edx": 50, "ee": [108, 112, 113], "ee24636": 184, "eec": 0, "ef": [142, 143], "ef5": [112, 113], "effect": [0, 2, 7, 10, 11, 13, 26, 27, 28, 38, 39, 40, 41, 42, 46, 47, 50, 51, 52, 53, 54, 55, 56, 58, 60, 65, 66, 69, 71, 72, 74, 75, 76, 78, 79, 81, 82, 85, 87, 90, 91, 92, 93, 94, 96, 98, 99, 101, 103, 105, 107, 112, 113, 117, 118, 121, 123, 127, 131, 132, 137, 138, 139, 140, 142, 144, 147, 148, 149, 151, 152, 153, 154, 156, 157, 158, 160, 161, 164, 166, 167, 168, 172, 173, 187], "effector": 45, "efficaci": [43, 50, 51, 56, 60, 112, 113], "effici": [0, 2, 7, 9, 11, 13, 39, 41, 47, 48, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 72, 74, 75, 77, 81, 82, 89, 92, 94, 96, 97, 98, 99, 101, 106, 107, 112, 113, 116, 117, 125, 127, 131, 132, 133, 134, 139, 141, 144, 146, 149, 151, 152, 155, 156, 160, 161, 162, 163, 164, 166, 167, 171, 172, 173], "efficientnet": [7, 10], "effort": [43, 54, 66, 78, 89, 90, 98, 99, 112, 113, 117, 122, 131, 139, 161, 167, 172, 173], "effortlessli": [1, 51], "efro": [0, 7], "eg": 151, "egalitarian": [112, 113], "egg": [112, 113, 133, 159], "egyptian": [112, 113], "eh": 108, "ehr": 78, "ei": 102, "eibi": [112, 113], "eichenbaum": 35, "eigenvalu": 127, "eigh": [178, 181], "eight": [37, 99, 112, 113, 129], "eighteen": 131, "eighteenth": [112, 113], "eighth": [0, 112, 113], "either": [10, 18, 31, 80, 82, 89, 92, 96, 97, 112, 113, 117, 122, 124, 131, 133, 138], "ej": 70, "ekonelectra": [15, 17, 18, 20, 22, 23], "ekonf": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 129, 146, 153], "ekonlpi": 143, "ekorpkit": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 129, 146], "ekorpkit_config_dir": [16, 18, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "ekorpkit_data_dir": [16, 18, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "ekorpkit_data_root": [17, 20, 21, 23], "ekorpkit_log_level": [16, 18, 25, 32, 33, 34, 35, 153], "ekorpkit_project": [16, 18, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "ekorpkit_project_dir": 18, "ekorpkit_workspace_root": [16, 18, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "el": [31, 96, 102], "elabor": [50, 54, 58, 112, 113, 166, 168], "elantra": [112, 113], "elaps": [16, 21, 25, 29, 31], "elast": 56, "elasticsearch": [65, 66, 160, 161], "elbaz": 122, "elect": [0, 31, 112, 113, 120, 121], "elector": [112, 113, 121], "electr": [100, 112, 113], "electra": [15, 23], "electraforsequenceclassif": [15, 17, 18, 23], "electromagnet": [112, 113], "electron": [50, 78, 112, 113, 124, 131, 153], "eleg": 127, "elegantli": 127, "element": [6, 10, 44, 46, 51, 53, 55, 58, 73, 89, 94, 98, 111, 112, 113, 114, 117, 122, 129, 130, 141, 142, 146, 147, 152, 158, 167, 172, 173], "elementari": [112, 113], "elementwis": [114, 115], "elev": [43, 51, 54, 112, 113, 120], "eleven": [112, 113], "elgam": [78, 79], "eli": [0, 7], "elicit": [54, 58], "elif": [0, 7], "elig": [112, 113], "elimin": [7, 9, 53, 85, 89, 98, 106, 112, 113, 121, 127, 164, 173], "elit": [112, 113], "elk": [65, 66, 160, 161], "ellipt": [78, 79], "elmo": [100, 127, 139], "elmor": [112, 113], "els": [15, 24, 26, 27, 28, 33, 101, 102, 109, 115, 124, 136, 146, 153, 157, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186], "elsewher": 153, "elucid": [42, 55, 60, 173], "elva": [112, 113], "em": [104, 106, 107, 152], "ema": 108, "emac": 175, "email": [43, 47, 50, 77, 78, 79, 122, 179], "emancip": [112, 113], "emb": [56, 129], "embed": [2, 7, 9, 10, 11, 47, 53, 60, 72, 89, 97, 103, 110, 111, 112, 113, 114, 115, 116, 117, 125, 128, 130, 131, 133, 140, 149, 170], "embedding_dim": 129, "embedding_s": [128, 129], "embodi": [45, 47, 112, 113, 117], "embrac": [47, 64, 90, 112, 113, 172], "emdedding_dim": 129, "emerald": [112, 113], "emerg": [0, 40, 43, 46, 47, 50, 53, 55, 57, 60, 75, 78, 84, 86, 87, 94, 101, 112, 113, 117, 121, 140, 145, 149, 152, 173], "emi": 108, "emigr": [112, 113], "emilio": 0, "emiss": [112, 113], "emma": [112, 113], "emnlp": 0, "emoji": 116, "emot": [4, 92, 112, 113, 119, 131, 135], "emoticon": 136, "emp": [21, 26, 27, 28, 29], "emp_diff_prev": [26, 27, 28, 29, 30, 34, 36], "emp_diff_year": [26, 27, 28, 29], "emperor": [112, 113], "emphas": [49, 51, 56, 60, 61, 64, 65, 66, 67, 88, 93, 112, 113, 157, 160, 161, 172, 173], "emphasi": [45, 51, 58, 60, 112, 113, 169, 172, 173], "emphasis": [112, 113], "empir": [0, 85, 93, 101, 112, 113], "emploi": [8, 10, 13, 39, 42, 43, 47, 50, 51, 56, 58, 60, 65, 78, 90, 96, 99, 112, 113, 134, 137, 138, 139, 140, 148, 149, 151, 152, 160, 163, 170, 171, 187], "employ": [13, 14, 39, 112, 113, 120, 121, 153], "employ_diff_prev": 26, "employe": [78, 112, 113, 135], "employm": 109, "empow": [60, 114, 131], "empti": [10, 65, 109, 146, 153, 160, 174, 186], "emptyset": 98, "emul": 47, "en": [96, 101, 102, 104, 106, 109, 111, 112, 113, 115, 131, 136, 137, 143, 145, 146], "en_core_web_sm": 145, "en_mc4": 96, "enabl": [1, 3, 6, 7, 8, 9, 10, 12, 13, 15, 23, 42, 43, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 72, 73, 74, 77, 78, 79, 81, 83, 84, 87, 89, 90, 92, 93, 94, 96, 98, 99, 101, 106, 110, 112, 113, 114, 115, 117, 119, 120, 122, 123, 127, 131, 139, 149, 160, 161, 167, 172, 173, 187], "enable_differential_privaci": [104, 106], "enable_sampl": 106, "enact": [112, 113], "enc": 102, "encapsul": [11, 43, 45, 51, 60, 65, 117, 127, 137, 160, 168], "encod": [2, 8, 9, 31, 53, 90, 96, 97, 98, 99, 100, 101, 105, 106, 112, 113, 115, 116, 125, 127, 131, 143, 147, 154, 155, 157], "encode_as_piec": 104, "encode_word": [102, 108, 109], "encoded_input": 105, "encoded_word": [102, 108, 109], "encompass": [47, 50, 51, 66, 90, 99, 161, 165, 168, 173, 187], "encount": [4, 8, 10, 46, 89, 90, 98, 112, 113, 117, 134, 140, 144, 174], "encourag": [7, 9, 11, 38, 64, 65, 66, 84, 86, 89, 98, 160, 161, 172], "encrypt": [2, 13, 39, 65, 67, 71, 75, 77, 79, 80, 83, 160], "encyclopedia": [94, 112, 113], "end": [4, 5, 9, 33, 35, 38, 47, 50, 52, 56, 68, 69, 75, 76, 78, 81, 92, 97, 98, 101, 102, 105, 106, 107, 108, 109, 112, 113, 116, 118, 124, 125, 126, 129, 130, 131, 133, 135, 137, 140, 141, 146, 151, 153, 156, 157, 158, 162, 167, 170, 173, 174, 182, 185], "end_idx": [108, 109], "endang": 98, "endeavor": 90, "endless": 3, "endogen": 0, "endors": [112, 113], "endow": 43, "endpoint": [73, 74], "enemi": [112, 113, 154], "energ": 102, "energi": [4, 50, 51, 54, 78, 87, 99, 102, 112, 113, 120, 153], "enforc": [7, 15, 65, 112, 113, 160, 173], "enfranchis": [112, 113], "eng": 109, "engag": [1, 43, 47, 50, 51, 53, 56, 58, 86, 90, 92, 93, 98, 112, 113, 172, 173], "engel": [112, 113], "engerland": [176, 177, 183], "engin": [2, 6, 9, 13, 43, 48, 57, 60, 63, 70, 72, 75, 76, 90, 92, 93, 97, 99, 112, 113, 122, 130, 131, 146, 150, 151, 156, 163, 169, 187], "england": [112, 113, 175, 176], "english": [11, 50, 86, 94, 96, 106, 112, 113, 117, 118, 121, 122, 123, 131, 136, 137, 138, 141, 143, 144, 145, 146, 150, 151, 153], "english_stop": 153, "enhanc": [3, 6, 10, 13, 38, 39, 46, 50, 51, 52, 53, 54, 55, 60, 65, 66, 68, 75, 77, 78, 80, 84, 86, 87, 94, 99, 101, 112, 113, 116, 117, 135, 139, 149, 151, 160, 161, 166, 168, 170, 173], "enhua": 0, "enjoi": [4, 66, 98, 112, 113, 161], "enjoy": 90, "enlighten": [112, 113], "enorm": 144, "enough": [10, 24, 98, 107, 112, 113, 140, 141, 175], "enrag\u00e9": [112, 113], "enrich": [0, 42, 47, 50, 53, 56, 60, 114, 171], "enrol": [38, 112, 113], "ensembl": [13, 74, 118, 139], "enslav": [112, 113], "ensu": 60, "ensur": [1, 2, 6, 7, 8, 11, 13, 29, 39, 43, 44, 46, 47, 50, 51, 52, 53, 54, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 74, 75, 76, 77, 78, 79, 81, 82, 83, 86, 89, 90, 92, 93, 94, 96, 98, 99, 101, 106, 107, 112, 113, 117, 127, 131, 134, 137, 143, 145, 147, 152, 160, 161, 162, 164, 165, 167, 168, 170, 172, 173, 186], "enta": 108, "entail": [51, 53, 99, 112, 113, 118, 148], "entelecheia": [1, 2, 15, 17, 18, 23, 25, 31, 97, 129, 146, 153, 174, 175, 176, 181, 185, 186], "enter": [4, 47, 52, 77, 78, 82, 83, 112, 113, 146, 167], "enterpris": [58, 60, 66, 72, 161, 170, 172], "entertain": [7, 8, 9, 12, 92, 112, 113], "enthusiast": [112, 113, 115], "entir": [6, 10, 11, 39, 43, 47, 53, 64, 65, 72, 93, 98, 102, 104, 111, 112, 113, 114, 117, 118, 129, 133, 134, 137, 139, 155, 159, 160, 162, 173], "entiti": [13, 45, 50, 51, 53, 75, 78, 92, 99, 112, 113, 114, 116, 123, 126, 131, 135, 144, 145, 157, 166, 170], "entranc": [112, 113], "entrant": 60, "entri": [9, 15, 16, 22, 44, 56, 80, 112, 113, 121, 137, 157, 158, 167, 173], "entropi": [0, 128, 129, 153], "enumer": [24, 25, 98, 109, 128, 129, 143, 150, 153, 156, 168, 171], "env": [16, 17, 18, 20, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 46, 74, 80, 124, 153], "env_or_fil": 43, "environ": [7, 17, 18, 20, 21, 22, 23, 30, 36, 43, 45, 46, 47, 51, 53, 54, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 71, 72, 75, 78, 81, 84, 90, 96, 116, 124, 137, 153, 160, 161, 164, 172, 173], "environment": [7, 13, 51, 56, 99, 112, 113, 121], "envis": [43, 58], "eo": [96, 98, 101], "eos_id": [104, 106], "eos_piec": [104, 106], "eos_token_id": [98, 101, 112], "eou": 80, "ep": [102, 142, 143, 153], "epc": [112, 113], "epel": 61, "epfl": 7, "ephem": 136, "epigenet": [112, 113], "epilepsi": [112, 113], "epoch": [46, 52, 100, 111, 112, 113, 114, 128, 129], "epsilon": [113, 148], "epu": [120, 138], "equ": 102, "equal": [10, 29, 84, 89, 112, 113, 116, 117, 127, 128, 137, 148, 155], "equat": [54, 112, 113, 127, 129, 133, 144, 146, 157], "equilibrium": 39, "equip": [43, 45, 51, 53, 78, 81, 90, 168, 171, 187], "equit": [89, 99], "equiti": [102, 129, 153], "equival": [10, 54, 106, 127, 133], "er": [102, 108, 109, 166, 170], "era": [3, 39, 57, 84, 112, 113], "erag": 108, "eras": 10, "erect": [112, 113], "erg": [102, 108], "eri": [102, 112, 113], "eric": 0, "erlich": [6, 131], "erna": 108, "ernest": [112, 113], "erod": [112, 113], "errico": [112, 113], "erron": 60, "error": [7, 9, 15, 17, 20, 21, 22, 43, 47, 54, 56, 60, 65, 66, 72, 89, 91, 94, 105, 106, 110, 112, 113, 116, 118, 125, 126, 131, 132, 146, 151, 152, 160, 161, 164, 168, 173, 176, 178, 185, 186], "ervi": 108, "ervic": 108, "escal": [51, 54, 165], "escap": [102, 106], "escape_whitespac": [104, 106], "escuela": [112, 113], "esd": 108, "esda": 108, "esdai": 109, "esearch": 121, "esg": [2, 15, 17, 18, 21, 22, 38], "esg_categories_20220905": 20, "esg_category_prediction_check": [17, 20], "esg_cv_polar": [17, 22], "esg_cv_polarity_d": 17, "esg_cv_polarity_data": 17, "esg_cv_top": [17, 22], "esg_cv_topic_data": 17, "esg_invalid": [17, 22], "esg_invalid_20220911": 22, "esg_invalid_cv_pr": 15, "esg_invalid_d": 17, "esg_invalid_data": 17, "esg_invalid_data_cv": 15, "esg_invalid_kr": [15, 17], "esg_invalid_kr_merg": 15, "esg_news_polarities_20220911": 22, "esg_news_polarity_20221229": 15, "esg_news_prediction_results_20221229": 15, "esg_news_topic_20221229": 15, "esg_news_topics_20220911": 22, "esg_news_valid_20220911": 22, "esg_news_valid_20221229": 15, "esg_polar": [15, 20, 23], "esg_polarities_20220905": 20, "esg_polarity_d": 21, "esg_polarity_data": 21, "esg_polarity_data_valid": 15, "esg_polarity_exist": 17, "esg_polarity_further_train": 15, "esg_polarity_kr": [15, 21], "esg_polarity_label": [15, 21], "esg_polarity_labels_valid": 15, "esg_polarity_prediction_check": 20, "esg_polarity_snorkel": 21, "esg_polarity_snorkel_data": 21, "esg_polarity_valid": [15, 17], "esg_prediction_data": 15, "esg_rubrix_topic_data": 17, "esg_top": [20, 23], "esg_topic_data": 21, "esg_topic_data_cv": 15, "esg_topic_data_cved_mreg": 15, "esg_topic_invalid_cv": 15, "esg_topic_invalid_merg": 15, "esg_topic_label": [15, 21], "esg_topic_label_error": 18, "esg_topic_labels_valid": 15, "esg_topic_valid": 15, "esg_topics_cv": 15, "esg_topics_cv_pr": 18, "esg_topics_exist": 17, "esg_topics_improv": [15, 18], "esg_topics_remap": 18, "esg_topics_valid": [15, 17], "esg_valid_polar": 17, "esg_valid_polarity_cv": 17, "esg_valid_polarity_data": 17, "esg_valid_polarity_kr": 17, "esg_valid_top": 17, "esg_valid_topic_d": 17, "esg_valid_topics_cv": 17, "esgml": [16, 18, 20], "esou": 108, "esour": 108, "esourc": 108, "especi": [10, 13, 39, 40, 47, 51, 53, 54, 60, 72, 98, 106, 107, 112, 113, 115, 117, 119, 127, 131, 136, 141, 144, 147, 148, 150, 152, 155, 156, 157, 158, 173], "esperanto": 96, "espous": [112, 113], "espresso": 148, "essai": [50, 85, 112, 113], "essenc": [43, 51, 112, 113, 117, 127, 134, 149], "essenti": [2, 8, 9, 11, 38, 39, 42, 43, 46, 47, 50, 56, 57, 58, 60, 65, 70, 72, 74, 76, 78, 79, 81, 82, 84, 89, 90, 94, 98, 99, 101, 106, 110, 112, 113, 114, 115, 116, 117, 118, 122, 123, 127, 128, 131, 132, 134, 135, 138, 139, 140, 143, 144, 145, 148, 149, 151, 157, 160, 167, 168, 173, 184], "est": [102, 107, 143], "establish": [7, 13, 14, 43, 54, 56, 64, 77, 79, 83, 90, 112, 113, 141, 170, 171, 173], "estim": [0, 9, 27, 28, 50, 54, 55, 89, 93, 102, 112, 113, 117, 121, 132, 134, 139, 146, 148, 152, 153, 168, 170], "estonian": 96, "et": [0, 7, 8, 53, 54, 72, 85, 96, 98, 99, 100, 102, 106, 107, 112, 113, 114, 116, 117, 118, 120, 121, 125, 126, 128, 129, 130, 146, 148], "et_al": 150, "eta": [133, 136, 137, 151, 152, 153, 182], "etc": [52, 65, 79, 81, 82, 98, 99, 100, 105, 106, 112, 113, 134, 135, 137, 141, 145, 146, 155, 160, 168], "etf": [102, 153], "ethic": [2, 5, 42, 46, 48, 51, 56, 60, 75, 87, 90, 93, 94, 99, 110, 112, 113, 171], "ethnic": [112, 113], "etl": 39, "etm": 142, "etn": 142, "etruscan": [112, 113], "etymolog": [112, 113], "eu": [96, 102, 140], "eugen": [0, 112, 113], "eugenia": 0, "eul": 131, "euro": 153, "eurocentr": [112, 113], "europ": [112, 113], "europarl": 94, "european": [112, 113, 141, 153], "ev": [112, 113], "eval": [15, 17, 18, 21, 23, 30, 31, 36, 52], "eval_accuraci": 111, "eval_batch_s": [15, 17, 18, 20, 23, 31], "eval_dataset": 111, "eval_loss": [15, 17, 18, 23, 31, 111, 113], "eval_pr": [52, 111], "eval_result": 113, "eval_runtim": [111, 113], "eval_samples_per_second": [111, 113], "eval_steps_per_second": [111, 113], "evalu": [5, 6, 7, 9, 10, 11, 15, 23, 38, 39, 47, 48, 54, 58, 64, 71, 72, 75, 76, 81, 84, 85, 86, 92, 96, 98, 99, 110, 111, 112, 113, 116, 123, 130, 131, 134, 136, 137, 143, 150, 151, 156, 159, 166, 168, 172, 173], "evaluate_classification_perform": 136, "evaluation_result": 111, "evan": 35, "evangel": [112, 113], "evapotranspir": [112, 113], "even": [2, 6, 7, 10, 11, 13, 43, 46, 50, 51, 57, 60, 62, 65, 77, 78, 89, 91, 93, 94, 98, 99, 101, 103, 107, 112, 113, 114, 116, 117, 119, 121, 123, 125, 126, 131, 133, 134, 137, 139, 140, 141, 143, 144, 146, 147, 148, 151, 153, 155, 156, 157, 160, 170, 172, 175], "evenli": 115, "event": [50, 74, 112, 113, 120, 131, 133, 135, 158], "event_timestamp": [15, 17, 18, 20], "eventu": [53, 112, 113, 151, 185], "ever": [3, 39, 78, 79, 89, 90, 91, 113, 137, 164, 170, 175], "everest": 101, "everett": 98, "evergreen": [112, 113], "everi": [11, 24, 53, 64, 77, 89, 108, 109, 112, 113, 116, 118, 122, 127, 129, 137, 140, 141, 152, 153, 155, 173, 186], "everybodi": [0, 25, 157], "everydai": [89, 112, 113], "everyon": [25, 72, 78, 99, 112, 113, 179], "everyth": [4, 62, 73, 89, 109, 137, 181], "everython": 89, "everywher": [4, 157], "evid": [3, 94, 112, 113, 120, 121, 141, 151], "evidenc": 120, "evil": [112, 113, 151], "eviron": [25, 26, 27, 28, 31, 32, 33, 34, 35, 36], "evolut": [8, 38, 51, 53, 57, 65, 75, 98, 112, 113, 152, 160, 165, 166, 173], "evolutionari": [98, 112, 113, 165, 172], "evolv": [3, 6, 7, 12, 47, 50, 51, 53, 54, 55, 56, 57, 58, 60, 63, 70, 78, 79, 84, 90, 123, 131, 152, 163, 164, 166, 167, 172, 173], "ex": [102, 175], "exacerb": [56, 94, 112, 113], "exact": [113, 118, 133, 145, 148, 151, 155, 156, 157, 179], "exactli": [15, 17, 18, 23, 98, 111, 115, 127], "exam": [48, 86], "examin": [39, 42, 48, 57, 95, 98, 112, 113, 114, 117, 121, 143, 152, 156, 157, 173], "exampl": [9, 10, 13, 31, 42, 46, 47, 50, 53, 60, 61, 62, 65, 66, 68, 70, 72, 74, 77, 78, 80, 81, 93, 94, 96, 98, 99, 100, 101, 102, 103, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 129, 131, 135, 137, 138, 139, 140, 141, 144, 145, 146, 148, 149, 151, 152, 154, 156, 157, 158, 160, 161, 168, 169, 173, 176, 177, 178, 181, 182, 183, 186], "example_id": [15, 23], "excav": [112, 113], "exce": [11, 98], "exceed": [112, 113], "exceedingli": [112, 113], "excel": [7, 9, 41, 42, 43, 47, 50, 54, 56, 60, 77, 86, 99, 116, 117, 124, 137, 149], "except": [3, 11, 58, 109, 112, 113, 117, 129, 140, 153, 155, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "exception": 117, "excess": [60, 131], "exchang": [78, 79, 123], "excis": [112, 113], "excit": [6, 12, 57, 89, 98, 131, 155], "exclam": [118, 141], "exclud": [15, 89, 96, 112, 113, 115, 117, 151, 156], "exclus": [112, 113, 117], "excus": 137, "exec": 61, "execut": [2, 44, 45, 47, 58, 60, 62, 66, 72, 77, 81, 82, 90, 112, 113, 115, 142, 161, 164, 166, 170, 172, 173], "exemplar": 185, "exemplari": [112, 113], "exemplifi": [3, 45, 47, 57, 112, 113], "exercis": [112, 113, 186], "exet": [112, 113], "exhaust": 172, "exhibit": [12, 45, 50, 56, 60, 112, 113], "exil": [112, 113], "exist": [2, 3, 6, 7, 10, 39, 47, 52, 54, 56, 57, 60, 64, 65, 66, 70, 77, 78, 85, 89, 90, 94, 102, 112, 113, 121, 122, 124, 131, 145, 157, 160, 161, 164, 165, 166, 167, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186], "exist_ok": [124, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "existing_data": 17, "existing_polarity_data": 17, "exit": [4, 82, 112, 113, 153, 167, 186], "exmapl": [15, 17, 18, 20, 21, 22, 23], "exmoor": 179, "exogen": 120, "exorbit": 50, "exp": [9, 102, 133], "expand": [6, 51, 53, 54, 60, 92, 96, 112, 113, 131, 149, 173], "expans": [46, 50, 53, 112, 113, 131], "expec": 108, "expect": [5, 6, 7, 15, 17, 18, 23, 38, 46, 47, 51, 55, 56, 72, 74, 90, 92, 99, 102, 106, 107, 111, 112, 113, 116, 118, 129, 131, 144, 148, 151, 152, 153, 156, 158, 165, 168, 172, 173, 181], "expedit": [112, 113], "expel": [112, 113], "expenditur": 120, "expens": [7, 47, 50, 51, 53, 58, 60, 89, 93, 94, 99, 101, 102, 112, 113, 116, 127, 129, 131, 135, 137, 139, 152, 164, 168, 171, 173], "experi": [1, 4, 7, 45, 50, 51, 53, 55, 57, 70, 71, 72, 76, 80, 81, 86, 90, 92, 93, 97, 98, 101, 112, 113, 117, 118, 121, 131, 137, 162, 170, 181, 182], "experienc": [57, 112, 113, 137], "experiment": [7, 56, 66, 72, 101, 161], "experimentalist": 7, "expert": [41, 54, 60, 75, 86, 112, 113, 131, 137, 167, 173], "expertis": [13, 46, 60, 65, 72, 89, 90, 92, 94, 99, 131, 160, 164, 167, 168, 170, 173], "expir": 129, "explain": [7, 13, 42, 51, 52, 54, 60, 69, 80, 83, 86, 99, 110, 112, 113, 116, 117, 120, 121, 129, 131, 137, 141, 148, 149, 152, 168, 171], "explan": [1, 15, 17, 18, 20, 41, 43, 46, 68, 89, 99, 112, 113, 117, 177], "explanatori": 165, "explicit": [11, 47, 53, 101, 106, 131, 152, 155, 157], "explicitli": [9, 10, 11, 18, 54, 74, 96, 106, 112, 113, 122, 131, 151, 171], "explod": [15, 16, 22, 53, 139], "explode_split": [16, 25], "exploit": [39, 54, 64, 78, 112, 113, 131], "explor": [0, 3, 4, 5, 6, 7, 9, 10, 38, 43, 45, 49, 50, 51, 54, 56, 58, 67, 68, 71, 77, 78, 81, 84, 88, 90, 91, 94, 95, 96, 98, 99, 100, 107, 112, 113, 115, 117, 118, 121, 131, 136, 137, 143, 152, 154, 156, 157, 162, 173], "exploratori": [2, 72, 94, 97], "explos": [60, 78, 117], "expon": 133, "exponenti": [0, 94, 106, 117, 129, 133, 144, 149], "export": [7, 13, 21, 46, 52, 61, 112, 113, 153], "export_annot": 21, "exporttyp": 21, "expos": [55, 62, 74, 78, 81, 107, 112, 113, 114, 120, 121, 167, 173], "exposur": [38, 112, 113, 120, 121], "express": [3, 7, 8, 24, 50, 56, 92, 96, 97, 98, 111, 112, 113, 117, 130, 131, 135, 136, 138, 140, 141, 143, 151, 155], "expresswai": [112, 113], "expuls": [112, 113], "ext": [16, 118], "extend": [7, 43, 47, 50, 51, 53, 54, 57, 58, 60, 65, 66, 67, 98, 106, 112, 113, 120, 127, 139, 142, 152, 153, 160, 161, 173], "extens": [3, 6, 7, 46, 47, 51, 53, 60, 61, 63, 66, 80, 89, 94, 96, 98, 110, 112, 113, 117, 120, 125, 139, 140, 144, 152, 153, 155, 161, 173], "extent": [45, 51, 53, 93, 112, 113, 117, 152], "extern": [43, 45, 51, 53, 56, 58, 73, 86, 92, 98, 112, 113, 131], "extinct": 4, "extra": [10, 46, 89, 112, 113, 133, 141, 151, 153, 176], "extract": [0, 1, 7, 8, 10, 13, 39, 42, 44, 52, 61, 72, 74, 92, 94, 96, 99, 101, 104, 106, 107, 112, 113, 117, 118, 119, 121, 122, 131, 136, 137, 139, 141, 145, 146, 147, 148, 149, 151, 152, 156, 166], "extract_arch": 18, "extractor": 8, "extran": 56, "extraordinarili": [112, 113], "extrem": [9, 11, 51, 86, 106, 112, 113, 127, 148, 151, 157, 172], "extrins": 133, "ey": [86, 112, 113, 157], "f": [15, 17, 20, 21, 22, 25, 27, 31, 33, 36, 68, 80, 81, 82, 95, 101, 102, 104, 105, 109, 111, 112, 113, 116, 124, 126, 129, 133, 137, 143, 153, 156, 158, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "f1": [15, 17, 23, 30, 31, 36, 52, 56, 75, 110, 131, 136, 137, 145], "f1_score": 136, "f3e88b4": 178, "f400fc7fc75fc9594a1731f6791aa0215fb1ead5": 185, "f5": [112, 113], "f6": 136, "f70a50493a56c656_": 113, "f9070a12dba861b399012944f966f08d40205281": 185, "f_": 120, "f_c": 156, "f_larg": 29, "f_small": 29, "f_tone": 34, "f_tone_data": 35, "f_w": 156, "f_wc": 156, "fa": [96, 102], "faa": 120, "fabric": [43, 112, 113], "fac": 102, "face": [2, 7, 9, 10, 13, 39, 43, 47, 48, 50, 60, 90, 94, 95, 97, 98, 101, 102, 104, 105, 108, 109, 111, 112, 113, 117, 120, 127, 135, 137, 140, 151, 153, 165, 168, 172], "facebook": [60, 99, 101, 117, 122, 135, 155], "facet": [2, 40, 45, 127, 168], "facetgrid": 27, "facial": [7, 51, 78, 112, 113], "facil": [112, 113], "facilit": [7, 39, 43, 45, 50, 51, 53, 54, 56, 58, 59, 60, 68, 78, 81, 84, 92, 99, 112, 113, 127, 152, 166, 172, 173], "fact": [11, 43, 50, 56, 72, 99, 102, 106, 112, 113, 116, 121, 127, 129, 131, 145], "factbook": 120, "faction": [112, 113], "facto": [112, 113], "factor": [13, 41, 50, 53, 60, 66, 78, 79, 89, 96, 100, 101, 112, 113, 118, 121, 122, 131, 133, 134, 137, 138, 139, 140, 148, 155, 156, 161, 172], "factori": [112, 113], "factual": [58, 85, 86, 99], "fade": [112, 113], "fai": [112, 113], "fail": [41, 107, 112, 113, 138, 148, 153, 157, 177, 178, 186], "failur": [56, 65, 66, 112, 113, 120, 160, 161, 167], "fair": [2, 13, 39, 42, 54, 60, 75, 90, 94, 99, 110, 131], "fairhop": [112, 113], "fairi": 4, "fairli": [115, 116], "faith": [17, 112, 113], "fake": [60, 85, 91, 99, 131], "fall": [29, 42, 85, 102, 112, 113, 120, 141, 153], "fallaci": [112, 113, 151], "fallen": [112, 113], "fals": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 46, 52, 60, 61, 78, 84, 86, 104, 112, 113, 124, 128, 129, 131, 144, 146, 150, 151, 153, 182], "famili": [2, 29, 47, 86, 87, 88, 112, 113, 121], "familiar": [38, 46, 47, 57, 70, 71, 76, 77, 81, 82, 88, 90, 98, 156], "famou": [3, 84, 100, 157], "famous": [112, 113], "fan": [112, 113, 178, 181, 182], "fanat": 151, "fanci": 119, "fangzhou": [0, 7], "fantasi": [4, 112, 113], "fantast": 179, "faq": [36, 170], "far": [54, 60, 96, 98, 112, 113, 117, 119, 157, 177], "fargo": [112, 113], "farm": [112, 113], "farmer": [89, 112, 113], "farmland": 13, "farthest": [112, 113], "fascin": [84, 127, 131], "fascism": [112, 113], "fascist": [112, 113], "fashion": 179, "fast": [7, 56, 96, 103, 106, 113, 122, 134, 142, 144, 146, 151, 167, 172, 178, 180], "fastaimodelartifact": 74, "fastapi": 73, "faster": [7, 50, 64, 65, 66, 72, 78, 89, 111, 112, 113, 121, 127, 129, 131, 151, 160, 161, 172, 173], "fasttext": [2, 127, 130, 139, 157], "fatal": [112, 113, 185], "father": [112, 113, 146], "fauna": [112, 113], "favor": [10, 60, 94, 98, 112, 113, 116, 137, 172], "favour": [112, 113], "favourit": 98, "fawr": [178, 181, 182], "fayett": [112, 113], "fb130a6169eb8f15_": 113, "fc52": 184, "fcdz04": 0, "fda": [112, 113], "fdd": 166, "fe": 102, "fear": [135, 153], "feasibl": [17, 47, 54, 90, 117, 133, 168], "feat": 140, "featherb": 156, "featur": [2, 6, 7, 8, 9, 10, 11, 13, 15, 23, 37, 38, 41, 47, 48, 50, 51, 60, 61, 63, 65, 66, 67, 68, 69, 72, 74, 76, 77, 89, 91, 94, 95, 103, 105, 106, 107, 111, 112, 113, 114, 117, 124, 125, 127, 131, 135, 138, 144, 145, 147, 149, 152, 157, 158, 160, 161, 168, 170, 171, 172, 173, 181, 187], "feature_build": [29, 34], "feature_extract": [137, 144, 151, 159], "featureset": 34, "februari": [112, 113, 130], "fed": [9, 10, 11, 26, 33, 53, 56, 113, 114, 117, 129, 153], "feder": [35, 39, 78, 79, 112, 113, 120, 121, 138], "federalist": [112, 113], "federalreserv": [24, 37], "fedfund": 35, "fedrat": 24, "fedu": 116, "fee": 177, "feed": [9, 41, 50, 53, 54, 72, 100, 112, 113, 114, 116, 117, 118], "feedback": [0, 2, 7, 10, 43, 50, 54, 56, 60, 64, 65, 66, 72, 75, 86, 92, 97, 112, 113, 131, 135, 160, 161, 167, 170, 171, 172, 173], "feeder": [112, 113], "feel": [47, 98, 112, 113, 131, 137, 156], "feet": 151, "fell": [112, 113, 153, 186], "felt": [112, 113, 137], "femal": [112, 113], "femin": [112, 113], "feminist": [112, 113], "feng": [0, 146], "fer": 102, "feral": [112, 113], "ferment": [112, 113], "fernando": [112, 113], "ferrer": [112, 113], "ferri": 168, "fertil": [112, 113], "festiv": [112, 113], "fetal": [112, 113], "fetch": [13, 22, 24, 69, 77, 113, 122, 124, 177, 178, 186], "fetch_20newsgroup": [150, 151], "fetch_builtin_corpu": 16, "fetcher": [22, 24, 25, 32, 35], "feudal": [112, 113], "fever": [93, 112, 113], "few": [3, 7, 48, 50, 52, 54, 56, 58, 66, 73, 98, 99, 110, 112, 113, 114, 115, 116, 118, 131, 137, 140, 145, 148, 152, 155, 161, 174, 175, 177, 183], "fewer": [10, 53, 66, 70, 94, 98, 112, 113, 118, 127, 131, 133, 134, 136, 151, 161], "ff": 102, "ffill": 35, "ffn": 53, "fi": [25, 96, 102, 105], "fiala": [112, 113], "fibroid": 137, "fica": [112, 113], "fiction": [112, 113, 175, 176], "fid": [10, 11], "fiddler": 60, "fidel": [7, 11], "fidler": [0, 7], "field": [3, 6, 7, 8, 9, 17, 39, 43, 50, 51, 53, 54, 55, 56, 60, 72, 77, 82, 84, 87, 89, 90, 92, 93, 94, 96, 97, 99, 112, 113, 114, 117, 119, 121, 123, 127, 130, 131, 142, 143, 144, 145, 151, 152, 153, 157, 158, 170], "field_tdr_date_valu": 24, "fieri": 18, "fifth": [112, 113], "fifti": [112, 113], "fig": [25, 150], "fight": [112, 113], "fight3r": 98, "figsiz": [15, 17, 18, 23, 24, 25, 26, 27, 28, 29, 32, 34, 95, 129, 137, 140, 150, 156], "figur": [7, 9, 13, 14, 15, 17, 18, 23, 24, 25, 26, 27, 28, 29, 32, 34, 95, 112, 113, 115, 120, 129, 137, 140, 156], "figure_format": [16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 115, 129, 146, 150, 151], "fil": [96, 102], "file": [1, 15, 16, 17, 18, 21, 22, 23, 25, 29, 31, 34, 39, 46, 52, 60, 61, 63, 67, 70, 71, 74, 77, 78, 79, 80, 81, 82, 83, 104, 106, 112, 113, 122, 124, 125, 136, 147, 151, 153, 174, 176, 179, 180, 181, 183, 184, 185, 186], "file_inv": 15, "fileid": 136, "filenam": [15, 16, 17, 20, 22, 31, 136, 151, 153, 180], "filepath": 31, "filesystem": 61, "filetyp": [18, 31], "filipino": 96, "fill": [9, 11, 27, 28, 53, 85, 89, 100, 108, 109, 116, 117, 118, 131, 153, 177, 179], "fillna": [18, 27, 28], "film": [7, 112, 113], "filmmak": [112, 113], "filosottil": 80, "filter": [10, 13, 25, 89, 94, 96, 98, 105, 118, 123, 139, 143, 144, 146, 147, 151], "filter_length": 25, "filtered_data": [15, 16, 20, 22], "filterwarn": 36, "fin": [102, 125], "final": [3, 8, 9, 10, 11, 38, 43, 52, 54, 56, 61, 69, 71, 88, 89, 91, 96, 98, 100, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 117, 118, 124, 128, 129, 131, 134, 137, 141, 143, 145, 148, 150, 151, 153, 154, 156, 168, 173, 178, 184, 185], "financ": [2, 39, 40, 42, 51, 102, 112, 113, 123, 131, 133, 153], "financi": [38, 39, 42, 49, 51, 72, 102, 108, 109, 110, 112, 113, 120, 121, 131, 133, 135, 137, 138, 165, 166, 168, 171], "financial_phrasebank": 31, "finbert": 32, "finbert_col": 36, "finbert_diffusion_minut": [31, 32, 33, 34, 35, 36], "finbert_diffusion_press_conf": [31, 32], "finbert_diffusion_speech": [31, 32, 34, 36], "finbert_diffusion_stat": [31, 32, 33, 34], "finbert_mean_minut": [31, 32], "finbert_mean_press_conf": [31, 32], "finbert_mean_speech": [31, 32], "finbert_mean_stat": [31, 32], "finbert_model": 31, "finbert_ton": [32, 33, 34], "find": [0, 1, 11, 17, 23, 37, 43, 44, 50, 54, 55, 56, 61, 63, 80, 89, 90, 94, 97, 98, 101, 102, 107, 108, 112, 113, 115, 116, 117, 120, 121, 131, 133, 139, 143, 145, 146, 148, 150, 151, 152, 156, 172, 173, 175, 178, 179, 182, 185], "find_corp_cod": 124, "find_dotenv": 124, "find_label_error": [15, 17, 18], "find_local_entropi": 146, "find_merg": 102, "find_speaker_of_sect": 25, "findabl": 39, "findal": [101, 150], "finder": 150, "findfont": 29, "findit": 102, "fine": [2, 7, 9, 10, 13, 15, 42, 48, 52, 54, 56, 58, 72, 76, 84, 85, 87, 89, 92, 94, 97, 98, 99, 100, 101, 107, 110, 112, 113, 116, 123, 131, 139, 145, 158], "finess": 115, "finetuin": [2, 97, 110], "finetun": [11, 46, 111, 118], "finger": 7, "fingerprint": [77, 78], "fingertip": 1, "finish": [17, 18, 23, 89, 98, 129, 173], "finit": [9, 140], "finn": [0, 136], "finnish": [96, 112, 113, 116], "fintech": 60, "fir": [102, 108], "fir57": 0, "fire": [17, 112, 113], "firebrand": 17, "firefli": 18, "firewal": [60, 153], "firm": [0, 50, 57, 112, 113, 121, 153, 172], "firmrisk_": 120, "first": [6, 7, 9, 10, 11, 24, 25, 27, 28, 50, 52, 53, 61, 73, 75, 77, 78, 81, 89, 90, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 121, 124, 125, 127, 128, 131, 133, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 156, 157, 159, 168, 174, 176, 177, 178, 179, 180, 182, 183, 185], "first_nam": 24, "firstli": [60, 139], "firth": [0, 157], "fiscal": [112, 113, 129, 153], "fish": [7, 47, 67, 100, 112, 113], "fishey": 9, "fit": [7, 21, 30, 36, 39, 42, 47, 57, 63, 65, 72, 74, 98, 102, 112, 113, 119, 137, 148, 151, 152, 153, 159, 160, 167, 168, 173], "fit_resampl": 137, "fit_transform": [137, 151, 159], "five": [7, 10, 112, 113, 116, 121, 136, 141, 166, 168], "fix": [2, 9, 10, 53, 64, 65, 66, 69, 72, 78, 89, 98, 106, 107, 112, 113, 115, 116, 117, 118, 121, 133, 134, 141, 144, 147, 152, 153, 158, 160, 161, 162, 167, 170, 172, 173, 181, 184, 187], "fixat": [112, 113, 115], "fixi": 60, "fl": [112, 113], "flag": [15, 23, 60, 62, 65, 80, 101, 104, 160, 174, 177], "flame": [0, 112, 113], "flaml": 36, "flan": 52, "flant5": 52, "flap": [112, 113], "flat": [112, 113], "flatten": [117, 127, 146], "flatter": 98, "flavor": 47, "flaw": [56, 98, 100], "flax": 9, "fled": [112, 113], "flexibl": [7, 9, 10, 43, 45, 46, 47, 51, 60, 61, 63, 70, 74, 75, 89, 107, 122, 127, 131, 152, 164, 167, 168, 170, 172, 173], "fli": 140, "flight": [112, 113], "flip": 129, "float": [26, 32, 89, 116, 125, 151, 153], "float64": 29, "floor": [127, 131], "flop": [89, 116, 151], "flora": [112, 113], "florenc": [112, 113], "florian": [0, 7], "florida": [112, 113], "flourish": [112, 113], "flow": [37, 53, 56, 89, 92, 115, 137, 153, 165, 166, 167, 171, 172, 173], "flowchart": [144, 171], "flower": [10, 17, 112, 113, 148], "fluctuat": [39, 51, 112, 113], "fluent": [85, 98, 99, 132, 140], "fluid": [7, 172], "fluiditi": 172, "fluoxetin": [112, 113], "fluvoxamin": [112, 113], "flux": [65, 112, 113, 160], "fly": [98, 106, 122, 140, 175], "flynt": [112, 113], "fma": [15, 23, 101], "fmri": [112, 113], "fmt": [26, 32, 137], "fn": [15, 17], "fname": 125, "fnc\ubd80\ubb38": 16, "fnielsen": 136, "fo": 102, "foam": [112, 113], "focal": [51, 89, 112, 113], "focu": [1, 8, 12, 48, 50, 51, 53, 56, 57, 60, 61, 66, 71, 75, 85, 88, 90, 94, 97, 98, 103, 104, 105, 106, 112, 113, 114, 115, 117, 123, 130, 131, 135, 151, 161, 168, 170, 172, 173, 187], "focus": [7, 9, 40, 42, 47, 49, 50, 51, 53, 54, 56, 60, 61, 63, 65, 67, 69, 72, 75, 77, 90, 92, 94, 96, 98, 101, 112, 113, 114, 117, 118, 121, 122, 123, 133, 135, 145, 148, 151, 154, 157, 160, 163, 164, 165, 167, 168, 170, 172, 173], "fol": 102, "folder": [1, 70, 174, 186], "foliag": [112, 113], "folk": 151, "follow": [1, 2, 5, 7, 10, 15, 23, 29, 43, 46, 47, 53, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 77, 78, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 125, 126, 127, 129, 131, 133, 134, 136, 140, 141, 142, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 172, 173, 174, 178, 179, 181, 182], "fomc": [0, 2, 13, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38], "fomc_": 31, "fomc_calendar": 24, "fomc_chunk": 25, "fomc_corpu": 25, "fomc_data": 25, "fomc_features_larg": 29, "fomc_features_smal": [29, 30], "fomc_finbert": 31, "fomc_meeting_script": [25, 31], "fomc_minut": 31, "fomc_sect": 25, "fomc_sent": [25, 31], "fomc_sent_senti": 31, "fomc_sent_sentiments_finbert": 31, "fomc_sent_sentiments_t5": 31, "fomc_sentiment_data": 31, "fomc_sentiment_finbert_next": 31, "fomc_sentiment_t5_next": 31, "fomc_t5": 31, "fomc_tone_data_finbert": [31, 32], "fomc_tone_data_lm": [31, 32, 33], "fomc_tone_data_merg": 32, "fomc_tone_data_t5": [31, 32], "fomc_tone_featur": [34, 36], "fomc_tone_finbert": 36, "fomc_tone_lm": 36, "fomc_tone_t5": 36, "fomc_tones_lm": 31, "fomc_train_ton": [34, 35], "fomccalendar": 37, "font": [29, 112, 113], "font_manag": 29, "fontsiz": [24, 25, 29], "fonttool": 137, "foo": 102, "food": [16, 47, 112, 113, 117, 144, 157], "foot": [7, 112, 113, 151], "footbal": [112, 113, 144, 152], "footer": [150, 151], "footprint": [39, 56, 61, 63, 99], "forc": [7, 16, 17, 18, 21, 23, 29, 31, 34, 60, 98, 112, 113, 114, 117, 134, 177], "force_download": [24, 25, 32, 35], "force_extract": 18, "forecast": [2, 13, 24, 25, 26, 27, 28, 32, 37, 38, 40, 41, 42, 114, 153], "forefront": 53, "foreground": 89, "foreign": [112, 113, 120, 146], "foreignrisk_": 120, "foreshadow": 120, "forest": [4, 13, 112, 113, 139], "forestri": [112, 113], "forg": 70, "forgeri": 78, "forget": [52, 175], "forgotten": 179, "fork": [2, 18, 71, 80, 162, 186, 187], "form": [0, 3, 6, 9, 13, 47, 50, 53, 54, 60, 78, 79, 89, 90, 97, 102, 105, 106, 107, 112, 113, 114, 115, 116, 117, 120, 123, 127, 130, 131, 134, 135, 140, 141, 143, 146, 147, 148, 150, 151, 153, 154, 156, 157, 164, 177, 179, 180], "formal": [48, 112, 113, 131, 165, 168, 172], "format": [7, 8, 9, 18, 23, 29, 42, 44, 46, 47, 56, 60, 65, 70, 72, 73, 74, 78, 79, 90, 98, 101, 102, 103, 104, 105, 107, 108, 109, 121, 122, 124, 127, 128, 129, 133, 139, 143, 151, 153, 160, 174], "format_word": 102, "formatted_warn": 31, "former": [10, 96, 112, 113, 137, 146, 153], "formerli": [112, 113, 142], "formid": [43, 54], "formul": [7, 13, 56, 58, 90, 112, 113, 169, 170], "formula": [98, 106, 107, 112, 113, 120, 121, 127, 134, 148, 158], "forrest": [112, 113], "fort": [112, 113], "forti": [112, 113], "fortinet": 83, "forum": [94, 112, 113, 121, 135, 170], "forward": [7, 37, 50, 53, 54, 77, 78, 89, 90, 111, 112, 113, 114, 115, 117, 118, 128, 129, 146, 178, 180], "fossil": [112, 113], "foster": [3, 38, 43, 60, 64, 65, 66, 72, 99, 112, 113, 160, 161, 172], "fought": [112, 113], "found": [9, 11, 16, 29, 34, 36, 46, 60, 70, 77, 85, 89, 90, 95, 98, 99, 101, 102, 104, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 137, 146, 152, 157, 185], "foundat": [8, 46, 47, 53, 55, 56, 61, 63, 65, 81, 84, 89, 90, 99, 112, 113, 122, 128, 131, 133, 134, 140, 148, 152, 155, 156, 160, 166, 170, 172], "founder": [60, 112, 113], "four": [4, 10, 39, 43, 65, 89, 105, 112, 113, 116, 117, 120, 148, 150, 151, 152, 153, 160, 172, 173, 180], "fourgram_model": 134, "fourth": [10, 89, 112, 113, 129], "fox": [112, 113, 116, 143, 145, 159], "fp": [7, 15, 17], "fp16": [52, 112, 113], "fr": 96, "frac": [9, 22, 100, 120, 125, 126, 129, 133, 144, 146, 148, 149, 158], "fraction": [11, 53, 72, 112, 113], "fractur": [112, 113], "fragil": [112, 113], "fragrant": 17, "frame": [7, 15, 16, 22, 117, 118, 168], "framework": [2, 7, 11, 13, 39, 45, 51, 54, 55, 57, 58, 65, 72, 73, 75, 81, 93, 99, 112, 113, 157, 160, 165, 167, 168, 170, 171, 173], "franc": [101, 112, 113, 153], "franchis": [112, 113], "francisco": [112, 113, 140], "francoi": 0, "fraud": [39, 112, 113], "fraudul": 50, "fred_api_kei": [31, 32, 33, 34, 35], "freddefrallan": 10, "free": [0, 2, 6, 8, 10, 50, 66, 89, 97, 98, 111, 112, 113, 117, 131, 140, 156, 161, 177], "freed": [112, 113], "freedmen": [112, 113], "freedom": [112, 113], "freeli": [78, 112, 113, 118, 122, 141], "freez": 118, "french": [47, 96, 112, 113, 116, 123, 131, 157], "freq": [102, 108, 109], "freq_dist": 140, "freqdist": 140, "frequenc": [9, 13, 14, 27, 41, 60, 95, 102, 104, 107, 108, 109, 112, 113, 120, 121, 125, 131, 134, 139, 140, 144, 147, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159], "frequent": [11, 13, 14, 43, 47, 56, 66, 94, 102, 104, 106, 107, 108, 109, 112, 113, 120, 121, 127, 129, 133, 137, 138, 139, 140, 141, 143, 144, 148, 151, 154, 158, 161, 165, 172, 173], "fresh": [17, 112, 113, 115, 133], "freshli": [112, 113], "freshwat": [112, 113], "fresnel": [112, 113], "fridai": 129, "friend": [112, 113], "friendli": [1, 60, 63, 70, 74, 77, 89, 96, 112, 113, 124, 127], "friendship": [112, 113], "fring": [112, 113], "frisian": 96, "from": [0, 2, 3, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 69, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 127, 128, 129, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 172, 173, 174, 175, 176, 177, 178, 180, 182, 184, 185, 186, 187], "from_dat": [24, 33], "from_fil": [104, 112, 113], "from_pretrain": [52, 98, 101, 105, 111, 112, 113, 115], "from_word": 150, "from_year": [24, 25, 32, 35], "front": [60, 112, 113, 117], "frontend": [61, 70, 182], "frontier": [56, 99, 112, 113, 119], "frost": 17, "frozen": [11, 47, 50, 53, 112, 113], "frugal": 36, "fruitcak": 151, "frustrat": 137, "fs_cfg": [30, 36], "fs_fomc": 30, "fsdp": 84, "fsdp_config": 52, "fsl": 101, "ftp": [78, 122, 151], "ftse": 153, "fu": [0, 102], "fucntion": 21, "fuel": [15, 112, 113, 153], "fugashi": 142, "ful": 140, "full": [2, 4, 7, 10, 26, 46, 47, 50, 53, 54, 58, 66, 77, 78, 82, 89, 94, 100, 112, 113, 117, 121, 127, 129, 141, 151, 153, 155, 161, 173, 176, 186], "full_matric": 151, "fullest": 53, "fulli": [40, 47, 53, 86, 89, 113, 114, 117, 118, 127, 128, 129, 135, 140, 146, 151, 172, 173], "fullnam": 18, "fun": [102, 129], "func": [18, 25], "function": [0, 8, 9, 10, 11, 16, 17, 20, 22, 23, 25, 29, 31, 34, 45, 47, 48, 50, 53, 55, 58, 60, 61, 63, 65, 66, 70, 72, 78, 81, 83, 85, 89, 91, 96, 98, 100, 102, 105, 106, 108, 109, 111, 112, 113, 114, 115, 117, 124, 125, 126, 127, 131, 134, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 156, 160, 161, 167, 168, 170, 171, 172, 173, 179], "functool": [16, 17, 20, 21, 22, 25, 29, 31, 34, 35], "fund": [35, 102, 112, 113, 134, 153], "fundament": [7, 38, 50, 51, 53, 57, 78, 81, 97, 130, 131, 134, 146, 147, 154, 158, 168, 169, 172, 173], "fundamentalist": [112, 113], "funsd": 52, "furnitur": [112, 113], "further": [7, 9, 10, 50, 51, 53, 60, 77, 78, 86, 90, 94, 97, 98, 101, 104, 105, 110, 111, 112, 113, 114, 117, 118, 121, 124, 129, 130, 131, 141, 148, 151, 153, 157, 173], "furthermor": [7, 9, 10, 39, 60, 78, 81, 87, 94, 97, 103, 130, 140], "fuse": 4, "fusiform": [112, 113], "fusion": [3, 55, 112, 113], "futur": [0, 2, 4, 7, 9, 23, 37, 39, 43, 53, 56, 76, 79, 84, 89, 90, 97, 98, 99, 111, 112, 113, 117, 121, 133, 153, 164, 168, 173, 177], "futurewarn": [29, 31, 111, 113], "futurist": [4, 112, 113], "fuzzi": 80, "fx": 182, "fy": [96, 112, 113], "fzf_default_opt": 80, "g": [0, 1, 6, 9, 13, 15, 17, 18, 20, 21, 22, 23, 33, 46, 54, 56, 61, 65, 66, 68, 76, 78, 79, 81, 83, 89, 98, 100, 101, 102, 106, 109, 111, 112, 113, 116, 118, 121, 124, 131, 133, 134, 138, 139, 140, 143, 144, 147, 148, 149, 153, 154, 157, 160, 161, 168, 171, 172, 175, 176, 178, 182], "g1490fd9": 29, "g3d56094": 16, "g69734d6": [25, 32, 33, 34, 35], "g8433774": [24, 26, 27, 28], "g90d1dea": [31, 36], "ga": [15, 96, 102, 112, 113], "gabriel": 0, "gad": [112, 113], "gade": 60, "gadsden": [112, 113], "gaelic": 96, "gai": [112, 113], "gain": [6, 7, 13, 42, 47, 51, 60, 76, 78, 90, 97, 102, 110, 112, 113, 115, 116, 117, 119, 129, 131, 135, 150, 151, 153, 162, 173], "gainer": 102, "galacticentr": 151, "galaxi": [17, 65, 160], "galician": 96, "galleanist": [112, 113], "galleri": 3, "galleria": [112, 113], "game": [6, 7, 43, 54, 55, 98, 112, 113, 131, 134, 137], "gan": [6, 7, 12, 131], "gantt": 171, "gap": [11, 45, 50, 53, 60, 64, 66, 74, 101, 112, 113, 131, 161], "garcilaso": [112, 113], "garden": [4, 118, 148], "gari": [0, 7, 112, 113], "garner": 53, "garrison": [112, 113], "gase": 4, "gasif": 15, "gasolin": 150, "gastrointestin": [112, 113], "gate": [50, 53, 131, 139], "gatewai": [78, 83], "gather": [13, 44, 56, 89, 112, 113, 117, 121, 122, 157, 166, 170], "gating_factor": 53, "gaug": [13, 51, 56, 138], "gaussian": [10, 96, 133], "gave": [112, 113, 117], "gaze": [112, 113], "gb": [53, 118], "gbm": 13, "gca": 156, "gd": 96, "gdmrmodel": 153, "gdp": [13, 14, 24, 26, 27, 28, 35, 112, 113], "gdp_diff_prev": [24, 26, 27, 28, 29, 30, 34, 36], "gdp_diff_year": [26, 27, 28, 29], "gdpc1": 35, "gdpdef": 35, "gdppot": [24, 26], "gdppot_diff_prev": [26, 27, 28, 29], "gdppot_diff_year": [26, 27, 28, 29], "gdpr": [60, 75, 94], "ge": 102, "gear": 89, "geb12c43": 30, "geda": 0, "gelbukh": 130, "gelli": 0, "gelu": [53, 113], "gen": [80, 102], "gender": [89, 99, 112, 113, 121, 141], "gene": [112, 113, 151], "gener": [0, 2, 3, 9, 10, 12, 13, 14, 29, 41, 43, 45, 46, 47, 48, 49, 52, 53, 54, 59, 62, 72, 73, 77, 78, 79, 81, 84, 86, 88, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 106, 110, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 125, 127, 129, 130, 134, 137, 139, 140, 141, 144, 145, 148, 149, 150, 151, 152, 153, 155, 165, 166, 168, 170, 177, 182, 183], "general_funct": 31, "generalist": 0, "generaliz": [51, 55, 120], "generate_chain_of_thought": 101, "generate_sent": 134, "generate_speech": 73, "generate_text": [73, 112], "generated_text": [101, 112], "genet": [8, 112, 113], "geneticist": [112, 113], "genom": [112, 113], "genotyp": [112, 113], "genr": [3, 94], "gensim": [13, 148, 150], "gentl": [17, 112, 113], "genuin": 2, "geo": [83, 121], "geochemistri": [112, 113], "geograph": [13, 89, 112, 113, 121], "geographi": [101, 112, 113], "geolog": [112, 113], "geometr": [7, 89, 112, 113], "geometri": [7, 112, 113], "geonam": 120, "georg": [0, 112, 113], "georgia": [112, 113, 134], "georgian": 96, "geq": 146, "ger": 102, "gerard": 0, "german": [96, 99, 112, 113, 116, 118, 123, 140], "germani": [0, 153], "gesehen": 140, "gestur": [112, 113], "get": [1, 4, 17, 18, 21, 25, 55, 65, 72, 80, 81, 82, 89, 90, 98, 100, 102, 112, 113, 116, 120, 124, 125, 129, 133, 134, 137, 138, 140, 141, 142, 144, 151, 156, 160, 172, 174, 176, 177, 178, 184, 185, 186], "get_bigram_count": 102, "get_coherence_per_top": 150, "get_feature_import": 30, "get_feature_names_out": 151, "get_group": 21, "get_irf": 35, "get_peft_config": 52, "get_peft_model": 52, "get_scor": 153, "get_text": 124, "get_tokens_from_vocab": 102, "get_topic_dist": 153, "get_topic_word": 153, "get_topic_word_dist": 153, "get_vocab_s": 112, "get_word_emded": 129, "get_workspac": [18, 20], "getcwd": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "getent": 82, "ggplot": 150, "gh": [70, 102], "ghani": 0, "ghe": 108, "gher": 108, "ghlight": 108, "ghost": [112, 113], "ght": 102, "gi": [102, 113], "giac": [112, 113], "giant": [94, 153], "gib": [104, 122, 131], "gibb": 153, "gibberish": 98, "gic": 102, "gid": 82, "giddi": 17, "gif": 151, "gil": 122, "gimenez": 0, "ging": 102, "ginosar": [0, 7], "giraff": 101, "giraudi": 0, "girl": [4, 112, 113], "git": [2, 65, 66, 67, 68, 69, 70, 71, 72, 76, 80, 81, 82, 160, 161, 162, 168, 170, 176, 179, 181, 183, 184, 186, 187], "git_dir": [175, 178, 180, 181, 182, 183, 185, 186], "git_exampl": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "git_example_dir": [174, 176, 177], "github": [2, 10, 11, 25, 30, 31, 36, 46, 50, 60, 61, 65, 66, 67, 70, 71, 76, 80, 89, 129, 131, 137, 146, 153, 160, 161, 162, 170, 181, 182, 185, 187], "gitignor": 182, "gitlab": [65, 66, 70, 77, 160, 161], "gitop": [2, 66, 71, 161, 162], "give": [10, 53, 54, 60, 102, 107, 112, 113, 114, 117, 131, 133, 137, 140, 145, 150, 157, 158, 159, 168, 170, 172, 177, 179], "given": [6, 7, 9, 10, 11, 12, 21, 36, 39, 43, 45, 47, 51, 52, 53, 54, 60, 87, 89, 90, 91, 93, 94, 98, 99, 100, 101, 102, 103, 106, 107, 108, 110, 112, 113, 114, 115, 116, 117, 120, 121, 125, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 144, 145, 146, 148, 151, 152, 153, 154, 155, 156, 157, 168, 180], "gl": [70, 96, 112, 113], "glacier": [112, 113], "glanc": 98, "glass": [4, 89, 131], "glassdoor": 121, "glean": 47, "gli": 140, "glid": [6, 131], "glide": 11, "glimps": 99, "glint": [112, 113], "glitter": [17, 126], "global": [0, 10, 55, 77, 89, 98, 102, 112, 113, 120, 126, 133, 153, 155, 174, 175], "global_step": [17, 18, 23, 111, 113], "globalis": [112, 113], "globalrisk_": 120, "globe": [112, 113, 120], "glottal": [112, 113], "glove": [2, 100, 125, 127, 130, 139, 157], "glue": [52, 100, 118, 123], "gluten": [112, 113], "glyder": [178, 180, 181, 182], "glyph": [112, 113], "gmail": 141, "gn": 102, "gnu": [67, 80, 182], "gnupg": 80, "go": [54, 56, 68, 77, 80, 98, 102, 105, 111, 112, 113, 118, 127, 131, 137, 141, 156, 176, 177, 178, 179, 183, 186], "goal": [2, 7, 10, 43, 45, 53, 56, 60, 61, 64, 65, 66, 86, 89, 90, 92, 93, 98, 101, 103, 105, 107, 112, 113, 117, 118, 121, 135, 139, 148, 149, 151, 152, 160, 161, 168, 170, 171, 173], "god": [112, 113, 121, 151], "godwin": [112, 113], "goe": [102, 146], "gold": [102, 116, 126, 131, 153], "goldberg": 137, "golden": [112, 113], "goldman": [112, 113, 153], "goldp": 116, "golf": [112, 113, 137], "golovin": 0, "gomez": 0, "gon": [0, 7], "gondola": 4, "gone": [112, 113, 141], "gong": 0, "gonzalez": 0, "goo": 102, "good": [2, 13, 25, 53, 54, 63, 65, 68, 73, 78, 79, 81, 94, 102, 111, 112, 113, 116, 118, 121, 127, 131, 133, 134, 137, 138, 139, 141, 142, 153, 156, 158, 160, 177, 178, 179, 180, 184, 185], "goodfellow": 6, "goodman": [112, 113], "goodyear": [112, 113], "googl": [3, 6, 10, 11, 13, 18, 22, 25, 32, 33, 34, 35, 43, 50, 52, 54, 60, 65, 67, 71, 72, 81, 90, 94, 99, 101, 106, 107, 111, 112, 113, 116, 117, 124, 131, 140, 144, 153, 155, 160, 174, 175, 176, 178, 180, 181, 182, 183, 185, 186], "googler": 140, "googlif": 140, "googlifi": 140, "gop": [112, 113], "gopher": 99, "gordon": [0, 7], "gorri": [112, 113], "gospel": [112, 113], "got": [18, 137, 184], "gothic": [112, 113], "gov": [24, 37], "govern": [4, 13, 60, 72, 86, 112, 113, 120, 134, 152, 153], "government": [13, 60], "governor": [112, 113], "goyal": 100, "gpdic1": 35, "gpg": [2, 67, 71, 79, 80, 81], "gpgsign": 77, "gpt": [2, 9, 10, 13, 43, 45, 46, 47, 48, 50, 53, 54, 56, 60, 75, 84, 87, 88, 93, 94, 98, 99, 101, 105, 110, 112, 118, 122, 123, 139, 147], "gpt2": [52, 98, 101, 105, 112], "gpt2_log": 112, "gpt2_token": 112, "gpt2_uncas": 112, "gpt2config": 112, "gpt2lmheadmodel": [101, 112], "gpt2token": [98, 101, 112], "gptengin": [43, 45], "gptzero": 91, "gpu": [7, 15, 46, 52, 53, 60, 75, 84, 89, 98, 111, 113, 151, 153], "gqa": 60, "gr": 102, "gra": [112, 113], "grace": 140, "grad": 102, "grade": [47, 50, 53, 72, 112, 113], "gradient": [9, 10, 11, 13, 46, 50, 52, 53, 74, 89, 110, 113, 117, 129, 139, 152], "gradient_accumul": 46, "gradient_accumulation_step": 52, "gradient_checkpoint": [52, 113], "gradient_clip": 52, "gradio": [2, 52, 71, 75], "gradual": [10, 53, 89, 97, 112, 113, 118, 121, 130, 173], "graduat": [112, 113], "grafana": [65, 66, 71, 72, 160, 161], "grain": [7, 112, 113, 145, 153, 158], "gram": [2, 50, 96, 98, 115, 121, 130, 132, 134, 137, 139, 140, 146, 147, 155, 157], "grammar": [54, 94, 99, 112, 113, 131, 132, 139, 140, 145], "grammat": [54, 56, 112, 131, 136, 137, 138, 139, 140, 145, 158], "grandin": [112, 113], "granduri": 0, "grant": [50, 78, 82, 84, 94, 112, 113, 122], "granular": [13, 54, 56, 107, 170], "graph": [7, 39, 55, 56, 99, 117, 178, 179, 181, 182, 184], "graphic": [0, 6, 7, 60, 98, 112, 113, 118, 145, 151], "grappl": 39, "grasp": [56, 81, 135, 180], "grass": [112, 113, 137], "grassroot": [112, 113], "grave": 0, "graviti": 120, "gre": 102, "great": [67, 91, 102, 112, 113, 117, 137, 175, 178, 184], "greater": [2, 10, 11, 43, 54, 66, 89, 91, 98, 112, 113, 117, 161, 173], "greatest": [112, 113, 131, 152], "greatli": [2, 112, 113, 117, 139, 141, 145, 155], "greatly_appreci": 150, "greec": [112, 113, 120], "greedi": 146, "greedili": 98, "greedy_output": 98, "greek": [2, 96, 112, 113, 116], "green": [1, 33, 112, 113, 133, 148, 156, 159, 177, 179], "greenhous": [112, 113], "greenspan": [24, 31, 32], "greet": [112, 113], "greg": 0, "grep": 61, "gretel": 60, "grew": [112, 113], "grid": [9, 26, 27, 33, 89], "griffith": 0, "groceri": [112, 113], "gross": [112, 113], "grossli": [112, 113], "ground": [47, 89, 99, 112, 113], "groundbreak": [8, 84, 89, 114, 117], "groundwork": [140, 166], "group": [7, 21, 43, 56, 60, 65, 66, 81, 84, 88, 96, 99, 102, 109, 112, 113, 120, 121, 127, 138, 139, 144, 149, 151, 153, 160, 161, 164, 170, 171], "group_text": 112, "groupbi": [21, 31], "groupchat": 43, "grow": [11, 42, 51, 56, 78, 85, 90, 94, 102, 112, 113, 117, 119, 121, 123, 131, 149, 152, 153, 164, 165, 172], "grown": [50, 94, 143], "growth": [27, 28, 35, 39, 54, 56, 66, 94, 102, 112, 113, 152, 153, 161], "grpc": 61, "gru": [131, 139], "grunya": [112, 113], "gt": 21, "gth": 108, "gu": [96, 102], "guanaco": 46, "guarante": [98, 134, 139, 151, 152], "guard": 80, "guardian": [13, 14], "guardrail": 60, "gubernatori": [112, 113], "guerrilla": [112, 113], "guess": 151, "gui": [0, 7, 102, 137], "guid": [9, 10, 11, 13, 43, 44, 46, 47, 51, 53, 54, 58, 60, 61, 62, 65, 70, 76, 82, 83, 89, 90, 93, 101, 111, 112, 113, 117, 120, 137, 160, 167, 168, 170, 172, 173], "guidanc": [2, 8, 10, 37, 50, 53, 90, 173], "guidelin": [2, 42, 54, 78, 84, 90, 112, 113, 122, 162, 165, 167, 169], "guilti": 138, "gujarati": 96, "gulf": [112, 113, 120], "gumbel": 9, "gump": 109, "gun": [112, 113], "guntersvil": [112, 113], "guo": [0, 7], "gustav": [112, 113], "gut": [112, 113], "gutenberg": 140, "gv80\uac00": 22, "gvisor": 61, "gy": 102, "gyn": 137, "gz": 136, "gzz": [0, 7], "h": [0, 7, 10, 53, 89, 102, 106, 109, 112, 113, 125, 130, 133, 134, 143, 146, 147, 151, 152, 153], "h1": 151, "h2o": 72, "h2omodelartifact": 74, "h_1": 127, "ha": [2, 3, 6, 7, 9, 10, 11, 18, 24, 37, 40, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 58, 60, 63, 64, 65, 70, 72, 77, 78, 79, 84, 86, 87, 89, 90, 91, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 127, 128, 129, 130, 131, 133, 134, 135, 137, 138, 139, 140, 141, 142, 145, 146, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 167, 170, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186], "habitat": [112, 113], "hacktivist": [112, 113], "had": [3, 40, 89, 101, 112, 113, 121, 131, 134, 137, 141, 184], "hadamard": 52, "haddow": 0, "hadlei": [112, 113], "hadoop": 39, "hagu": [112, 113], "hai": 153, "hail": [112, 113, 134], "haitian": 96, "hal": 102, "halax": 98, "haleyvil": [112, 113], "half": [112, 113, 146], "halko": 151, "hallucin": 43, "ham": [133, 159], "hammer": 131, "hamp": 109, "hamper": [112, 113], "han": [0, 112, 113, 117], "hand": [1, 7, 10, 43, 46, 47, 48, 50, 51, 54, 60, 63, 67, 76, 77, 93, 94, 97, 98, 101, 103, 106, 107, 112, 113, 116, 117, 122, 127, 129, 138, 143, 152, 157, 159, 162, 173, 179], "handl": [2, 7, 9, 10, 11, 13, 40, 41, 42, 43, 54, 55, 56, 58, 60, 72, 74, 75, 77, 78, 84, 89, 92, 94, 98, 103, 104, 105, 106, 107, 111, 112, 113, 117, 123, 127, 131, 134, 135, 137, 139, 140, 149, 154, 166, 173], "handle_chinese_char": 113, "handler": [65, 160], "handwash": [112, 113], "handwrit": [70, 112, 113], "handwritten": [112, 113], "hang": 153, "hangout": [112, 113], "hansard": 131, "hansen": [0, 121], "haodi": 0, "hapk": [112, 113], "happen": [25, 46, 51, 64, 111, 112, 113, 127, 131, 137, 138, 151, 157, 175, 176, 179], "happi": [131, 135, 138, 179], "har": [46, 47, 50, 51, 52, 53, 57, 75, 102], "har54": 0, "har70": 0, "haralson": [112, 113], "harass": [112, 113], "harbert": [112, 113], "harbor": [143, 153], "hard": [13, 14, 42, 112, 113, 119, 141, 143, 151, 153, 175, 176, 180], "hard_vocab_limit": [104, 106], "harder": [112, 113, 141, 148, 155, 165], "hardi": 17, "hardli": [112, 113], "hardship": [112, 113, 121], "hardwar": [7, 46, 50, 51, 53, 60, 78, 79, 90, 98, 111, 113, 153, 164, 168, 170, 171], "hardwork": 121, "hare": [112, 113], "harm": [54, 60, 86, 87, 93, 99, 112, 113, 131], "harmon": [39, 56], "harmoni": [4, 112, 113], "harmonica": [112, 113], "harold": 6, "harp": [112, 113], "harri": [0, 146, 157], "harrison": 60, "harsh": [112, 113], "harvard": [97, 130], "harvei": [112, 113], "harvest": 50, "hash": [78, 79, 116, 125, 176, 180, 182, 184], "hashicorp": [65, 66, 160, 161], "hashingvector": 144, "hasn": [8, 10, 89, 113], "hassan": [0, 120], "hat": [66, 100, 112, 113, 127, 161], "hate": [112, 113, 128, 152], "hausa": 96, "have": [3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 21, 25, 29, 31, 35, 38, 43, 45, 46, 50, 51, 52, 53, 54, 57, 58, 60, 62, 64, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 139, 140, 141, 144, 145, 146, 148, 150, 151, 152, 153, 155, 156, 157, 158, 164, 165, 168, 172, 174, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186], "haven": [114, 140, 143, 181, 186], "haw": 96, "hawaii": [112, 113], "hawaiian": 96, "hayden": [0, 7], "hayn": 0, "haze": [17, 18], "hdp": 153, "hdpmodel": 153, "he": [100, 102, 106, 109, 112, 113, 117, 131, 134, 137, 140, 153], "head": [9, 10, 11, 15, 17, 20, 21, 22, 26, 27, 28, 29, 31, 34, 53, 68, 69, 73, 89, 110, 111, 112, 113, 115, 133, 137, 150, 175, 178, 180, 181, 182, 184, 185], "head_view": 115, "header": [22, 150, 151], "headlin": [102, 108, 109], "headquart": [112, 113, 120], "heal": 102, "health": [13, 50, 78, 99, 102, 112, 113, 131, 137, 146], "healthcar": [49, 51, 60, 112, 113, 120, 123, 131], "healthi": [72, 146], "hear": [112, 113, 117, 140], "heart": [4, 50, 51, 53, 93, 112, 113, 148], "heat": [112, 113], "heatmap": [26, 32, 137], "heatmap2": 26, "heavi": [112, 113], "heavier": 116, "heavili": [7, 54, 55, 66, 78, 93, 94, 112, 113, 138, 139, 147, 161], "hebrew": 96, "hedg": 153, "height": [11, 27, 80, 112, 113, 137, 157], "heighten": 13, "heightmap": 7, "heigold": 0, "heinrich": [112, 113], "hel": 106, "held": [110, 112, 113, 120, 131], "helium": 4, "hell": 106, "hello": [70, 105, 106, 147], "hello_world": 147, "helm": [65, 66, 160, 161], "help": [1, 8, 10, 11, 13, 25, 39, 46, 51, 53, 57, 60, 61, 62, 64, 65, 66, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 89, 90, 94, 97, 98, 99, 101, 103, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 127, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 144, 145, 147, 148, 149, 151, 152, 153, 158, 160, 161, 167, 172, 173, 178, 182, 184], "helpdesk": 170, "helper": [7, 137, 151], "helvellyn": [177, 178, 180, 181], "hemispher": [112, 113], "henc": [112, 113, 127], "heng": 0, "henri": [112, 113], "her": [101, 102, 112, 113, 131], "herald": 120, "herb": [47, 112, 113], "herbert": [112, 113], "herbivor": 4, "here": [9, 24, 31, 37, 43, 52, 65, 66, 69, 70, 72, 74, 77, 89, 94, 98, 99, 101, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 121, 127, 133, 134, 137, 140, 141, 142, 143, 144, 145, 147, 148, 150, 152, 153, 154, 156, 158, 160, 161, 174, 176, 177, 178, 183], "herit": [112, 113], "heritag": [112, 113], "hernando": [112, 113], "herzenstein": 0, "hessian": 85, "heterogen": [39, 112, 113, 120], "heterosex": [112, 113], "heterosexu": [112, 113], "heurist": [118, 135, 136, 138, 151], "hf_token": 46, "hf_xxx": 46, "hfr": 16, "hg": [174, 186], "hhvlt19": 0, "hi": [96, 98, 102, 112, 113, 118, 131, 137, 151, 153, 178], "hidden": [0, 67, 89, 98, 113, 116, 127, 128, 139, 145, 152], "hidden1": 128, "hidden2": 128, "hidden3": 128, "hidden_act": 113, "hidden_dropout_prob": 113, "hidden_lay": 129, "hidden_s": 113, "hideout": [112, 113], "hierarch": [12, 112, 113, 127, 138, 139, 145, 149, 153], "hierarchi": [10, 112, 113, 138], "hieroglyph": [112, 113], "high": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 26, 39, 42, 43, 46, 47, 53, 54, 56, 57, 60, 63, 66, 72, 74, 75, 78, 81, 86, 89, 90, 91, 93, 96, 98, 99, 101, 102, 107, 108, 110, 112, 113, 115, 117, 120, 121, 122, 123, 127, 129, 131, 134, 137, 138, 139, 140, 141, 146, 148, 149, 153, 154, 155, 157, 161, 164, 167, 170, 172, 173], "higher": [7, 8, 9, 10, 11, 26, 43, 47, 53, 65, 66, 78, 86, 89, 94, 98, 102, 112, 113, 115, 116, 117, 121, 127, 129, 133, 134, 144, 150, 153, 160, 161, 168], "highest": [10, 94, 98, 101, 102, 109, 112, 113, 120, 146, 156], "highli": [6, 7, 8, 10, 26, 47, 50, 51, 72, 87, 89, 93, 98, 99, 102, 112, 113, 114, 117, 121, 131, 144, 156, 168, 173], "highligh": 102, "highlight": [1, 7, 9, 49, 53, 56, 57, 60, 75, 76, 78, 90, 93, 94, 102, 112, 113, 114, 115, 117, 121, 137, 139], "highwai": [47, 112, 113], "hike": [26, 27, 28, 29, 30, 34, 36, 129], "hill": [112, 113, 130, 175, 176, 177, 178, 179, 183], "hilli": 179, "him": [112, 113, 137, 140, 151], "himself": [112, 113], "hinder": 50, "hindi": [96, 131, 140], "hindranc": 50, "hindu": [99, 112, 113], "hinduism": [112, 113], "hines": 0, "hing": [56, 60], "hinneburg": 0, "hint": 178, "hinton": 54, "hipaa": [60, 78], "hire": [112, 113, 120, 121], "hispan": [112, 113], "hist": 16, "histogram": 95, "histor": [50, 54, 112, 113, 118, 121, 131, 135, 140], "histori": [6, 17, 18, 23, 50, 65, 92, 93, 112, 113, 117, 131, 133, 160, 174, 175, 177, 181, 182, 184, 186], "histplot": [25, 27, 95], "hit": [73, 102, 112, 113, 137, 153, 177, 178], "hks17": [0, 7], "hldamodel": 153, "hlight": 108, "hmm": [15, 145], "hmmr": 7, "hmn": 96, "hmong": 96, "hmp18": 0, "hmr": 7, "hn": 102, "ho": 102, "hoar": [112, 113], "hobbi": 174, "hoberg": [0, 120], "hoc": [112, 113], "hofmann": 152, "hold": [3, 26, 27, 28, 29, 30, 34, 36, 54, 102, 112, 113, 127, 129, 140, 153], "holden": [0, 7], "holdout": [72, 112], "hole": 89, "holidai": [112, 113], "holist": [39, 64], "holland": 0, "holonym": 138, "holt": [0, 112, 113], "holtzman": 98, "home": [24, 50, 67, 80, 81, 82, 95, 101, 102, 104, 108, 109, 111, 112, 113, 115, 133, 134, 136, 137, 142, 143, 151, 156, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185], "homebrew": 80, "homeopathi": [112, 113], "homepag": 18, "homewood": [112, 113], "homonym": 141, "homonymi": 141, "homosexu": [112, 113], "hon": 153, "honda": [112, 113], "hong": [0, 7, 153], "honorif": [131, 141], "hood": 151, "hook": [70, 112, 113], "hooper": [112, 113], "hope": [112, 113, 146, 153], "hopeless": 146, "hopkin": [112, 113], "hopkinsvil": [112, 113], "horizon": 98, "horizont": [112, 113, 179], "horn": [112, 113], "hornsbi": [112, 113], "horowitz": 57, "hors": 118, "horsesho": [112, 113], "hospit": [112, 113, 137], "host": [46, 62, 65, 66, 77, 78, 82, 112, 113, 122, 160, 161, 174], "hostnam": [82, 83], "hot": [6, 112, 113, 127, 129, 131, 138, 155, 157], "hotel": [112, 113, 137], "hotmail": [174, 175, 176, 181, 185], "hotpot": [6, 131], "hotspot": [112, 113], "hotter": [112, 113], "hottest": [112, 113], "hou": 102, "houlsbi": 53, "hour": [112, 113, 137, 145, 168], "hous": [10, 47, 94, 101, 112, 113, 120, 138, 148], "hover": 179, "hovi": 100, "how": [2, 5, 7, 9, 10, 13, 15, 22, 24, 42, 46, 49, 50, 51, 52, 53, 56, 57, 58, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 81, 82, 90, 92, 95, 97, 98, 101, 102, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 118, 120, 121, 124, 127, 129, 130, 131, 132, 137, 144, 145, 146, 148, 151, 152, 153, 156, 158, 166, 167, 171, 173, 175, 176, 177, 178, 179, 183, 187], "howev": [6, 7, 10, 13, 40, 43, 45, 47, 50, 53, 54, 56, 60, 67, 70, 72, 74, 77, 78, 89, 91, 92, 93, 94, 96, 98, 99, 100, 103, 105, 110, 111, 112, 113, 114, 117, 118, 121, 122, 124, 127, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 146, 147, 148, 150, 152, 153, 157, 158, 166, 170, 173, 175], "hp": 36, "hp16": 0, "hpamodel": 153, "href": [44, 153], "hsale": 24, "hsales_d": 24, "hsales_diff_prev": [24, 26, 27, 28, 29], "hsales_diff_year": [24, 26, 27, 28, 29, 30, 34, 36], "hsm": [78, 79], "hsst21": 0, "hsv": [112, 113], "ht": 96, "htm": [24, 37], "html": [11, 13, 30, 36, 44, 56, 94, 101, 102, 104, 109, 111, 112, 113, 115, 122, 124, 136, 137, 147, 153, 170, 183], "htt": 178, "http": [0, 6, 9, 10, 11, 17, 18, 20, 21, 23, 24, 25, 31, 36, 37, 46, 52, 54, 62, 68, 69, 70, 71, 73, 74, 77, 78, 79, 80, 81, 82, 83, 95, 97, 101, 102, 104, 109, 111, 112, 113, 115, 129, 130, 131, 133, 136, 137, 142, 146, 151, 153, 177, 178, 179, 181, 182, 183, 185, 186], "hu": [53, 96, 102], "hub": [13, 60, 61, 62, 63, 73, 101, 102, 104, 108, 109], "hue": [25, 26, 27], "huemer": [112, 113], "huffman": 129, "hug": [2, 43, 47, 48, 95, 97, 101, 102, 104, 105, 108, 109, 111, 112, 113, 137], "huge": [4, 112, 113], "huggingfac": [2, 18, 31, 48, 51, 60, 73, 95, 101, 102, 104, 108, 109, 111, 112, 113, 118, 137, 147], "hugginggpt": 43, "hugh": [112, 113], "human": [0, 2, 3, 4, 6, 8, 10, 12, 43, 45, 50, 52, 54, 56, 58, 60, 65, 66, 72, 75, 85, 86, 87, 92, 94, 97, 98, 99, 101, 103, 112, 113, 117, 120, 122, 123, 127, 130, 131, 135, 140, 146, 147, 148, 149, 155, 160, 161, 165, 167, 172], "human3": 7, "human_byt": [18, 23, 29], "humanist": [112, 113], "humanloop": 57, "humanml3d": 7, "humid": [112, 113], "hundr": [112, 113, 131], "hungarian": 96, "hunt": [112, 113], "huntsvil": [112, 113], "hurdl": [41, 56, 58, 170], "hurrican": [112, 113], "husband": 137, "hxw": 0, "hy": 96, "hybrid": [41, 42, 53, 90, 167, 168], "hydrogen": [4, 112, 113], "hymenaeus_beta": 150, "hype": 73, "hyperact": [112, 113], "hyperbar": [112, 113], "hyperfast": [2, 69, 71], "hyperlink": 122, "hypernym": [138, 144], "hyperparam": 52, "hyperparamet": [43, 46, 53, 56, 72, 76, 98, 112, 118, 152, 153, 155], "hyperparmet": [30, 36], "hyperplan": 139, "hyphen": 140, "hyponym": 138, "hypothes": 98, "hypothesi": [85, 98, 112, 113, 118, 158], "hyundai": [112, 113], "h\u00e9ll\u00f2": 105, "h\u00f4w": 105, "h\uc9c0\uc218\uc758": [15, 17], "i": [0, 2, 3, 4, 5, 6, 7, 9, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 143, 144, 146, 148, 149, 150, 151, 152, 155, 156, 157, 161, 163, 164, 165, 166, 167, 168, 170, 172, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186], "ia": [52, 53], "iac": [65, 160], "ian": 6, "ia\u00b3": 53, "ib": 102, "ibm": 50, "ic": [102, 112, 113, 140, 146], "icd": [112, 113], "icecream": 146, "iceland": [86, 96], "ici": [17, 18], "icl": 53, "iclr": [90, 100], "icml": 0, "icon": [1, 18, 83, 131, 178], "ict\uc5c5\uacc4": 17, "id": [0, 9, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 29, 31, 34, 35, 61, 77, 80, 82, 96, 101, 102, 105, 106, 111, 112, 113, 116, 153, 171], "id_ed25519": 77, "id_kei": [16, 25], "id_rsa": 186, "id_to_word": [128, 129], "idea": [2, 3, 7, 53, 72, 90, 97, 98, 101, 109, 111, 112, 113, 114, 115, 117, 130, 133, 134, 137, 140, 151, 152, 157, 158, 164, 168, 170, 181, 184], "ideal": [27, 28, 47, 50, 53, 84, 94, 100, 112, 113, 156, 171], "ident": [11, 15, 17, 18, 23, 77, 78, 79, 80, 105, 111, 112, 113, 121, 148], "identif": [78, 79, 85, 112, 113, 152, 167, 173], "identifi": [0, 2, 3, 8, 10, 13, 50, 51, 53, 54, 56, 60, 64, 65, 66, 72, 75, 84, 85, 89, 91, 96, 99, 106, 107, 109, 112, 113, 117, 120, 121, 123, 127, 131, 132, 135, 137, 138, 139, 140, 148, 149, 151, 152, 156, 157, 158, 160, 161, 168, 170, 171, 173, 175], "ideolog": [112, 113], "ideologi": [98, 112, 113], "idf": [2, 120, 127, 130, 137, 139, 147, 149, 154, 155, 157], "idiomat": 92, "idiosyncrasi": 170, "idiosyncrat": [112, 113], "idri": [181, 182], "idx": [129, 150, 153], "ieee": [0, 7, 90], "ig": 96, "igbo": 96, "igcc": 15, "igh": 108, "igher": 108, "ighlight": 108, "ignor": [36, 41, 125, 129, 133, 155, 174, 175, 176, 177, 178, 180, 181, 183, 185, 186], "igpt": 6, "iguazio": 72, "ii": [2, 60, 79, 90, 112, 113, 119, 120, 130, 152], "iii": [79, 90, 112, 113], "ij": [126, 129], "ik": 108, "il": 102, "ilikeanappl": 146, "ilikechocol": 146, "ill": [98, 102], "illeg": [112, 113, 116], "illegitim": [112, 113], "illia": 0, "illicit": [86, 112, 113], "illinoi": [112, 113], "illumin": [112, 113, 127], "illus": [112, 113], "illustr": [13, 39, 47, 52, 53, 57, 60, 85, 101, 107, 112, 113, 114, 115, 117, 131, 150, 154, 159, 168, 171, 179], "iloc": [24, 137], "ilya": 0, "im": [102, 153], "imag": [0, 2, 3, 5, 7, 8, 9, 13, 41, 42, 51, 52, 60, 63, 73, 74, 76, 86, 101, 112, 113, 123, 127, 139, 151, 152], "imagen": [2, 5, 6, 12, 131], "imagin": [6, 47, 89, 112, 113, 127, 140, 151, 179], "imap": 78, "imbal": [89, 94], "imbalanc": [26, 94], "imblearn": 137, "imdb": 111, "imf": 16, "imier": [112, 113], "imit": [2, 6, 7, 112, 113], "immedi": [13, 47, 97, 107, 112, 113, 130, 173], "immens": [13, 53, 54, 56], "immers": [7, 51, 92], "immigr": [112, 113], "immun": [112, 113], "immut": [65, 160], "impact": [2, 3, 9, 10, 13, 24, 41, 50, 53, 55, 56, 57, 60, 65, 78, 79, 86, 89, 90, 94, 99, 103, 110, 112, 113, 117, 121, 131, 138, 147, 160, 167, 171], "impair": [50, 112, 113, 131, 132], "impart": 48, "imped": 50, "imper": [39, 42, 51, 56, 112, 113], "imperfect": 7, "imperi": [112, 113], "impetu": [112, 113], "implaus": [112, 113], "implement": [2, 8, 11, 13, 31, 44, 47, 48, 51, 53, 56, 58, 61, 65, 69, 71, 75, 76, 77, 78, 84, 86, 88, 97, 98, 103, 106, 107, 111, 112, 113, 121, 130, 131, 133, 135, 137, 143, 144, 145, 146, 148, 153, 155, 157, 158, 159, 160, 167, 168, 172, 173], "impli": [55, 109, 112, 113, 117, 131, 133], "implic": [3, 5, 13, 40, 48, 53, 90, 94, 99, 110, 112, 113, 140, 157], "implicit": 10, "implicitli": 134, "import": [2, 7, 9, 11, 13, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 43, 46, 52, 60, 67, 70, 74, 75, 76, 78, 79, 86, 91, 93, 94, 95, 96, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 121, 124, 125, 127, 128, 129, 131, 133, 134, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 158, 159, 167, 171, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186, 187], "import_fil": 22, "importerror": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "importlib": 137, "impos": [112, 113], "imposit": [112, 113], "imposs": 119, "impract": [47, 51, 54, 90, 112, 113], "imprecis": [9, 151], "impress": [56, 87, 94, 117], "impressionist": [112, 113], "imprint": [112, 113], "imprison": [112, 113], "impro": 102, "improp": 56, "improv": [0, 2, 7, 8, 10, 11, 12, 19, 38, 39, 42, 43, 45, 46, 47, 50, 51, 53, 55, 58, 60, 61, 64, 65, 66, 72, 73, 75, 78, 79, 84, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 104, 106, 108, 110, 112, 113, 116, 117, 118, 121, 122, 131, 132, 133, 134, 135, 137, 138, 139, 151, 152, 160, 161, 166, 167, 172, 173, 179], "imshow": 137, "in_colab": 124, "inabl": [112, 113, 134, 136], "inaccess": 78, "inaccur": [131, 133, 151], "inaccuraci": [13, 94, 131], "inact": [112, 113], "inadequ": 165, "inadvert": 56, "inam": 80, "inappropri": [112, 113, 131], "inattent": [112, 113], "inc": [62, 102, 112, 113, 129, 153], "incept": [50, 167], "incest": [112, 113], "incid": [60, 65, 112, 113, 160], "inclin": [112, 113], "includ": [5, 6, 7, 8, 9, 10, 13, 37, 39, 40, 41, 43, 46, 48, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 87, 89, 90, 92, 93, 94, 96, 97, 98, 99, 101, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 127, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 148, 149, 151, 152, 153, 155, 156, 157, 160, 161, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184], "include_percentag": [15, 17, 18, 23], "include_valu": [15, 17, 18, 23], "include_var": [65, 160], "inclus": [60, 99, 147], "incoher": [93, 98], "incom": [74, 89, 102, 112, 113, 153], "incompat": [65, 160], "incompet": 137, "incomplet": [72, 121], "incomprehens": 137, "inconsist": [7, 56, 65, 90, 94, 112, 113, 152, 153, 160, 184], "inconveni": 153, "incorpor": [2, 7, 8, 10, 12, 13, 39, 41, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 60, 65, 73, 75, 78, 86, 90, 92, 94, 99, 101, 106, 112, 113, 114, 115, 117, 131, 134, 139, 152, 160, 167, 170, 171, 172, 173], "incorrect": [13, 21, 58, 60, 94, 103, 131, 135, 138], "incorrectli": 31, "incr": 102, "increa": 153, "increas": [2, 7, 10, 11, 39, 50, 51, 53, 56, 60, 64, 72, 75, 78, 86, 89, 90, 93, 94, 98, 101, 112, 113, 116, 117, 118, 120, 121, 123, 129, 134, 139, 144, 146, 147, 153, 172, 173], "increasingli": [3, 6, 42, 50, 51, 54, 60, 78, 85, 91, 92, 94, 112, 113, 117, 119, 127, 131, 135, 139], "incred": 127, "incredibli": [138, 181], "increment": 172, "increment_or_add": 182, "incub": 143, "incumb": [112, 113], "incur": [51, 116], "ind": 102, "indecis": 166, "indefinit": [112, 113], "independ": [11, 51, 53, 56, 61, 63, 78, 79, 98, 100, 106, 107, 112, 113, 116, 131, 133, 139, 140, 141, 144, 148, 152, 153, 156, 158], "index": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 29, 31, 32, 34, 35, 46, 56, 112, 113, 120, 124, 127, 129, 133, 136, 137, 138, 140, 142, 151, 153, 154, 157, 175, 176, 178, 180, 181, 182], "index_column_nam": [16, 29, 34], "indi": [25, 102], "india": 130, "indian": [112, 113], "indic": [10, 14, 17, 18, 20, 22, 31, 37, 50, 53, 54, 61, 77, 78, 89, 98, 102, 108, 109, 112, 113, 114, 115, 117, 119, 120, 121, 127, 131, 133, 134, 137, 138, 139, 140, 141, 146, 147, 148, 150, 152, 156, 179], "indica": 25, "indices_to_print": 102, "indirect": [112, 113], "indirectli": [112, 113], "indirectmeasur": 153, "indispens": [45, 60], "indistinguish": [6, 91, 99], "individu": [7, 9, 13, 39, 41, 47, 50, 77, 92, 97, 101, 106, 107, 109, 112, 113, 114, 117, 120, 130, 131, 133, 139, 141, 143, 144, 145, 147, 148, 154, 155, 157, 162, 165, 170, 172, 173, 187], "individualist": [112, 113], "indo": [112, 113, 141], "indoctrin": [112, 113], "indonesian": [96, 116], "indu": 102, "induc": [112, 113, 143], "industr": 102, "industri": [0, 7, 9, 39, 41, 50, 53, 54, 60, 61, 78, 102, 112, 113, 123, 131, 135, 153, 165, 172], "indycar": [112, 113], "ine": 102, "ineffect": [53, 112, 113, 117, 173], "ineffici": [50, 103, 154, 168], "inequ": [112, 113], "inerti": 7, "inertia": [24, 26, 27, 28, 29], "inertia_diff": [24, 26, 27, 28, 29, 30, 34, 36], "iness": 146, "inevit": [112, 113], "inf": 102, "infami": [112, 113], "infanc": [112, 113], "infant": [112, 113], "infantil": [112, 113], "infeas": [78, 90], "infect": [112, 113, 143], "infecti": [112, 113], "infer": [7, 10, 11, 15, 17, 18, 23, 47, 58, 72, 74, 94, 105, 111, 112, 113, 116, 117, 122, 123, 131, 139, 149, 157], "inferenc": 60, "inference_mod": 52, "infest": [112, 113], "infinit": [9, 10, 60, 106, 140], "infix": 140, "inflamm": [112, 113], "inflammatori": [112, 113], "inflat": [14, 25, 138, 153], "inflect": [60, 112, 113, 116, 131, 140, 143], "inflex": [167, 173], "influenc": [0, 2, 9, 39, 53, 55, 56, 99, 101, 112, 113, 131, 133, 137, 138, 140, 141, 147, 148, 152, 173], "influenti": [88, 112, 113, 117, 121], "influx": [112, 113], "info": [17, 18, 20, 21, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 43, 61, 104, 106, 113, 153], "info_fil": 18, "info_list": 18, "info_upd": [18, 23, 29], "inform": [0, 1, 7, 8, 9, 10, 11, 12, 13, 38, 39, 42, 43, 44, 45, 46, 47, 50, 53, 54, 60, 64, 65, 66, 70, 72, 74, 77, 78, 82, 84, 89, 90, 92, 94, 95, 99, 101, 103, 105, 106, 107, 112, 113, 115, 116, 117, 119, 121, 122, 125, 127, 128, 131, 133, 138, 139, 140, 141, 143, 145, 146, 147, 149, 151, 152, 154, 155, 157, 159, 160, 161, 172, 173, 179, 186], "infrastructur": [2, 13, 38, 48, 56, 59, 65, 67, 72, 74, 79, 81, 112, 113, 120, 160, 170], "infrequ": [72, 131, 158], "infring": 122, "infus": 170, "ing": [76, 102, 125, 147], "ingenu": 3, "ingest": [13, 39, 56, 57], "ingredi": [47, 118], "ingress": 81, "inhabit": [120, 140], "inher": [42, 47, 51, 53, 55, 56, 58, 60, 78, 100, 101, 112, 113, 117, 131, 135, 139, 140, 151, 152, 172, 173], "inherit": [54, 112, 113, 131], "inhibit": [112, 113], "inhospit": 84, "ini": [65, 160], "init": [17, 18, 20, 21, 22, 53, 65, 80, 160, 174, 186], "initi": [7, 9, 10, 15, 17, 18, 23, 29, 39, 43, 44, 45, 46, 47, 51, 53, 54, 55, 60, 61, 63, 70, 73, 89, 98, 100, 101, 104, 106, 107, 110, 111, 112, 113, 117, 120, 121, 137, 143, 149, 151, 153, 159, 167, 172, 173, 174, 184, 186], "initial_alphabet": 112, "initialize_vocab": [102, 108, 109], "initializer_rang": 113, "initiate_chat": 43, "initil": 18, "inject": [7, 11, 53], "injuri": [112, 113], "inland": [112, 113], "inlinebackend": [16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 115, 129, 146, 150, 151], "innat": [112, 113], "inner": [15, 22, 89, 115], "innov": [3, 9, 51, 53, 54, 60, 66, 86, 90, 94, 99, 117, 120, 127, 131, 161, 168, 170], "inoxum": [112, 113], "inpaint": 10, "inplac": [24, 27, 28, 35], "input": [6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 20, 23, 31, 43, 47, 50, 51, 52, 53, 55, 56, 58, 59, 60, 72, 73, 74, 86, 89, 90, 92, 94, 99, 100, 101, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115, 116, 122, 123, 125, 127, 128, 131, 138, 139, 140, 142, 144, 145, 146, 151, 154, 172, 173], "input_batch": [128, 129], "input_fil": [77, 125], "input_format": [104, 106], "input_id": [31, 98, 101, 105, 111, 112, 113], "input_sentence_s": [104, 106], "input_split": [16, 21, 25, 31], "inquiri": 131, "ins": 102, "inscrib": [112, 113], "inscript": [112, 113], "insert": [53, 80, 100, 108, 109, 115, 116, 140, 153, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186], "insi": 102, "insid": [61, 77, 112, 113, 129, 140], "insight": [7, 13, 41, 42, 43, 46, 51, 52, 58, 90, 95, 115, 117, 119, 131, 134, 135, 136, 137, 139, 140, 145, 147, 148, 150, 152, 158, 168, 169], "insist": [112, 113], "insol": [112, 113], "insomnia": [112, 113], "inspect": [111, 137, 166, 179], "inspir": [2, 3, 6, 7, 9, 54, 70, 84, 89, 101, 112, 113, 117, 131], "instabl": 13, "instagram": [122, 135], "instal": [15, 24, 25, 31, 76, 78, 95, 96, 98, 101, 106, 111, 112, 113, 125, 133, 136, 137, 142, 143, 151, 170, 179, 182], "installshield": 170, "instanc": [3, 39, 43, 46, 47, 50, 51, 52, 53, 60, 65, 74, 78, 81, 94, 96, 99, 103, 106, 107, 112, 113, 114, 121, 124, 127, 133, 135, 137, 138, 140, 141, 144, 145, 147, 148, 152, 153, 157, 160], "instance_data_dir": 52, "instance_dir": 52, "instance_prompt": 52, "instant": 1, "instanti": [16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 113, 150], "instead": [7, 10, 23, 24, 47, 60, 61, 72, 77, 85, 89, 94, 98, 100, 107, 111, 112, 113, 116, 117, 118, 125, 127, 129, 135, 140, 144, 152, 155, 159, 174, 176, 178], "instinct": [47, 127], "institut": [78, 90, 112, 113, 131, 187], "instruct": [7, 15, 23, 43, 46, 47, 52, 61, 62, 65, 74, 83, 84, 89, 93, 99, 101, 112, 113, 160, 165, 177, 179, 186], "instructgpt": [47, 93], "instrument": [7, 112, 113, 150], "insuffici": [7, 39, 47, 51, 60, 167], "insular": [112, 113], "insur": [102, 112, 113, 153], "insurg": [112, 113], "insurrectionari": [112, 113], "int": [15, 18, 22, 102, 108, 109, 125, 133, 156], "int32": [111, 113], "int64": [15, 16, 22, 23, 26], "int64index": [15, 16, 22], "int8": [111, 113], "intact": [51, 62], "intak": [112, 113], "intang": 109, "intangibl": 109, "integ": [125, 136, 144, 151], "integr": [1, 3, 7, 8, 15, 40, 41, 43, 46, 47, 50, 53, 55, 56, 58, 60, 61, 63, 64, 65, 67, 71, 72, 73, 77, 78, 79, 81, 89, 92, 106, 112, 113, 117, 160, 165, 167, 170, 173, 178], "intellectu": [60, 75, 99, 112, 113], "intellig": [1, 2, 3, 4, 6, 9, 12, 43, 45, 50, 53, 54, 55, 57, 60, 78, 79, 84, 88, 90, 91, 92, 94, 98, 101, 112, 113, 120, 123, 130, 131, 142], "intellij": 170, "intend": [2, 10, 11, 37, 58, 60, 84, 94, 112, 113, 122, 131, 168, 171], "intens": [13, 47, 50, 51, 53, 54, 56, 58, 60, 78, 94, 99, 112, 113, 114, 117, 127, 133, 138, 173], "intensifi": [13, 51, 94, 112, 113, 138], "intent": [47, 92, 121, 179], "intention": [112, 113, 121], "inter": [13, 100, 102], "interact": [3, 7, 8, 12, 43, 47, 50, 51, 54, 56, 57, 58, 61, 65, 72, 73, 80, 84, 87, 89, 92, 94, 112, 113, 115, 117, 122, 130, 131, 145, 160, 172, 178, 184, 186], "intercept": [78, 83, 112, 113], "interchang": [112, 113, 122], "interconnect": [51, 79, 89, 112, 113, 131], "interdepend": 79, "interdisciplinari": [8, 12, 90], "interest": [7, 10, 13, 24, 94, 98, 106, 112, 113, 117, 119, 120, 121, 131, 137, 138, 148, 151, 153, 168], "interestingli": 119, "interfac": [1, 39, 46, 57, 58, 60, 61, 62, 63, 70, 73, 75, 81, 82, 92, 98, 124, 167, 170, 177, 181], "interfer": [112, 113, 179], "intergovernment": [112, 113], "intergraph": [112, 113], "interject": 141, "interlink": 138, "intermedi": [7, 10, 54, 98, 101, 112, 113], "intermediate_s": 113, "intermingl": [112, 113], "intern": [0, 7, 8, 10, 38, 44, 60, 86, 90, 94, 99, 102, 105, 106, 108, 112, 113, 116, 117, 121, 130, 131, 153, 155], "interna": 108, "internat": 108, "internati": 108, "internatio": 108, "internationa": 108, "internet": [7, 10, 50, 51, 78, 79, 83, 112, 113, 122, 127, 177, 186], "interoper": [39, 61, 63, 78], "interplai": 117, "interpol": [7, 10, 11, 137], "interpret": [2, 5, 9, 11, 38, 39, 40, 42, 50, 54, 58, 72, 86, 90, 92, 94, 99, 103, 110, 112, 113, 114, 115, 117, 121, 123, 127, 131, 132, 135, 139, 147, 148, 149, 150, 151, 152, 171], "interrupt": [112, 113], "intersect": [6, 9, 51, 58, 89, 131], "interst": [112, 113], "intertwin": [112, 113], "interv": [134, 153], "interven": 53, "intervent": [43, 45, 50, 65, 66, 67, 86, 94, 112, 113, 121, 160, 161], "interview": [112, 113, 170], "intestin": [112, 113], "intimaci": [112, 113], "intimid": [112, 113], "intoler": [112, 113], "intra": [50, 112, 113], "intradai": 129, "intraparti": 121, "intrauterin": [112, 113], "intric": [43, 47, 50, 54, 58, 94, 127, 140], "intricaci": [47, 48, 51, 81, 94], "intrigu": [43, 57, 117], "intrins": [51, 60, 112, 113, 133], "introduc": [1, 6, 7, 8, 9, 10, 11, 38, 47, 50, 51, 53, 54, 56, 60, 68, 78, 80, 81, 84, 89, 90, 91, 94, 96, 97, 98, 106, 112, 113, 116, 117, 121, 125, 126, 128, 129, 130, 131, 133, 137, 139, 152, 155, 167, 169, 171, 173, 174, 175], "introduct": [5, 38, 43, 48, 50, 71, 79, 81, 97, 114, 162, 187], "introductori": [81, 98], "intuit": [11, 46, 47, 50, 112, 113, 115, 120, 131, 154, 157], "inuktitut": 131, "inv": 102, "inval_cv_filenam": 15, "inval_cved_filenam": 15, "invalid": 78, "invalid_dataset": 17, "invalid_preds_df": [15, 22], "invalu": [47, 90], "invari": [7, 141], "invent": [6, 112, 113, 121, 184], "inventori": [112, 113], "invers": [10, 112, 113, 121, 131, 139, 159], "invert": [10, 89, 156], "invert_yaxi": 156, "invertebr": [112, 113], "invest": [35, 39, 50, 60, 86, 94, 102, 108, 109, 112, 113, 120, 131, 146, 153, 173], "investig": [48, 112, 113, 148], "investor": [60, 102, 129, 133, 153], "invis": [112, 113], "invit": [112, 113], "invoc": 74, "invok": [72, 80], "involuntari": [112, 113], "involv": [6, 7, 8, 9, 10, 12, 13, 44, 46, 47, 48, 50, 51, 53, 54, 55, 56, 58, 60, 61, 65, 66, 68, 72, 75, 78, 79, 81, 89, 90, 92, 93, 94, 98, 99, 101, 103, 105, 106, 109, 111, 112, 113, 114, 117, 119, 120, 121, 122, 127, 131, 135, 139, 140, 141, 143, 145, 147, 148, 152, 156, 157, 158, 160, 161, 166, 167, 168, 170, 172, 173], "io": [11, 15, 16, 21, 22, 23, 24, 25, 29, 31, 32, 35, 36, 61, 71, 72, 81, 101, 102, 104, 109, 111, 112, 113, 115, 125, 136, 137, 170, 183], "iot": [13, 18, 51, 79], "iou": 89, "iowa": [112, 113], "ip": [78, 79, 82, 83, 102, 141], "ipa": [112, 113], "iphon": 108, "ipo": 124, "iprogress": [101, 102, 104, 109, 111, 112, 113, 115, 137], "ipsec": [78, 79, 83], "ipsum": 118, "ipynb": [10, 52], "ipython": [25, 32, 33, 34, 35, 153], "ipywidget": [101, 102, 104, 109, 111, 112, 113, 115, 137], "iq": [112, 113], "iqbal": [0, 7], "ir": [102, 108], "ira": [0, 7], "iraqi": [112, 113], "irf": 35, "iri": [74, 78], "iris_classifier_servic": 74, "irisclassifi": 74, "irish": [96, 112, 113], "iron": [112, 113], "ironi": 135, "iroquoian": [112, 113], "irp": 21, "irradi": [112, 113], "irregular": [140, 141], "irrelev": [56, 94], "irrig": 13, "irrit": [112, 113], "irst": 108, "is_colab": [15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "is_fast": [112, 113], "is_live_top": 153, "is_notebook": [16, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 153], "isa": 153, "isbn": 38, "isc": 108, "isha": 108, "ishar": [102, 108], "ishii": [0, 146], "isi": 146, "isin": [15, 17], "isit": 146, "isl": [112, 113], "islam": [112, 113], "island": [112, 113], "ism": [112, 113], "isn": [53, 98, 111, 117, 137, 140, 158], "isnul": 26, "iso": [112, 113], "iso22301": 21, "isol": [43, 112, 113, 114, 117], "isomap": 29, "isopropyl": 143, "iss": 108, "issu": [10, 42, 43, 53, 55, 56, 60, 64, 65, 66, 74, 78, 84, 85, 90, 94, 96, 98, 107, 110, 112, 113, 116, 117, 121, 134, 135, 138, 139, 148, 152, 158, 159, 160, 161, 167, 171, 173], "itakura": 152, "ital": [102, 112, 113], "itali": [112, 113], "italian": [96, 112, 113, 117, 140], "itard": [112, 113], "ite": 102, "item": [15, 16, 18, 22, 24, 32, 89, 102, 108, 109, 111, 112, 113, 127, 128, 129, 134, 144, 150, 156, 157], "itemgett": 156, "iter": [10, 43, 44, 47, 56, 66, 72, 86, 87, 89, 101, 102, 106, 108, 109, 117, 129, 149, 152, 153, 161, 165, 170, 172], "iterrow": 33, "itertool": 153, "iti": [102, 108, 109, 146], "itio": 108, "its": [1, 2, 3, 6, 7, 9, 10, 11, 38, 39, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 70, 72, 74, 75, 77, 78, 79, 80, 81, 84, 86, 87, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 105, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 121, 122, 123, 124, 125, 127, 129, 131, 133, 134, 135, 137, 138, 139, 140, 141, 142, 144, 145, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159, 160, 165, 167, 168, 170, 171, 172, 173, 175, 176, 181, 187], "itself": [7, 43, 54, 89, 98, 106, 112, 113, 115, 117, 141, 155, 156, 178, 185], "iu": 108, "iv": [79, 90, 112, 113], "ivan": [112, 113], "ivei": [112, 113], "iw": 96, "ix": 129, "j": [0, 21, 31, 35, 54, 70, 100, 102, 107, 108, 109, 112, 113, 120, 126, 127, 129, 130, 148, 153, 156, 168, 182], "j04": 0, "ja": [96, 106], "jaccard": 153, "jack000": [6, 131], "jacki": 0, "jackson": [112, 113], "jacksonvil": [112, 113], "jacob": [0, 100, 113], "jail": [112, 113], "jaim": 0, "jair": 90, "jakob": 0, "jame": [112, 113, 174], "jan": [102, 153], "jane": 101, "janet": [24, 25], "janpanes": 146, "januari": [31, 102, 112, 113, 153], "japan": [0, 121, 153], "japanes": [0, 96, 103, 106, 112, 113, 121, 142, 153], "jaquet": 6, "jargon": [90, 110, 116, 175], "jason": 0, "jauvin": 0, "java": [50, 98, 142, 170], "javanes": 96, "javascript": [70, 118, 122, 170], "javier": 0, "jax": 9, "jc": 142, "je": [102, 112, 113], "jealousi": [112, 113], "jean": [0, 112, 113], "jeff": 0, "jefferson": [112, 113], "jeffrei": 0, "jemison": [112, 113], "jenkin": [65, 66, 72, 76, 160, 161, 170], "jeremiah": [112, 113], "jericho": [112, 113], "jerom": [24, 25, 26, 27, 28, 32], "jess": [0, 112, 113, 131], "jesu": 151, "jetson": 7, "jew": [112, 113], "jewish": [112, 113], "jfif": 151, "ji": [0, 7], "jiangxi": 153, "jianyuan": 0, "jihoon": [0, 7], "jim": [112, 113, 151, 176, 180], "jin": [0, 146], "jinja": 70, "jira": [66, 161, 170], "jiseob": [0, 7], "jitendra": [0, 7], "jitter": 89, "jj": 145, "jkb": 142, "jko": [142, 143], "jmlr": [0, 100], "jnalivxin2qcehqa": 73, "jo": 102, "job": [74, 98, 112, 113, 121, 137, 172], "jobless": [153, 156], "joblib": [16, 21, 25, 31, 133, 136, 142, 151], "joe": 0, "johann": [112, 113], "john": [0, 101, 112, 113], "johnson": 137, "join": [102, 104, 106, 112, 113, 124, 128, 129, 134, 137, 150, 151, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "join_path": 153, "joint": [7, 112, 113], "jointli": [100, 112, 113, 117], "jointplot": 29, "joke": 137, "jon": 102, "jone": [0, 112, 113, 151], "jonni": [0, 7], "joon": [0, 174, 175, 176, 181, 185], "jordan": [112, 113, 153], "josa": 141, "joseph": [112, 113], "josh": 0, "jost": 0, "joulin": 0, "journal": [0, 85, 90, 99, 112, 113, 120, 131, 153], "journei": [54, 140, 172], "journ\u00e9": 143, "joy": [112, 113], "jpeg": [10, 151], "jpss": [112, 113], "jpy66": 153, "jq5": [112, 113], "jr": 130, "json": [15, 21, 22, 65, 70, 74, 101, 104, 105, 112, 113, 115, 122, 146, 160], "jti06": 0, "ju": 102, "judaism": [112, 113], "judg": [84, 112, 113, 137, 138], "judgment": [47, 99, 112, 113, 131, 138], "judici": [112, 113], "judiciari": [112, 113], "judith": [112, 113], "juli": [0, 102, 112, 113, 153], "julian": 0, "july5": [112, 113], "jum": 102, "jump": [7, 86, 116, 118, 143, 145, 153, 159], "jun": [0, 7], "junctur": 51, "june": [94, 112, 113, 129], "junegunn": 80, "jungl": 4, "junit": 170, "jupyt": [30, 36, 101, 102, 104, 109, 111, 112, 113, 115, 137, 145, 174], "jupyter_cli": [25, 32, 33, 34, 35], "jura": [112, 113], "jurafski": 130, "juri": [112, 113], "jurisdict": [112, 113], "just": [1, 3, 7, 18, 47, 52, 53, 54, 57, 60, 65, 66, 72, 74, 78, 89, 93, 97, 98, 99, 106, 110, 112, 113, 114, 117, 127, 129, 130, 131, 134, 137, 141, 144, 147, 148, 153, 155, 160, 161, 172, 174, 175, 179, 180, 181, 182, 184, 186], "justic": [112, 113], "justifi": [112, 113, 166, 168, 171], "justinjohn0306": 10, "jv": 96, "jvc": [112, 113], "jx": 142, "k": [9, 10, 53, 56, 100, 102, 103, 105, 106, 109, 112, 113, 114, 115, 117, 120, 127, 129, 133, 134, 139, 149, 151, 152, 153, 158, 175], "ka": 96, "kai": [0, 112, 113], "kaiser": 0, "kaist": 142, "kakao": 122, "kale": 0, "kalman": 152, "kalyani": 0, "kanazawa": [0, 7], "kanban": [66, 161, 172], "kane": [0, 7], "kang": 0, "kannada": 96, "kanner": [112, 113], "karl": [112, 113], "kata": 61, "katherin": 0, "katz": 0, "kavad": [112, 113], "kazakh": 96, "kb": [133, 136, 137, 151], "kb\uae08\uc735": 20, "kb\uae08\uc735\uc9c0\uc8fc": 20, "kb\uc99d\uad8c": 20, "kc": 106, "kdc": 78, "kde": [25, 27, 95], "kdeplot": 27, "ke": [8, 102], "ked": 102, "keei": 24, "keep": [39, 43, 47, 51, 53, 56, 64, 67, 68, 69, 77, 80, 82, 89, 98, 104, 107, 108, 109, 112, 113, 116, 118, 119, 120, 121, 131, 139, 144, 145, 147, 156, 157, 171, 175, 176, 177, 182, 184, 186], "keepdim": [128, 153], "kei": [6, 7, 10, 11, 13, 16, 29, 35, 47, 53, 56, 60, 63, 65, 66, 72, 73, 74, 77, 79, 81, 82, 83, 86, 89, 90, 92, 93, 94, 95, 99, 102, 107, 108, 109, 111, 113, 115, 117, 124, 130, 131, 134, 145, 150, 156, 160, 161, 168, 171, 173, 177, 182], "kemelmach": [0, 7], "kenlm": 96, "kenton": 0, "kentucki": [112, 113], "kept": [31, 77, 78, 89, 107, 112, 113, 137, 179, 186], "kerasmodelartifact": 74, "kerbero": [78, 79], "kernel": [133, 136, 137, 139, 142, 151], "ket": 108, "kevin": [0, 7], "key_column": 18, "key_id": 77, "keyfil": 73, "keygen": [77, 80], "keypair": 186, "keyword": [92, 93, 94, 137, 146], "khan": 86, "khazatski": 0, "khmer": 96, "ki": [0, 146], "kib": 29, "kibana": [65, 66, 160, 161], "kick": [7, 144], "kill": [112, 113], "kilomet": [112, 113], "kim": [0, 7], "kind": [10, 41, 112, 113, 115, 124, 129, 134, 137, 146, 150, 152, 153, 157, 174], "kinda": 137, "kindergarten": 151, "kinemat": 7, "king": [10, 102, 125, 157, 159], "kirchhoff": [112, 113], "kirillov": 8, "kit": 7, "kitchen": [47, 119], "kitten": 114, "kiwisolv": 137, "kk": 96, "kkc22": [0, 7], "kl": [0, 7, 8, 9], "klan": [112, 113], "kleffner": [112, 113], "klein": 98, "klux": [112, 113], "km": 96, "kmp_duplicate_lib_ok": [16, 17, 18, 20, 22, 25, 30, 32, 33, 34, 35, 153], "kn": 96, "kneser": [96, 134], "knight": [112, 113], "know": [4, 78, 79, 98, 107, 111, 112, 113, 114, 115, 116, 118, 131, 137, 140, 151, 157, 174, 181, 183, 184, 185], "knowledg": [0, 1, 10, 39, 43, 45, 47, 50, 51, 55, 56, 58, 65, 66, 70, 76, 78, 81, 82, 85, 86, 88, 90, 92, 94, 99, 101, 109, 110, 112, 113, 114, 131, 134, 135, 137, 139, 151, 157, 160, 161, 164], "known": [2, 9, 10, 39, 47, 50, 53, 54, 60, 65, 70, 73, 74, 78, 79, 84, 87, 92, 93, 98, 99, 102, 103, 107, 110, 112, 113, 117, 120, 123, 128, 133, 134, 135, 139, 140, 141, 142, 144, 146, 147, 154, 155, 157, 158, 159, 160, 173, 185], "ko": [95, 96, 104, 131, 142], "ko_mc4": 95, "koasati": [112, 113], "koeberl": [112, 113], "kolesnikov": 0, "komura": [0, 7], "kong": 153, "konlpi": 142, "konrad": 0, "koppen": [112, 113], "korea": [0, 13, 121, 124], "korean": [0, 2, 94, 95, 96, 103, 104, 121, 124, 130, 140, 177], "koresh": 151, "kotlin": 170, "kpbs288v": 18, "kpbs288vsync": 18, "krishna": 60, "kristina": 0, "kroneck": 52, "kronstadt": [112, 113], "kropotkin": [112, 113], "ksuccessfulli": 178, "kt": 15, "ktb\ud22c\uc790\uc99d\uad8c": 20, "ku": [96, 112, 113], "kube": 81, "kubectl": [81, 82], "kubeflow": 72, "kubernet": [65, 66, 71, 72, 76, 160, 161, 170], "kud18": 0, "kudo": [0, 106, 107], "kullback": [8, 9, 152], "kumiko": 0, "kuprel": [6, 131], "kurdish": 96, "kuwaiti": [112, 113], "kvfran": 10, "ky": 96, "kyrgyz": 96, "kytea": 106, "l": [0, 7, 9, 10, 15, 21, 22, 35, 89, 100, 102, 103, 106, 107, 109, 112, 113, 126, 127, 129, 146, 147, 153, 174, 178, 182], "l_ff": 53, "l_k": 53, "l_v": 53, "la": [0, 96, 102, 112, 113], "lab": [2, 7, 60, 94, 97, 103, 110, 123, 130, 135, 140, 149, 155], "label": [7, 10, 13, 15, 17, 23, 31, 33, 39, 47, 50, 53, 93, 94, 99, 101, 110, 111, 112, 113, 114, 116, 117, 123, 129, 131, 135, 136, 137, 138, 139, 140, 147, 150, 153, 179, 180, 182, 184], "label_column": 52, "label_config": 22, "label_error_candid": [15, 17, 18], "label_studio_serv": 18, "labelbox": 60, "labelencod": 137, "labelingfunct": 21, "labelrot": 25, "labels_by_annot": 21, "labelstudio": 18, "labor": [35, 58, 85, 112, 113, 121, 140, 164, 171], "labour": [112, 113, 140], "labyrinthin": 39, "lace": 17, "lack": [9, 11, 13, 14, 39, 50, 56, 58, 60, 63, 72, 84, 94, 98, 112, 113, 127, 131, 135, 141, 148, 152, 167, 173], "ladd": [112, 113], "lag": [13, 14, 112, 113], "lai": [60, 102, 140, 170], "laid": [128, 152], "laion": [6, 131], "lake": [17, 112, 113, 177, 178, 180, 181, 183], "lakeland": [177, 178, 180, 182], "lambda": [15, 20, 22, 24, 26, 27, 28, 53, 60, 108, 109, 112, 113, 150, 151, 153], "lambert": [112, 113], "lambertian": [112, 113], "lamda": [50, 53, 99], "lampl": 96, "lan": 100, "land": [112, 113, 134, 153], "landau": [112, 113], "landauer": [112, 113], "landfal": [112, 113], "landfil": 15, "landform": [112, 113], "landmark": 7, "landscap": [3, 4, 39, 47, 50, 51, 56, 57, 60, 64, 78, 79, 94, 112, 113, 127, 170, 173], "lang": 18, "langchain": [2, 43, 57, 60, 71, 75], "langdetect": 118, "langsmith": 58, "languag": [0, 1, 2, 6, 9, 10, 11, 12, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 58, 59, 65, 66, 70, 73, 75, 84, 85, 86, 88, 89, 90, 92, 94, 95, 97, 98, 101, 103, 104, 105, 106, 108, 111, 112, 113, 115, 116, 117, 118, 121, 123, 127, 130, 135, 136, 138, 139, 140, 142, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 164, 166, 168, 170, 171, 182, 184], "lao": [96, 112, 113], "laozi": [112, 113], "lapidari": [112, 113], "laplac": [133, 134], "larg": [0, 2, 6, 7, 9, 10, 12, 13, 27, 28, 38, 43, 45, 46, 47, 49, 53, 57, 58, 59, 61, 70, 72, 73, 74, 75, 77, 84, 85, 86, 87, 89, 92, 94, 96, 97, 98, 100, 101, 103, 106, 107, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 127, 129, 131, 133, 134, 135, 137, 138, 139, 140, 144, 145, 149, 150, 151, 152, 153, 155, 156, 157, 159, 164, 167, 170, 172, 173], "larger": [7, 10, 52, 60, 89, 98, 99, 108, 109, 112, 113, 115, 116, 117, 118, 131, 133, 134, 143, 144, 155, 158, 172, 173], "largest": [10, 89, 112, 113, 116, 131, 150, 151, 153], "larson": 151, "last": [10, 17, 18, 23, 25, 35, 54, 60, 89, 102, 104, 109, 112, 113, 114, 117, 118, 120, 121, 129, 137, 151, 153, 175, 186], "last_nam": [24, 33], "lastli": [57, 112, 113, 127], "late": [64, 112, 113, 120, 134, 153, 167, 172, 173], "latenc": [0, 7, 56, 60, 116], "latent": [8, 9, 10, 37, 131, 139, 149, 151, 153], "later": [9, 99, 111, 112, 113, 121, 125, 129, 131, 151, 153, 178, 179], "latest": [56, 61, 64, 78, 79, 81, 82, 86, 88, 90, 94, 97, 112, 113, 131, 176], "latin": [96, 112, 113, 141], "latitud": [112, 113], "latn": 96, "latt": 148, "latter": [10, 51, 112, 113, 146, 151], "lattic": 78, "latvian": 96, "laud": [112, 113], "launch": [52, 60, 83, 151, 170], "lauren": 0, "laurenc": 0, "law": [60, 99, 112, 113, 131, 138], "lawrenc": 35, "lawsuit": [112, 113], "lawyer": [112, 113], "layer": [4, 10, 11, 41, 47, 50, 53, 75, 78, 79, 83, 86, 89, 98, 100, 101, 111, 112, 113, 114, 115, 116, 117, 118, 128, 139, 140, 141], "layer_norm": 53, "layer_norm_ep": 113, "layernorm": 111, "laymen": 7, "layout": 137, "layoutlmfortokenclassif": 52, "lazi": [116, 143, 145, 159], "lb": 96, "lbsa": 31, "lcd": 15, "lcw99": 104, "lcw99___parquet": 104, "ld": [102, 106], "lda": [127, 139, 149], "lda_bas": 153, "ldamodel": 153, "lding": 108, "ldot": [100, 120, 127, 134, 144], "le": [0, 100, 102, 103, 107, 108, 109, 112, 113, 137], "lead": [7, 9, 10, 13, 43, 48, 51, 53, 54, 56, 60, 64, 65, 72, 74, 89, 94, 98, 99, 102, 103, 106, 107, 112, 113, 117, 118, 120, 121, 131, 133, 135, 138, 140, 144, 147, 149, 152, 154, 155, 160, 165, 167, 172, 173], "leader": [60, 72, 112, 113, 152, 153, 178], "leaderboard": 52, "leaderless": [112, 113], "leadership": [112, 113, 152], "leaf": 129, "leagu": [112, 113], "leah": [112, 113], "leakag": [53, 122], "lean": [112, 113, 166, 172], "leaner": [30, 36], "leap": [43, 47, 50, 54, 78, 140], "leapt": 140, "learn": [0, 2, 6, 8, 9, 10, 11, 12, 18, 19, 29, 35, 39, 40, 41, 42, 43, 45, 46, 49, 52, 53, 55, 56, 60, 65, 66, 67, 68, 73, 79, 81, 82, 86, 87, 89, 90, 91, 92, 94, 98, 99, 100, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 119, 123, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 141, 142, 144, 145, 147, 149, 152, 153, 154, 155, 157, 160, 161, 168, 170, 174, 179, 187], "learnabl": [9, 51, 53, 117, 128], "learner": [54, 100, 116], "learning_git": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "learning_r": [30, 36, 46, 52], "learninglearn": 18, "least": [65, 78, 96, 98, 108, 109, 112, 113, 117, 118, 121, 126, 140, 150, 151, 152, 160, 168], "leav": [53, 82, 101, 112, 113, 137, 176, 180, 185], "lectur": [1, 13, 40, 42, 45, 49, 51, 53, 57, 58, 60, 68, 69, 73, 77, 78, 80, 81, 90, 98, 100, 101, 102, 103, 104, 107, 109, 112, 113, 115, 133, 136, 137, 142, 143, 151, 154, 156, 159, 162, 166, 168, 169, 170, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186, 187], "lecturebot": 2, "lecun": 54, "led": [3, 9, 50, 54, 78, 98, 99, 110, 112, 113, 117, 121, 131], "lee": [0, 54, 100, 104, 111, 112, 113, 121, 152, 153, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "lee22": 0, "leech": 7, "leed": [112, 113], "left": [24, 64, 112, 113, 114, 129, 133, 137, 146, 148, 178, 181, 185, 186], "left_index": [32, 34, 35], "leftist": [112, 113], "leftmost": 150, "leg": [101, 112, 113], "legal": [13, 46, 60, 78, 94, 99, 110, 112, 113, 123, 131, 168], "legend": [24, 27, 33, 140, 150], "legendari": [112, 113, 131], "legion": [112, 113], "legisl": [0, 112, 113, 120, 138], "legislatur": [112, 113, 121], "legitim": [78, 112, 113], "legitimaci": [112, 113], "legwork": 70, "lehman": 120, "lei": [0, 7], "leibler": [8, 9, 152], "leighton": 153, "leipzig": 94, "leisur": [112, 113], "lemair": 0, "lemmat": [105, 137, 139, 143, 151], "lemmatize_text": 137, "lemongrass": 47, "len": [9, 15, 16, 17, 18, 20, 21, 22, 25, 31, 60, 95, 102, 105, 108, 109, 111, 112, 128, 129, 131, 133, 134, 146, 150, 151, 153, 156], "len_byt": [18, 25], "len_column": 25, "len_func": [16, 25], "len_word": [16, 25], "lend": 121, "lendingtre": [112, 113], "leng": 109, "length": [7, 17, 18, 20, 22, 25, 26, 31, 53, 78, 80, 94, 96, 98, 99, 101, 102, 104, 105, 108, 109, 111, 112, 113, 114, 116, 127, 137, 146, 153, 158], "lengthen": [112, 113], "lengthi": [10, 50, 112, 113], "lenin": [112, 113], "lent": 0, "leo": [112, 113], "leq": 158, "lerner": 0, "lesli": [112, 113], "less": [9, 25, 47, 50, 53, 78, 84, 89, 94, 98, 101, 110, 112, 113, 114, 116, 117, 122, 125, 129, 131, 137, 139, 146, 148, 151, 154, 158, 172, 173], "lessen": [112, 113], "lesser": [50, 84], "lesson": [65, 86, 151, 160, 172, 179], "lester": 53, "let": [9, 25, 31, 54, 68, 74, 81, 95, 98, 102, 104, 105, 106, 107, 111, 114, 115, 117, 124, 129, 133, 134, 136, 137, 141, 143, 144, 145, 148, 150, 151, 153, 156, 159, 175, 176, 177, 178, 179, 181], "letter": [50, 109, 112, 113, 137, 147], "letter_freq": 109, "leve": [112, 113], "level": [0, 7, 8, 9, 10, 12, 13, 24, 25, 26, 27, 28, 29, 31, 36, 39, 43, 51, 53, 54, 55, 56, 58, 60, 63, 66, 78, 86, 89, 93, 94, 100, 101, 103, 105, 109, 112, 113, 115, 118, 121, 123, 131, 138, 141, 143, 144, 147, 148, 149, 150, 153, 161, 168, 170, 172], "leverag": [1, 7, 8, 12, 13, 39, 43, 46, 47, 51, 53, 54, 56, 57, 60, 61, 65, 67, 80, 83, 87, 92, 94, 96, 99, 101, 106, 110, 111, 114, 117, 127, 131, 138, 139, 160, 170], "levi": [112, 113], "levin": [0, 7], "lewi": [96, 100, 131, 184], "lexic": [131, 138], "lexicograph": 157, "lexicon": [2, 31, 39, 130, 131, 135, 137, 139, 157], "lf": 21, "lf_summari": 21, "lfg": 15, "lg": 21, "lgbm": [30, 36], "lgbmclassifi": [30, 36], "lgbmclassifierlgbmclassifi": [30, 36], "lgbt": [112, 113], "lg\uac00": [15, 22], "lg\uadf8\ub8f9\uc740": 17, "lg\uc5d0\ub108\uc9c0\uc194\ub8e8\uc158\uc73c\ub85c": 21, "lg\uc720\ud50c\ub7ec\uc2a4": 15, "lg\uc804\uc790\ub294": [16, 20], "lg\ud654\ud559": [15, 21], "lg\ud654\ud559\uacfc": [15, 17], "lg\ud654\ud559\uc740": [15, 17, 21], "lg\ud654\ud559\uc758": 21, "lg\ud654\ud559\uc774": [15, 21], "lh": 33, "li": [0, 4, 7, 39, 42, 50, 53, 54, 60, 85, 87, 102, 112, 113, 115, 117, 127, 148, 152, 167, 172], "liabil": [99, 112, 113], "liali": 53, "liang": [0, 7], "liangzh": 0, "lib": [29, 31, 101, 102, 104, 109, 111, 112, 113, 115, 133, 136, 137, 142, 151], "liber": [0, 29, 112, 113, 121], "libertarian": [112, 113], "liberti": [112, 113], "libnvinf": 15, "libnvinfer_plugin": 15, "librari": [2, 13, 15, 23, 44, 48, 51, 61, 62, 65, 72, 73, 74, 76, 78, 90, 94, 95, 97, 98, 101, 105, 106, 111, 112, 113, 115, 120, 124, 125, 131, 133, 136, 137, 142, 143, 145, 147, 148, 153, 159, 160, 168, 171, 179], "licens": [18, 84, 89, 112, 113, 182], "lid": 121, "lide": 108, "lie": [85, 172, 175, 177, 178, 180], "lieuten": [112, 113], "lif": 102, "life": [2, 3, 4, 7, 61, 72, 94, 112, 113, 137, 153, 162, 163, 173], "lifecycl": [39, 61, 62, 64, 65, 66, 70, 72, 81, 160, 161, 162, 172, 173], "lifelik": 7, "lifetim": [60, 112, 113], "lift": 129, "ligatur": [112, 113], "light": [2, 5, 50, 106, 108, 112, 113, 115], "lightgbmmodelartifact": 74, "lightli": 94, "lightlink": 98, "lightn": [112, 113], "lightweight": [7, 61, 62, 63, 81, 84, 106], "like": [2, 3, 4, 7, 9, 10, 11, 13, 14, 15, 25, 27, 28, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 65, 66, 67, 68, 70, 72, 74, 75, 76, 77, 78, 81, 84, 85, 86, 87, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 139, 140, 141, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 166, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 186], "likelihood": [50, 65, 90, 91, 98, 101, 106, 107, 108, 116, 128, 129, 132, 134, 148, 152, 153, 160, 164, 168], "liken": 157, "likewis": 113, "limamu": [112, 113], "lime": 13, "limeston": [112, 113], "limit": [0, 6, 7, 10, 15, 40, 43, 44, 45, 46, 47, 53, 55, 58, 60, 61, 75, 77, 81, 84, 87, 90, 91, 94, 98, 99, 100, 101, 103, 112, 113, 116, 117, 118, 120, 122, 131, 133, 134, 136, 138, 139, 147, 148, 151, 152, 156, 157, 158, 167, 168, 171, 172, 173], "limit_alphabet": 113, "linalg": 151, "linchpin": 60, "line": [8, 25, 31, 57, 60, 62, 70, 74, 81, 82, 96, 102, 104, 112, 113, 118, 125, 136, 147, 153, 168, 174, 175, 176, 178, 179, 183, 186], "lineag": [72, 112, 113], "linear": [10, 40, 41, 53, 89, 113, 114, 117, 127, 128, 129, 133, 137, 139, 152, 172, 173, 181, 184], "linear1": 129, "linear2": 129, "linearli": [53, 117, 139, 152], "linearsvc": 137, "linearsvclinearsvc": 137, "lineplot": [24, 26, 27, 28, 32, 33], "linewidth": 33, "linger": [112, 113, 153], "lingual": [94, 96, 110, 123], "linguist": [0, 50, 90, 94, 100, 110, 114, 121, 122, 127, 129, 130, 131, 133, 136, 137, 151, 157], "link": [10, 11, 97, 112, 113, 120, 121, 127, 133, 179], "linkag": [112, 113], "lint": [0, 65, 160], "linux": [61, 62, 76, 82, 175], "liquid": [13, 153], "list": [1, 15, 18, 23, 24, 35, 44, 46, 50, 61, 66, 70, 80, 81, 90, 96, 101, 102, 103, 105, 106, 108, 109, 112, 113, 118, 120, 121, 124, 125, 127, 128, 129, 131, 133, 134, 135, 136, 138, 140, 142, 144, 145, 147, 148, 151, 153, 161, 167, 168, 172, 175, 179, 181, 182], "list_project": [21, 22], "listen": 141, "listseq": 95, "lit": [4, 137], "lite": 100, "liter": [112, 113, 135], "literaci": [86, 112, 113], "literari": [112, 113], "literatur": [7, 47, 50, 53, 94, 112, 113, 121], "lithuanian": 96, "litig": [112, 113], "littl": [7, 101, 112, 113, 115, 129, 139, 143, 151, 173], "liu": [0, 7, 53, 96, 100], "live": [4, 10, 17, 92, 112, 113, 131], "liwc": 127, "lkp19": 0, "ll": [65, 73, 95, 96, 98, 102, 104, 106, 111, 112, 113, 117, 133, 136, 137, 142, 143, 145, 153, 156, 159, 160, 174, 175, 176, 177, 178, 179, 183], "ll54": 184, "ll_per_word": 153, "llama": [53, 60], "llamaindex": 57, "llc": 102, "lldamodel": 153, "lleng": 109, "lli": 102, "llion": [0, 102], "llm": [2, 48, 49, 51, 60, 73, 85, 86, 87, 88, 98], "llm_config": 43, "llmop": [2, 71], "lm": [2, 32, 50, 85, 97, 110], "lm_col": 36, "lm_tone": [32, 33, 34], "lmsa": 31, "ln": 124, "lo": [0, 96, 102, 106, 120, 140], "load": [1, 7, 17, 18, 21, 23, 39, 51, 52, 53, 96, 101, 102, 106, 108, 109, 115, 120, 122, 124, 134, 136, 140, 145, 146, 156], "load_calendar": [24, 25, 32], "load_candid": 31, "load_data": [15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 129, 146, 153], "load_datafram": [17, 21, 29, 34], "load_dataset": [21, 95, 96, 102, 104, 108, 109, 111, 112, 113, 137], "load_dotenv": 124, "load_iri": 74, "load_metr": 111, "load_model": [15, 125], "load_vector": 125, "loader": [15, 16, 22], "loadrunn": 170, "loan": [0, 13, 78, 121], "lobbi": [13, 112, 113, 120], "loc": 33, "local": [1, 7, 8, 17, 18, 23, 31, 55, 61, 62, 67, 68, 69, 70, 77, 81, 82, 98, 111, 112, 113, 116, 120, 121, 126, 134, 137, 139, 146, 155, 170, 178, 179, 180, 181, 182, 183], "local_bar": 186, "local_machin": 52, "locat": [1, 7, 9, 13, 44, 61, 62, 67, 68, 80, 94, 99, 112, 113, 121, 123, 129, 131, 141, 146, 172], "loci": [112, 113], "lock": 153, "locomot": 7, "log": [9, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 35, 36, 42, 52, 61, 65, 73, 76, 77, 81, 85, 91, 100, 104, 106, 107, 108, 109, 111, 115, 122, 126, 128, 129, 133, 146, 148, 152, 153, 154, 156, 158, 160, 176, 177, 178, 180, 181, 182, 184, 186], "log2": 133, "log_2": 129, "log_dir": 112, "log_level": [15, 17, 20, 21, 22, 23], "log_max_bin": [30, 36], "log_prob": 129, "log_prob_sum": 133, "logarithm": [148, 159], "logcond": 153, "logging_dir": 111, "logic": [7, 50, 54, 55, 56, 58, 59, 90, 99, 106, 112, 113, 140, 164, 170], "login": [18, 23, 31], "logist": [13, 129, 135, 137, 139, 152], "logit": [89, 98, 111], "loglikelihood": 153, "loglog": 140, "logstash": [65, 66, 160, 161], "loha": 52, "lokr": 52, "london": [112, 113, 153], "lone": [112, 113], "loneli": [112, 113], "long": [0, 3, 7, 13, 14, 42, 47, 50, 53, 54, 84, 87, 99, 101, 103, 104, 106, 107, 112, 113, 114, 117, 118, 121, 129, 131, 133, 134, 135, 139, 146, 153, 156, 157, 158, 168, 172, 175], "longer": [17, 18, 20, 22, 31, 53, 56, 89, 98, 100, 105, 112, 113, 116, 117, 118, 129, 133, 146, 176], "longest": [102, 109, 111, 112, 113, 146], "longev": 170, "longleaf": [112, 113], "longtensor": [128, 129], "loo": 102, "look": [6, 7, 11, 51, 54, 57, 63, 65, 69, 89, 90, 98, 102, 105, 107, 109, 112, 113, 117, 127, 128, 129, 133, 136, 137, 140, 141, 142, 143, 145, 148, 151, 152, 153, 155, 159, 160, 172, 174, 177, 178, 179, 181, 183, 184], "lookup": [74, 128], "loop": [0, 7, 43, 44, 47, 56, 58, 60, 64, 72, 98, 108, 109, 112, 113, 129, 137, 146, 156, 172, 173], "loos": 11, "lope": [0, 7], "lora": 53, "lora_alpha": [46, 52], "lora_dreambooth": 52, "lora_dropout": [46, 52], "lora_linear": 53, "lora_r": [46, 52], "lora_text_encoder_alpha": 52, "lora_text_encoder_r": 52, "loraconfig": 52, "lorem": 118, "lorenzo": 0, "lose": [0, 51, 112, 113, 116, 117, 127, 144, 153, 168, 176], "loser": [102, 108], "loss": [7, 8, 9, 17, 18, 23, 54, 56, 86, 93, 100, 102, 106, 107, 109, 111, 112, 113, 117, 147, 153, 155], "loss0": [17, 18, 23], "loss1": 18, "loss_funct": 129, "lossi": 144, "lossless": 106, "lost": [112, 113, 144, 146], "lot": [4, 52, 98, 112, 113, 119, 131, 134, 140, 151, 158, 175, 184], "loud": [112, 113], "loughran": [31, 32, 120], "loui": 98, "louisian": [112, 113], "louisiana": [112, 113, 121], "louisvil": [112, 113], "louka": 0, "lovabl": 127, "love": [4, 98, 101, 112, 113, 133, 134, 144, 159], "lovelac": 6, "low": [0, 7, 10, 11, 13, 14, 36, 52, 53, 56, 75, 98, 102, 107, 110, 112, 113, 121, 128, 134, 142, 144, 148, 150, 153, 157, 158, 170], "low_cost_partial_config": 36, "lower": [9, 11, 85, 91, 94, 100, 102, 108, 109, 110, 112, 113, 116, 127, 129, 131, 133, 134, 137, 139, 143, 150, 151, 152, 153, 156], "lowercas": [102, 104, 105, 106, 108, 109, 112, 113, 137, 139, 147], "lowest": [89, 108, 109, 112, 113, 150], "lownd": [112, 113], "loyalist": [112, 113], "lpga": [112, 113], "lr": [17, 18, 23, 128, 129, 148], "lr_schedul": 52, "lr_warmup_step": 52, "lrb": 145, "lsa": [151, 155], "lsmt": 53, "lstm": [7, 42, 53, 100, 131, 135, 139], "lt": [96, 120], "lte": 18, "lu": 102, "luan": 100, "luca": 0, "lucidchart": 170, "lucidrain": [9, 10], "lucio": [0, 7], "lueck": [25, 31], "luggag": 100, "lumber": [112, 113], "lump": 109, "lunar": [112, 113, 151], "lunch": [25, 31], "luong": 100, "luther": [112, 113], "luxembourgish": 96, "lv": 96, "lve": 115, "ly": [102, 127, 140], "lymp": 109, "lymph": 109, "lympho": 109, "lymphom": 109, "lymphoma": 109, "lynch": [112, 113], "lyric": 17, "m": [0, 7, 15, 17, 18, 20, 21, 22, 23, 25, 38, 43, 54, 68, 69, 77, 80, 96, 98, 100, 102, 106, 109, 112, 113, 124, 130, 131, 134, 137, 140, 141, 145, 146, 148, 151, 152, 153, 175, 176, 177, 178, 179, 182], "m2": 35, "m2sl": 35, "m_": 148, "m_r": 148, "ma": [33, 102, 112, 113], "maarten": 0, "mabila": [112, 113], "mac": [62, 175], "macedonian": 96, "mach": 0, "machiel": 182, "machin": [0, 1, 2, 7, 8, 9, 10, 38, 39, 40, 41, 42, 46, 47, 48, 50, 53, 54, 56, 60, 65, 67, 68, 69, 73, 74, 75, 77, 79, 81, 82, 87, 88, 90, 92, 94, 97, 98, 99, 100, 101, 103, 105, 106, 107, 113, 119, 123, 127, 130, 132, 133, 134, 135, 136, 137, 141, 142, 143, 145, 146, 147, 149, 153, 154, 155, 156, 157, 160, 168, 170, 186], "machine_rank": 52, "mackenzi": [0, 7], "maco": [62, 80], "macro": [9, 15, 17, 23, 30, 31, 36, 120, 136, 137], "macroeconom": [119, 121], "made": [3, 4, 9, 10, 53, 54, 60, 64, 65, 68, 72, 93, 96, 112, 113, 117, 121, 122, 127, 128, 131, 137, 138, 160, 176, 177, 179, 181, 182, 184], "madison": [112, 113], "mae": [30, 36, 89], "mag": 142, "magazin": [112, 113], "mage": 6, "magenta": 3, "magic": [112, 113, 127, 174], "magnifi": [11, 60], "magnitud": [112, 113, 114, 148], "mai": [0, 9, 10, 11, 13, 21, 24, 41, 43, 45, 46, 47, 53, 58, 60, 61, 65, 67, 68, 70, 77, 78, 83, 84, 89, 90, 91, 92, 93, 94, 98, 99, 100, 101, 103, 104, 105, 112, 113, 114, 117, 121, 122, 131, 133, 134, 136, 137, 138, 139, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 157, 158, 159, 160, 167, 170, 171, 172, 173, 174, 176, 178, 181, 186], "mail": [137, 151], "main": [0, 7, 10, 24, 25, 31, 38, 42, 52, 53, 66, 68, 69, 76, 78, 81, 88, 90, 92, 98, 100, 101, 103, 105, 109, 110, 112, 113, 115, 117, 121, 131, 133, 134, 138, 139, 140, 143, 146, 147, 152, 153, 155, 156, 157, 161, 168, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 186], "main_rebase_carollian": 184, "main_training_funct": 52, "mainli": [98, 101, 106, 112, 113, 120, 167], "mainlin": 172, "mainstream": [112, 113], "maintain": [7, 9, 13, 39, 45, 47, 51, 53, 56, 57, 60, 62, 65, 67, 68, 71, 72, 75, 78, 79, 81, 82, 89, 90, 92, 94, 96, 98, 99, 112, 113, 117, 138, 139, 144, 160, 164, 166, 167, 168, 172, 174], "mainten": [56, 72, 112, 113, 162, 170, 172, 173], "maj": 142, "major": [51, 54, 60, 100, 112, 113, 117, 120, 121, 122, 131, 138, 140, 153, 155, 172], "majuscul": [112, 113], "make": [2, 4, 6, 7, 8, 9, 10, 11, 13, 15, 38, 39, 40, 42, 43, 45, 46, 47, 50, 51, 53, 54, 55, 58, 60, 61, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 78, 80, 81, 82, 84, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 124, 125, 127, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 146, 148, 149, 151, 152, 153, 155, 157, 160, 161, 165, 168, 172, 173, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186], "make_batch": 128, "make_doc": 153, "make_worker_lf": 21, "makedir": [124, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "makefil": 182, "maker": [6, 13, 37, 41, 131], "maketran": [137, 143], "makhno": [112, 113], "maladapt": [112, 113], "malagasi": 96, "malai": 96, "malatesta": [112, 113], "malayalam": 96, "male": [60, 112, 113], "malfunct": [112, 113], "malici": [53, 60, 78, 79, 93, 99], "malik": [0, 7], "maltes": 96, "mamidanna": [0, 7], "mammal": [84, 112, 113], "mammalian": 84, "man": [0, 10, 100, 102, 112, 113, 131, 157], "manag": [2, 7, 31, 43, 51, 54, 56, 58, 60, 62, 63, 69, 70, 71, 72, 74, 75, 76, 77, 81, 92, 101, 102, 112, 113, 117, 120, 121, 122, 124, 127, 129, 133, 134, 153, 162, 163, 165, 167, 168, 170, 171, 173, 174, 175, 187], "mandarin": 131, "mandat": 48, "mandatori": [70, 81], "mandir": [112, 113], "maneuv": 134, "mani": [6, 7, 24, 39, 41, 47, 54, 65, 66, 72, 74, 81, 90, 94, 97, 98, 99, 100, 101, 104, 106, 109, 112, 113, 116, 119, 123, 127, 128, 129, 130, 131, 133, 134, 137, 139, 141, 142, 143, 145, 146, 153, 155, 156, 157, 160, 161, 165, 174, 175, 179, 186], "mania": 151, "manifest": [43, 50, 65, 160], "manifesto": [121, 172], "manifold": [29, 139], "manipul": [7, 9, 10, 13, 93, 112, 113, 117, 122, 127, 131, 153], "manner": [2, 9, 10, 11, 53, 61, 65, 67, 69, 90, 92, 100, 112, 113, 117, 143, 152, 160, 167, 172], "manu": 0, "manual": [47, 60, 65, 66, 67, 72, 89, 94, 98, 105, 106, 112, 113, 121, 122, 133, 136, 139, 151, 160, 161, 165, 168, 170, 176, 178, 179], "manufactur": [112, 113, 121, 153], "manylinux2014_x86_64": [137, 151], "manylinux_2_17_x86_64": [137, 151], "maori": 96, "map": [7, 9, 18, 20, 24, 26, 27, 28, 56, 62, 99, 103, 106, 111, 112, 113, 125, 127, 128, 129, 137, 139, 140, 144, 151, 157], "map_datafram": 27, "mapreduc": 39, "mar": [0, 102, 112, 113, 151], "marathi": 96, "march": [102, 112, 113, 117, 153], "mardi": [112, 113], "marengo": [112, 113], "marga": 31, "margaret": 0, "margin": [41, 98, 112, 113, 116, 118, 153], "marginalis": [112, 113], "mari": [112, 113], "mark": [3, 7, 43, 51, 53, 54, 55, 73, 102, 112, 113, 115, 118, 127, 131, 140, 141, 145, 178], "markdown": [177, 182, 183], "markedli": [112, 113], "marker": [7, 112, 113, 131, 137, 140], "markerless": [0, 7], "market": [0, 2, 37, 41, 42, 50, 51, 60, 65, 66, 72, 99, 102, 112, 113, 119, 120, 121, 127, 129, 133, 135, 151, 153, 160, 161, 167, 168, 170, 172, 173], "marketplac": [66, 161], "markoff": 137, "markov": [145, 152], "marku": 0, "markup": [65, 160, 174], "maron": 0, "marri": [112, 113, 121], "marriag": [112, 113], "marshal": [112, 113], "martha": [112, 113], "martial": 7, "martian": 4, "martin": [35, 112, 113, 130], "marvel": 3, "marx": [112, 113], "marxism": [112, 113], "marxist": [112, 113], "masculin": 141, "mask": [9, 10, 83, 85, 96, 99, 101, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118], "mask_token": [112, 113], "mass": [98, 100, 112, 113, 134, 148, 150], "massiv": [0, 10, 11, 39, 53, 87, 89, 94, 96, 99, 112, 113, 114, 116, 123, 129, 157], "master": [10, 47, 54, 68, 78, 168, 172, 179, 184, 185, 186], "master_merge_carollian": 184, "masteri": 164, "mat": [8, 102, 133, 137, 154], "match": [0, 1, 6, 9, 10, 12, 53, 54, 56, 65, 78, 112, 113, 115, 117, 118, 124, 131, 141, 151, 153, 156, 160, 167], "matched_posit": 102, "matena": [0, 100], "materi": [38, 47, 53, 90, 112, 113, 122, 140, 151, 153, 165], "materialis": 140, "materiel": [112, 113], "matern": [112, 113], "math": [43, 108, 109, 130, 133, 147, 156], "mathbb": [9, 85, 106, 120], "mathbf": [106, 125, 126, 127], "mathcal": [9, 100, 106, 126, 129], "mathchat": 43, "mathemat": [6, 50, 54, 55, 78, 90, 98, 112, 113, 127, 131, 133, 148, 155, 165], "mathematician": 6, "mathesiu": [112, 113], "mathi": [0, 7], "matplotlib": [29, 95, 129, 137, 140, 150, 151, 156, 182], "matric": [51, 53, 100, 113, 151, 152, 159], "matrix": [53, 60, 116, 117, 120, 129, 137, 139, 144, 147, 149, 155, 156, 159, 170], "matter": [1, 60, 112, 113, 137, 174], "matthew": [0, 151], "matthia": [0, 7], "matur": [57, 64, 72, 112, 113, 121], "max": [18, 26, 31, 52, 102, 112, 113, 128, 129, 146, 156], "max_bin": [30, 36], "max_depth": 36, "max_featur": 137, "max_font_s": 137, "max_leav": 36, "max_length": [25, 31, 98, 101, 111, 112, 113], "max_position_embed": 113, "max_scor": 109, "max_sentence_length": [104, 106], "max_sentencepiece_length": [104, 106], "max_seq_length": [15, 17, 18, 20, 23, 31], "max_token": 101, "max_train_step": 52, "maxim": [10, 11, 45, 47, 55, 99, 101, 107, 117, 133, 146, 152], "maximum": [9, 10, 17, 18, 20, 22, 56, 89, 98, 104, 107, 111, 112, 113, 121, 134, 149, 172], "mayb": [175, 176, 177, 183], "mazdak": [112, 113], "mb": [15, 16, 22, 52, 102, 133, 136, 137, 151], "mbe": 108, "mber": 102, "mc4": [2, 94, 97, 110], "mc4_subset_with_five_languag": 96, "mc4gaussian": 96, "mcc": [15, 17, 18, 23], "mcdonald": [31, 32, 120], "mcdonough": 31, "mcgraw": 130, "mcmahon": 0, "mcmc": 152, "mct": 54, "md": [174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186], "mdl": 153, "me": [2, 6, 25, 31, 98, 102, 114, 131, 137, 141, 145, 151, 178, 181], "meal": [112, 113, 131], "mean": [2, 9, 10, 11, 26, 27, 28, 32, 33, 35, 47, 51, 53, 56, 65, 70, 85, 89, 92, 98, 99, 100, 106, 107, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 125, 126, 127, 129, 131, 133, 135, 138, 139, 140, 141, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 173, 175, 177, 178, 181], "meaning": [25, 38, 60, 69, 90, 94, 98, 103, 107, 110, 112, 113, 117, 119, 131, 141, 143, 146, 147, 149, 151, 152, 154, 157], "meaningfulli": [90, 147], "meant": [112, 113], "meantim": [112, 113], "meanwhil": [129, 153], "measur": [0, 2, 10, 11, 13, 24, 39, 56, 78, 79, 84, 86, 89, 92, 94, 99, 109, 110, 112, 113, 116, 119, 121, 130, 133, 134, 138, 144, 146, 149, 150, 153, 156, 158, 159, 166, 168, 171, 173], "measure_token_length": 102, "meat": 157, "mecab": [106, 143], "mechan": [9, 12, 39, 49, 55, 56, 57, 60, 78, 93, 99, 112, 113, 115, 116, 131, 139, 166], "medal": 131, "medi": 102, "media": [6, 17, 18, 23, 41, 42, 47, 60, 94, 99, 112, 113, 119, 121, 122, 131, 135, 136, 138, 142, 149, 152, 153], "median": 18, "mediatyp": 61, "medic": [6, 7, 8, 46, 47, 50, 72, 78, 93, 102, 110, 112, 113, 127, 131, 137], "medicar": [112, 113], "medicin": [93, 99, 112, 113], "mediev": [112, 113], "medium": [6, 11, 112, 113, 116], "meek": [112, 113], "meet": [0, 2, 13, 24, 25, 31, 37, 46, 47, 56, 64, 66, 72, 77, 87, 88, 94, 99, 112, 113, 138, 161, 164, 165, 166, 167, 168, 171, 172, 173], "megatron": 94, "megatron_lm_config": 52, "meiosi": [112, 113], "meld": 184, "melodi": 3, "melt": [112, 113], "meltdown": [112, 113], "melvil": 140, "melvin": [112, 113], "mem": 18, "member": [31, 37, 43, 64, 65, 76, 81, 82, 84, 112, 113, 160, 168, 173], "membership": [112, 113], "memor": [112, 113], "memori": [7, 9, 15, 16, 22, 39, 42, 50, 52, 53, 57, 60, 101, 103, 106, 111, 112, 113, 131, 133, 135, 139, 144, 146, 155], "memoryless": 133, "memphi": [112, 113], "men": [102, 112, 113], "mendelian": [112, 113], "ment": [102, 108, 109, 146], "mental": [99, 112, 113], "mention": [15, 81, 112, 113, 115, 118, 121, 131, 135, 139, 144, 168, 171], "menu": [111, 112, 113, 179], "meokda": 131, "mer": 102, "merced": [112, 113], "merchant": 153, "mercuri": [70, 112, 113, 174, 186], "mere": [39, 43, 47, 50, 60, 112, 113, 127], "meredith": 185, "merg": [9, 15, 16, 20, 22, 24, 25, 34, 35, 51, 54, 55, 56, 66, 101, 106, 107, 113, 127, 149, 161, 172, 173, 174, 176, 179, 180, 182, 187], "merge_output": [16, 21, 25, 31], "merge_pair": 109, "merge_vocab": 102, "merged_tone_data": [32, 33, 34], "merger": 102, "merit": 127, "meronym": 138, "merovingian": [112, 113], "mesoamerican": [112, 113], "messag": [25, 43, 47, 69, 73, 77, 78, 92, 112, 113, 118, 122, 131, 151, 175, 176, 178, 185], "messi": 72, "met": [25, 98, 102, 112, 113, 137], "meta": [16, 58, 60, 84, 101, 106], "meta_column": [15, 20], "meta_fil": [18, 23, 29], "meta_piec": [104, 106], "metabol": [112, 113], "metabolit": [112, 113], "metadata": [15, 16, 17, 18, 20, 39, 72, 94, 104, 122, 136, 137, 153, 184], "metagpt": [43, 45], "metal": [76, 112, 113, 153], "metamodel": 11, "meteor": 153, "meteorit": [112, 113], "meteosat": [112, 113], "meter": [41, 112, 113], "method": [0, 2, 7, 8, 10, 11, 13, 17, 18, 20, 22, 30, 31, 38, 39, 40, 47, 54, 55, 56, 60, 67, 77, 78, 79, 83, 85, 89, 90, 94, 96, 98, 99, 101, 102, 105, 106, 107, 110, 111, 112, 113, 117, 119, 120, 121, 122, 124, 127, 128, 129, 130, 131, 133, 134, 135, 136, 141, 142, 143, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 164, 165, 170, 173, 179], "methodist": [112, 113], "methodolog": [51, 112, 113], "methodologi": [2, 7, 38, 42, 51, 53, 65, 66, 72, 97, 120, 122, 130, 149, 160, 161, 162, 163, 164, 166, 168, 170, 171, 173], "methylphenid": [112, 113], "meticul": [56, 58, 173], "metric": [5, 7, 13, 15, 17, 18, 20, 43, 46, 54, 56, 60, 64, 66, 72, 75, 76, 81, 90, 92, 110, 111, 113, 133, 134, 136, 137, 145, 148, 158, 161, 168], "metropolitan": [112, 113], "metzler": 0, "mexico": [112, 113, 153], "mfa": [78, 79], "mg": 96, "mgldamodel": 153, "mgm": [112, 113], "mhmg": 137, "mi": [96, 102], "mi_lik": 150, "miami": 120, "mib": [23, 104], "mic": 102, "mice": [7, 112, 113], "michael": [0, 102, 112, 113], "michal": 0, "mickei": 134, "microk8": 82, "micron": 129, "microscopi": 89, "microservic": [56, 72, 73], "microsoft": [6, 36, 43, 60, 86, 94, 123, 131, 170], "microwav": [112, 113], "mid": [100, 102, 112, 113], "middl": [112, 113, 148], "midjournei": [6, 131], "midland": [112, 113], "midlatitud": [112, 113], "midlif": [112, 113], "midterm": [48, 97, 130, 162], "midwest": [112, 113], "midwestern": [112, 113], "mig": 113, "might": [3, 10, 25, 42, 46, 47, 50, 51, 55, 64, 65, 75, 93, 98, 101, 104, 105, 106, 111, 112, 113, 116, 117, 127, 129, 131, 133, 134, 135, 137, 138, 139, 140, 141, 145, 148, 151, 152, 158, 160, 177, 180, 182, 183, 184, 186], "migrat": [70, 112, 113], "mihir": 0, "mike": [98, 112, 113], "mikhail": [112, 113], "mikolov": [0, 129], "mild": [112, 113], "mildli": 153, "mile": [60, 112, 113], "mileston": [54, 86, 94, 112, 113, 167, 168, 171, 172, 173], "milieu": [112, 113], "milit": [112, 113], "militari": [112, 113], "militia": [112, 113], "milk": [112, 113], "mill": [112, 113], "million": [10, 53, 89, 112, 113, 114, 118, 123, 125, 131, 140, 153], "millionair": 131, "millisecond": 89, "mime": 78, "mimic": [6, 7, 91, 92], "mimick": [43, 54], "min": [6, 18, 26, 102, 131, 156], "min_cf": 153, "min_child_sampl": [30, 36], "min_child_weight": 36, "min_df": [151, 153], "min_frequ": [104, 113, 146], "min_length": 25, "minchul": 0, "mind": [3, 11, 56, 77, 86, 98, 112, 113, 131, 156], "minder": 0, "mindsey": [6, 131], "mine": [0, 60, 99, 112, 113, 135, 149, 152, 153, 178], "miner": [112, 113], "ming": 0, "mingyuan": [0, 7], "mini": [9, 129, 133, 167], "minibatch": [16, 17, 18, 21, 25, 31], "minibatch_s": [16, 21, 25, 31], "minim": [7, 10, 11, 13, 25, 51, 53, 56, 60, 65, 66, 89, 98, 99, 101, 112, 113, 116, 117, 118, 147, 149, 152, 160, 161, 164, 167, 173], "minimagen": 11, "minimalist": [61, 63], "minimis": 9, "minimum": [98, 112, 113, 153], "minor": [47, 99, 112, 113, 118], "minu": [112, 113, 136, 175], "minuscul": [112, 113], "minut": [0, 7, 13, 31, 37, 120, 138, 183], "mirror": [2, 47, 54, 67, 112, 113, 122, 157], "misappropri": [112, 113], "misc": [151, 153], "miscellan": 153, "misconcept": [112, 113], "misconfigur": [65, 160], "misdiagnos": [112, 113], "misgoogl": 140, "misinform": [54, 84, 93, 94], "mislabel": 94, "mislead": [50, 131, 150], "mismatch": [10, 11, 56], "misrepres": 138, "miss": [11, 15, 90, 98, 99, 100, 102, 108, 112, 113, 116, 118, 151, 153], "missil": 134, "mission": [72, 151], "mississippi": [112, 113], "mississippian": [112, 113], "misspel": 146, "mist": 102, "mistak": [2, 43, 94, 131, 137, 162, 174, 187], "mistaken": [112, 113], "misunderstand": [112, 113], "misus": [54, 60, 75, 86, 99, 131], "mit": [21, 54, 78, 102], "mitchel": [0, 85, 130], "mitig": [13, 47, 50, 51, 54, 55, 56, 58, 60, 75, 78, 84, 86, 93, 94, 98, 99, 107, 117, 122, 167, 168, 171, 173], "mix": [7, 10, 41, 98, 112, 113, 140, 152, 180], "mixed_precis": 52, "mixtur": [13, 112, 113, 148, 149, 152], "mk": 96, "mkdir": [81, 82, 186], "ml": [2, 53, 73, 74, 75, 76, 78, 79, 81, 96, 98, 113, 130, 135, 143], "mle": 134, "mle_mu": 133, "mle_p": 133, "mle_sigma": 133, "mlfoundat": 10, "mlk": 0, "mlm": [2, 97, 110, 114], "mlm_probabl": 113, "mlop": [2, 57, 71, 75, 83], "mlp": [89, 117], "mm": 143, "mmc": [0, 7], "mment": 108, "mmlu": 86, "mmr": [112, 113], "mn": 96, "mnli": [101, 118], "mnt": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "mo": 102, "mob": [112, 113], "mobi": 140, "mobil": [72, 102, 112, 113, 170], "mobilenetv2": 7, "moby_dick": 140, "mocap": 7, "mockup": 170, "mod": 125, "modal": [10, 51, 92, 117], "mode": [1, 7, 112, 113, 175, 177, 178, 182, 184, 186], "model": [0, 1, 2, 5, 9, 15, 18, 20, 22, 30, 31, 33, 36, 38, 39, 40, 42, 43, 45, 46, 47, 49, 53, 55, 57, 59, 64, 68, 71, 72, 74, 81, 84, 85, 86, 88, 89, 92, 94, 95, 97, 98, 101, 103, 104, 106, 109, 114, 115, 117, 121, 122, 123, 126, 127, 130, 131, 135, 136, 138, 140, 144, 150, 157, 158, 162, 166, 169, 170, 172], "model_cfg": [17, 18, 20, 22, 23, 30, 31, 36], "model_dir": 15, "model_econ": 36, "model_engin": 101, "model_filenam": 125, "model_finbert": 36, "model_input": [31, 53], "model_lm": 36, "model_loss": [108, 109], "model_max_length": 31, "model_nam": [46, 52, 101], "model_name_or_path": [15, 23, 52], "model_pr": 129, "model_prefix": [104, 106], "model_s": 113, "model_select": 137, "model_t5": 36, "model_typ": [104, 106, 115], "model_vers": [22, 115], "model_view": 115, "model_without_token": [108, 109], "moder": [99, 112, 113, 131], "modern": [7, 10, 42, 45, 53, 60, 65, 70, 77, 112, 113, 122, 134, 147, 160, 186], "moderna": [112, 113], "modest": [112, 113], "modi": [112, 113], "modif": [10, 47, 51, 53, 54, 55, 58, 61, 65, 98, 100, 116, 118, 160, 173], "modifi": [8, 10, 47, 51, 53, 55, 65, 85, 89, 90, 99, 110, 112, 113, 116, 121, 122, 129, 131, 137, 144, 160, 165, 175, 177, 182], "modified_info": 18, "modnet": 8, "modul": [7, 51, 53, 70, 72, 78, 79, 105, 112, 113, 115, 124, 128, 129, 137, 145, 148, 151, 164, 170, 173], "modular": [60, 61, 63, 67, 72], "module_nam": 70, "mohl": [112, 113], "molecul": [65, 160], "mollusk": [112, 113], "molyneux": [112, 113], "moment": 177, "momentum": [112, 113], "mon": [102, 181, 185], "monarchi": [112, 113], "monast": [112, 113], "mone": 102, "monei": [112, 113, 137, 153], "monetari": [0, 2, 13, 24, 37, 38, 112, 113, 138], "monetarypolici": [24, 37], "mong": 96, "mongolian": 96, "moni": [112, 113], "monitor": [56, 59, 60, 61, 64, 65, 71, 72, 74, 76, 82, 83, 86, 99, 131, 135, 160, 164, 170], "monocular": 7, "monolingu": [96, 123], "monolith": [39, 94], "monopoli": [112, 113], "monster": 184, "mont": [54, 152], "montgomeri": [112, 113], "month": [32, 86, 102, 112, 113, 118, 120, 121, 122, 129, 137, 138, 153, 168], "monthli": [96, 112, 113, 120, 138, 168], "monument": [112, 113], "mood": [41, 112, 113, 141], "moon": [11, 31, 112, 113, 151], "moor": [112, 113, 179], "mor": 102, "moral": [112, 113, 172], "morbid": [112, 113], "more": [4, 6, 7, 9, 10, 11, 13, 14, 26, 31, 36, 39, 41, 42, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 109, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 166, 167, 168, 171, 172, 173, 174, 175, 179], "moreov": [10, 50, 60, 72, 93, 103, 112, 113, 139, 170], "morgan": [86, 112, 113], "morin": 129, "mormon": [112, 113], "morn": [25, 112, 113, 120], "morph": 142, "morphem": [0, 141, 142], "morpholog": [116, 122, 131, 142, 143], "morphologi": [7, 97, 107, 116, 130, 131, 155], "morri": [112, 113], "mortal": [112, 113, 154], "mosaicml": 60, "moscow": [112, 113], "mose": 106, "mosqu": [112, 113], "most": [6, 7, 9, 10, 12, 27, 28, 42, 43, 47, 51, 53, 54, 56, 58, 67, 70, 77, 78, 81, 84, 86, 87, 90, 91, 94, 96, 98, 100, 102, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 124, 127, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 147, 148, 150, 152, 153, 154, 155, 157, 159, 172, 176, 178], "mostafa": 0, "mostli": [112, 113], "mother": [112, 113], "motion": [0, 2, 5], "motiondiffus": 0, "motiv": [90, 112, 113, 117, 164, 172, 173], "motor": [112, 113], "motorsport": [112, 113], "mou": 21, "moun": 102, "mound": [112, 113], "moundvil": [112, 113], "mount": [61, 62, 73, 101, 112, 113, 124, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "mount_google_dr": [15, 17, 18, 20, 21, 22, 23], "mountain": [17, 101, 102, 112, 113, 175, 176, 177, 178, 180, 181, 182, 183, 186], "mountaintop": [112, 113], "mous": [7, 101], "move": [7, 10, 43, 47, 50, 54, 74, 80, 82, 89, 102, 111, 112, 113, 116, 129, 131, 137, 153, 167, 174, 180, 184], "movement": [7, 112, 113, 120, 133], "movi": [101, 111, 112, 113, 118, 123, 135, 138, 139, 150, 151], "movie_review": 136, "mowa": [112, 113], "mozumder_prov": 150, "mp": 121, "mpb": 121, "mpl": 109, "mply": 109, "mpqa": 139, "mpurver": 0, "mr": [25, 31, 96, 140], "mrpc": 52, "msc": 0, "mscoco": 123, "mse": [30, 36], "msl": [112, 113], "mt": [94, 96], "mt0": 52, "mt5": 0, "mtl": 11, "mu": [9, 102, 129, 133, 152], "much": [10, 13, 25, 47, 53, 72, 89, 94, 98, 112, 113, 114, 115, 116, 117, 127, 129, 140, 141, 146, 147, 155, 157, 174, 179], "multi": [7, 52, 53, 54, 58, 60, 62, 63, 78, 79, 80, 84, 89, 112, 113, 115, 127, 131, 137, 153, 155], "multi_label": [15, 17, 18, 20], "multidimension": 10, "multifacet": 56, "multifari": 39, "multifilesentenceiter": [104, 106], "multigen": [112, 113], "multiinst": 175, "multilay": [89, 117], "multilingu": [0, 10, 50, 96, 106, 110, 116, 122, 123, 131], "multimedia": 47, "multimod": [0, 6, 50, 86, 89, 92, 122, 123, 131], "multinomi": [129, 152, 153], "multipl": [0, 2, 7, 10, 13, 39, 40, 43, 45, 52, 53, 54, 56, 57, 60, 62, 65, 66, 67, 70, 72, 89, 92, 94, 98, 101, 106, 107, 110, 112, 113, 114, 116, 117, 118, 123, 129, 131, 135, 138, 140, 141, 142, 143, 148, 152, 154, 158, 160, 161, 162, 165, 171, 172, 173, 187], "multipli": [53, 60, 98, 117, 127, 129, 133, 134, 152], "multitask": [52, 99, 100, 118], "multitud": [112, 113], "mun": 102, "mung": 74, "municip": [112, 113], "murthi": [0, 7], "muscl": [112, 113], "muscoge": [112, 113], "musenet": 3, "museum": [112, 113], "music": [2, 5, 7, 112, 113, 150], "musician": 3, "muskoge": [112, 113], "muskogean": [112, 113], "muslim": [112, 113], "must": [2, 10, 11, 13, 39, 46, 47, 54, 78, 92, 93, 99, 112, 113, 116, 117, 131, 134, 139, 166, 170, 172, 173], "mutat": [112, 113, 116], "mute": [112, 113], "mutual": [112, 113], "mutualist": [112, 113], "mv": [82, 104], "my": [25, 31, 61, 67, 69, 86, 96, 98, 100, 102, 112, 113, 117, 121, 124, 131, 137, 145, 151, 174, 175, 178], "my_copier_templ": 70, "my_vc": 174, "mydriv": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "myfil": 182, "mygitserv": 186, "mymachin": 186, "myron": [112, 113], "myself": [151, 178], "mysteri": 4, "myth": [112, 113], "m\u00e1rmol": [112, 113], "n": [0, 2, 7, 16, 20, 25, 29, 43, 50, 52, 96, 98, 100, 101, 102, 104, 106, 107, 109, 112, 113, 115, 116, 117, 120, 121, 128, 129, 130, 132, 134, 137, 139, 140, 143, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 182], "n1": 95, "n15th": [112, 113], "n1760": [112, 113], "n1819": [112, 113], "n1910": [112, 113], "n1980\ub144\ub300": 16, "n2019": 95, "n20th": [112, 113], "n21st": [112, 113], "n4": 133, "n___________________________________________________": 136, "n_c": 120, "n_class": 128, "n_compon": 151, "n_ctx": 112, "n_d": 120, "n_e": 127, "n_embd": 112, "n_estim": [30, 36], "n_featur": 144, "n_head": 112, "n_i": [120, 127], "n_k": 120, "n_layer": 112, "n_neighbor": 29, "n_posit": 112, "n_w": 127, "n_x": 127, "na": [18, 112, 113, 153], "nabout": [112, 113], "naccord": [112, 113], "naccredit": [112, 113], "nacion": [112, 113], "naerosol": [112, 113], "nafrican": [112, 113], "nafter": [112, 113], "nagricultur": [112, 113], "naiv": [112, 113, 135, 138], "naive_seg": 146, "nalabama": [112, 113], "nalbedo": [112, 113], "naltern": [112, 113], "nalthough": [112, 113], "nam": 102, "name": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 36, 52, 55, 61, 62, 65, 70, 72, 73, 77, 80, 82, 83, 96, 98, 99, 101, 104, 106, 111, 112, 113, 114, 117, 120, 123, 124, 126, 127, 129, 131, 137, 140, 142, 146, 152, 153, 155, 160, 170, 171, 177, 178, 182, 183, 186], "nameerror": 104, "namong": [112, 113], "namoo": 122, "nan": [26, 27, 28, 31, 32, 33, 35, 112, 113], "nanalysi": [112, 113], "nanarch": [112, 113], "nanarchist": [112, 113], "nanarcho": [112, 113], "nancestor": [112, 113], "nancestri": [112, 113], "nani": [112, 113], "nano": [81, 175], "nanoth": [112, 113], "nanti": [112, 113], "naquacultur": [112, 113], "narang": [0, 100], "narasimhan": 100, "narctic": [112, 113], "narea": [112, 113], "naround": [112, 113], "narr": [13, 54], "narrow": [54, 90, 98, 101, 112, 113], "narrowli": [112, 113], "narticl": [112, 113], "nasa": [112, 113, 151], "nascar": [112, 113], "nascent": 41, "nasd": [112, 113], "nasdaq": [129, 153], "nasti": 176, "nat": [32, 112, 113], "natchez": [112, 113], "nathan": [112, 113], "nation": [0, 13, 14, 94, 102, 112, 113, 121, 142, 153], "nationwid": [112, 113], "nativ": [57, 61, 63, 112, 113], "natur": [0, 2, 3, 6, 9, 10, 12, 41, 42, 45, 47, 48, 51, 53, 54, 56, 58, 60, 72, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 108, 111, 112, 113, 114, 117, 118, 121, 122, 123, 126, 127, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 152, 154, 155, 156, 157, 158, 159, 166, 168, 173], "naturalist": [112, 113], "naughti": 118, "nautism": [112, 113], "nautist": [112, 113], "nautomak": [112, 113], "naver": 122, "naviat": [112, 113], "navig": [1, 7, 39, 44, 46, 51, 54, 69, 81, 82, 122, 149, 152, 179], "na\u00efv": 139, "nb": 182, "nbank": [112, 113], "nbc": [112, 113], "nbecaus": [112, 113], "nbefor": [112, 113], "nbegin": [112, 113], "nbest_siz": 106, "nbeyond": [112, 113], "nblack": [112, 113], "nbrasfield": [112, 113], "nbviewer": [30, 36, 137], "nby": [112, 113], "ncaa": [112, 113], "ncahaba": [112, 113], "ncaus": [112, 113], "ncbi": 122, "nce": 129, "ncensu": [112, 113], "ncharacterist": [112, 113], "nchildren": [112, 113], "ncitat": [112, 113], "nciti": [112, 113], "ncivil": [112, 113], "nclassic": [112, 113], "nclassif": [112, 113], "nclimat": [112, 113], "nclimatologi": [112, 113], "nclinic": [112, 113], "ncloud": [112, 113], "ncol": [24, 25, 26, 150], "ncolleg": [112, 113], "ncommun": [112, 113], "ncomput": [112, 113], "nconstruct": [112, 113], "ncontemporari": [112, 113], "ncontigu": [112, 113], "ncontinu": [112, 113], "nconvers": [112, 113], "ncounti": [112, 113], "ncryoconit": [112, 113], "ncultur": [112, 113], "nd": 146, "ndarrai": [15, 23], "ndemograph": [112, 113], "nder": 108, "nderiv": [112, 113], "ndescend": [112, 113], "ndespit": [112, 113], "ndiagnosi": [112, 113], "ndraw": [112, 113], "ndure": [112, 113], "ndustri": 108, "ne": [96, 102, 120], "neal": [112, 113], "nealanalyt": 72, "nearbi": [85, 112, 113, 129, 158], "nearest": [9, 56, 80, 120], "nearli": [112, 113, 121], "nearth": [112, 113], "neater": 184, "neccessari": 151, "necesari": 179, "necess": [51, 53, 173], "necessari": [1, 24, 43, 47, 56, 60, 61, 62, 72, 81, 83, 90, 93, 98, 101, 105, 106, 109, 110, 111, 112, 113, 115, 117, 119, 122, 123, 124, 127, 135, 137, 138, 142, 143, 144, 147, 148, 151, 173, 187], "necessarili": [7, 11, 112, 113], "necessit": [39, 42, 47, 51, 53, 56, 58], "neck": 101, "neconom": [112, 113], "neconomi": [112, 113], "neduc": [112, 113], "need": [0, 6, 7, 9, 10, 11, 13, 26, 42, 43, 46, 47, 50, 52, 53, 54, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 121, 122, 123, 124, 128, 129, 131, 133, 136, 137, 139, 140, 141, 142, 143, 147, 148, 151, 152, 153, 155, 156, 158, 160, 161, 164, 165, 166, 168, 169, 172, 173, 174, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186], "neg": [10, 15, 17, 20, 21, 22, 23, 31, 78, 85, 91, 94, 99, 101, 106, 108, 111, 112, 113, 114, 115, 118, 120, 121, 128, 131, 133, 135, 136, 137, 138, 139, 148, 150, 156, 158], "negat": [13, 135], "negoti": 172, "nei": [96, 134], "neighbor": [56, 128, 129, 139], "neill": [112, 113], "neither": 54, "nelect": [112, 113], "nelectromagnet": [112, 113], "nelectron": [112, 113], "nemploy": [112, 113], "nenceladu": [112, 113], "nenglish": [112, 113], "neo": [112, 113], "neolog": [112, 113, 142], "nepali": 96, "nepidemiologi": [112, 113], "ner": [123, 126], "nerdyrod": 10, "nerv": [112, 113], "nervou": [112, 113], "ness": 146, "nest": [89, 127, 146], "nestor": [112, 113], "net": [0, 10, 11, 98, 102, 112, 113, 153], "network": [0, 6, 9, 10, 12, 15, 17, 23, 39, 42, 49, 50, 51, 53, 55, 56, 58, 62, 66, 74, 77, 78, 79, 82, 83, 87, 88, 89, 92, 94, 98, 99, 101, 103, 106, 112, 113, 114, 115, 117, 118, 119, 128, 129, 131, 135, 140, 145, 153, 155, 161, 179], "netymologi": [112, 113], "netzer": [0, 121], "neural": [0, 2, 6, 9, 11, 15, 23, 42, 49, 50, 51, 55, 74, 87, 88, 89, 90, 92, 94, 98, 99, 100, 101, 103, 104, 106, 112, 113, 114, 115, 117, 119, 129, 130, 132, 135, 140, 145, 155], "neurip": [90, 100], "neurodevelop": [112, 113], "neurodevelopment": [112, 113], "neurodivers": [112, 113], "neurogenet": [112, 113], "neuroimag": [112, 113], "neuroinflamm": [112, 113], "neurolog": [112, 113], "neurologi": [112, 113], "neuromorph": 51, "neuron": [89, 114, 115, 129, 131], "neuron_model": 115, "neuron_token": 115, "neuron_view": 115, "neuropean": [112, 113], "neuropsycholog": [112, 113], "neuropsychologist": [112, 113], "neurosci": [0, 7], "neuroscientist": [7, 112, 113], "neurotyp": [112, 113], "neuter": 141, "neutr": 102, "neutral": [15, 17, 20, 21, 22, 23, 31, 99, 102, 111, 112, 113, 118, 135, 137, 138], "never": [10, 89, 101, 112, 113, 131, 133, 134, 137, 140, 148, 151, 175], "nevertheless": 133, "nevolutionari": [112, 113], "new": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 17, 18, 23, 39, 42, 43, 46, 47, 50, 51, 52, 53, 54, 56, 57, 60, 61, 62, 65, 67, 72, 77, 78, 79, 81, 83, 84, 85, 89, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 127, 129, 130, 131, 133, 134, 135, 136, 137, 138, 140, 141, 142, 144, 145, 147, 148, 149, 151, 152, 153, 155, 160, 164, 170, 173, 174, 175, 181, 183, 184, 185, 186], "new_token": 109, "new_topic_dataset": 17, "new_usernam": 82, "newborn": 140, "newer": [91, 112, 113], "newest": 136, "newli": [15, 17, 18, 23, 79, 111, 112, 113, 179, 186], "newlin": [113, 125], "newman": 153, "news_data_dir": 15, "news_sent": 134, "news_slic": [15, 22], "newsgroup": 151, "newsgroups_test": 151, "newsgroups_train": 151, "newspap": [112, 113, 120, 122], "nex": 102, "nexampl": [112, 113], "nexposur": [112, 113], "next": [2, 6, 9, 10, 11, 25, 31, 37, 38, 43, 53, 57, 61, 63, 77, 79, 87, 93, 98, 100, 102, 105, 107, 108, 109, 110, 111, 112, 113, 114, 118, 124, 129, 131, 133, 136, 137, 144, 145, 150, 151, 152, 154, 157, 159, 172, 173, 177, 178], "next_decis": [25, 26, 27, 28, 31], "next_meet": [25, 31], "next_rat": [25, 31], "next_start": [108, 109], "next_word": 134, "next_word_candid": 134, "next_word_prob": 134, "nextern": [112, 113], "nfar": [112, 113], "nfc": 105, "nfd": 105, "nfeder": [112, 113], "nfew": [112, 113], "nfinal": [112, 113], "nfkc": [105, 106], "nfkd": 105, "nfl": 152, "nflora": [112, 113], "nfollow": [112, 113], "nfootnot": [112, 113], "nfor": [112, 113], "nfriedrich": [112, 113], "nfrom": [112, 113], "nft": 4, "nfurther": [112, 113], "ng": [102, 108, 133, 153], "ngastrointestin": [112, 113], "ngc": [133, 136, 137, 142, 151], "ngender": [112, 113], "ngener": [112, 113], "ngeographi": [112, 113], "nginx": [61, 65, 160], "nginx_instal": [65, 160], "nglobal": [112, 113], "ngr": 108, "ngra": 108, "ngrad": 108, "ngrade": 108, "ngram": [31, 133, 134, 144], "ngrams_count": 133, "ngt": 108, "nh": [112, 113], "nhealth": [112, 113], "nhealthcar": [112, 113], "nhistori": [112, 113], "nhttp": 95, "nhuman": [112, 113], "ni": [25, 102], "nice": [98, 137, 176, 185], "nich": 60, "nichol": 11, "nichola": 0, "nicknam": [112, 113], "nielsen": [0, 136], "night": [4, 6, 17, 131, 137], "nightcaf": [6, 131], "nightmareai": [6, 131], "nihil": [112, 113], "niki": 0, "nikkei": 153, "nillumin": [112, 113], "nimmigr": [112, 113], "nin": [112, 113], "nincept": [112, 113], "nindigen": [112, 113], "nindividualist": [112, 113], "nindustri": [112, 113], "nine": [10, 86, 112, 113, 123, 141], "nineteen": [112, 113], "nineteenth": [112, 113], "ning": 108, "ninja": [112, 113], "ninsol": [112, 113], "ninth": [112, 113], "nippon": [112, 113], "niso": [112, 113], "nissan": 153, "nit": [112, 113], "nital": [112, 113], "nix": 70, "nj": 130, "njew": [112, 113], "njust": [112, 113], "nkanner": [112, 113], "nkb\uc99d\uad8c\uc774": 20, "nke": 108, "nkei": [112, 113], "nl": [96, 131], "nland": [112, 113], "nlanguag": [112, 113], "nlargest": [112, 113], "nlate": [112, 113], "nlaw": [112, 113], "nleft": [112, 113], "nlegal": [112, 113], "nlegion": [112, 113], "nlg": [92, 94], "nlh19": 0, "nlibertarian": [112, 113], "nliteratur": [112, 113], "nlocal": [112, 113], "nlp": [2, 11, 12, 37, 42, 50, 53, 54, 87, 92, 99, 103, 105, 106, 107, 108, 110, 111, 113, 114, 116, 117, 126, 127, 133, 134, 135, 136, 140, 142, 144, 145, 147, 154, 155, 156, 157, 158, 159, 166], "nlp_deep": 97, "nlte": 18, "nltk": [13, 130, 134, 136, 137, 140, 142, 143, 144, 145, 150, 151, 153, 156], "nltk_data": [133, 134, 136, 143, 151, 156], "nlu": [58, 92], "nm": 89, "nmajor": [112, 113], "nmale": [112, 113], "nmanag": [112, 113], "nmani": [112, 113], "nmatern": [112, 113], "nmechan": [112, 113], "nmedia": [112, 113], "nmedic": [112, 113], "nmember": [112, 113], "nmf": 139, "nmi_dat": 24, "nmi_diff_year": 24, "nmobil": [112, 113], "nmodern": [112, 113], "nmost": [112, 113], "nmt_nfkc": [104, 106], "nmuslim": [112, 113], "nmutual": [112, 113], "nn": [54, 56, 128, 129, 131, 145], "nneurolog": [112, 113], "nng": [142, 143], "nnlm": 128, "nno": [112, 113], "nnon": [112, 113], "nnotabl": [112, 113], "nnote": [112, 113], "nnp": 145, "no_deprecation_warn": [111, 113], "no_repeat_ngram_s": 98, "noah": 0, "noam": 0, "nobject": [112, 113], "noccalula": [112, 113], "nocturn": [112, 113], "node": [39, 54, 58, 61, 63, 89, 114, 129, 131], "node_num": 104, "nodej": 70, "nof": [112, 113], "nofollow": 122, "nois": [7, 10, 11, 13, 46, 56, 89, 94, 110, 112, 113, 139, 147, 148, 149, 151], "noisi": [94, 116, 118, 146, 149], "noisier": 10, "nokai": 25, "nom": 108, "nomin": [131, 141], "nomo": [112, 113], "non": [11, 13, 15, 16, 22, 40, 53, 84, 89, 112, 113, 117, 118, 120, 121, 122, 128, 131, 134, 139, 144, 149, 153, 167, 168, 178, 179, 184], "noncommerci": 84, "nonconsci": 98, "none": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 101, 108, 109, 111, 112, 113, 133, 136, 151, 153], "nonetheless": [112, 113], "nonli": [112, 113], "nonlinear": [7, 41, 129], "nonsens": 50, "nonverb": [112, 113], "nonviol": [112, 113], "nope": 151, "noplugin": 175, "noptic": [112, 113], "nor": [54, 102, 108, 112, 113, 140], "norigin": [112, 113], "norm": [10, 112, 113], "normal": [10, 11, 53, 56, 89, 90, 104, 106, 112, 113, 114, 117, 118, 120, 122, 127, 128, 133, 134, 138, 143, 146, 147, 152, 179], "normalis": 129, "normalization_rule_tsv": [104, 106], "normalize_str": 105, "normalizer_spec": [104, 106], "north": [112, 113], "northeast": [112, 113], "northeastern": [112, 113], "northern": [18, 112, 113], "northernmost": [112, 113], "northport": [112, 113], "northwest": [112, 113], "norwegian": 96, "nosess": 175, "notabl": [7, 8, 12, 13, 43, 60, 72, 87, 102, 112, 113, 117, 131, 157], "notat": [112, 113, 181], "notch": 137, "note": [15, 52, 69, 77, 78, 80, 90, 98, 106, 112, 113, 127, 129, 131, 133, 134, 136, 137, 142, 150, 151, 156, 157, 166, 170, 174, 175, 176, 177, 178, 179, 181, 184, 186], "notebook": [16, 18, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 43, 52, 98, 113, 137, 153, 174, 178], "notebook_tqdm": [101, 102, 104, 109, 111, 112, 113, 115, 137], "notepad": 175, "notetak": [112, 113], "noteworthi": [39, 43, 60], "noth": [151, 174, 177, 179], "nother": [112, 113], "notic": [51, 112, 113, 151, 175, 176, 177, 179], "notif": 179, "notifi": 179, "notion": [2, 3, 60, 112, 113, 117], "noun": [112, 113, 120, 131, 136, 140, 141, 142, 144, 145, 146], "nov": 185, "novel": [3, 6, 7, 8, 53, 85, 90, 112, 113, 114, 140], "novelti": [56, 140], "novemb": [112, 113], "noveral": [112, 113], "novikov": 0, "now": [0, 1, 6, 9, 13, 14, 15, 16, 21, 23, 25, 29, 31, 42, 47, 52, 53, 61, 68, 72, 73, 77, 82, 93, 95, 98, 101, 102, 104, 105, 109, 111, 112, 113, 115, 117, 124, 128, 133, 136, 137, 140, 143, 145, 153, 155, 159, 174, 175, 176, 177, 178, 179, 182, 183, 184, 186], "nowcast": [38, 41], "noxiou": [112, 113], "np": [24, 32, 35, 111, 129, 131, 133, 141, 145, 150, 151, 153, 182], "nparent": [112, 113], "nper": 153, "npervas": [112, 113], "nphilosoph": [112, 113], "nphilosophi": [112, 113], "nphonet": [112, 113], "npm": [1, 70], "npmi": [148, 153], "npolit": [112, 113], "nport": [112, 113], "npost": [112, 113], "npp": [112, 113], "npre": [112, 113], "nprevent": [112, 113], "nprimari": [112, 113], "nprofession": [112, 113], "nprognosi": [112, 113], "nproperti": [112, 113], "npublic": [112, 113], "nra": 121, "nradar": [112, 113], "nradiat": [112, 113], "nradiometri": [112, 113], "nrail": [112, 113], "nreconstruct": [112, 113], "nrefer": [112, 113], "nregion": [112, 113], "nrelat": [112, 113], "nrelationship": [112, 113], "nreligion": [112, 113], "nrepetit": [112, 113], "nresearch": [112, 113], "nresult": [112, 113], "nrevolutionari": [112, 113], "nroad": [112, 113], "nrow": [24, 25, 26, 150], "nscatter": [112, 113], "nscreen": [112, 113], "nsecondari": [112, 113], "nsee": [112, 113], "nsever": [112, 113], "nsexual": [112, 113], "nsign": [112, 113], "nsmall": [112, 113], "nsnow": [112, 113], "nsocial": [112, 113], "nsocieti": [112, 113], "nsolar": [112, 113], "nsome": [112, 113], "nsourc": [112, 113], "nsouth": [112, 113], "nsoutheastern": [112, 113], "nsouthern": [112, 113], "nsp": 114, "nspecif": [112, 113], "nspectrum": [112, 113], "nsport": [112, 113], "nstate": [112, 113], "nsteel": [112, 113], "nstudi": [112, 113], "nsubj": 131, "nsummer": [112, 113], "nsurfac": [112, 113], "ntactic": [112, 113], "ntangibl": 109, "ntax": [112, 113], "ntelecommun": [112, 113], "nterminologi": [112, 113], "nterna": 108, "nternat": 108, "nterrestri": [112, 113], "ntertiari": [112, 113], "ntext": 105, "ntf": 159, "nth": [108, 148], "nthank": 25, "nthe": [112, 113], "nthere": [112, 113], "nthi": [25, 112, 113], "nthoma": [112, 113], "nthose": [112, 113], "nthought": [112, 113], "nthree": [112, 113], "ntourism": [112, 113], "ntransport": [112, 113], "ntree": [112, 113], "ntrigram": 133, "ntwo": [112, 113], "ntypograph": [112, 113], "nu": [112, 113], "nuab": [112, 113], "nuanc": [2, 13, 46, 47, 50, 53, 54, 58, 60, 92, 94, 99, 107, 110, 131, 132, 138, 140], "nuclear": [112, 113], "nuclei": [112, 113], "nucleu": [112, 113], "nucor": [112, 113], "nudism": [112, 113], "nueural": 128, "null": [11, 15, 16, 22, 127, 182], "nullifi": 60, "num": [21, 151, 153], "num_attention_head": 113, "num_beam": 98, "num_byt": [18, 23, 29], "num_bytes_count": 18, "num_bytes_max": 23, "num_bytes_median": 23, "num_bytes_min": 23, "num_bytes_sum": 18, "num_class_imag": 52, "num_cod": [15, 16, 20, 22], "num_column": 18, "num_epoch": 46, "num_exampl": [18, 23, 29, 31], "num_examples_stat": 33, "num_hidden": 128, "num_hidden_lay": 113, "num_label": 111, "num_leav": [30, 36], "num_machin": 52, "num_merg": 102, "num_proc": 113, "num_process": 52, "num_return_sequ": [98, 101], "num_row": [15, 95], "num_step": 128, "num_sub_iter": [104, 106], "num_thread": [104, 106], "num_token": [31, 104, 106], "num_tokens_mean": 31, "num_tokens_mean_beigebook": [31, 32, 33], "num_tokens_mean_meeting_script": [31, 32, 33], "num_tokens_mean_minut": [31, 32, 33], "num_tokens_mean_press_conf": [31, 32, 33], "num_tokens_mean_speech": [31, 32, 33], "num_tokens_mean_stat": [31, 32, 33], "num_tokens_mean_testimoni": [31, 32, 33], "num_tokens_median": 31, "num_tokens_sum": 31, "num_tokens_sum_speech": [31, 32, 33], "num_tokens_sum_stat": [31, 32, 33], "num_tokens_sum_testimoni": [31, 32, 33], "num_top": 151, "num_top_word": 151, "num_train_epoch": [15, 17, 18, 20, 23, 31, 111, 112, 113], "num_word": [25, 153], "num_work": [16, 17, 18, 20, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 153], "number": [7, 9, 10, 11, 15, 21, 22, 33, 43, 51, 53, 60, 78, 82, 87, 89, 94, 95, 98, 99, 101, 102, 103, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 125, 127, 128, 129, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 146, 148, 149, 152, 153, 155, 156, 158, 159, 172, 177, 179], "numel": 113, "numer": [2, 6, 9, 11, 37, 38, 47, 53, 54, 55, 56, 60, 65, 66, 89, 94, 99, 103, 106, 112, 113, 116, 117, 133, 135, 137, 139, 140, 158, 160, 161], "numexpr": 15, "numexpr_max_thread": 15, "numpi": [15, 23, 24, 32, 35, 111, 129, 133, 137, 142, 150, 151, 153, 179, 182], "numpydoc": 179, "nuniqu": 16, "nunless": [112, 113], "nuntil": [112, 113], "nunusu": [112, 113], "nurseri": [112, 113], "nuse": [112, 113], "nut": 101, "nutrit": [112, 113], "nutshel": [106, 127], "nvda": 43, "nvidia": [3, 7, 15, 60, 94, 113, 133, 136, 137, 142, 151], "nvme1n1p2": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "nvowel": [112, 113], "nwater": [112, 113], "nwell": [112, 113], "nwhat": [112, 113], "nwhen": [112, 113], "nwhere": [112, 113], "nwhile": [112, 113], "nwhite": [112, 113], "nwikipedia": [112, 113], "nwinter": [112, 113], "nwith": [112, 113], "ny": 96, "nyanja": 96, "nyc": 137, "nyse": 153, "nyu": 137, "n\u00aa": [112, 113], "n\u00e5": [112, 113], "n\u00e6": [112, 113], "n\u0250": [112, 113], "n\u0251": [112, 113], "n\u0252": [112, 113], "n\u03b1": [112, 113], "n\u03bb": [112, 113], "n\u0430": [112, 113], "n\u0561": [112, 113], "n\u1d00": [112, 113], "n\u1d90": [112, 113], "n\u1d9b": [112, 113], "n\u6545": 20, "n\ua7bb": [112, 113], "n\uab31": [112, 113], "n\uac00\uc18d\ud558\ub294": 17, "n\uac01": 17, "n\uac1c\ubc1c\uc790": 17, "n\uacb0\uad6d": 20, "n\uace0\uc2b9\ubc94": 16, "n\uad6c\uccb4\uc801": 17, "n\uad6d\ub0b4": 18, "n\uae40\uc6a9\uad6c": 20, "n\ub124\ud2b8\uc6cc\ud06c": 17, "n\ub2e4\ub9cc": 18, "n\uba3c\uc800": 20, "n\ubc30\ud130\ub9ac": 17, "n\ube14\ub85d": 17, "n\uc0ac\uc6a9\uc790": 17, "n\uc0b0\uc5c5\ud1b5\uc0c1\uc790\uc6d0\ubd80\ub294": 16, "n\uc2e0\uc9c0\uc724": 20, "n\uc2e0\ud55c\uc740\ud589": 15, "n\uc5c5\uccb4": 18, "n\uc640\uc774\ube0c\ub85c": 18, "n\uc6b0\ud06c\ub77c\uc774\ub098\uc640": [16, 20], "n\uc720\uc8fc": 15, "n\uc774\ub7ec\ud55c": 18, "n\uc774\uc6c5\uc5f4": 16, "n\uc778\uacf5\uc9c0\ub2a5": 18, "n\uc815\ubcf4\ud1b5\uc2e0": 16, "n\uc99d\uad8c": 17, "n\ucd5c\uadfc": 17, "n\ucf54\uc624\ub871": 16, "n\ud68c\uc0ac\ucc44": [16, 20], "n\ud800\udf00": [112, 113], "n\ud802\udd00": [112, 113], "o": [18, 61, 76, 77, 80, 102, 103, 106, 107, 109, 112, 113, 117, 118, 120, 124, 129, 146, 147, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "oai_config_list": 43, "oauth": [78, 79], "obedi": [112, 113], "obei": [112, 113, 131], "obes": [112, 113], "obj": [104, 106], "object": [6, 7, 10, 11, 15, 16, 22, 23, 24, 29, 47, 51, 55, 60, 64, 66, 89, 90, 93, 96, 101, 103, 105, 110, 111, 112, 113, 114, 116, 117, 123, 126, 127, 131, 141, 145, 151, 152, 161, 166, 169, 170], "oblig": [112, 113], "obscen": 118, "observ": [7, 9, 11, 26, 52, 53, 65, 66, 85, 89, 91, 95, 101, 106, 112, 113, 116, 121, 133, 134, 140, 148, 152, 160, 161], "obsess": [112, 113], "obsolet": [112, 113], "obstacl": [7, 78, 112, 113], "obtain": [7, 9, 10, 11, 24, 50, 53, 54, 94, 98, 99, 101, 112, 113, 114, 117, 122, 124, 126, 131, 133, 148, 149, 155], "oc": [102, 112, 113], "occasion": [51, 112, 113], "occup": [112, 113], "occupi": [60, 91, 112, 113], "occur": [10, 39, 51, 53, 54, 58, 98, 99, 107, 109, 112, 113, 118, 120, 121, 126, 129, 131, 133, 134, 138, 139, 140, 143, 144, 146, 148, 156, 157, 158, 167, 173], "occurr": [44, 112, 113, 115, 120, 133, 134, 148, 149, 152, 154, 155, 158], "ocean": [112, 113], "oci": [61, 63], "ocr": 146, "oct": [129, 134], "octob": [0, 112, 113, 129], "oculist": 157, "od": 0, "odd": [112, 113], "odu": 108, "oduc": 108, "off": [11, 43, 46, 51, 89, 93, 102, 112, 113, 116, 134, 137, 151, 153, 165], "offens": [50, 99], "offer": [7, 9, 10, 13, 14, 38, 39, 40, 41, 42, 43, 46, 50, 51, 53, 54, 55, 56, 58, 60, 63, 64, 65, 66, 67, 70, 75, 77, 78, 94, 98, 110, 112, 113, 117, 122, 124, 127, 131, 137, 139, 143, 145, 148, 149, 152, 157, 160, 161, 162, 165, 170, 172, 173, 178, 179], "offic": [94, 112, 113, 137], "offici": [43, 62, 83, 112, 113, 122, 153, 179], "offlin": 106, "offload": 52, "offload_optimizer_devic": 52, "offload_param_devic": 52, "offset": [24, 32, 112, 113, 129], "often": [3, 7, 9, 13, 14, 39, 41, 42, 43, 47, 50, 51, 55, 56, 57, 58, 60, 64, 66, 67, 72, 78, 81, 89, 90, 91, 92, 94, 98, 99, 101, 105, 106, 107, 109, 110, 112, 113, 115, 116, 118, 122, 123, 127, 131, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 161, 165, 167, 170, 172, 173, 182], "oh": 67, "ohio": [112, 113], "oil": [102, 112, 113, 153], "oint": 108, "ok": [176, 177, 185], "okai": 25, "okenizer_config": [101, 115], "oklahoma": [112, 113], "ol": 102, "old": [4, 102, 108, 112, 113, 118], "older": [112, 113, 174, 181, 186], "oldest": [112, 113], "olv": 101, "olymp": [109, 131], "olympi": 109, "olympiad": 86, "omega_": 127, "omit": 82, "omment": 108, "omnibu": [112, 113], "omw": 151, "onc": [6, 7, 9, 50, 68, 69, 73, 74, 77, 83, 89, 90, 98, 106, 109, 111, 112, 113, 117, 118, 122, 126, 128, 131, 145, 167, 170, 173, 179, 181], "one": [2, 3, 6, 7, 8, 9, 10, 11, 26, 42, 47, 51, 52, 61, 65, 70, 72, 73, 78, 79, 80, 84, 89, 90, 96, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 127, 128, 129, 131, 132, 133, 134, 135, 137, 140, 141, 143, 145, 146, 148, 149, 151, 153, 155, 156, 157, 159, 160, 164, 167, 168, 172, 173, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186], "one_al": 153, "one_on": 153, "one_pr": 153, "one_set": 153, "one_suc": 153, "oneapi": [15, 23], "onednn": [15, 23], "onelin": [175, 177, 178, 180, 181, 182, 184, 186], "ones": [11, 13, 60, 62, 65, 70, 99, 112, 113, 121, 124, 127, 128, 149, 160, 184], "oneself": [112, 113, 131], "ong": 102, "ongo": [50, 51, 60, 64, 73, 78, 92, 99, 112, 113, 117, 131, 145, 165, 170, 173], "onli": [2, 7, 9, 10, 11, 12, 15, 24, 41, 47, 51, 52, 53, 56, 60, 62, 65, 69, 72, 73, 77, 78, 82, 89, 90, 92, 93, 94, 96, 97, 98, 99, 100, 101, 106, 112, 113, 115, 116, 117, 118, 120, 123, 126, 129, 130, 131, 133, 134, 137, 144, 149, 151, 152, 153, 154, 159, 160, 164, 172, 173, 175, 177, 179, 182, 184, 186], "onlin": [13, 38, 54, 72, 74, 83, 84, 112, 113, 121, 122, 135], "ons": [81, 102], "onset": [112, 113], "ontanon": 100, "onto": [6, 7, 112, 113, 127, 137, 149, 177, 181, 184], "ontologi": [39, 157], "onu": 39, "onward": [54, 112, 113], "on\u00ed": [112, 113], "oo": 102, "oom": 52, "oov": [103, 104, 107, 134], "op": [66, 72, 102, 108, 115, 161], "opac": 53, "opaqu": [13, 53], "open": [1, 3, 6, 7, 9, 12, 15, 50, 53, 54, 60, 61, 63, 64, 65, 66, 68, 69, 70, 72, 74, 77, 78, 79, 81, 84, 89, 90, 92, 98, 101, 102, 104, 112, 113, 121, 122, 124, 125, 129, 131, 134, 135, 137, 140, 153, 157, 160, 161, 170, 172, 177, 179, 185], "open_clip": 10, "openai": [1, 3, 6, 9, 10, 43, 47, 54, 60, 84, 86, 87, 94, 98, 99, 100, 101, 122, 123], "openid": [78, 79], "openli": [7, 78], "openpgp": 77, "openreview": 0, "openshift": [66, 161], "openwebtext2": 46, "oper": [7, 9, 11, 13, 15, 23, 39, 43, 45, 46, 50, 53, 54, 56, 57, 58, 60, 64, 65, 66, 72, 74, 75, 82, 83, 89, 101, 106, 107, 109, 112, 113, 114, 116, 117, 127, 151, 152, 153, 156, 160, 161, 164, 165, 166, 167, 172, 173, 180], "opera": 76, "operation": 59, "operatornam": [98, 107], "ophnfb": 35, "opim": 129, "opinion": [13, 65, 93, 94, 99, 112, 113, 120, 131, 135, 160], "oppo": 146, "oppon": [112, 113], "opportun": [13, 14, 38, 54, 56, 60, 73, 102, 108, 109, 112, 113, 131, 135, 146], "oppos": [43, 53, 112, 113, 117, 157, 173], "opposit": [10, 112, 113, 115, 121, 135, 138, 148, 155, 158], "oppress": [112, 113], "opt": [29, 31, 47, 52, 82], "optic": [9, 112, 113], "optiguid": 43, "optim": [7, 8, 12, 13, 15, 23, 42, 43, 46, 50, 51, 52, 53, 54, 55, 60, 65, 66, 75, 76, 78, 86, 89, 93, 98, 99, 100, 101, 106, 107, 110, 111, 113, 117, 133, 139, 148, 151, 152, 153, 160, 161, 162, 164, 167, 173], "optima": 55, "optimist": 129, "option": [6, 7, 9, 10, 11, 43, 46, 47, 60, 61, 63, 65, 70, 74, 76, 77, 80, 82, 94, 98, 112, 113, 115, 118, 127, 129, 137, 153, 156, 160], "optometri": [112, 113], "or5": [112, 113], "oral": [88, 164], "orang": [112, 113, 114, 115, 128], "orati": 108, "oratio": 108, "orb": [112, 113], "orbit": 151, "orchestr": [43, 45, 57, 61, 62, 63, 65, 72, 76, 81, 160], "order": [11, 52, 98, 100, 102, 112, 113, 116, 117, 118, 123, 125, 129, 131, 133, 134, 137, 139, 141, 151, 152, 153, 154, 155, 167], "ordereddict": [16, 21, 25, 29, 31], "ordin": [112, 113], "ordinari": [112, 113, 146], "org": [0, 9, 10, 30, 36, 46, 54, 70, 71, 80, 112, 113, 120, 133, 136, 137, 142, 151, 153], "organ": [39, 47, 50, 51, 53, 60, 64, 66, 67, 69, 71, 72, 75, 78, 82, 86, 94, 99, 110, 112, 113, 118, 121, 122, 123, 131, 135, 138, 146, 149, 151, 153, 161, 167, 168, 172, 173], "organis": [112, 113, 178], "orgin": 146, "orient": [7, 33, 43, 63, 112, 113, 131, 151], "origin": [3, 8, 9, 10, 11, 21, 37, 47, 50, 51, 52, 53, 55, 58, 60, 63, 68, 69, 72, 78, 79, 80, 84, 85, 90, 94, 96, 98, 99, 100, 101, 105, 106, 107, 111, 112, 113, 116, 117, 118, 121, 124, 125, 127, 140, 149, 151, 152, 157, 173, 177, 178, 179, 181, 182, 183, 185, 186], "original_label": 18, "orlean": [112, 113], "orm": 54, "orp": 108, "orpor": 108, "orporati": 108, "orporatio": 108, "ors": 102, "ort": 181, "orthodox": [112, 113], "orthogon": [10, 118, 148, 149, 151, 158], "orthographi": [112, 113], "oser": 108, "osni": [112, 113], "oss": 106, "osteopath": [112, 113], "other": [0, 6, 7, 9, 10, 11, 13, 15, 17, 18, 21, 23, 26, 43, 45, 46, 51, 52, 53, 55, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 75, 77, 78, 81, 84, 87, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 104, 107, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 127, 129, 133, 134, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 157, 159, 160, 161, 165, 167, 171, 172, 173, 174, 175, 177, 178, 179, 181, 184, 186], "otherwis": [3, 108, 109, 112, 113, 118, 119, 127, 153, 167], "ou": 102, "ought": [52, 112, 113], "ould": 102, "oun": 102, "ound": 102, "ouput": 116, "ouputperform": 126, "our": [2, 3, 11, 25, 47, 73, 78, 90, 92, 98, 102, 104, 105, 107, 108, 109, 111, 112, 113, 116, 117, 121, 131, 137, 140, 143, 144, 145, 148, 151, 154, 155, 156, 159, 167, 168, 174, 176, 177, 179, 182, 184], "ourc": 108, "ourselv": [151, 182], "out": [11, 13, 47, 52, 60, 63, 70, 74, 78, 81, 96, 98, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 115, 116, 118, 120, 121, 125, 127, 129, 131, 134, 137, 140, 143, 145, 146, 147, 156, 157, 167, 175, 178, 182, 184, 185], "out_proj": [15, 17, 18, 23], "out_typ": 106, "outag": [56, 66, 161], "outbreak": [112, 113], "outcom": [3, 13, 43, 45, 47, 54, 72, 98, 112, 113, 127, 131, 133, 147, 167, 168, 171, 173], "outdat": [94, 112, 113], "outer": [112, 113], "outflow": 120, "outl": 108, "outlaw": [112, 113], "outlier": [13, 90, 149], "outlin": [47, 57, 68, 90, 99, 112, 113, 156, 168, 170, 171], "outlo": 108, "outloo": 108, "outlook": [102, 153], "outokumpu": [112, 113], "outpac": 94, "outperform": [7, 10, 11, 85, 86, 114, 116, 118, 121, 131, 153], "output": [5, 6, 7, 9, 10, 11, 15, 17, 18, 21, 22, 23, 25, 31, 41, 43, 44, 47, 50, 52, 53, 54, 56, 58, 59, 60, 61, 72, 73, 75, 77, 84, 87, 89, 94, 98, 99, 100, 101, 103, 106, 107, 111, 112, 113, 114, 115, 116, 117, 120, 122, 125, 127, 128, 131, 139, 140, 142, 143, 144, 145, 149, 151, 173, 174, 175, 181, 182], "output_attent": 115, "output_dir": [16, 17, 18, 20, 22, 24, 25, 31, 32, 52, 111, 112, 113], "output_fil": [16, 17, 18, 20, 22, 25, 31, 77, 125], "output_lay": 129, "outset": 172, "outshin": 43, "outsid": [6, 43, 112, 113], "outweigh": [112, 113], "over": [7, 9, 10, 11, 12, 41, 43, 47, 48, 50, 53, 56, 60, 72, 73, 75, 77, 78, 79, 86, 89, 92, 96, 98, 99, 100, 102, 106, 107, 112, 113, 116, 118, 119, 121, 123, 127, 128, 129, 131, 137, 139, 143, 145, 147, 148, 149, 151, 152, 153, 156, 159, 164, 172, 173, 179, 186], "overal": [8, 10, 37, 51, 53, 64, 72, 89, 90, 92, 94, 96, 98, 112, 113, 117, 118, 120, 121, 131, 132, 135, 136, 138, 145, 148, 151, 168, 172], "overarch": 131, "overcom": [43, 55, 56, 58, 60, 72, 78, 94, 98, 117, 131, 135, 152], "overestim": [112, 113, 144], "overfit": [46, 52, 53, 98, 111, 118, 139, 152], "overgener": 56, "overhaul": [51, 164], "overhead": [47, 53, 61, 89, 173], "overlap": [21, 89, 112, 113, 117, 131, 172], "overli": [51, 90, 112, 113], "overload": [112, 113, 122], "overlook": [112, 113, 116, 148], "overnight": 143, "overpopul": 56, "overreli": 56, "overrid": [16, 17, 18, 20, 22, 25, 31, 112, 113], "overrun": 165, "oversampl": 96, "overse": [112, 113], "overseen": [112, 113], "oversight": [13, 60, 112, 113], "oversimplifi": 106, "overt": [112, 113], "overthrow": [112, 113], "overturn": [112, 113], "overview": [7, 10, 13, 38, 57, 60, 66, 72, 74, 78, 85, 90, 98, 111, 131, 161, 166, 168], "overwhelmingli": [54, 112, 113], "overwrit": [112, 175, 176, 177, 178, 181, 182, 183], "overwrite_output_dir": [112, 113], "ovi": 108, "ow": [112, 113], "owasp": 170, "owen": [112, 113, 131], "owl": 42, "own": [5, 7, 9, 10, 39, 43, 46, 50, 60, 69, 70, 72, 89, 90, 93, 97, 98, 103, 104, 112, 113, 117, 120, 125, 130, 131, 135, 137, 142, 145, 149, 151, 153, 167, 173, 177, 178, 179, 184], "owner": [68, 69, 112, 113, 122, 172], "ownership": [78, 112, 113, 131], "owng": 108, "owngr": 108, "owngra": 108, "owngrad": 108, "ox": [112, 113], "ozark": [112, 113], "p": [9, 52, 53, 61, 62, 80, 81, 82, 85, 96, 100, 102, 103, 106, 107, 109, 112, 113, 117, 120, 129, 130, 133, 134, 138, 143, 144, 146, 148, 153, 156, 158, 182, 184, 186], "p06": 0, "p16": 0, "p4g": 21, "p7or7r6x": 17, "p7or7r6xsync": 17, "p8": 113, "p_": [85, 129, 148], "p_1": 133, "p_2": 133, "p_3": 133, "p_4": 133, "p_c": 156, "p_tune": 53, "p_w": 156, "p_wc": 156, "pa": [96, 102, 153], "pablo": 0, "pac": 102, "pace": [112, 113], "pachinko": 153, "pachyderm": 72, "pacifist": [112, 113], "pack": [74, 177], "packag": [7, 24, 25, 29, 31, 43, 46, 61, 62, 63, 65, 66, 70, 72, 73, 74, 81, 82, 95, 101, 102, 104, 109, 111, 112, 113, 115, 122, 133, 134, 136, 137, 142, 143, 147, 151, 153, 156, 160, 161, 170], "pad": [31, 89, 98, 101, 104, 105, 106, 109, 111, 112, 113, 116, 127], "pad_id": [104, 106], "pad_left": 133, "pad_piec": [104, 106], "pad_right": 133, "pad_token": [112, 113], "pad_token_id": [98, 101, 112, 113], "padding_idx": 111, "paddl": [112, 113], "padlock": 83, "page": [0, 1, 7, 24, 30, 36, 44, 61, 68, 94, 96, 97, 118, 120, 123, 124, 131, 137, 145, 177, 178, 179, 182, 186], "pai": [90, 93, 102, 112, 113, 114, 117, 121, 137, 153, 182], "paid": [6, 112, 113, 131], "paideia": [112, 113], "paint": [6, 10, 101], "painter": [3, 6, 112, 113], "pair": [6, 7, 9, 10, 11, 12, 47, 54, 77, 81, 89, 99, 102, 106, 112, 113, 117, 120, 123, 131, 133, 134, 139, 144, 147, 148, 149, 156, 172, 178, 183], "pair_freq": 109, "pair_scor": 109, "pairwis": 10, "paka": 60, "palat": 47, "pale": [112, 113], "palett": [3, 27, 33], "palm": [94, 99], "palmer": [112, 113], "pamodel": 153, "pan": [0, 7, 102], "panda": [13, 15, 16, 22, 24, 74, 95, 124, 137, 142, 150], "panel": [112, 113, 120], "panorama": 9, "paper": [0, 6, 7, 9, 10, 11, 47, 48, 50, 52, 53, 85, 88, 89, 90, 94, 97, 112, 113, 114, 116, 117, 120, 121, 125, 130, 138, 139, 149, 153, 155], "paper1": 52, "paper2": 52, "par": [11, 102], "parad": [112, 113], "paradigm": [48, 50, 55, 57, 60], "paragraph": [10, 56, 135, 144, 154, 155], "parallel": [18, 39, 50, 53, 54, 56, 60, 75, 94, 99, 100, 117, 123, 131, 151, 167, 173, 181], "paralleliz": 60, "param": 52, "paramet": [2, 7, 9, 10, 11, 42, 46, 47, 48, 50, 53, 75, 77, 84, 85, 90, 94, 96, 98, 99, 100, 106, 107, 112, 113, 114, 115, 116, 117, 118, 124, 128, 129, 131, 133, 137, 152, 153], "parameter": [100, 127], "parametr": 7, "paramount": [39, 46, 51, 53, 60], "paraphras": [99, 123], "parent": [44, 112, 113, 129, 137, 180], "pari": [47, 101, 112, 113], "parisotto": 0, "park": [0, 4, 112, 113], "parker": [112, 113], "parkwai": [112, 113], "parmar": 0, "parol": [112, 113], "parquet": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 102, 104, 108, 109, 129, 146, 153], "pars": [2, 13, 15, 22, 44, 92, 122, 130, 131, 138, 140, 147], "parser": [15, 16, 22, 124, 131, 143, 158], "parsinlu": 99, "part": [0, 2, 7, 9, 10, 13, 47, 48, 50, 53, 64, 67, 72, 73, 74, 75, 89, 92, 97, 98, 100, 102, 106, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 122, 123, 128, 130, 131, 133, 136, 137, 138, 139, 140, 144, 146, 147, 151, 153, 168, 173, 175, 177, 179], "parti": [0, 6, 62, 78, 79, 112, 113, 121, 131, 135], "partial": [16, 17, 20, 21, 22, 25, 29, 31, 34, 35, 36, 41, 43, 98, 112, 113, 153, 167, 173], "particip": [43, 45, 48, 71, 86, 88, 89, 97, 98, 112, 113, 123, 130, 153, 162, 173], "particl": [112, 113, 141, 145], "particul": [112, 113], "particular": [46, 50, 51, 55, 57, 58, 60, 93, 94, 99, 110, 112, 113, 115, 116, 121, 131, 133, 137, 141, 145, 152, 158, 159, 175, 181, 182, 186], "particularli": [3, 9, 10, 39, 42, 46, 47, 51, 53, 54, 58, 60, 78, 93, 94, 98, 99, 101, 103, 107, 110, 112, 113, 116, 117, 121, 122, 131, 138, 139, 140, 144, 148, 149, 151, 152, 159, 173], "partisan": [112, 113], "partit": [149, 173], "partli": [112, 113], "partn": 102, "partner": [43, 94, 102, 178], "partner_dir": 178, "partnership": 60, "pascal": 0, "pashto": 96, "pass": [2, 9, 11, 31, 50, 53, 65, 67, 71, 73, 78, 101, 112, 113, 114, 115, 117, 128, 129, 151, 153, 160], "passag": [2, 10, 67, 71, 85, 91, 112, 113, 131], "passage_dir": 80, "passeng": [47, 112, 113], "passfil": 80, "passiv": 101, "passphras": 77, "passwd": 82, "password": [2, 65, 71, 77, 78, 79, 83, 146, 160, 177, 186], "password_store_dir": 80, "past": [3, 43, 77, 81, 92, 112, 113, 116, 129, 133, 140, 153, 172], "pastel": 27, "pastri": 47, "pat": [153, 177], "patch": [82, 117, 181], "patel": 99, "patent": [94, 121], "path": [15, 18, 23, 25, 31, 46, 52, 53, 54, 55, 61, 65, 70, 72, 73, 77, 80, 89, 96, 104, 106, 111, 113, 117, 124, 129, 146, 153, 160, 164, 170, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "pathet": 137, "pathfind": 55, "patholog": [112, 113], "pathologist": [112, 113], "pathophysiologi": [112, 113], "pathwai": [10, 47, 54, 112, 113], "patient": [51, 78, 93, 112, 113, 131, 137], "patriarchi": [112, 113], "patron": 137, "pattern": [0, 3, 6, 7, 13, 43, 45, 47, 50, 51, 54, 55, 60, 89, 90, 91, 94, 99, 112, 113, 114, 117, 120, 121, 123, 131, 132, 133, 135, 137, 138, 139, 146, 148, 149, 152, 168], "paul": [24, 25, 32, 112, 113], "paulo": 0, "paulu": 98, "pave": [7, 9, 43, 45, 54, 94, 112, 113, 117], "pavlick": 99, "payment": [112, 113], "payn": [112, 113], "payoff": 116, "pb": [112, 113], "pc": [112, 113], "pc1": 29, "pca": [10, 29, 56, 112, 113, 127, 139, 149, 152], "pcb": [112, 113], "pce": 24, "pce_diff_prev": [26, 27, 28, 29], "pce_diff_year": [24, 26, 27, 28, 29], "pcecc96": 35, "pcoord": 29, "pct_chang": 35, "pd": [24, 95, 137, 150], "pdd": [112, 113], "pdf": [0, 10, 78, 122, 147, 182], "pdfpage": 182, "pe": [21, 25, 31, 102], "peac": [112, 113], "peach": [112, 113], "peak": [52, 112, 113], "peanut": [112, 113], "pearson": 130, "peasant": [112, 113], "peckerwood": [112, 113], "pedant": [112, 113], "pediatr": [112, 113], "pediatrician": [112, 113], "peebl": [112, 113], "peer": [48, 90, 94, 112, 113, 120], "peft": [2, 48], "peft_config": 52, "peft_lora_clm_accelerate_big_model_infer": 52, "peft_lora_layoutlmfortokenclassification_on_funsd": 52, "peft_lora_seq2seq_accelerate_ds_zero3_offload": 52, "peirc": [112, 113], "pelham": [112, 113], "pem": 73, "pen": [102, 178, 181, 182], "penal": [112, 113], "penalti": [98, 112, 113], "penetr": [112, 113], "peng": [0, 7], "penicillin": 156, "peninsula": [112, 113], "penn": [43, 123, 131, 140], "pennin": 186, "pennington": [0, 126], "pensacola": [112, 113], "pentagon": 60, "penygad": 182, "peopl": [4, 7, 72, 99, 112, 113, 117, 131, 146, 151, 152, 153, 179, 184], "pepsico": 153, "per": [7, 25, 53, 61, 89, 102, 106, 112, 113, 116, 118, 150, 153, 165, 181], "per_device_eval_batch_s": 111, "per_device_train_batch_s": [111, 112, 113], "perceiv": [45, 89, 112, 113, 120, 138], "percent": [112, 113, 153], "percent_to_remov": [108, 109], "percentag": [107, 110, 112, 113, 145], "percentil": 11, "percept": [13, 112, 113, 120], "perceptron": [89, 117], "perceptu": 7, "perch": 129, "perf": 113, "perfect": [24, 47, 112, 113], "perform": [7, 10, 11, 15, 23, 39, 41, 42, 43, 45, 46, 50, 53, 54, 55, 58, 60, 61, 63, 64, 65, 66, 72, 74, 75, 76, 77, 78, 84, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 116, 117, 118, 122, 123, 127, 130, 131, 132, 133, 134, 135, 137, 138, 139, 141, 143, 145, 147, 149, 151, 153, 160, 161, 164, 165, 167, 170, 172], "perhap": [89, 112, 113], "period": [1, 24, 65, 94, 112, 113, 118, 121, 140, 145, 152, 153, 160, 170, 172], "perish": [112, 113], "perkin": [97, 130], "perman": [112, 113], "permiss": [76, 81, 82, 122, 177, 179, 186], "permit": [51, 112, 113], "permut": 58, "perpetu": [54, 93, 94, 112, 113], "perplex": [0, 56, 112, 134], "perplexity_model": 96, "perri": [112, 113], "persian": 96, "persist": [17, 21, 29, 34, 62, 112, 113], "person": [1, 7, 47, 51, 60, 67, 68, 72, 92, 94, 99, 112, 113, 118, 121, 122, 123, 131, 177, 186], "personnel": 168, "perspect": [56, 99, 101, 112, 113, 117, 131, 158, 172, 173], "persuad": [112, 113], "pertain": [39, 112, 113], "pertin": [60, 94, 117], "pervas": [112, 113], "pesticid": [112, 113], "pet": [112, 113, 127, 148, 150], "petabyt": [94, 118, 122, 123], "peter": [0, 112, 113], "petit": [112, 113], "petrochina": 153, "petrograd": [112, 113], "pfnn": 7, "pga": [112, 113], "pgp": [78, 79], "ph": [102, 108, 141], "pharm": 102, "pharma": 102, "pharmaci": [112, 113, 137], "phase": [0, 47, 50, 55, 56, 60, 90, 94, 99, 112, 113, 114, 165, 167, 170, 171, 172], "phenix": [112, 113], "phenol": [112, 113], "phenomena": [112, 113, 133, 137], "phenomenon": [11, 58, 60, 131, 140, 141], "phenonema": 116, "phenotyp": [112, 113], "phenylketonuria": [112, 113], "phil": [112, 113], "philadelphia": [112, 113], "philip": [112, 113], "phillip": [0, 120], "philosoph": [3, 112, 113], "philosophi": [66, 112, 113, 161, 173], "philschmid": 52, "phoenician": [112, 113], "phone": [82, 121, 137], "phonem": [0, 112, 113, 131], "phonet": [103, 112, 113, 114, 140], "photo": [10, 52, 89], "photograph": [9, 112, 113], "photographi": 89, "photometr": [112, 113], "photometri": [112, 113], "photometria": [112, 113], "photor": [10, 11], "photorealist": [11, 12], "photosynthesi": [112, 113], "photovolta": [112, 113], "phoutthavihan": [112, 113], "php": 122, "phrase": [0, 9, 56, 92, 93, 98, 99, 112, 113, 117, 118, 123, 131, 132, 135, 136, 137, 139, 140, 141, 143, 144, 145, 147, 155], "phthalat": [112, 113], "physcap": 7, "physi": [112, 113], "physic": [0, 98, 112, 113, 131, 151], "physician": [112, 113], "pi": [24, 102], "pianist": 7, "piano": 7, "picc": 153, "pick": [73, 98, 112, 113, 134, 181, 184], "pictogram": [112, 113], "pictur": [117, 127, 137], "pid": 113, "piec": [3, 5, 6, 50, 60, 89, 90, 104, 106, 111, 113, 135, 143, 147, 155, 172, 184], "piedmont": [112, 113], "pierr": [6, 112, 113], "pieter": [0, 7], "pigment": 6, "pii": 60, "pillow": 137, "pin": [65, 160], "pinch": 182, "pine": [103, 107, 112, 113, 146], "pineappl": [103, 107, 146], "pinecon": 60, "ping": 102, "pinnacl": 56, "pinpoint": 54, "pioneer": [53, 60, 112, 113, 121], "piotr": 0, "pip": [31, 43, 46, 62, 70, 95, 98, 101, 104, 106, 111, 112, 113, 115, 124, 125, 133, 136, 137, 142, 143, 151, 153, 182], "pipe": [16, 17, 20, 21, 22, 25, 29, 31, 34, 35, 112, 113], "pipefail": 80, "pipelin": [2, 7, 8, 16, 17, 19, 20, 21, 22, 25, 29, 34, 35, 38, 39, 42, 54, 57, 58, 59, 65, 66, 67, 71, 75, 76, 83, 86, 97, 101, 103, 106, 107, 112, 116, 140, 160, 161, 171], "pipx": 70, "piqu": 90, "piqua": [112, 113], "pissarro": [112, 113], "pistol": [112, 113], "pit": [112, 113, 129], "pitch": [112, 113], "piv": 80, "pivot": [13, 31, 35, 39, 43, 45, 47, 51, 53, 60, 112, 113, 147, 172], "pixel": [6, 9, 10, 11, 89, 117], "pixrai": [6, 131], "pizza": 133, "pki": 79, "pkm": [0, 7], "pl": [96, 102, 146], "place": [4, 7, 11, 46, 58, 72, 73, 78, 112, 113, 122, 145, 153, 157, 169, 171, 173, 175, 182], "placebo": [112, 113], "placehold": 116, "placement": [145, 149], "plagu": [112, 113], "plai": [6, 7, 43, 47, 51, 52, 53, 55, 56, 65, 72, 73, 77, 78, 90, 93, 97, 98, 112, 113, 117, 118, 123, 130, 132, 139, 141, 144, 145, 146, 147, 148, 151, 160, 179], "plain": [52, 94, 112, 113, 122], "plain_text": 111, "plaintext": [78, 79], "plaintext_pars": [15, 16, 22], "plan": [7, 43, 45, 72, 84, 86, 90, 102, 112, 113, 153, 164, 168, 169, 170, 171], "plane": 151, "planet": [112, 113], "planetari": [112, 113], "plant": [112, 113, 148], "plantat": [112, 113], "planter": [112, 113], "plasma": 18, "plasmid": 143, "plastic": [15, 112, 113], "plateau": [112, 113], "platform": [7, 13, 15, 23, 39, 43, 46, 47, 53, 57, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74, 75, 77, 81, 92, 101, 111, 112, 113, 121, 122, 131, 135, 160, 161, 170], "plausibl": [7, 9, 11, 58], "play": 23, "player": [53, 54, 60, 134, 152], "pldamodel": 153, "ple": [106, 146], "plead": 121, "pleas": [15, 23, 30, 31, 36, 100, 101, 102, 104, 109, 111, 112, 113, 115, 137, 143, 156], "pleasur": [112, 113], "plethora": 13, "plm": 53, "plot": [15, 17, 18, 23, 24, 25, 27, 28, 29, 32, 34, 41, 43, 95, 96, 137, 140, 150, 156], "plot_distribut": 27, "plot_feature_import": [30, 36], "plot_irf": 35, "plot_learning_curv": [30, 36], "plot_local_entropi": 146, "plot_sentiments_over_chair_period": 33, "plot_sentiments_over_crisis_period": 33, "plt": [95, 129, 137, 140, 150, 151, 156], "plu": [43, 72, 86, 112, 113, 136, 140, 175], "pluggabl": 61, "plugin": [43, 61, 67, 70], "plum": [112, 113], "plummet": 164, "plural": [112, 113, 122, 131, 140], "pmi": [26, 27, 28, 29, 30, 34, 36, 144, 150, 153], "pmi_diff_prev": [26, 27, 28, 29], "pmi_diff_year": [26, 27, 28, 29], "pmi_valu": 156, "pmlr": 0, "pnc": [112, 113], "png": [15, 23, 25], "po": [102, 111, 131, 136, 137, 139, 142, 143], "poarch": [112, 113], "poc": 72, "pod": 61, "poem": 50, "poet": 6, "poetri": [112, 113], "poin": [102, 108], "point": [7, 10, 11, 13, 21, 24, 26, 47, 51, 52, 56, 60, 61, 70, 89, 90, 94, 102, 110, 112, 113, 116, 117, 118, 127, 129, 139, 140, 141, 143, 148, 149, 151, 153, 157, 158, 171, 177, 180, 184], "pointless": 146, "pois": [51, 54, 117, 172], "poke": [112, 113], "pol_data": 15, "pol_fil": 15, "pol_pr": 15, "pol_preds_new": 15, "polairty_pr": 15, "polar": [2, 19, 21, 31, 32, 33, 38, 111, 112, 113, 135, 136, 137, 138], "polarity_data": [15, 22], "polarity_diffus": 31, "polarity_diffusion_beigebook": [31, 32, 33], "polarity_diffusion_label": 31, "polarity_diffusion_meeting_script": [31, 32, 33], "polarity_diffusion_minut": [31, 32, 33, 34, 35, 36], "polarity_diffusion_minutes_d": 32, "polarity_diffusion_press_conf": [31, 32, 33], "polarity_diffusion_speech": [31, 32, 33, 34, 36], "polarity_diffusion_stat": [31, 32, 33, 34], "polarity_label": 31, "polarity_ma": 33, "polarity_mean": 31, "polarity_mean_beigebook": [31, 32, 33], "polarity_mean_label": 31, "polarity_mean_meeting_script": [31, 32, 33], "polarity_mean_minut": [31, 32, 33], "polarity_mean_press_conf": [31, 32, 33], "polarity_mean_speech": [31, 32, 33], "polarity_mean_stat": [31, 32, 33], "polarity_mean_testimoni": [31, 32, 33], "polarity_pr": [15, 20, 22], "polarity_preds_df": [20, 22], "polarity_record": 20, "polarity_scor": 136, "polarity_valid_preds_df": 17, "pole": [112, 113], "polic": [112, 113], "polici": [0, 2, 13, 24, 37, 38, 40, 41, 42, 72, 86, 112, 113, 122, 135, 138], "policymak": [13, 24, 42, 99, 121, 131], "polish": 96, "polit": [0, 112, 113, 131, 135, 138, 152], "politic": [112, 113], "politician": [112, 113, 120, 121], "poll": [112, 113], "pollut": [4, 112, 113], "polosukhin": 0, "polyamori": [112, 113], "polyaxon": 72, "ponferrada": 0, "poodl": 138, "pool": [10, 11, 98, 112, 113, 121, 139], "pooler": [111, 113], "poor": [11, 56, 112, 113, 131, 137, 149, 152], "poorer": [112, 113], "poorli": [53, 94, 111, 112, 113, 173], "pop": [108, 109, 111, 129, 175, 176, 178, 184], "pope": [112, 113], "popul": [60, 112, 113], "popular": [6, 7, 10, 43, 50, 53, 63, 65, 66, 67, 68, 70, 73, 74, 77, 81, 91, 94, 97, 99, 102, 106, 112, 113, 119, 120, 122, 130, 131, 135, 138, 149, 151, 152, 155, 160, 161, 172], "popularli": [112, 113], "por": 102, "porat": 108, "porati": 108, "poratio": 108, "pork": 0, "porsch": 95, "port": [62, 77, 83, 102, 108, 112, 113, 153], "portabl": [61, 63, 67, 72], "portal": [112, 113], "porter": 151, "porter_stemm": 153, "porterstemm": [143, 151, 153], "portfolio": [42, 50, 102, 133], "portion": [51, 112, 113, 129], "portrait": 8, "portugues": [96, 112, 113], "pos_": 145, "pose": [0, 7, 13, 54, 93, 94, 117, 127, 131, 140, 141, 144], "posit": [7, 9, 10, 11, 13, 15, 17, 20, 21, 22, 23, 31, 47, 53, 54, 78, 89, 90, 99, 100, 101, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 129, 131, 135, 136, 137, 138, 139, 146, 148, 150, 151, 153, 154, 156, 157, 185], "possess": [43, 47, 58, 84, 94, 101, 112, 113, 131], "possibl": [3, 6, 7, 9, 12, 18, 53, 54, 75, 90, 98, 99, 100, 106, 107, 109, 112, 113, 115, 117, 118, 131, 133, 139, 140, 146, 148, 167, 170, 173, 176], "possibli": [43, 55, 74, 112, 113, 129, 151, 171], "post": [9, 10, 13, 47, 53, 56, 73, 74, 79, 94, 98, 104, 112, 113, 119, 120, 121, 129, 131, 135, 138, 149, 151, 167, 168, 173], "post0": [15, 17, 18, 20, 21, 22, 23, 153], "poster": [0, 130], "posterior": 152, "postposit": 141, "postprocess": 89, "postprocess_metadata": 25, "postsecondari": [112, 113], "postul": 140, "postur": [0, 7, 64, 78], "pot": [6, 102, 131], "potent": [42, 43, 51], "potenti": [1, 2, 3, 6, 7, 9, 10, 11, 13, 17, 37, 38, 40, 41, 43, 47, 50, 51, 53, 56, 58, 60, 61, 64, 72, 74, 75, 78, 79, 84, 87, 89, 90, 92, 93, 94, 95, 96, 98, 99, 101, 106, 110, 112, 113, 117, 118, 121, 131, 133, 134, 135, 137, 138, 140, 144, 156, 167, 168, 170, 171, 172, 173], "poultri": [112, 113], "pound": [112, 113], "pour": [112, 113], "poverti": [112, 113], "powderi": [112, 113], "powel": [24, 25, 26, 27, 28, 32], "power": [1, 7, 9, 10, 11, 13, 41, 42, 43, 46, 50, 51, 52, 53, 54, 56, 57, 58, 60, 62, 65, 70, 73, 74, 75, 77, 78, 80, 82, 84, 87, 89, 93, 100, 106, 107, 110, 111, 112, 113, 114, 115, 118, 127, 131, 133, 139, 145, 149, 154, 157, 158, 160, 181], "powerhous": [43, 112, 113], "pp": 133, "ppmi": 156, "ppmi_valu": 156, "pport": 109, "pprint": 146, "practic": [6, 10, 11, 13, 43, 45, 46, 47, 48, 52, 53, 56, 57, 66, 67, 68, 69, 71, 72, 79, 86, 88, 90, 93, 97, 98, 99, 102, 106, 112, 113, 114, 117, 123, 130, 131, 134, 136, 137, 142, 143, 147, 150, 158, 161, 162, 167, 169, 170, 173, 182], "practition": [47, 89, 110, 115, 123, 137, 152], "prado": 0, "pragmat": [112, 113], "pranav": [0, 7], "prat": 0, "praxi": [112, 113], "pre": [0, 2, 6, 8, 13, 46, 47, 48, 50, 51, 53, 58, 61, 62, 63, 74, 83, 85, 87, 89, 92, 96, 97, 99, 100, 101, 102, 106, 111, 113, 115, 117, 118, 122, 125, 129, 130, 131, 139, 140, 153, 165, 173, 177], "pre_token": [104, 105, 108, 109, 112, 146], "pre_tokenize_str": 105, "preach": [112, 113], "preacher": [112, 113], "preced": [98, 112, 113, 118, 133, 141], "precipit": [112, 113], "precis": [9, 15, 17, 23, 30, 31, 36, 43, 54, 55, 56, 58, 60, 75, 127, 136, 137, 138, 145, 147, 151, 153], "precision_scor": 136, "precison": [15, 17, 23, 30, 31, 36], "precomput": 89, "preconcept": [112, 113], "precursor": [112, 113, 114, 152], "pred": [15, 17, 20, 21, 22, 129], "pred_fil": 22, "pred_label": [15, 17, 20, 22, 31], "pred_prob": [15, 17, 20, 22, 31], "predatori": [112, 113], "predecessor": [10, 50, 57, 87, 98, 112, 113], "predefin": [45, 56, 60, 65, 92, 98, 106, 135, 136, 138, 144, 157, 160], "predic": [112, 113], "predict": [2, 6, 7, 9, 10, 17, 18, 19, 21, 23, 26, 37, 38, 41, 42, 46, 47, 51, 54, 56, 58, 60, 72, 74, 75, 86, 87, 89, 91, 93, 98, 99, 100, 101, 103, 108, 110, 111, 112, 113, 114, 116, 117, 118, 121, 123, 127, 128, 131, 132, 133, 134, 136, 137, 139, 140, 141, 144, 146, 147, 155, 157, 167, 168, 173], "predict_sent": 31, "predicted_label": 136, "prediction_ag": [15, 17, 18, 20], "prediction_fil": 22, "prediction_loss_onli": 113, "predominantli": [50, 112, 113], "preds_df": [20, 22], "preempt": [112, 113], "preexist": 118, "prefer": [10, 11, 31, 38, 43, 47, 65, 74, 88, 92, 93, 112, 113, 133, 135, 158, 160, 175, 183], "prefigur": [112, 113], "prefix": [31, 52, 53, 80, 82, 106, 109, 112, 113, 118, 131, 134, 140, 146, 175], "pregnanc": [112, 113], "preliminari": [105, 112, 113, 168], "preload": 112, "premia": 120, "premis": [66, 118, 151, 157, 159, 161], "premium": 129, "prenat": [112, 113], "preoccup": [112, 113], "prepar": [2, 7, 8, 9, 19, 31, 37, 38, 47, 72, 76, 78, 90, 97, 101, 106, 107, 110, 117, 130, 136, 137, 139, 140, 150, 153, 168, 170, 171, 172], "prepare_seq2seq_batch": 31, "prepared_data": 153, "preposit": 145, "preprint": [0, 7, 54, 100], "preprocess": [8, 13, 16, 42, 72, 76, 81, 94, 95, 96, 104, 106, 110, 111, 112, 113, 116, 131, 137, 139, 141, 149, 150, 151, 153, 156], "preprocess_funct": 112, "preprocessed_corpu": 153, "preprocessor": [16, 25, 31], "prerequisit": 166, "presbyterian": [112, 113], "preschool": [112, 113], "prescrib": [112, 113, 157], "prescript": [78, 137], "presenc": [94, 107, 112, 113, 116, 131, 137, 138], "present": [7, 8, 9, 10, 39, 42, 53, 54, 56, 60, 65, 76, 78, 80, 87, 88, 89, 90, 93, 96, 99, 103, 107, 110, 112, 113, 114, 115, 116, 117, 120, 121, 125, 130, 131, 139, 140, 160, 168, 171, 172, 173, 177, 178, 179], "preserv": [39, 51, 89, 99, 106, 112, 113, 117, 127, 128, 139, 144, 149, 151, 155], "preset": 153, "presid": [112, 113, 153], "presidenti": 120, "press": [37, 54, 60, 82, 112, 113], "pressur": 153, "prestigi": [112, 113], "presum": [112, 113], "preterm": [112, 113], "pretokenization_delimit": 104, "pretrain": [0, 2, 17, 18, 20, 22, 31, 89, 96, 97, 99, 116, 118, 123], "pretrained_model_name_or_path": 52, "pretrainedtokenizerfast": [111, 112, 113], "pretti": [78, 79, 137, 177, 178], "prettili": 177, "prev_decis": [26, 27, 28, 29, 30, 34, 36], "prevail": 117, "preval": [50, 112, 113, 116, 140, 152], "prevent": [7, 53, 56, 78, 79, 86, 98, 112, 113, 122, 131, 134, 148, 157], "previou": [7, 9, 11, 24, 26, 27, 28, 50, 53, 65, 67, 73, 82, 86, 87, 89, 93, 98, 100, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 129, 133, 134, 139, 148, 153, 160, 168, 170, 173, 178, 182, 184, 185], "previous": [7, 9, 11, 60, 73, 96, 98, 111, 112, 113, 117, 127, 131], "pri": 102, "price": [13, 39, 41, 43, 60, 102, 112, 113, 119, 120, 129, 135, 139, 153], "pride": [90, 112, 113], "primari": [10, 38, 43, 50, 58, 60, 61, 68, 70, 80, 92, 96, 99, 103, 110, 112, 113, 115, 117, 119, 144, 147, 152, 157, 158, 171, 172, 173], "primarili": [10, 42, 50, 54, 55, 77, 106, 112, 113, 115, 117, 123, 127, 139, 170, 172], "prime": [17, 98, 117, 129, 148], "primit": [112, 113], "primitiv": [112, 113], "princeton": 138, "princip": [10, 60, 112, 113, 127, 139, 149, 151], "principl": [10, 47, 51, 53, 65, 66, 67, 72, 81, 112, 113, 117, 131, 134, 141, 147, 152, 160, 161, 162, 163, 164, 172, 173], "print": [4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 44, 70, 95, 96, 98, 101, 102, 104, 105, 106, 108, 109, 111, 112, 113, 121, 124, 125, 128, 129, 133, 134, 136, 137, 142, 143, 144, 145, 146, 151, 153, 156, 159, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "print0": 80, "print_config": 16, "print_token": 102, "print_trainable_paramet": 52, "printer": 121, "prior": [7, 9, 38, 47, 86, 101, 112, 113, 121, 131, 149, 152], "prior_loss_weight": 52, "priori": 139, "priorit": [8, 51, 56, 94, 112, 113, 131, 172, 173], "prioriti": [42, 112, 113, 166], "prisk_": 120, "prison": 157, "privaci": [2, 39, 42, 46, 48, 60, 72, 75, 79, 80, 83, 86, 89, 90, 94, 110, 112, 113, 122, 131], "privat": [46, 62, 77, 78, 79, 83, 112, 113], "privileg": [43, 65, 82, 112, 113, 160], "prj": 151, "pro": [45, 102, 112, 113, 121], "proactiv": [13, 78, 173], "prob": [144, 153], "probabilist": [0, 7, 9, 50, 55, 106, 107, 121, 122, 131, 139, 149], "probabl": [0, 9, 15, 17, 18, 23, 47, 85, 91, 98, 100, 106, 109, 111, 112, 113, 114, 117, 118, 121, 128, 129, 131, 132, 134, 139, 144, 146, 152, 153, 156, 158, 186], "probat": [112, 113], "probe": 151, "probestim": 153, "problem": [10, 11, 38, 42, 43, 45, 50, 51, 52, 54, 58, 65, 66, 72, 74, 76, 78, 86, 88, 89, 90, 93, 97, 98, 99, 101, 103, 106, 107, 112, 113, 116, 118, 126, 127, 129, 130, 131, 134, 137, 139, 140, 144, 146, 147, 152, 160, 161, 162, 164, 166, 168, 169, 170, 171, 176], "problemat": 60, "proc": [16, 21, 25, 31], "procain": 156, "proce": [46, 112, 113, 134, 137, 168], "procedur": [10, 46, 58, 107, 111, 112, 113, 117, 121, 165, 170], "proceed": [0, 7, 82], "process": [0, 2, 3, 6, 7, 9, 10, 11, 12, 15, 16, 17, 18, 21, 22, 23, 25, 29, 31, 38, 42, 43, 45, 46, 47, 48, 51, 53, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 121, 122, 123, 124, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 144, 145, 148, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 169, 172, 178], "processio": 98, "processor": [112, 113], "proclam": 172, "prod": [98, 108, 144, 158], "prod_": [100, 106, 107, 133], "prodigi": [112, 113], "produ": [102, 108], "produc": [3, 7, 9, 10, 11, 13, 43, 47, 50, 60, 75, 78, 85, 89, 90, 92, 93, 94, 98, 102, 105, 106, 112, 113, 117, 118, 127, 128, 131, 133, 135, 139, 148, 153, 163, 164, 173, 182], "product": [0, 10, 35, 41, 43, 50, 52, 53, 57, 60, 65, 66, 67, 71, 72, 74, 75, 76, 83, 86, 89, 99, 101, 102, 106, 107, 109, 112, 113, 114, 115, 117, 119, 126, 127, 129, 133, 135, 138, 139, 144, 148, 151, 153, 159, 160, 161, 164, 165, 167, 170, 172, 173, 181], "profession": [7, 50, 51, 86, 90, 99, 112, 113, 168, 169], "professor": [97, 112, 113, 130], "profici": [38, 43, 44, 50, 94, 112, 113, 122, 173], "profil": [39, 47, 60, 67, 70, 92, 112, 113, 178, 179], "profit": [35, 118, 122, 153], "profound": [3, 51, 112, 113], "prognosi": [112, 113], "program": [6, 7, 38, 54, 58, 70, 81, 88, 92, 94, 98, 99, 112, 113, 122, 131, 142, 162, 164, 168, 170, 171, 172, 175, 182, 183], "programmat": [0, 60, 70, 121], "progress": [39, 46, 51, 56, 64, 76, 92, 93, 94, 97, 112, 113, 114, 130, 167, 168, 172, 173], "progress_p": [15, 16, 22], "prohibit": [84, 112, 113], "project": [2, 3, 7, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 45, 53, 60, 61, 62, 63, 65, 67, 68, 69, 71, 72, 73, 81, 83, 84, 88, 89, 90, 96, 98, 106, 112, 113, 117, 122, 124, 127, 131, 139, 147, 149, 153, 160, 162, 164, 168, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186], "project_dir": [15, 17, 18, 20, 21, 22, 23], "project_id": [21, 22, 46], "project_list": [21, 22], "project_nam": [18, 70], "proletariat": [112, 113], "prolifer": [50, 86, 91, 112, 113], "prolong": 51, "prometheu": [65, 66, 72, 160, 161], "promin": [47, 53, 112, 113, 117], "promis": [3, 7, 13, 41, 51, 54, 55, 78, 91, 93, 98, 99, 117, 121, 131, 145], "promot": [43, 60, 65, 66, 67, 72, 86, 99, 112, 113, 131, 152, 160, 161, 172], "prompt": [1, 2, 3, 5, 7, 9, 11, 47, 48, 52, 54, 56, 65, 75, 77, 81, 82, 83, 93, 97, 99, 112, 160, 182], "prompt_embed": 53, "prompt_token": 53, "prompt_tun": 53, "pron": 145, "prone": [50, 112, 113, 116, 119, 152, 167], "pronoun": [112, 113, 131, 141, 145], "pronounc": [112, 113, 116], "pronunci": [112, 113, 116], "proof": [50, 78, 90], "propag": [50, 51, 56, 110, 128], "propaganda": [112, 113, 131], "propagandist": 151, "propens": [60, 121], "proper": [78, 81, 96, 112, 113, 120, 134, 142, 146], "properli": [11, 15, 39, 46, 108, 109, 112, 113, 146, 156], "properti": [10, 60, 72, 75, 95, 99, 110, 112, 113, 127, 131, 133, 148, 151, 152, 153, 157], "propn": 145, "propon": [112, 113], "proport": [112, 113, 116, 131, 134, 152], "proportion": [112, 113], "propos": [2, 7, 9, 12, 53, 90, 97, 106, 107, 112, 113, 116, 117, 121, 128, 129, 146, 148, 157, 162, 166], "proposit": 60, "proprietari": 60, "proselyt": [112, 113], "prospect": [51, 112, 113], "prosper": [112, 113], "protect": [60, 65, 75, 77, 78, 79, 83, 94, 112, 113, 131, 160], "protest": [112, 113], "proto": [112, 113], "protocol": [13, 56, 77, 79, 83, 177], "prototyp": [60, 73, 166, 172, 173], "proudhon": [112, 113], "prove": [7, 47, 54, 78, 85, 112, 113, 117], "proven": [51, 58, 87, 117, 119, 157], "provid": [1, 2, 3, 7, 8, 9, 10, 11, 13, 36, 38, 39, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 104, 105, 106, 107, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 147, 148, 149, 151, 152, 153, 155, 156, 157, 159, 160, 161, 164, 166, 167, 168, 169, 170, 171, 172, 173, 184, 187], "provinc": [112, 113], "proving_exist": 150, "provis": [65, 66, 74, 112, 113, 160, 161], "provoc": [112, 113], "prowess": 2, "proxi": [41, 43, 120], "proxim": [112, 113], "prp": 145, "prune": [53, 56, 75, 80, 107], "pschaldenbrand": 10, "psentiment_": 120, "pseudo": [53, 134, 153], "pseudocod": 170, "psm14": 0, "psychiatr": [112, 113], "psychiatri": [112, 113], "psychiatrist": [112, 113], "psychoact": [112, 113], "psycholog": [112, 113, 138], "psychologi": [90, 112, 113, 131], "psychologist": [112, 113], "psychopath": [112, 113], "psychosoci": [112, 113], "pt": [96, 101, 115], "ptab": 17, "pteridophyt": [112, 113], "ptmodel": 153, "pu": 102, "pub": [77, 151, 157, 186], "public": [13, 37, 60, 62, 63, 73, 77, 78, 79, 81, 82, 86, 93, 98, 112, 113, 118, 120, 121, 122, 131, 135, 152, 168, 177, 178, 182, 186], "publicli": [37, 90, 94, 121, 122], "publish": [2, 10, 13, 14, 37, 38, 88, 112, 113, 117, 120, 130, 153, 162, 178, 187], "pubm": 94, "pull": [2, 61, 65, 71, 77, 81, 82, 160, 162, 178, 181, 182, 183, 184, 186, 187], "puls": [112, 113], "pulse\ub85c": 22, "pulumi": [65, 160], "pump": 109, "punct": 145, "punctuat": [56, 103, 105, 118, 131, 137, 140, 141, 143, 154], "punish": [112, 113], "punjabi": 96, "punk": [112, 113], "punkt": [133, 143], "pupil": [112, 113], "puppet": [65, 66, 160, 161], "puppi": 114, "purchas": [60, 112, 113], "pure": [0, 106, 181], "purpos": [2, 6, 10, 11, 39, 46, 50, 54, 55, 60, 72, 77, 79, 89, 90, 106, 109, 111, 113, 116, 122, 131, 137, 138, 141, 153, 168, 174], "pursu": [51, 112, 113], "pursuit": 101, "purview": [112, 113], "push": [3, 6, 47, 53, 61, 73, 74, 77, 81, 82, 112, 113, 158, 177, 181, 182, 183, 184, 186], "push_to_hub": 46, "put": [2, 19, 38, 53, 112, 113, 122, 129, 137, 173, 178, 182], "puzzl": 54, "pwd": [174, 178], "pwr": 113, "pxp": 117, "py": [29, 31, 44, 52, 62, 70, 81, 101, 102, 104, 109, 111, 112, 113, 115, 136, 137, 182, 185], "py2": 136, "py3": [101, 102, 104, 109, 115, 133, 136, 137, 142, 151], "py_util": 15, "pyautogen": 43, "pyc": 182, "pydant": [31, 32, 33, 34, 35], "pylab": 182, "pyldavi": 153, "pyop": 143, "pypars": 137, "pypi": [74, 133, 136, 137, 142, 151, 153], "pyplot": [95, 129, 137, 140, 150, 151, 156], "pypoetri": [101, 102, 104, 109, 115, 133, 136, 137, 142, 151], "pysbd": [25, 143, 147], "pysbdsegment": 25, "python": [2, 13, 38, 43, 46, 50, 52, 60, 62, 66, 69, 70, 71, 73, 74, 81, 88, 95, 98, 101, 106, 111, 112, 113, 122, 124, 125, 130, 133, 136, 137, 142, 143, 145, 153, 156, 161, 162, 168, 170, 182, 185], "python3": [29, 31, 43, 101, 102, 104, 109, 111, 112, 113, 115, 133, 136, 137, 142, 151], "pytorch": [9, 10, 13, 46, 52, 72, 76, 84, 97, 111, 113], "pytorch_model": [101, 113, 115], "pytorchmodelartifact": 74, "pytz": [137, 142], "pyv": 143, "q": [2, 9, 35, 48, 53, 85, 98, 100, 101, 102, 109, 114, 115, 117, 120, 121, 129], "q1": 102, "q2": 102, "q3": 102, "q4": 102, "qatar": 0, "qe": 24, "qian": 0, "qmul": 0, "qu": 102, "qua": [112, 113], "quadgram": 133, "quadrant": 173, "quadrat": 117, "quadrupl": 11, "qualifi": 127, "qualit": [7, 11, 13, 50, 112, 121], "qualiti": [6, 7, 8, 9, 10, 11, 12, 14, 43, 46, 47, 54, 60, 65, 66, 72, 81, 84, 89, 90, 92, 93, 96, 98, 99, 101, 110, 112, 113, 122, 123, 131, 133, 135, 137, 139, 142, 148, 150, 151, 160, 161, 165, 166, 167, 170, 171, 172, 173], "quandl": [24, 35], "quantif": [112, 113], "quantifi": [112, 113, 127, 133, 148, 149, 156, 158], "quantit": [7, 11, 13, 14, 112, 129], "quantiti": [24, 99, 101], "quantiz": [9, 10, 75], "quantum": [50, 51, 79], "quar": 102, "quart": 108, "quarter": [96, 102, 112, 113, 120, 129, 153], "quarterli": [0, 13, 121, 129], "quartil": 96, "queen": [134, 157], "queer": [112, 113], "queri": [25, 42, 43, 47, 50, 53, 58, 85, 93, 115, 117, 122, 124, 131, 148, 156], "question": [1, 3, 13, 43, 54, 56, 58, 60, 70, 84, 87, 90, 93, 94, 99, 101, 110, 112, 113, 114, 116, 117, 118, 120, 123, 132, 137, 141, 152, 155, 156, 158, 178, 184], "questionnair": [52, 70, 112, 113], "queue": 168, "qui": 102, "quick": [116, 122, 143, 144, 145, 159, 167, 173], "quicker": [53, 54], "quickfact": [112, 113], "quickli": [11, 60, 64, 65, 66, 72, 90, 98, 101, 110, 112, 113, 116, 131, 133, 160, 161, 167, 172, 181], "quickstart": 136, "quit": [47, 98, 112, 113, 129, 131, 141, 143, 150, 153], "quoc": 0, "quot": [77, 150, 151], "quotat": 118, "r": [0, 15, 24, 33, 38, 46, 52, 53, 54, 62, 77, 80, 81, 100, 101, 102, 106, 107, 108, 109, 112, 113, 120, 125, 131, 146, 147, 148, 181], "r2": [30, 36], "ra": [79, 102], "raab": [0, 7], "race": [94, 112, 113], "racehors": 7, "racial": [112, 113], "racism": [112, 113], "racist": [112, 113], "radar": [112, 113], "rade": 102, "radford": 100, "radi": [112, 113], "radiat": [112, 113], "radic": [112, 113], "radicalis": [112, 113], "radios": [112, 113], "radiu": [112, 113], "radviz": 29, "raffel": [0, 116, 118], "raft": 52, "rag": [2, 48, 60], "rage": 26, "rai": [9, 102, 112, 113, 151], "raid": [174, 178, 186], "rail": [112, 113], "railroad": [112, 113], "rain": [112, 113], "rainfal": [112, 113], "rainforest": [4, 112, 113], "rais": [13, 39, 56, 78, 94, 99, 110, 112, 113, 117, 120, 122, 131, 153], "ral": 102, "ralli": [112, 113, 153], "ram": 52, "rami": 0, "ramp": 109, "ran": [102, 114], "random": [9, 10, 13, 78, 89, 96, 98, 99, 100, 106, 112, 113, 116, 129, 133, 134, 137, 139, 145, 150, 153, 185], "random_batch": 129, "random_index": 129, "random_input": 129, "random_label": 129, "random_st": [17, 21, 29, 34, 137, 151], "randomforestclassifi": 74, "randomized_svd": 151, "randomli": [10, 11, 98, 100, 102, 104, 107, 108, 109, 110, 113, 114, 129, 134], "randomundersampl": 137, "rang": [4, 6, 7, 8, 9, 10, 11, 13, 25, 42, 47, 50, 51, 53, 54, 56, 60, 63, 66, 72, 74, 87, 89, 93, 94, 95, 98, 99, 101, 102, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 122, 124, 125, 128, 129, 131, 133, 134, 137, 139, 146, 149, 153, 156, 157, 161, 168, 172], "rangeindex": [15, 22], "rangl": 109, "ranjel": [112, 113], "rank": [0, 9, 10, 52, 53, 56, 89, 93, 98, 102, 107, 112, 113, 117, 131, 140, 144, 153], "rank1d": [29, 34], "rank2d": [29, 34], "ransfer": 118, "ransform": 118, "rape": [112, 113], "rapid": [51, 64, 72, 75, 90, 94, 112, 113, 122, 167, 172, 173], "rapidli": [3, 47, 56, 87, 101, 118, 131], "rapier": [112, 113], "rapporteur": [112, 113], "rare": [0, 103, 107, 112, 113, 120, 126, 129, 140, 144, 158, 159], "rat": [7, 102], "rate": [2, 9, 11, 13, 14, 25, 28, 29, 31, 33, 35, 38, 39, 46, 47, 89, 102, 112, 113, 116, 117, 120, 129, 136, 137, 138, 153], "rate_chang": [24, 25, 26, 27, 28, 32], "rate_decis": [24, 25, 26, 27, 28, 32], "rather": [3, 10, 13, 42, 47, 53, 65, 72, 93, 98, 100, 112, 113, 115, 116, 117, 119, 133, 141, 148, 153, 155, 157, 160], "ratifi": [112, 113], "ratio": [15, 21, 27, 28, 46, 56, 89, 112, 113, 133, 153, 159], "ration": [112, 113], "rational": [171, 172], "raw": [0, 24, 25, 31, 42, 47, 93, 94, 96, 98, 113, 116, 123, 129, 131, 136, 139, 146, 150, 153, 157, 174], "raw_output": [15, 23], "raw_pr": [15, 17, 20, 22, 31], "rawl": [112, 113], "rayid": 0, "raymond": [112, 113], "raz": [112, 113], "rb": [17, 18, 20, 112, 113], "rb_category_dataset": 17, "rb_cfg": [17, 18, 20], "rbs043xj": 17, "rbs043xjsync": 17, "rc4": [78, 79], "rce": 108, "rcparam": [18, 23, 27, 29, 31, 33], "rdf": [15, 42], "rdzv_backend": 52, "re": [0, 1, 2, 46, 47, 53, 70, 80, 81, 82, 101, 102, 105, 108, 109, 111, 112, 113, 127, 131, 140, 145, 150, 151, 153, 156, 157, 162, 163, 175, 176, 177, 178, 182, 186], "re100": [16, 20], "rea": [102, 125], "reach": [3, 7, 10, 51, 54, 98, 107, 109, 112, 113, 121, 157, 180], "react": 168, "reaction": [112, 113], "reactiv": [13, 45], "read": [0, 38, 50, 62, 71, 80, 88, 90, 91, 98, 99, 103, 112, 113, 116, 119, 120, 125, 131, 140, 151, 179, 182], "read_csv": 24, "readabl": [60, 65, 66, 97, 148, 160, 161], "reader": [53, 90, 112, 113, 131], "readi": [60, 74, 111, 112, 113, 179, 181, 182], "readili": [94, 112, 113, 127], "readlin": 125, "readm": [104, 137, 177], "readthedoc": [101, 102, 104, 109, 111, 112, 113, 115, 136, 137], "real": [0, 3, 6, 7, 11, 35, 38, 41, 43, 47, 48, 51, 52, 55, 56, 57, 58, 60, 64, 66, 72, 75, 78, 86, 88, 89, 90, 91, 94, 97, 98, 99, 112, 113, 114, 116, 127, 129, 130, 134, 135, 151, 156, 161, 168, 182], "realism": [7, 12], "realist": [6, 7, 8, 54, 60, 93, 116, 134, 152], "realiti": [7, 51], "realiz": [2, 140], "realli": [4, 98, 131, 133, 137, 175, 177, 179, 184], "realm": [3, 9, 43, 47, 50, 51, 53, 78, 106, 112, 113, 117, 127, 140, 154, 157, 169], "realnew": 118, "reapport": [112, 113], "reason": [7, 9, 54, 55, 58, 60, 72, 86, 93, 98, 99, 107, 112, 113, 116, 118, 119, 127, 131, 132, 136, 150, 164, 175], "reassess": 172, "rebas": [2, 162, 178, 187], "rebelli": [112, 113], "rebellion": [112, 113], "rebuild": [15, 23, 29, 101], "rebuilt": [112, 113], "recal": [15, 17, 23, 30, 31, 36, 56, 75, 136, 137, 145], "recalcul": 117, "recalibr": 47, "recall_scor": 136, "recap": 79, "receiv": [1, 11, 43, 47, 54, 55, 60, 77, 78, 79, 89, 101, 112, 113, 114, 115, 122, 124, 173, 178], "recent": [6, 7, 51, 60, 78, 87, 88, 90, 92, 93, 94, 98, 104, 112, 113, 116, 117, 119, 131, 133, 139, 145, 153, 176], "recent_decis": [25, 31], "recent_meet": [25, 31], "recent_r": [25, 31], "recess": 33, "recip": [47, 84], "recipi": [77, 78, 80, 117], "reciproc": [112, 113], "recit": 7, "reclaim": [112, 113], "reclam": [112, 113], "recogn": [6, 8, 10, 13, 47, 60, 92, 101, 103, 107, 112, 113, 117, 131, 133, 140, 142, 146], "recognit": [0, 7, 10, 50, 51, 78, 99, 112, 113, 114, 117, 123, 126, 130, 131, 132, 133, 134, 144, 145, 146], "recommend": [13, 38, 43, 50, 69, 76, 78, 92, 99, 101, 112, 113, 151, 152, 176], "reconcil": [39, 56, 65, 160], "reconfigur": 60, "reconsid": 98, "reconstruct": [7, 8, 9, 10, 96, 112, 113, 129, 152], "record": [7, 15, 17, 18, 20, 33, 50, 56, 70, 72, 73, 78, 102, 108, 109, 112, 113, 122, 131, 175, 176], "records_with_label_error": [15, 17, 18], "recov": [11, 118, 125], "recoveri": [65, 80, 160], "recreat": [7, 65, 160], "rectifi": 89, "recupero": 38, "recur": 90, "recurr": [7, 13, 50, 92, 100, 115, 117, 127, 131, 135], "recurs": 139, "red": [33, 66, 102, 112, 113, 148, 161, 177], "reddit": [13, 122], "redeem": [112, 113], "redefin": 3, "redesign": 173, "redi": 62, "redirect": [73, 179], "redistribut": [98, 134], "redistrict": [112, 113], "redo": 173, "redraw": [112, 113], "redston": [112, 113], "reduc": [10, 39, 43, 46, 47, 50, 51, 53, 54, 56, 58, 61, 64, 65, 66, 72, 75, 78, 86, 89, 94, 96, 99, 105, 106, 110, 112, 113, 116, 117, 120, 121, 125, 127, 129, 131, 139, 143, 147, 149, 151, 158, 160, 161, 164, 167, 168, 172, 173], "reduct": [51, 56, 112, 113, 120, 127, 152, 164, 173], "redund": [101, 127, 164, 173], "redworm": [112, 113], "ree": 102, "reed": [0, 117], "ref": [112, 113, 178, 186], "refactor": [172, 173], "refer": [6, 9, 10, 13, 51, 53, 56, 59, 65, 72, 90, 93, 96, 99, 101, 106, 111, 112, 113, 114, 117, 121, 122, 127, 131, 135, 136, 137, 138, 140, 141, 145, 148, 150, 152, 160, 172, 181, 186], "referenc": 56, "referendum": [112, 113], "referr": [112, 113, 137], "refil": 137, "refin": [7, 10, 12, 43, 47, 51, 53, 54, 56, 60, 86, 89, 90, 93, 99, 101, 112, 113, 117, 131, 152, 167, 173], "refineri": [112, 113], "reflect": [3, 7, 9, 10, 11, 43, 45, 54, 60, 90, 91, 112, 113, 152, 172], "reflector": [112, 113], "reflex": 45, "reform": [112, 113, 121], "reformist": [112, 113], "refract": [112, 113], "refresh": 177, "refriger": [112, 113], "refuge": [112, 113], "refund": 60, "refus": [15, 112, 113], "reg": 31, "reg_alpha": [30, 36], "reg_lambda": [30, 36], "regain": [112, 113], "regard": [39, 51, 99, 112, 113, 135], "regardless": [53, 74, 112, 113, 117, 129], "regener": 182, "regex": [31, 133, 136, 142], "region": [10, 13, 56, 85, 89, 91, 112, 113, 117, 121, 140, 149, 153], "regist": [112, 113], "registr": [79, 112, 113], "registri": [61, 63, 72, 74], "regolith": [112, 113], "regress": [7, 81, 89, 98, 112, 113, 118, 119, 121, 126, 127, 129, 135, 137, 139, 153], "regret": [112, 113, 137], "regul": [13, 39, 75, 78, 90, 94, 112, 113, 120, 121, 138, 168], "regular": [0, 9, 13, 31, 37, 64, 89, 104, 107, 134, 141, 145, 152, 172, 173], "regularli": [51, 56, 112, 113, 122, 140, 172], "regulatori": [72, 99], "reinforc": [0, 2, 50, 51, 54, 55, 92, 97, 112, 113, 131], "reinstat": [112, 113], "reit": 102, "reiter": [90, 168, 171], "reject": [112, 113, 186], "rejoin": [112, 113], "rel": [7, 9, 10, 11, 78, 85, 89, 100, 102, 110, 112, 113, 114, 118, 122, 131, 133, 139, 142, 144, 150, 151, 159], "relabelled_dataset": 18, "relat": [10, 11, 13, 36, 47, 51, 52, 54, 56, 58, 65, 67, 72, 73, 78, 90, 93, 99, 101, 110, 112, 113, 117, 119, 120, 121, 124, 127, 129, 137, 139, 140, 145, 148, 149, 150, 152, 153, 155, 156, 158, 160, 173], "relationship": [3, 8, 9, 10, 11, 12, 40, 41, 49, 50, 53, 54, 56, 99, 101, 103, 112, 113, 114, 115, 117, 123, 127, 128, 131, 133, 136, 138, 139, 141, 145, 148, 149, 150, 152, 155, 156, 157, 166, 170, 181], "relativedelta": 24, "relax": 127, "rele": 102, "releas": [11, 23, 24, 37, 61, 64, 66, 72, 84, 89, 94, 96, 98, 112, 113, 116, 118, 120, 122, 133, 136, 137, 142, 151, 153, 161, 172, 173, 181, 182], "releg": [112, 113], "relev": [1, 10, 42, 43, 47, 50, 54, 56, 58, 60, 72, 75, 76, 87, 92, 94, 98, 99, 101, 112, 113, 114, 115, 117, 119, 120, 124, 131, 132, 133, 139, 152, 156, 171, 172], "reli": [7, 9, 10, 13, 14, 31, 47, 50, 65, 66, 70, 77, 78, 85, 94, 101, 106, 112, 113, 114, 121, 123, 131, 132, 133, 135, 136, 138, 139, 145, 146, 160, 161], "reliabl": [1, 13, 39, 56, 60, 64, 65, 66, 72, 86, 94, 99, 101, 112, 113, 133, 160, 161, 163, 164, 167, 173], "relianc": [56, 78, 86], "relic": [65, 160, 170], "reliev": [112, 113], "religi": [11, 112, 113, 151], "religion": [112, 113, 151], "reload": [1, 73, 151, 179], "relogin": [18, 23, 31], "relu": [11, 89, 118, 129], "rema": 102, "remain": [7, 10, 39, 40, 42, 46, 47, 50, 51, 53, 54, 60, 62, 77, 78, 79, 83, 86, 90, 92, 94, 96, 100, 101, 109, 111, 112, 113, 116, 117, 134, 141, 149, 152, 153, 164, 173], "remaining_substr": 102, "remap_cat": 18, "remark": [9, 43, 51, 84, 99, 117, 127], "remedi": [64, 98], "rememb": [1, 90, 96, 104, 111, 112, 137, 142, 143, 145, 147], "remind": [89, 182], "reminisc": 55, "remiss": [112, 113], "remot": [2, 66, 69, 77, 82, 83, 112, 113, 161, 162, 178, 180, 181, 182, 183, 184, 187], "remote_serv": 77, "remov": [7, 10, 11, 15, 17, 23, 25, 31, 35, 46, 53, 56, 61, 89, 94, 96, 102, 105, 107, 108, 109, 111, 112, 113, 116, 118, 121, 129, 131, 137, 139, 141, 143, 146, 147, 149, 150, 151, 153, 174, 176, 177, 181, 182, 183], "remove_column": [112, 113], "remove_extra_whitespac": [104, 106], "remove_punctu": 137, "remove_stopword": 137, "removed_top_word": 153, "ren": [102, 140], "renaiss": [112, 113], "renam": [15, 17, 20, 22, 23, 27, 28, 35], "rename_column": 18, "render": [9, 10, 30, 36, 50, 51, 70, 78, 137, 145, 173, 174, 177, 182], "renew": [99, 112, 113], "reng": 108, "rengt": 108, "rength": 108, "renown": [53, 55, 60, 137], "ren\u00e9": [112, 113], "repair": [112, 113, 121], "repay": 121, "repeat": [89, 98, 99, 102, 107, 112, 113, 117, 118, 134, 137, 146, 148, 173], "repeatedli": [9, 77, 112, 113, 122, 173], "repertoir": 7, "repetit": [56, 66, 91, 98, 112, 113, 116, 161], "rephras": [9, 99], "replac": [10, 11, 31, 32, 47, 61, 77, 80, 81, 82, 83, 85, 96, 100, 102, 106, 109, 112, 113, 116, 117, 118, 127, 129, 133, 134, 141, 143, 144, 147], "replic": [6, 60, 67, 112, 113, 131], "replika": 131, "repo": [44, 70, 186], "repo_id": 46, "repo_nam": 46, "report": [0, 13, 15, 17, 23, 30, 31, 36, 97, 102, 112, 113, 120, 122, 124, 129, 136, 137, 153], "repositori": [39, 46, 61, 65, 66, 67, 70, 76, 77, 79, 94, 118, 160, 161, 175, 178, 180, 181, 182, 183, 184, 186, 187], "repositorynam": 183, "repostiori": 180, "repr": 153, "repres": [7, 9, 45, 46, 47, 50, 51, 53, 54, 55, 57, 58, 60, 74, 78, 82, 89, 90, 94, 98, 100, 103, 106, 107, 110, 112, 113, 114, 116, 117, 120, 121, 125, 126, 127, 128, 129, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 151, 152, 154, 155, 158, 159, 165, 171, 172, 173, 184], "represent": [0, 2, 7, 8, 9, 10, 11, 13, 30, 36, 50, 51, 53, 56, 60, 89, 90, 94, 96, 97, 99, 100, 105, 106, 110, 112, 113, 117, 125, 126, 127, 128, 129, 130, 134, 135, 137, 139, 140, 145, 149, 151, 152, 154, 156, 158, 159, 173], "reproduc": [7, 65, 66, 70, 72, 90, 98, 160, 161], "reptil": [112, 113], "republ": [112, 113], "republican": [112, 113], "repurpos": [47, 51], "reput": [53, 90, 94], "request": [43, 56, 65, 73, 74, 78, 112, 113, 121, 122, 124, 160, 173, 181, 183, 187], "requir": [2, 5, 7, 9, 10, 13, 38, 39, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 60, 62, 65, 66, 67, 70, 71, 72, 74, 75, 78, 79, 80, 81, 83, 84, 85, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 103, 106, 107, 110, 112, 113, 115, 116, 117, 118, 121, 122, 124, 125, 127, 131, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 151, 152, 153, 158, 160, 161, 162, 163, 164, 165, 168, 170, 171, 172, 173, 180, 186], "required_char": [104, 106], "rerout": [112, 113], "rerun": [30, 36, 137], "resampl": 35, "rescal": [89, 118], "rescu": 127, "research": [0, 2, 6, 7, 9, 10, 12, 39, 48, 50, 53, 54, 55, 56, 60, 78, 84, 87, 88, 89, 92, 93, 94, 97, 98, 99, 101, 110, 112, 113, 115, 117, 118, 119, 122, 123, 127, 130, 135, 142, 149, 152, 153, 155, 170, 174], "resembl": [98, 112, 113], "reserv": [116, 120, 138], "reset": [16, 180, 182], "reset_index": [15, 16, 17, 21, 22, 24, 25, 29, 34, 35], "reshap": [2, 78, 87, 167], "resid": [112, 113], "residenti": [112, 113], "residu": [10, 11, 53, 117, 118], "resign": [112, 113], "resili": [86, 172], "resist": [78, 112, 113], "resiz": 111, "resize_token_embed": 111, "resnet": [10, 118], "resolut": [10, 52, 56, 89, 112, 113, 117, 131, 173], "resolv": [9, 10, 11, 39, 56, 65, 112, 113, 117, 132, 160, 166, 176], "reson": 2, "resou": 108, "resour": [102, 108], "resourc": [7, 21, 24, 31, 46, 47, 50, 51, 52, 53, 54, 56, 60, 61, 63, 64, 65, 66, 72, 75, 76, 78, 82, 84, 89, 90, 92, 94, 96, 99, 102, 106, 108, 110, 112, 113, 117, 133, 137, 138, 151, 157, 160, 161, 164, 167, 170, 173], "respect": [7, 9, 10, 74, 77, 84, 91, 93, 94, 106, 111, 112, 113, 114, 117, 118, 129, 131, 138, 149, 153, 170, 178], "respond": [7, 45, 50, 56, 66, 92, 112, 113, 121, 131, 161, 172], "respons": [9, 10, 11, 13, 43, 47, 50, 51, 58, 60, 61, 62, 63, 64, 65, 66, 73, 84, 85, 86, 89, 92, 93, 94, 98, 99, 101, 112, 113, 117, 131, 135, 148, 160, 161, 165, 168, 170, 172, 173], "responsibli": [13, 131], "rest": [11, 51, 53, 62, 72, 74, 78, 96, 98, 111, 112, 113, 131, 134, 146, 153], "restart": [133, 136, 137, 142, 151], "restaur": [112, 113, 140], "restock": 101, "restor": [65, 67, 106, 112, 113, 141, 160, 174, 175, 177, 181, 182], "restraint": [112, 113], "restrict": [9, 50, 83, 84, 112, 113, 116, 122], "resu": 102, "resul": 102, "result": [3, 5, 7, 8, 10, 17, 18, 20, 22, 26, 38, 39, 43, 44, 47, 50, 51, 53, 54, 56, 58, 61, 66, 74, 78, 79, 85, 89, 90, 91, 93, 94, 97, 98, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 129, 131, 133, 134, 136, 137, 138, 140, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 167, 172, 173, 174, 178, 182, 184], "resum": 60, "resurg": [112, 113], "reta": 102, "retail": [13, 27, 28, 102, 112, 113, 153], "retain": [10, 50, 51, 52, 53, 89, 103, 107, 112, 113, 117, 118, 121, 141, 184], "retain_graph": 129, "retard": [112, 113], "retarget": 7, "retent": [50, 53], "reti": 102, "retina": [16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 115, 129, 146, 150, 151], "retir": [102, 167], "retrain": [10, 47, 72, 75, 84, 112], "retreat": 153, "retrench": 120, "retriev": [2, 10, 43, 47, 48, 50, 60, 75, 96, 99, 124, 125, 131, 141, 148, 149, 151, 152, 154, 156, 158], "retrievechat": 43, "retroflex": [112, 113], "retrospect": [112, 113, 172], "rett": [112, 113], "return": [21, 53, 73, 74, 82, 89, 98, 101, 102, 105, 106, 108, 109, 111, 112, 113, 114, 115, 125, 128, 129, 131, 133, 134, 136, 137, 142, 146, 151, 153, 179], "return_num_sequ": 98, "return_parent_dir": 18, "return_special_tokens_mask": 113, "return_tensor": [98, 101, 115], "return_x_i": 150, "reus": [0, 43, 63, 104, 112, 113, 116, 121, 137, 153], "reusabl": [39, 65, 160, 165], "reuter": [123, 153], "reveal": [10, 53, 60, 78, 96, 98, 112, 113, 117, 129, 131, 139, 149, 152, 172, 173], "reven": 102, "revenu": [102, 112, 113, 153], "revers": [10, 11, 53, 80, 102, 106, 108, 109, 112, 113, 125, 135, 138, 140, 150, 156], "reversibli": 106, "revert": [65, 160, 177, 178, 180], "review": [0, 47, 48, 65, 68, 69, 94, 99, 101, 111, 112, 113, 123, 131, 135, 136, 137, 138, 139, 149, 160, 166, 167, 172, 173, 174, 179], "revis": [90, 101, 112, 113, 130, 173, 175, 179, 182, 184, 185], "revisit": [51, 98, 173], "reviv": [112, 113], "revolut": [98, 112, 113], "revolution": [6, 51, 53, 54, 84, 92, 117, 131, 139], "revolutionari": [1, 112, 113], "revolv": 172, "reward": [47, 50, 52, 55, 90, 93, 131], "rework": 173, "rewrit": [112, 113, 133, 184], "reynold": [112, 113], "rf": [108, 178, 185, 186], "rfou": 0, "rgb": [7, 8, 117], "rgi": 108, "rh": 33, "rhyme": [112, 113], "rhythmic": [112, 113], "ri": 102, "rice": [131, 134], "rich": [7, 56, 65, 94, 107, 116, 127, 131, 138, 155, 160], "richard": [0, 112, 113], "richer": [11, 50, 53, 127], "richest": 131, "rickwood": [112, 113], "rico": 0, "rid": [129, 176, 178], "ride": [4, 11, 112, 113, 118], "ridg": [112, 113], "ridgelin": [112, 113], "rifl": 121, "rig": 7, "righ": 108, "right": [1, 25, 46, 51, 68, 69, 72, 89, 98, 99, 102, 103, 107, 112, 113, 114, 121, 129, 131, 133, 137, 145, 146, 148, 155, 166, 174, 177, 178, 179, 181, 186], "right_index": [32, 34, 35], "rightarrow": 118, "rigid": [112, 113, 172, 173], "rigidli": 167, "rigor": [13, 14, 56, 90, 167, 168, 173], "rilei": [112, 113], "ring": [112, 113], "rinoh": 182, "rinohtyp": 182, "riot": [112, 113], "rip": 102, "rise": [0, 4, 6, 45, 50, 57, 102, 112, 113, 139, 140, 141, 153, 157], "rishi": 0, "risk": [0, 2, 25, 42, 51, 53, 60, 64, 65, 66, 72, 75, 78, 86, 87, 93, 94, 99, 112, 113, 121, 122, 131, 133, 153, 160, 161, 167, 170, 172, 173, 184], "riski": [86, 120, 167, 173], "risperidon": [112, 113], "ritual": [112, 113], "ritualist": [112, 113], "rival": [112, 113, 120], "rivalri": 152, "river": [100, 112, 113, 130, 131], "riverchas": [112, 113], "rket": 108, "rl": [47, 54, 55, 93], "rlhf": [2, 50, 92, 97], "rm": [62, 80, 178, 182, 185, 186], "rm_top": 153, "rmi": 62, "rmsprop": 110, "rmtree": 174, "rn50x16": 10, "rn50x4": 10, "rn50x64": 10, "rning": 108, "rnn": [13, 92, 100, 115, 117, 131, 135, 147], "ro": [96, 102], "road": [112, 113], "roadblock": 13, "roadmap": [90, 167, 168, 170], "robert": [0, 100, 112, 113, 121], "roberta": [52, 96, 99, 109, 110, 118, 139], "robi": [112, 113], "robinson": 134, "robot": [2, 5, 6, 7, 54, 55, 60, 90, 92, 122], "robust": [7, 10, 13, 39, 42, 43, 51, 54, 55, 56, 60, 61, 72, 77, 78, 79, 80, 84, 90, 93, 106, 107, 116, 121, 123, 131, 138, 141, 148, 167, 168, 169, 170], "robustli": 100, "rob\u00e9": [112, 113], "rock": [4, 112, 113], "rocket": [112, 113], "rocketship": 11, "rocki": [112, 113, 129], "rod": 157, "roderbh15": 0, "rodrigo": [112, 113], "rodu": 108, "roger": [112, 113], "roi": [112, 113, 168], "rojava": [112, 113], "role": [3, 6, 7, 38, 43, 45, 47, 51, 53, 54, 55, 56, 58, 64, 72, 75, 77, 78, 79, 90, 93, 98, 112, 113, 117, 123, 127, 131, 132, 139, 141, 145, 147, 148, 151, 156, 165, 168, 171], "rolex": [112, 113], "roll": [33, 65, 72, 112, 113, 160, 167, 175], "rollback": [65, 160, 174], "rollout": [65, 160, 170], "rom": 102, "roman": [112, 113], "romanian": 96, "romantic": [112, 113], "romero": 0, "roof": [112, 113, 121], "rooftop": [112, 113], "room": [10, 53, 73, 82, 112, 113, 116, 146], "root": [18, 22, 53, 82, 105, 112, 113, 129, 131, 140, 141, 143, 147, 148, 151, 175], "rosa": [0, 96], "rose": [17, 112, 113, 120, 153], "rosenwald": [112, 113], "rotat": [9, 10], "rou": 102, "roug": [56, 112, 113], "rough": [7, 102, 112, 113, 137], "roughli": [10, 112, 113, 185], "roun": [102, 108], "round": [4, 84, 112, 113], "rout": [47, 73, 83, 112, 113], "routin": [112, 113], "row": [15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 117, 120, 126, 127, 129, 137, 151, 152, 158, 159], "row_num": 33, "rp": [108, 145], "rpf": 15, "rporat": 108, "rporati": 108, "rporatio": 108, "rrb": 145, "rsa": [78, 79], "rsale": 24, "rsales_d": 24, "rsales_diff_prev": [24, 26, 27, 28, 29], "rsales_diff_year": [24, 26, 27, 28, 29, 30, 34, 36], "rsdai": 109, "rsn20": 0, "rsr": 0, "rstrip": 125, "rsync": 67, "rtc": 182, "rtner": 108, "rtunit": 146, "rtx": 113, "ru": [96, 102, 137], "rubber": [112, 113], "rubella": [112, 113], "rubi": [66, 161], "rubrix": [17, 20], "rui": 0, "rule": [6, 31, 45, 50, 54, 55, 58, 91, 92, 97, 106, 112, 113, 121, 130, 131, 133, 135, 136, 138, 140, 141, 151, 152], "ruler": [112, 113], "rumin": [112, 113], "rump": 109, "run": [1, 7, 15, 17, 18, 20, 22, 23, 30, 31, 36, 46, 52, 54, 63, 70, 72, 73, 77, 80, 81, 82, 89, 98, 101, 104, 106, 111, 112, 113, 115, 116, 120, 124, 133, 134, 136, 137, 142, 147, 151, 153, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "run_auto": 70, "runc": 61, "runic": [112, 113], "runner": 73, "runtim": [61, 63, 65, 81, 89, 111, 113, 160], "runtimeclass": 61, "runtimeerror": 153, "rural": [17, 112, 113], "rush": [112, 113], "russ": 0, "russel": [112, 113], "russia": [112, 113], "russian": [96, 112, 113, 116], "rust": 108, "rvic": 108, "rvice": 108, "ry": 102, "rych": 151, "rzp": 0, "r\u00f6der": 148, "s3": 39, "s_": 129, "s_i": 148, "sa": 89, "saanich": [112, 113], "sabotag": [112, 113], "sac": [112, 113], "sack": [112, 113], "sad": [4, 131, 135], "saddl": 130, "safe": [4, 15, 93, 152, 172, 177], "safeguard": [2, 39, 60, 75, 78, 79, 131], "safer": [53, 64, 78, 86], "safeti": [51, 84, 93, 112, 113], "sagemak": 72, "sagwa": 131, "sahara": [112, 113], "sai": [95, 112, 113, 129, 131, 134, 153, 175, 178], "said": [112, 113, 137, 140, 146, 151, 153, 157, 177, 181], "saisana": 38, "saito": [0, 7, 152], "sake": 113, "sal": 102, "sala": 0, "salakhutdinov": [0, 100], "sale": [13, 27, 28, 102, 112, 113, 153, 168], "saliman": 100, "saltstack": [65, 66, 160, 161], "saltwat": [112, 113], "sam": [8, 133], "same": [7, 9, 10, 11, 53, 56, 65, 67, 72, 78, 79, 89, 96, 98, 100, 101, 104, 105, 106, 107, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 125, 127, 129, 131, 134, 136, 138, 140, 141, 143, 144, 146, 147, 148, 152, 153, 156, 157, 158, 159, 160, 174, 176, 179, 182, 184], "same_network": 52, "samford": [112, 113], "samoan": 96, "sampa": [112, 113], "sampl": [0, 7, 10, 11, 22, 29, 76, 85, 89, 91, 95, 102, 104, 106, 108, 109, 112, 113, 116, 122, 131, 133, 135, 137, 144, 152, 153], "sample_data": 95, "sample_hdp_model": 153, "sample_output": 98, "sample_review": 137, "sample_s": 95, "sample_sent": 104, "sampling_method": 96, "samsung": 124, "samuel": 0, "san": [29, 84, 140], "sanitari": [112, 113], "sanja": [0, 7], "santa": [112, 113], "sarcasm": 135, "sasanian": [112, 113], "sat": [133, 154], "satellit": [41, 112, 113, 151], "satisfact": [135, 172, 173], "satisfactori": 46, "satisfi": [7, 11, 133, 136, 137, 142, 151], "satur": 11, "saturn": [112, 113], "sauc": 47, "saunder": [0, 7], "sausag": 159, "savant": [112, 113], "save": [15, 16, 17, 21, 22, 23, 25, 29, 30, 31, 36, 47, 51, 61, 64, 74, 77, 80, 81, 83, 90, 100, 104, 106, 116, 146, 151, 164, 173, 176, 179, 182, 184], "save_a": 18, "save_data": [15, 16, 17, 18, 22, 24, 25, 27, 28, 31, 32, 34], "save_datafram": [16, 25, 31], "save_dir": 153, "save_html": 153, "save_model": [112, 113, 125], "save_path": 153, "save_pr": 21, "save_pretrain": [111, 112, 113], "save_step": [112, 113], "save_total_limit": [112, 113], "saved_path": 74, "savvi": 55, "saw": [24, 54, 112, 113, 114, 131, 134, 153], "saxon": [112, 113], "sc": [102, 112, 113, 142], "scaffold": 70, "scalabl": [39, 42, 46, 47, 50, 51, 60, 66, 72, 75, 78, 89, 91, 92, 117, 131, 161, 163, 167, 170, 173], "scale": [0, 7, 9, 11, 38, 39, 42, 47, 50, 52, 53, 60, 61, 66, 72, 74, 75, 84, 86, 87, 89, 90, 92, 94, 99, 101, 106, 110, 112, 113, 114, 117, 122, 123, 131, 139, 149, 150, 152, 161, 164, 170], "scan": [78, 112, 113], "scandal": [112, 113], "scanner": 41, "scant": [112, 113], "scarc": [47, 99, 131], "scarciti": 94, "scarlet": 18, "scatter": [74, 112, 113, 117, 129], "scatter_cfg": [26, 33], "scatterplot": [24, 26, 33], "scenario": [13, 43, 47, 51, 53, 55, 56, 58, 60, 63, 78, 94, 116, 127, 141, 148, 152, 155, 173], "scene": [6, 9, 10, 112, 113, 117, 150], "sceptic": [112, 113], "sch": 102, "schaeffer": 129, "schedul": [89, 112, 113, 165], "schema": [39, 72], "scheme": [78, 100], "schizophrenia": [112, 113], "schoen": [0, 7], "scholar": [90, 112, 113], "scholarli": 48, "school": [47, 99, 112, 113, 134], "schoolwork": [112, 113], "schreger": 0, "schwa": [112, 113], "schwedel": 0, "sci": [102, 151], "scienc": [0, 2, 13, 39, 40, 42, 50, 55, 58, 73, 74, 90, 94, 98, 112, 113, 127, 130, 131, 151, 169], "scientif": [47, 50, 89, 94, 112, 113, 122, 131, 152, 163], "scientist": [39, 60, 72, 75, 112, 113], "scikit": [13, 137], "scikit_learn": 151, "scipi": [142, 151], "scm": 71, "scope": [49, 50, 51, 53, 55, 60, 76, 167, 169, 173, 177, 178, 180, 181], "score": [10, 13, 15, 17, 23, 30, 36, 53, 56, 75, 86, 89, 91, 93, 98, 110, 114, 115, 117, 118, 120, 121, 129, 131, 135, 136, 137, 138, 139, 145, 147, 148, 152, 153], "score_ngram": 150, "scot": [112, 113], "scotland": [178, 180, 181, 182], "scott": [0, 121], "scottish": 96, "scrape": [44, 90, 94, 96, 118, 121], "scrapi": [13, 94], "scratch": [47, 73, 92, 102, 103, 109, 110, 112, 113], "scratchpad": 99, "screen": [44, 60, 112, 113, 177, 178, 179], "screener": [112, 113], "screw": 184, "scrip": 102, "script": [7, 37, 44, 46, 50, 52, 62, 65, 67, 72, 80, 81, 84, 96, 112, 113, 116, 122, 123, 137, 145, 156, 160], "scrum": [66, 161, 168, 171], "scrutin": 60, "scrutini": [51, 60], "scrypt": 77, "scullei": [0, 72], "sd": [52, 96], "sdai": [102, 108], "sdlc": [2, 162, 163], "sdsks18": [0, 7], "se": 102, "sea": [4, 18, 102, 112, 113], "seaborn": [95, 137, 150], "seafood": [112, 113], "seal": [65, 160], "seamless": [1, 7, 12, 43, 51, 52, 56, 60, 92], "seamlessli": [43, 52, 92], "seaport": [112, 113], "search": [0, 2, 13, 36, 43, 50, 56, 60, 80, 90, 94, 97, 99, 116, 120, 122, 124, 131, 146, 151, 152, 156, 158], "search_keyword": [15, 17, 18, 20], "searcher": 36, "season": [4, 13, 47, 112, 113, 153], "seat": [112, 113], "seattl": [112, 113], "sebastian": 0, "secc": [112, 113], "seced": [112, 113], "secess": [112, 113], "second": [6, 10, 53, 89, 96, 98, 100, 106, 109, 112, 113, 114, 115, 116, 117, 118, 121, 127, 131, 134, 138, 142, 153, 181, 184, 186], "secondari": [112, 113], "secondary_i": [26, 33], "secondli": [60, 112, 113, 139], "secreci": 78, "secret": [4, 67, 78, 79, 80, 81, 131, 177, 184], "secretari": [31, 112, 113], "secretstr": [31, 32, 33, 34, 35], "sect": [112, 113], "sectarian": [112, 113], "section": [1, 9, 10, 13, 44, 50, 53, 56, 61, 64, 72, 73, 74, 77, 78, 82, 83, 90, 96, 104, 111, 112, 113, 117, 118, 143, 150, 176], "section_id": [25, 31], "secto": 108, "sector": [13, 38, 39, 42, 46, 49, 50, 51, 53, 54, 60, 89, 102, 120, 153, 168], "secular": [112, 113], "secur": [2, 46, 50, 60, 61, 64, 65, 71, 72, 80, 82, 83, 112, 113, 121, 122, 131, 153, 160, 166, 168, 170, 171], "sed": [80, 102], "sedol": 54, "see": [6, 10, 24, 25, 26, 27, 28, 31, 52, 61, 73, 92, 98, 100, 101, 102, 104, 105, 109, 111, 112, 113, 115, 129, 131, 134, 137, 143, 144, 153, 174, 176, 177, 178, 179, 181, 186], "seed": [15, 21, 98, 102, 104, 106, 107, 108, 109, 153], "seed_sentencepiece_s": [104, 106], "seek": [51, 77, 112, 113, 131], "seekabl": 77, "seem": [98, 112, 113, 115, 133, 137, 140, 145, 148, 150, 151, 178], "seen": [9, 58, 60, 90, 94, 96, 98, 99, 101, 112, 113, 114, 120, 127, 129, 133, 134, 140, 152, 153, 157, 179], "seg": [143, 153], "seg_cfg": 25, "segment": [0, 2, 16, 25, 53, 88, 100, 105, 106, 107, 108, 109, 112, 113, 130, 131, 140, 141, 143, 153, 172, 173], "segment_na": 146, "segreg": [112, 113], "seiz": [112, 113], "select": [1, 9, 10, 15, 20, 51, 54, 58, 61, 65, 66, 67, 68, 71, 72, 73, 76, 80, 89, 90, 92, 94, 98, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 127, 130, 132, 133, 134, 138, 148, 152, 160, 161, 168, 169, 177, 179, 184], "selected_category_pr": 20, "selected_polarity_pr": 20, "selenium": [94, 122, 170], "self": [0, 11, 21, 43, 60, 74, 89, 90, 99, 100, 106, 112, 113, 115, 128, 129, 131, 139, 140, 164], "self_attent": 53, "self_attention_adalora": 53, "self_attention_ia3": 53, "self_attention_lora": 53, "self_test_sample_s": [104, 106], "sell": [102, 153], "selma": [112, 113], "semant": [2, 7, 11, 13, 39, 50, 56, 60, 89, 94, 97, 99, 101, 103, 107, 110, 111, 114, 116, 127, 128, 130, 131, 136, 139, 140, 141, 142, 147, 148, 151, 154, 155, 156, 158], "semest": 130, "semi": [43, 45, 60, 112, 113, 123, 124], "semiconductor": 129, "semicurs": [112, 113], "semin": [53, 88], "semistructur": [112, 113], "semit": [112, 113], "sen": [0, 7, 102, 128], "senat": [112, 113], "send": [43, 73, 122, 151], "sender": [77, 78, 79], "seng": 153, "senior": [112, 113, 129], "sennrich": [0, 106, 107], "sens": [58, 97, 101, 103, 112, 113, 115, 117, 130, 131, 138, 149, 151, 154, 157, 158], "sensat": [112, 113, 127], "sensibl": 178, "sensit": [7, 39, 46, 47, 50, 53, 55, 60, 65, 72, 75, 77, 78, 94, 98, 112, 113, 116, 120, 131, 133, 136, 139, 148, 149, 160], "sensor": [7, 10, 13, 41, 42, 45, 90, 112, 113], "sensori": [112, 113], "sent": [78, 128, 133, 134, 143, 145, 156], "sent_id": [25, 31], "sent_token": 143, "sentenc": [11, 33, 53, 92, 93, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 122, 123, 125, 126, 127, 128, 129, 131, 133, 135, 137, 138, 139, 140, 144, 145, 146, 148, 151, 154, 155, 156, 158], "sentence_a": 115, "sentence_b": 115, "sentenceiter": [104, 106], "sentencepiec": [2, 97, 103, 107, 116], "sentencepiece_token": 104, "sentencepiece_tokenizer_path": 104, "sentencepiece_train": [104, 106], "sentencepieceprocessor": [104, 106], "sentencepiecetrain": [104, 106], "sentences_nltk": 143, "sentences_pysbd": 143, "sentient": 131, "sentiment": [2, 22, 37, 38, 41, 42, 47, 51, 76, 94, 99, 101, 110, 112, 113, 114, 118, 119, 120, 121, 123, 127, 130, 131, 133, 139, 152, 154, 155, 157], "sentiment_afinn": 136, "sentiment_analysis_model": 111, "sentiment_map": 137, "sentiment_peft": 52, "sentiment_textblob": 136, "sentiment_vad": 136, "sentimentintensityanalyz": 136, "sentinel": [13, 116], "sentiwordnet": 139, "seo": 116, "seoul": 142, "sep": [21, 22, 104, 105, 109, 112, 113, 115, 153, 175, 176, 181, 185], "sep_token": [112, 113], "separ": [7, 10, 16, 25, 53, 62, 70, 72, 75, 77, 78, 81, 85, 91, 96, 100, 102, 103, 105, 106, 107, 109, 112, 113, 115, 121, 125, 129, 131, 136, 139, 141, 144, 145, 151, 152, 159, 177, 179, 180], "sephard": [112, 113], "sept": 129, "septemb": [112, 113], "seq": 53, "seq_2_seq_lm": 52, "seq_embed": 53, "seq_token": 53, "sequenc": [7, 8, 9, 10, 11, 17, 18, 20, 22, 31, 50, 52, 53, 54, 58, 60, 84, 87, 88, 91, 95, 98, 99, 100, 102, 103, 106, 107, 111, 112, 113, 114, 115, 116, 117, 118, 121, 131, 132, 134, 137, 139, 140, 144, 146, 173, 181], "sequence_classif": 52, "sequenti": [50, 53, 54, 100, 117, 139, 147, 167, 172, 173], "sequestr": [112, 113], "ser": [102, 108], "serbian": 96, "seren": 18, "sergei": [0, 7], "sergio": 0, "seri": [7, 10, 13, 42, 47, 54, 66, 72, 87, 88, 95, 101, 102, 112, 113, 117, 121, 131, 148, 161, 165, 167], "series_id": [24, 35], "series_nam": [24, 35], "serif": [29, 112, 113], "seriou": [112, 113], "serv": [2, 3, 8, 9, 10, 41, 44, 47, 49, 50, 53, 55, 57, 58, 60, 61, 65, 72, 76, 84, 89, 90, 112, 113, 115, 117, 122, 127, 133, 134, 138, 145, 148, 149, 160, 166, 167, 168, 170, 173], "server": [2, 56, 65, 66, 71, 73, 74, 76, 77, 78, 81, 122, 160, 161, 170, 177, 179, 181], "server_ip": [82, 83], "serverless": [39, 74], "servi": [102, 108], "servic": [38, 39, 43, 46, 49, 53, 56, 57, 60, 61, 63, 65, 66, 67, 72, 74, 81, 86, 92, 93, 108, 112, 113, 122, 124, 131, 135, 139, 140, 160, 161, 174], "servisfirst": [112, 113], "session": [0, 57, 64, 82, 88, 95, 111, 112, 113, 120, 136, 137, 172, 178], "set": [6, 7, 9, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 31, 39, 43, 45, 47, 50, 51, 52, 53, 56, 58, 60, 61, 62, 67, 69, 72, 73, 76, 79, 80, 83, 85, 89, 90, 92, 96, 98, 99, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 121, 124, 128, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 162, 164, 168, 170, 172, 173, 177, 178, 179, 181, 183, 185, 186], "set_format": 111, "set_index": [24, 31, 35], "set_se": 98, "set_titl": 150, "set_verbosity_error": 115, "set_word_prior": 153, "set_workspac": [15, 17, 18, 20, 21, 22, 23], "set_xlabel": 150, "set_xlim": [27, 28], "set_ylabel": 150, "setlogg": [16, 18, 25, 30, 32, 33, 34, 35, 153], "setminu": 120, "settl": [112, 113], "settlement": [44, 112, 113], "settler": [112, 113], "setup": [2, 46, 50, 65, 66, 67, 71, 81, 89, 112, 113, 160, 161], "seung": 152, "seven": [112, 113], "seventeen": [112, 113], "sever": [6, 7, 8, 9, 10, 11, 12, 39, 47, 50, 56, 60, 65, 66, 67, 72, 77, 78, 84, 89, 91, 94, 96, 97, 98, 99, 106, 107, 110, 112, 113, 117, 118, 122, 130, 131, 135, 144, 147, 148, 149, 151, 152, 153, 154, 160, 161, 168, 172, 173, 174, 184], "sewel": [112, 113], "sex": [112, 113], "sexual": [112, 113, 131], "sf": [120, 142, 143], "sfa": [78, 79], "sft": [46, 47], "sfv": 0, "sgd": [110, 129], "sh": [46, 81, 102, 185], "sha": [112, 113], "sha256": 136, "shadow": [17, 18, 112, 113], "shafir": [0, 7], "shakespear": [112, 113], "shall": 157, "shallow": [127, 129], "shap": 13, "shape": [3, 9, 15, 17, 21, 22, 24, 27, 28, 42, 53, 54, 60, 78, 112, 113, 144, 151], "shaplei": 41, "shar": 102, "sharan": 0, "share": [3, 7, 15, 63, 64, 65, 66, 72, 76, 77, 78, 79, 83, 84, 89, 90, 100, 102, 106, 112, 113, 114, 120, 121, 123, 127, 128, 146, 148, 153, 156, 157, 160, 161, 172, 174, 178, 181, 186], "sharegpt": 84, "sharehold": 102, "sharp": [9, 96, 98, 101, 112, 113, 153], "sharpen": 98, "sharper": 98, "sharpli": [9, 112, 113, 121, 153], "shatter": [112, 113], "shawn": 185, "shawne": [112, 113], "shazeer": [0, 100], "shb16": 0, "she": [101, 131], "shed": 153, "sheer": 11, "sheet": [112, 113], "shelbi": [112, 113], "shelf": [89, 101], "shell": [67, 82, 174, 186], "shelter": [112, 113], "sheriff": [112, 113], "shg": 0, "shi": 102, "shield": [112, 113], "shift": [24, 26, 27, 28, 39, 47, 50, 54, 60, 64, 65, 66, 75, 98, 106, 112, 113, 143, 151, 160, 161, 166, 172], "shih": 0, "shihao": [0, 7], "shinewar": 142, "ship": [13, 74, 153], "shippabl": 172, "shiri": [0, 7], "shirt": [112, 113], "shkurti": [0, 7], "shlizerman": [0, 7], "sho": 102, "shoal": [112, 113], "shock": [2, 37, 38, 120, 121], "shock_nam": 35, "shockingli": 11, "shoe": [112, 113], "shomayim": [112, 113], "shona": 96, "shonenkov": [6, 131], "shonenkovai": [6, 131], "shoot": [112, 113], "shop": [101, 112, 113], "shor": 102, "shore": [112, 113], "short": [6, 7, 10, 31, 42, 50, 53, 64, 72, 112, 113, 116, 118, 131, 134, 135, 137, 139, 151, 172, 176, 177], "shortcom": 11, "shortcut": [70, 94], "shorten": [112, 113], "shorter": [10, 47, 89, 105, 112, 113, 116, 127], "shortest": 55, "shorthand": 116, "shot": [0, 2, 9, 11, 48, 52, 54, 58, 89, 97, 98, 99, 110, 116], "should": [1, 2, 5, 9, 15, 17, 18, 23, 31, 38, 42, 46, 51, 52, 61, 69, 75, 77, 78, 82, 85, 90, 92, 93, 94, 97, 98, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 122, 127, 129, 130, 131, 133, 137, 140, 147, 151, 153, 156, 165, 166, 167, 168, 170, 171, 172, 173, 174, 176, 177, 178, 181, 184, 186], "show": [4, 7, 30, 36, 53, 54, 73, 80, 95, 97, 98, 100, 101, 106, 112, 113, 114, 115, 116, 117, 118, 121, 129, 130, 131, 133, 137, 140, 150, 151, 152, 153, 156, 172, 174, 181, 182, 184], "show_progress": 113, "show_result": [30, 36], "show_top": 151, "showcas": [13, 43, 90, 94, 99, 112, 113, 117], "showinlin": 22, "shown": [43, 51, 84, 91, 98, 101, 104, 110, 112, 113, 117, 131, 139, 177], "shri": [112, 113], "shrink": 118, "shrinking_factor": [104, 106], "shuffl": [15, 21, 29, 96, 102, 108, 109, 118], "shuffle_input_sent": [104, 106], "shutil": 174, "shuttl": [112, 113], "shuttlesworth": [112, 113], "si": [96, 102, 112, 113, 146], "siberia": [112, 113], "sibl": [112, 113], "sick": [112, 113], "siddhant": 0, "side": [89, 99, 112, 113, 122, 146, 173, 179, 181], "siden": 102, "sider\u00fargica": [112, 113], "siefka": 185, "sift": 50, "sigal": [0, 7], "sight": 117, "sigkdd": 0, "sigma": [129, 133, 152], "sigmoid": [89, 129], "sign": [2, 13, 65, 71, 79, 112, 113, 115, 160, 165, 177], "signal": [0, 10, 13, 41, 47, 50, 89, 112, 113, 121, 129, 152], "signatur": [77, 79, 115], "signifi": [10, 54, 58, 60, 117, 148], "signific": [2, 3, 6, 7, 9, 10, 41, 42, 43, 45, 47, 50, 53, 54, 55, 56, 58, 60, 72, 75, 78, 92, 93, 94, 98, 99, 103, 106, 110, 112, 113, 114, 116, 117, 119, 120, 127, 131, 139, 141, 144, 151, 158, 172, 173], "significantli": [7, 43, 46, 47, 51, 53, 55, 75, 78, 87, 92, 94, 96, 98, 99, 101, 103, 112, 113, 116, 117, 120, 121, 131, 138, 147, 167, 172, 173], "signingkei": 77, "signup": [6, 131], "sikhism": [112, 113], "sil": 102, "silent": [112, 113], "silicon": [52, 112, 113], "silli": 176, "silo": [64, 66, 161], "silver": [54, 153], "silveri": 17, "sim": [85, 98, 106, 112, 113, 148], "sim_": 158, "similar": [2, 3, 6, 9, 10, 11, 39, 53, 54, 55, 56, 60, 67, 72, 77, 85, 89, 98, 99, 101, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 126, 127, 129, 130, 134, 139, 144, 146, 147, 150, 151, 152, 155, 159, 175], "similarli": [7, 65, 99, 107, 112, 113, 115, 117, 118, 129, 138, 140, 148, 158, 160], "simmon": [112, 113], "simpl": [2, 7, 8, 9, 15, 17, 18, 23, 43, 45, 51, 54, 58, 65, 66, 71, 72, 73, 74, 78, 79, 89, 92, 97, 98, 105, 106, 109, 112, 113, 114, 115, 119, 130, 131, 133, 134, 136, 137, 138, 139, 140, 141, 142, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 167, 172, 174], "simpleclassif": [15, 17, 23], "simpler": [9, 61, 77, 127, 140, 151, 152], "simplest": [103, 119, 154, 155], "simpletoken": 153, "simpletransform": [15, 23], "simpli": [3, 11, 21, 27, 28, 70, 73, 89, 98, 102, 109, 112, 113, 124, 133, 137, 151, 159], "simplic": [61, 74, 77, 154, 172], "simplif": [99, 133], "simplifi": [9, 10, 43, 57, 60, 61, 62, 63, 65, 66, 67, 75, 77, 78, 89, 99, 106, 113, 118, 124, 127, 129, 133, 149, 151, 152, 160, 161, 165, 167], "simplist": [98, 112, 113], "simul": [7, 54, 56, 89, 90], "simultan": [9, 56, 60, 73, 89, 112, 113, 114, 117, 173], "sinait": [112, 113], "sinc": [7, 10, 11, 25, 37, 47, 53, 60, 65, 78, 81, 89, 98, 101, 106, 112, 113, 114, 116, 117, 118, 120, 122, 124, 125, 126, 129, 131, 133, 141, 148, 151, 153, 154, 160, 184], "sindhi": 96, "sine": [112, 113, 117], "sing": 102, "singl": [7, 9, 10, 21, 22, 52, 53, 56, 58, 62, 65, 67, 70, 72, 74, 78, 79, 89, 101, 102, 106, 107, 112, 113, 114, 116, 117, 118, 123, 127, 129, 133, 135, 140, 142, 144, 148, 150, 153, 159, 160, 178, 184], "singular": [53, 112, 113, 123, 131, 140, 141], "sinhala": 96, "sink": 119, "sion": 102, "siri": [50, 131], "sit": [9, 112, 113, 129, 137, 146], "site": [1, 29, 31, 101, 102, 104, 109, 111, 112, 113, 115, 122, 133, 136, 137, 140, 142, 151, 173, 179], "siti": 102, "situat": [9, 37, 53, 101, 112, 113, 121, 131, 134, 137, 158, 172], "six": [112, 113, 116, 121, 137, 142, 168], "sixteen": [112, 113], "sixteenth": [112, 113], "sixth": [112, 113], "sixti": [112, 113], "sizabl": [51, 116], "size": [10, 11, 16, 17, 18, 21, 25, 31, 39, 42, 43, 46, 47, 50, 51, 52, 53, 54, 60, 75, 78, 84, 89, 96, 98, 104, 106, 107, 108, 109, 111, 112, 113, 116, 117, 122, 125, 126, 127, 129, 131, 133, 134, 136, 137, 140, 144, 147, 148, 152, 153, 154, 155, 156, 157, 164, 165, 167, 172], "size_in_byt": [18, 23, 29], "size_in_human_byt": [18, 23, 29], "sk": [16, 20, 52, 96, 108], "skeleton": [7, 70], "sketch": 170, "skew": [98, 148], "ski": [112, 113], "skill": [0, 38, 43, 47, 50, 65, 68, 71, 72, 81, 86, 88, 90, 98, 101, 112, 113, 121, 122, 131, 160, 164, 168, 170, 173, 187], "skin": [89, 112, 113], "skinni": 151, "skip": [10, 104, 117, 118, 125, 155, 176, 178], "skip_gram": 129, "skip_special_token": [98, 101], "skipgram": [125, 129], "skipgram_test": 129, "skipgrammodel": 129, "skipna": 32, "sklearn": [29, 74, 127, 136, 137, 144, 150, 151, 159], "sklearnmodelartifact": 74, "skool": [112, 113], "skt": 15, "sky": [4, 112, 113, 159], "skyflow": 60, "sk\ub294": [16, 20], "sk\uc774\ub178\ubca0\uc774\uc158": 17, "sk\uc774\ub178\ubca0\uc774\uc158\uc740": 17, "sk\ud558\uc774\ub2c9\uc2a4": [17, 20], "sk\ud558\uc774\ub2c9\uc2a4\ub294": 20, "sl": [93, 96, 102], "slam": 134, "slang": [47, 92, 103, 116, 146], "slant": [112, 113], "slate": 140, "slave": [112, 113], "slaveri": [112, 113], "sldamodel": 153, "sleep": [112, 113], "sleev": [112, 113], "slept": [112, 113], "slerp": 10, "sli": 102, "slice": 152, "slide": [7, 102, 148], "slight": [47, 112, 113], "slightli": [10, 85, 106, 112, 113, 118, 129], "slim": 62, "slimi": 184, "slithi": 184, "slovak": 96, "slovenian": 96, "slow": [50, 100, 104, 112, 113, 118, 121, 122, 142], "slowdown": 116, "slower": [78, 113, 117, 122, 126], "slowli": [11, 112, 113], "slp3": 130, "slump": [109, 153], "sm": [15, 23, 78, 79, 96, 102], "sm_inval": 15, "sm_pol": 15, "sm_topic": 15, "sma": 108, "small": [9, 10, 11, 50, 51, 53, 66, 69, 72, 81, 85, 89, 96, 98, 99, 101, 102, 105, 106, 110, 112, 113, 114, 115, 116, 118, 126, 129, 131, 134, 140, 148, 151, 152, 154, 158, 159, 161, 172, 176, 179], "smaller": [9, 10, 26, 43, 47, 50, 51, 53, 58, 60, 63, 70, 75, 77, 84, 89, 98, 99, 101, 103, 106, 107, 110, 112, 113, 117, 118, 127, 131, 133, 140, 143, 144, 146, 164, 173], "smallest": [98, 131, 141], "smangrul": 52, "smart": [10, 41, 50, 78, 79, 121, 168, 170, 171], "smarter": 131, "smartphon": [112, 113, 121], "smell": 117, "smi": 113, "smile": [112, 113], "smith": [121, 140], "smoke": [112, 113], "smola": 100, "smooth": [7, 9, 17, 81, 90, 96, 112, 113, 133], "smoothli": 7, "smt": [15, 23], "smtp": 78, "smyth": 153, "sn": [16, 95, 96, 108, 137, 150], "snake": [112, 113], "snapshot": [61, 63, 122, 186], "snapshott": 61, "sne": [56, 96, 139, 149], "sne\ub9ac\uc11c\uce58\ub294": 17, "snippet": [7, 50, 52, 53, 58, 98, 131, 143, 144, 151], "snorkel": 60, "snow": [4, 112, 113], "snowdon": [178, 181, 182], "snowfal": [112, 113], "snowmelt": [112, 113], "snowpack": [112, 113], "snowstorm": [112, 113], "so": [9, 11, 15, 26, 52, 54, 58, 60, 68, 73, 78, 89, 96, 98, 101, 102, 105, 107, 109, 111, 112, 113, 114, 115, 118, 119, 121, 127, 128, 129, 131, 133, 137, 140, 141, 144, 145, 147, 148, 150, 153, 154, 155, 156, 157, 168, 172, 174, 175, 176, 177, 178, 179, 181, 184, 186], "soc": [60, 121], "socher": 0, "social": [6, 41, 42, 45, 47, 84, 86, 94, 98, 99, 112, 113, 116, 119, 121, 122, 127, 131, 135, 136, 138, 142, 149, 152], "socialist": [112, 113], "societ": [2, 54, 90, 93, 112, 113], "societi": [3, 93, 98, 112, 113, 131], "socioeconom": [112, 113], "sock": 61, "socket": [78, 79], "socrat": [112, 113], "sof": 102, "soft": [9, 13, 14, 89, 180], "soft_prompt": 53, "softeng": [174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "softmax": [9, 53, 98, 114, 117, 128], "softwar": [2, 7, 39, 43, 50, 60, 62, 64, 65, 66, 70, 71, 72, 74, 78, 83, 90, 98, 112, 113, 122, 130, 151, 160, 161, 163, 169, 178, 179, 181, 186, 187], "soil": [112, 113, 148], "sol": 102, "solar": [112, 113], "sold": [101, 112, 113], "soldier": [112, 113], "sole": [10, 78, 84, 112, 113, 117, 135, 145, 168], "solicit": 134, "solid": [15, 81, 90, 112, 113, 131, 137, 140], "solidar": [112, 113], "solidifi": 98, "solo": [2, 162, 187], "solut": [7, 13, 39, 40, 42, 43, 45, 46, 47, 51, 53, 56, 60, 61, 62, 63, 65, 66, 77, 78, 87, 90, 98, 117, 127, 152, 160, 161, 167], "solv": [38, 43, 45, 51, 54, 58, 66, 72, 74, 78, 86, 89, 90, 97, 98, 101, 113, 115, 129, 130, 131, 146, 147, 161, 162, 164, 166, 168, 171], "solvent": [112, 113], "solver": 7, "somali": 96, "some": [3, 6, 9, 10, 11, 12, 13, 15, 17, 18, 23, 43, 47, 50, 61, 63, 65, 67, 70, 72, 74, 75, 77, 78, 84, 86, 89, 90, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 129, 130, 131, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 146, 148, 149, 150, 151, 152, 153, 157, 158, 160, 174, 175, 176, 178, 180, 181, 183, 184, 186], "somefil": 174, "somenam": 186, "someon": [112, 113, 174, 184, 186], "someth": [6, 57, 78, 79, 108, 109, 112, 113, 131, 137, 140, 157, 174, 175, 183], "sometim": [10, 24, 51, 55, 85, 98, 112, 113, 117, 131, 133, 137, 141, 143, 179, 182], "somewhat": [25, 31, 50, 112, 113, 137], "somewher": 151, "son": 102, "song": 150, "soni": 153, "soohyon": 0, "soon": [6, 84, 112, 113, 131], "sooner": 173, "soot": [112, 113], "sop": [2, 67, 71], "sophist": [13, 14, 45, 54, 55, 56, 78, 86, 91, 94, 114, 117, 131, 148, 154, 155, 173], "sophocl": [112, 113], "sorghum": [112, 113], "sort": [11, 102, 107, 108, 109, 124, 140, 148, 150, 156], "sort_top": 153, "sorted_pmi": 156, "sorted_ppmi": 156, "sorted_scor": [108, 109], "sorted_subword": [108, 109], "sorted_token": 102, "sota": [7, 52], "sotho": 96, "soto": [112, 113], "sou": 102, "sought": [112, 113, 117], "sound": [3, 51, 91, 92, 98, 103, 112, 113, 131, 140, 141], "soup": 124, "sourc": [0, 2, 7, 14, 16, 37, 38, 39, 42, 43, 53, 56, 58, 60, 61, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 81, 84, 85, 92, 94, 96, 98, 99, 106, 108, 112, 113, 115, 117, 121, 124, 125, 131, 135, 151, 160, 161, 170, 171, 174, 177, 179, 182, 185], "south": [0, 84, 112, 113, 124, 179], "southeast": [112, 113], "southeastern": [112, 113], "southern": [96, 112, 113], "southernmost": [112, 113], "southwest": 179, "soviet": [112, 113], "soybean": [112, 113], "sp": 102, "sp500": 35, "space": [0, 8, 10, 52, 54, 56, 60, 89, 98, 102, 103, 106, 107, 112, 113, 116, 117, 125, 127, 131, 133, 137, 139, 140, 141, 142, 144, 146, 149, 151, 152, 154, 157, 158, 178], "space_token": 102, "space_token_len": 102, "spaci": [145, 147], "spain": [112, 113], "spam": [47, 99, 118, 131], "span": [10, 13, 33, 50, 78, 96, 116, 120], "span_arg": 33, "spanish": [0, 50, 94, 96, 112, 113, 116, 123, 131], "spare": 98, "spark": [3, 39], "spars": [9, 54, 56, 89, 112, 113, 116, 127, 152, 154, 155, 156, 158, 159], "sparsiti": [56, 133, 134, 139, 152], "spatial": [9, 10, 11, 50, 117, 122, 127, 139, 149, 157], "spatio": 7, "spawn": 80, "spe": 102, "speak": [112, 113, 131], "speaker": [24, 25, 26, 27, 28, 31, 32, 94, 131], "spearhead": 60, "speci": [4, 7, 112, 113], "special": [7, 9, 11, 13, 39, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 57, 58, 60, 65, 89, 90, 102, 105, 106, 107, 110, 112, 113, 115, 116, 126, 134, 144, 147, 152, 160, 169, 178, 183], "special_token": [104, 112, 113], "special_tokens_map": [112, 113], "special_tokens_mask": 113, "specialist": [112, 113, 137], "specif": [7, 9, 10, 13, 31, 38, 39, 42, 43, 45, 46, 47, 53, 54, 56, 58, 59, 60, 61, 63, 65, 66, 67, 69, 70, 72, 75, 77, 81, 83, 85, 87, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 127, 129, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 145, 146, 147, 148, 152, 153, 157, 158, 159, 160, 161, 165, 167, 169, 170, 172, 173, 175, 179, 181], "specifi": [17, 18, 20, 22, 31, 44, 45, 46, 53, 61, 62, 65, 83, 90, 96, 101, 102, 104, 105, 106, 111, 112, 113, 115, 122, 124, 149, 150, 151, 160, 165, 166, 171, 177, 186], "spectral": [112, 113, 127, 151], "spectrum": [47, 51, 53, 112, 113, 114, 127, 173], "specul": [53, 112, 113], "specular": [112, 113], "specularli": [112, 113], "speech": [2, 37, 44, 51, 56, 112, 113, 117, 122, 123, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 144, 146, 147], "speech2text": 73, "speed": [7, 56, 60, 65, 72, 112, 113, 116, 122, 127, 134, 150, 160, 170], "speedup": 118, "spell": [10, 99, 100, 103, 105, 112, 113, 116, 132, 142, 144, 176], "spend": [13, 112, 113, 120, 151], "spent": [47, 112, 113], "sperm": [112, 113], "spermatophyt": [112, 113], "sphere": [112, 113], "spheric": [9, 10], "spider": 122, "spike": 120, "spin": 7, "spiral": 171, "spite": [112, 113], "splash": [112, 113], "splinter": [112, 113], "split": [15, 16, 17, 18, 21, 22, 23, 29, 31, 34, 72, 77, 95, 96, 102, 103, 105, 106, 107, 108, 111, 112, 113, 125, 127, 128, 129, 137, 139, 140, 142, 144, 145, 146, 147, 151, 153], "split_by_numb": [104, 106], "split_by_unicode_script": [104, 106], "split_by_whitespac": [104, 106], "split_digit": [104, 106], "split_kei": [16, 25], "split_sampl": [17, 21, 29, 34], "split_sent": 142, "splunk": [66, 161], "spm": [104, 106], "spoke": [112, 113], "spoken": [50, 94, 122, 131], "spontan": [112, 113], "sport": [7, 60, 112, 113, 131, 152], "spot": [2, 92, 97, 174], "spracklen": [112, 113], "spread": [91, 112, 113, 121, 173], "spreadsheet": 170, "spring": [112, 113], "springenberg": 0, "springer": [0, 38, 130], "sprint": [168, 170, 172], "spun": [6, 184], "spur": [43, 112, 113], "spuriou": [89, 94], "sq": 96, "sql": 13, "sqrt": [144, 149, 158], "squad": [118, 123], "squar": [53, 89, 112, 113, 115, 126, 149, 152, 185], "squash": 113, "squat": [112, 113], "squeez": [52, 128], "sr": [24, 96, 112, 113, 167, 170], "src_text": 31, "srf": 15, "ss": 102, "ssab": [112, 113], "sse2": 153, "sset": 108, "ssh": [2, 67, 71, 76, 79], "ssion": 102, "ssl": [73, 78, 79, 83], "sso": 78, "ssri": [112, 113], "st": [96, 98, 102, 107, 108, 112, 113, 118], "sta": [102, 108], "stabil": [6, 53, 60, 131, 139, 170, 172, 173], "stabilis": [112, 113], "stabilityai": 52, "stabl": [6, 52, 70, 89, 101, 102, 104, 109, 111, 112, 113, 115, 131, 137, 151, 172, 173], "stable_diffus": 52, "stack": [2, 9, 10, 13, 48, 57, 61, 65, 66, 114, 116, 117, 153, 160, 161, 168, 170, 171], "stack_llama": 52, "stackgan": 12, "stadium": [112, 113, 134], "staf": 170, "staff": [137, 168, 171], "stage": [7, 10, 41, 47, 50, 56, 64, 65, 72, 81, 89, 106, 110, 112, 113, 131, 160, 165, 166, 168, 170, 171, 173, 177, 180, 182], "stai": [53, 64, 66, 75, 78, 79, 94, 119, 131, 137, 152, 161, 168, 172, 176], "stainless": [112, 113], "stake": [112, 113], "stakehold": [93, 99, 166, 167, 168, 170, 171, 172], "stalagmit": [112, 113], "stale": 94, "stalin": [112, 113], "stamp": [58, 168], "stanc": 138, "stand": [7, 10, 47, 50, 51, 53, 60, 70, 105, 112, 113, 114, 117, 126, 127, 140, 144, 172, 174], "standalon": [45, 61, 62, 63, 173], "standard": [7, 10, 29, 39, 42, 46, 47, 60, 61, 67, 68, 72, 74, 75, 77, 78, 79, 98, 105, 106, 111, 112, 113, 115, 116, 117, 118, 131, 133, 137, 140, 143, 145, 147, 164, 166, 173], "stanford": [84, 123, 126, 130, 155], "stanlei": 86, "stapl": [7, 54], "star": [2, 4, 23, 48, 54, 102, 112, 113, 137], "start": [1, 10, 11, 15, 17, 18, 20, 21, 22, 23, 33, 47, 51, 53, 60, 63, 65, 66, 67, 68, 69, 70, 72, 73, 76, 81, 89, 90, 94, 95, 97, 98, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 117, 118, 125, 126, 129, 130, 131, 133, 134, 137, 140, 143, 149, 151, 155, 156, 160, 161, 165, 168, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187], "start_idx": [108, 109], "start_index": 153, "start_year": [31, 32, 33, 34, 35], "starter": 73, "startswith": 109, "startup": 60, "stat": [18, 21, 29], "state": [0, 7, 9, 11, 43, 51, 53, 54, 55, 65, 66, 67, 72, 78, 86, 89, 90, 99, 109, 110, 112, 113, 114, 116, 117, 118, 120, 121, 131, 135, 139, 152, 153, 157, 160, 161, 167, 168, 169, 171, 172, 173, 178, 180, 181, 182, 184, 185], "statehood": [112, 113], "stateless": [74, 112, 113], "statement": [31, 32, 33, 37, 56, 135, 140, 168, 170, 173], "statewid": [112, 113], "static": [52, 56, 58, 100], "station": [112, 113], "statist": [6, 21, 29, 38, 49, 50, 54, 72, 99, 108, 112, 113, 122, 127, 131, 133, 141, 146, 147, 148, 155, 158, 159, 168], "statsmodel": 13, "statu": [15, 17, 18, 20, 61, 81, 112, 113, 131, 172, 174, 177, 182, 185], "std": [26, 133], "ste": 102, "steadi": [112, 113], "steadili": 2, "steel": [112, 113], "steelmak": [112, 113], "steep": [112, 113], "steer": 10, "stem": [10, 60, 92, 105, 131, 137, 138, 139, 141, 143, 149, 151, 153], "step": [1, 2, 7, 10, 43, 50, 53, 54, 55, 56, 58, 65, 68, 73, 74, 76, 77, 78, 82, 83, 86, 89, 90, 93, 96, 97, 98, 101, 103, 105, 106, 107, 110, 111, 112, 113, 114, 117, 118, 121, 131, 133, 134, 137, 139, 140, 141, 145, 147, 148, 151, 152, 153, 154, 156, 157, 160, 162, 166, 169, 185], "stephan": 0, "stephen": [0, 112, 113], "stepwis": 96, "stereotyp": [84, 94, 112, 113, 131], "steve": [112, 113], "steven": 0, "stew": 157, "stewart": 0, "stick": 7, "stigma": [112, 113], "still": [7, 11, 41, 51, 52, 70, 94, 98, 112, 113, 115, 117, 125, 127, 131, 133, 134, 136, 137, 140, 150, 153, 157, 173, 176, 177, 180, 184], "stimul": [112, 113], "stimuli": [112, 113], "stirner": [112, 113], "stm": 11, "sto": 102, "stochast": [98, 139], "stock": [39, 42, 43, 102, 120, 124, 129, 153], "stoic": [112, 113], "stoicism": [112, 113], "stone": [112, 113, 140, 170], "stood": 131, "stop": [43, 61, 63, 98, 101, 102, 105, 107, 112, 113, 131, 141, 143, 147, 149, 151, 154, 184], "stop_word": [137, 143, 144, 151], "stopword": [31, 137, 139, 143, 150, 151, 153], "stor": 102, "storag": [57, 60, 61, 62, 66, 67, 74, 75, 78, 79, 81, 161, 168, 171], "store": [13, 39, 44, 47, 52, 53, 54, 56, 58, 60, 61, 62, 65, 66, 67, 72, 75, 77, 78, 80, 111, 112, 113, 115, 122, 129, 136, 146, 151, 153, 160, 161, 177], "storei": [112, 113], "stori": [50, 54, 98, 112, 113, 118, 175, 176], "storm": [112, 113], "storylin": 101, "stow": 67, "stoxx": 153, "str": [15, 16, 18, 22, 23, 29, 31, 32, 102, 106, 112, 113, 137, 143, 153, 156], "str4d": 80, "strai": 60, "straightforward": [58, 72, 74, 81, 92, 98, 102, 131, 135, 140, 141, 145, 148, 167], "strain": [122, 143], "strang": 10, "strate": 102, "strateg": [13, 55, 60, 173], "strategi": [2, 9, 13, 45, 47, 51, 55, 60, 72, 75, 79, 97, 99, 101, 104, 106, 112, 113, 118, 121, 131, 133, 134, 137, 144, 148, 168, 170, 171, 173], "stratify_on": [17, 21, 29, 34], "straw": 115, "strawberri": 115, "stre": 102, "stream": [9, 15, 17, 18, 23, 77, 96, 111, 112, 113, 147], "stream_executor": 15, "streamabl": 77, "streamlin": [43, 47, 50, 56, 57, 62, 64, 65, 66, 70, 72, 75, 77, 106, 160, 161, 164, 173], "street": [4, 102, 114, 120, 131], "stren": 108, "streng": [102, 108], "strengt": 108, "strength": [41, 42, 47, 51, 55, 56, 77, 78, 84, 91, 102, 103, 107, 112, 113, 117, 142, 144, 145, 157, 167, 173], "stress": [60, 112, 113, 173], "stretch": [112, 113], "stri": 102, "strict": [78, 173], "strictli": [53, 131, 168], "stride": [43, 45, 50], "strike": [51, 98, 103, 107, 112, 113], "strikingli": [112, 113], "string": [96, 102, 103, 104, 105, 106, 111, 113, 137, 140, 143, 146, 156], "string_token": 102, "stringent": 60, "strip": [61, 101, 112, 143, 153], "strip_acc": 113, "stripe": [86, 133], "strive": [2, 51, 94], "stroke": [112, 113], "strong": [2, 47, 61, 70, 71, 72, 77, 78, 88, 90, 102, 112, 113, 138, 150, 152, 153, 156, 167, 172, 173], "stronger": [54, 77], "strongest": [112, 113], "stronghold": [112, 113], "strongli": [112, 113, 115, 158, 168], "stru": 102, "struck": [112, 113, 131], "struct": 102, "structur": [0, 3, 8, 11, 39, 41, 42, 43, 44, 47, 48, 50, 51, 54, 55, 56, 60, 65, 67, 69, 70, 81, 92, 93, 94, 95, 99, 100, 112, 113, 114, 120, 123, 127, 129, 131, 132, 137, 138, 139, 141, 142, 143, 144, 145, 148, 149, 151, 152, 154, 155, 160, 164, 167, 168, 172, 173], "structuralist": [112, 113], "struggl": [42, 55, 56, 85, 92, 94, 98, 103, 112, 113, 131, 135, 139], "strunk": 130, "stry": 108, "stuck": [55, 98], "student": [5, 38, 48, 50, 51, 71, 76, 85, 88, 97, 98, 112, 113, 130, 141, 162, 168, 169, 170, 171, 173, 177, 187], "studi": [0, 8, 39, 60, 77, 89, 90, 97, 98, 112, 113, 120, 121, 127, 130, 157], "studio": [6, 131], "stupend": 151, "style": [3, 6, 8, 9, 10, 50, 56, 90, 112, 113, 118, 130, 131, 137, 140, 145, 150, 172, 174], "style_clipdraw": 10, "styleclipdraw": 10, "stylelog": 182, "stylist": [3, 56], "styliz": 121, "stylometr": 137, "su": [82, 96, 102, 112, 113], "sub": [7, 11, 53, 57, 75, 76, 102, 104, 106, 108, 109, 112, 113, 145, 146], "sub_doc": 124, "sub_it": [104, 106], "subcompon": 118, "subcultur": [112, 113, 143], "subdivid": 60, "subdivis": 120, "subfield": [6, 12, 90, 92, 94, 123, 130, 131], "subfold": 70, "subgroup": [112, 113], "subject": [1, 7, 8, 54, 60, 72, 94, 112, 113, 114, 117, 122, 131, 135, 139, 141, 149, 158, 182], "sublim": 175, "submiss": 52, "submit": [5, 21, 68, 73, 97, 112, 113, 122, 174, 179], "suboptim": [50, 98, 112, 113], "subpar": 47, "subpart": [89, 98], "subplot": [24, 25, 26, 150], "subproblem": 146, "subproject": 70, "subsampl": [36, 96], "subscript": [112, 113], "subsequ": [39, 47, 50, 60, 98, 104, 114, 117, 120, 121, 131, 137, 149, 154], "subset": [9, 16, 21, 32, 51, 53, 96, 112, 113, 115, 123, 148, 150, 151, 154, 172, 173], "subseteq": 148, "subsidi": 13, "subsidiari": [112, 113], "subsist": [112, 113], "subspac": 53, "substack": 106, "substanc": [112, 113], "substanti": [13, 47, 50, 51, 53, 54, 112, 113, 116, 117, 118, 135, 139, 141, 165, 173], "substitut": [106, 144], "substr": [102, 107, 108, 109], "substract": 99, "substring_end_posit": 102, "substring_start_posit": 102, "subtl": [54, 151], "subtleti": 121, "subtract": [99, 114], "subtrop": [112, 113], "suburban": [112, 113], "subvers": [174, 186], "subword": [0, 2, 9, 97, 102, 104, 105, 108, 109, 112, 113, 116, 146], "subwords_freq": [108, 109], "succeed": [112, 113], "success": [7, 9, 17, 18, 23, 42, 43, 53, 54, 55, 56, 64, 72, 75, 77, 90, 94, 98, 99, 101, 112, 113, 117, 118, 119, 122, 127, 131, 139, 146, 147, 152, 166, 167, 168, 172, 173], "successfulli": [7, 9, 17, 18, 23, 61, 64, 75, 77, 98, 112, 113, 133, 136, 137, 139, 151], "successor": 78, "suck": 137, "suddenli": 47, "sudo": [61, 65, 80, 81, 82, 160], "sue": [174, 180], "suffer": [7, 50, 94, 98, 112, 113, 117, 134, 139, 152], "suffici": [7, 10, 53, 58, 89, 99, 101, 116, 117, 131, 133], "suffix": [18, 31, 70, 104, 106, 112, 113, 131, 140], "suffrag": [112, 113], "suggest": [2, 43, 55, 72, 90, 93, 106, 112, 113, 116, 117, 118, 121, 132, 140, 148, 150, 152, 157, 172, 178, 179], "suicid": [112, 113], "suissa": [112, 113], "suit": [7, 10, 42, 46, 51, 53, 61, 78, 83, 90, 94, 107, 110, 117, 137, 138, 152, 167, 168, 172, 173], "suitabl": [8, 50, 51, 53, 58, 61, 63, 77, 89, 90, 98, 99, 106, 111, 112, 113, 122, 137, 139, 143, 146, 147, 149, 151, 152, 153, 167, 173], "sukhareva": [112, 113], "sulski": 0, "sum": [18, 26, 32, 53, 102, 106, 108, 109, 112, 113, 114, 117, 120, 126, 128, 129, 133, 134, 138, 144, 148, 149, 150, 153, 157], "sum_": [9, 100, 106, 107, 120, 125, 126, 129, 146, 148, 149, 158], "summar": [16, 51, 54, 56, 60, 61, 87, 90, 93, 94, 98, 99, 116, 117, 118, 123, 131, 132, 149, 152, 156, 168, 171], "summari": [7, 15, 17, 18, 21, 23, 50, 53, 54, 72, 77, 78, 85, 89, 90, 93, 96, 99, 101, 104, 107, 114, 117, 121, 131, 133, 139, 142, 148, 149, 151, 153, 158], "summaris": 175, "summary_stat": 18, "summaryinfo": 18, "summer": [112, 113], "summerhil": [112, 113], "sump": 109, "sumpt": 109, "sumpti": 109, "sun": [17, 112, 113, 175, 176], "sundai": [112, 113], "sundanes": 96, "sungjoon": [0, 7], "sunlight": [112, 113], "sunset": 17, "suomi": [112, 113], "sup": 102, "super": [17, 18, 54, 102, 112, 113, 128, 129], "superb": 101, "supercomput": 86, "superflu": 56, "superglu": 118, "superimpos": [112, 113], "superior": [54, 86, 112, 113, 172], "superscript": [112, 113], "superspeedwai": [112, 113], "superus": 82, "supervis": [0, 6, 7, 39, 74, 81, 89, 93, 94, 100, 112, 113, 121, 123, 153], "supervisori": 124, "supplant": 50, "supplement": [53, 112, 113, 143], "supplementari": 7, "suppli": [13, 43, 101, 112, 113], "supplier": [112, 113], "support": [7, 11, 15, 17, 23, 30, 31, 36, 43, 45, 46, 60, 61, 64, 66, 67, 70, 77, 79, 83, 89, 90, 92, 94, 99, 106, 112, 113, 131, 135, 136, 137, 138, 139, 142, 145, 148, 153, 161, 170, 172, 173], "suppos": [47, 107, 111, 114, 121, 129, 133, 148], "suppress": [89, 112, 113, 115], "suprem": [112, 113], "supremaci": [112, 113], "suptitl": 150, "sur": 102, "sure": [15, 65, 66, 67, 82, 90, 95, 98, 133, 160, 161, 173, 174, 178, 179], "surfac": [42, 112, 113, 131, 151], "surg": [98, 112, 113], "surgeri": 137, "surmount": 56, "surnam": 151, "surpass": [2, 6, 43, 50, 60, 86, 112, 113, 116], "surpris": [98, 129], "surprisingli": 154, "surreal": [3, 112, 113, 151], "surrealist": [112, 113], "surrend": [112, 113], "surround": [4, 6, 56, 110, 112, 113, 114, 117, 129, 138, 140, 156], "survei": [13, 14, 53, 112, 113, 122, 135, 170], "surveil": [112, 113], "surviv": [112, 113], "suscept": 122, "suspicion": [112, 113], "sustain": [51, 53, 56, 112, 113], "sutskev": [0, 100], "sutton": 54, "suv": 22, "sv": 96, "svc": 73, "svd": [53, 149], "svm": [137, 139], "svn": [174, 186], "sw": [96, 148], "swaggerui": 73, "swahili": [96, 116], "swaminarayan": [112, 113], "swap": 178, "swarm": [61, 63], "swath": 50, "sweat": 0, "swedish": 96, "sweet": 18, "swift": [51, 89, 170], "swing": 129, "swiss": [112, 113], "switch": [1, 60, 68, 69, 80, 112, 113, 116, 127, 178, 181, 183, 185], "sy": [102, 124, 151], "sydnei": 0, "syllabl": [112, 113], "sylvain": 0, "symbiot": 3, "symbol": [101, 102, 107, 112, 113, 133, 147, 178, 181], "symlink": 67, "symmetr": [77, 78, 79, 148, 153], "symmetri": 72, "symptom": [93, 112, 113], "synagogu": [112, 113], "synaps": [112, 113], "synapt": [112, 113], "sync": [17, 18, 23, 31, 56, 67, 68], "synchron": [56, 65, 98, 112, 113, 160, 172], "synchronis": 186, "syndic": [112, 113], "syndicalist": [112, 113], "syndrom": [112, 113], "synergi": 51, "synonym": [56, 63, 112, 113, 120, 121, 138, 144, 157], "synopsi": [0, 168], "syntact": [11, 39, 110, 114, 116, 122, 123, 127, 128, 131, 138, 139, 141, 145, 147, 155, 157], "syntax": [70, 94, 97, 99, 101, 106, 111, 130, 131, 133, 141, 147], "synthes": [7, 117, 131], "synthesi": [0, 2, 5, 10, 12, 50, 57, 112, 113, 131], "synthet": 131, "syria": [112, 113], "syst": 102, "system": [0, 2, 5, 7, 9, 10, 12, 13, 39, 41, 42, 43, 45, 47, 51, 54, 55, 58, 60, 61, 62, 66, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 89, 90, 92, 94, 97, 99, 102, 103, 106, 112, 113, 117, 121, 123, 124, 130, 131, 132, 133, 134, 138, 140, 141, 142, 146, 151, 152, 153, 155, 161, 162, 163, 164, 165, 166, 167, 169, 170, 172, 173, 174, 175, 177, 186], "systemat": [56, 58, 90, 112, 113, 122, 138, 163, 167, 170, 173], "systemctl": [61, 81], "systemd": [65, 160], "t": [4, 6, 8, 10, 21, 24, 25, 47, 52, 53, 54, 55, 56, 60, 62, 65, 73, 77, 85, 86, 89, 93, 94, 96, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 127, 129, 130, 131, 133, 134, 137, 139, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 160, 167, 175, 176, 177, 178, 179, 181, 182, 183, 186], "t0": 52, "t0_3b": 52, "t4": 52, "t5": [2, 32, 48, 52, 97, 98, 99, 105, 116, 117], "t5_classification_with_simpl": 31, "t5_col": 36, "t5_diffusion_minut": [31, 32, 33, 34, 35, 36], "t5_diffusion_minutes_d": 32, "t5_diffusion_press_conf": [31, 32], "t5_diffusion_press_conf_d": 32, "t5_diffusion_speech": [31, 32, 34, 36], "t5_diffusion_speech_d": 32, "t5_diffusion_stat": [31, 32, 33, 34], "t5_diffusion_statement_d": 32, "t5_model": 31, "t5_tone": [32, 33, 34], "ta": [96, 102], "tab": [73, 111, 136, 179], "tab10": 27, "tabl": [2, 10, 44, 53, 54, 55, 60, 74, 90, 107, 112, 113, 122, 127, 128, 131, 137, 146, 157], "tablet": 121, "tackl": [13, 39, 50, 54, 55, 56, 60, 117, 127, 131, 133, 168], "tactic": [112, 113], "tactil": 92, "tag": [2, 56, 60, 70, 73, 77, 116, 123, 130, 131, 136, 139, 140, 144, 147, 180], "tag_": 145, "tagger": 131, "tahoun": 0, "tai": 0, "taiga": [0, 7], "tail": [15, 20, 22, 24, 25, 26, 27, 28, 31, 101, 131, 133], "tailor": [1, 10, 43, 46, 47, 48, 50, 51, 53, 56, 60, 61, 62, 77, 81, 87, 92, 98, 112, 113, 137, 138, 172, 173], "tain": 102, "taiwan": 153, "tajik": 96, "tak": 118, "takahashi": 37, "take": [2, 7, 9, 10, 11, 45, 53, 54, 55, 64, 65, 72, 73, 74, 81, 89, 90, 93, 97, 98, 100, 103, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 117, 121, 127, 129, 130, 133, 137, 140, 141, 142, 145, 148, 151, 152, 153, 155, 156, 160, 173, 177, 179, 181, 183], "takeawai": 79, "taken": [3, 9, 55, 106, 112, 113, 121, 133, 148], "taku": [0, 7], "tal": 102, "tale": [4, 102], "talent": [112, 113], "talk": [9, 112, 113, 137, 151, 179], "tall": [151, 157, 175, 176, 177, 183], "talladega": [112, 113], "tallapoosa": [112, 113], "tallest": 175, "talli": [112, 113], "tamil": 96, "tamper": 78, "tanaka": [0, 146], "tangibl": [50, 109, 173], "tanh": 128, "taoism": [112, 113], "taoist": [112, 113], "tap": 102, "tape": [102, 129], "tar": [108, 136], "tarek": 0, "target": [7, 10, 27, 28, 29, 31, 34, 44, 47, 50, 51, 53, 60, 65, 72, 74, 82, 85, 89, 94, 99, 100, 101, 106, 107, 110, 112, 113, 117, 118, 122, 124, 128, 131, 132, 133, 135, 137, 138, 146, 151, 153, 155, 156, 158, 160, 168], "target_batch": [128, 129], "target_nam": [137, 151], "target_usernam": 82, "tariff": [112, 113], "tarrida": [112, 113], "task": [6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 20, 21, 22, 23, 39, 42, 43, 44, 45, 47, 50, 51, 53, 54, 55, 56, 57, 58, 60, 65, 66, 70, 72, 75, 76, 77, 82, 87, 89, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 123, 124, 126, 127, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 143, 145, 146, 147, 151, 152, 154, 155, 157, 158, 160, 161, 164, 165, 168, 170, 172, 173], "task_typ": 52, "tasktyp": 52, "tatoeba": 94, "tau": [112, 113, 121], "taught": [103, 112, 113], "tax": [112, 113, 153], "taxpay": [112, 113], "taycan": 95, "taylor": [27, 28, 29, 121], "taylor2": 24, "taylor_diff": [24, 26, 27, 28, 29], "taz": [112, 113], "tbc": 118, "tbt": 16, "tdd": 172, "tdf": 15, "te": [96, 102], "teach": [10, 43, 47, 50, 55, 76, 97, 98, 111, 112, 113, 130, 140], "teacher": [112, 113], "team": [13, 43, 50, 60, 64, 65, 66, 72, 83, 84, 101, 112, 113, 116, 117, 152, 160, 161, 162, 166, 167, 168, 172, 173, 187], "teamwork": [164, 173], "tear": [112, 113], "tech": [60, 72, 94, 102, 121, 172], "technic": [0, 2, 7, 13, 38, 40, 50, 56, 60, 90, 97, 121, 130, 131, 164, 166, 169, 170, 173], "techniqu": [7, 9, 10, 11, 12, 13, 14, 38, 39, 42, 48, 50, 56, 57, 60, 72, 75, 78, 79, 87, 88, 89, 92, 94, 96, 97, 98, 99, 101, 106, 110, 112, 113, 114, 116, 117, 119, 121, 122, 123, 127, 129, 130, 132, 134, 136, 141, 143, 146, 148, 149, 151, 152, 155, 166, 170, 187], "technocrat": 121, "technolog": [56, 153], "technologi": [0, 2, 6, 13, 16, 39, 40, 43, 50, 53, 56, 57, 60, 63, 64, 65, 79, 81, 83, 87, 92, 94, 98, 102, 112, 113, 116, 129, 131, 132, 160, 166, 168, 170, 171, 172], "tediou": [57, 70], "tee": 81, "teh": 140, "tekton": [65, 160], "telescop": [112, 113, 131], "televis": [112, 113], "tell": [11, 137, 140, 174, 179, 181, 182], "telugu": [96, 116], "tem": 108, "temp": 113, "temper": [112, 113], "temperatur": [9, 98, 101, 112, 113], "templ": [112, 113], "templat": [2, 8, 43, 52, 62, 65, 67, 68, 69, 71, 92, 160, 162, 169, 170, 172], "tempor": [7, 50, 95, 112, 113, 117, 122, 152], "temporari": [112, 113], "temporarili": [112, 113, 182], "ten": [7, 112, 113], "tend": [91, 93, 94, 98, 112, 113, 115, 116, 120, 121, 129, 131, 137, 158], "tendenc": [112, 113, 148], "tenet": [112, 113], "tennesse": [112, 113], "tenni": [112, 113], "tens": [121, 140, 141, 145], "tension": [112, 113], "tensor": [52, 111, 112, 113, 117, 129], "tensorflow": [13, 15, 23, 72, 76, 98, 101, 118], "tensorflowsavedmodelartifact": 74, "tensorrt": 15, "tent": [112, 113], "tenth": [112, 113], "ter": 102, "teratogen": [112, 113], "term": [7, 8, 9, 10, 11, 42, 50, 51, 53, 54, 60, 75, 79, 94, 98, 106, 112, 113, 116, 117, 122, 128, 131, 133, 135, 138, 139, 140, 144, 145, 146, 148, 149, 151, 152, 153, 157, 158, 159, 162, 165, 168, 181, 182], "term_frequ": 153, "termin": [1, 77, 81, 112, 113, 118, 179], "terminologi": [90, 93, 112, 113, 140], "termweight": 153, "terra": [112, 113], "terraform": [65, 66, 160, 161], "terrain": [7, 112, 113, 127], "terrestri": [112, 113], "terri": [112, 113], "terribl": 137, "territori": [3, 112, 113], "terror": [112, 113], "terrorist": [112, 113], "tesla": 43, "test": [7, 9, 11, 15, 17, 21, 23, 29, 50, 55, 56, 58, 60, 64, 66, 72, 75, 76, 77, 78, 84, 86, 90, 94, 95, 107, 110, 111, 112, 113, 116, 117, 118, 128, 131, 133, 134, 137, 145, 151, 161, 162, 165, 166, 168, 170, 171, 173, 175, 176, 177, 178, 181, 182, 183, 185], "test_data": [129, 133], "test_dataset": 111, "test_fil": 181, "test_siz": [15, 17, 21, 29, 34, 111, 137], "test_split_ratio": 21, "test_word_count": 133, "testabl": 166, "testimoni": [31, 37, 136], "teuthonista": [112, 113], "tevet": [0, 7], "texa": [112, 113, 134], "text": [0, 1, 2, 5, 9, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 31, 33, 37, 41, 42, 43, 44, 46, 47, 49, 51, 53, 54, 56, 60, 73, 84, 86, 87, 89, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 123, 124, 125, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 175, 176, 179, 184], "text2im": 10, "text2imag": [6, 131], "text2length": 7, "text2mot": 7, "text2speech": 73, "text_columm": 46, "text_column": 113, "text_kei": 18, "text_length": 95, "text_num_word": [25, 31], "textclassificationrecord": [15, 17, 18, 20], "textcoord": 129, "textdataset": 112, "textil": [112, 113], "textmat": 175, "textual": [2, 6, 7, 9, 10, 11, 12, 38, 43, 50, 55, 60, 87, 98, 120, 121, 127, 131, 135, 136, 138, 148], "textur": [9, 151], "tezg\u00fcino": 157, "tf": [2, 15, 98, 101, 108, 120, 127, 130, 137, 139, 147, 149, 154, 155, 157], "tf2tensorrt": 15, "tfgpt2lmheadmodel": [98, 101], "tfidf": 159, "tfidf_matrix": 159, "tfidfvector": [137, 159], "tg": [96, 102], "tgt_text": 31, "th": [25, 96, 98, 102, 109, 126, 129], "thai": [47, 96, 116], "thailand": 120, "than": [3, 4, 7, 9, 10, 13, 17, 18, 20, 22, 25, 26, 31, 42, 44, 47, 51, 53, 54, 65, 72, 74, 75, 78, 89, 91, 93, 94, 96, 98, 100, 101, 102, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 126, 127, 129, 131, 133, 134, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 158, 160, 164, 173], "thank": [25, 121, 125, 127], "thei": [4, 6, 7, 8, 9, 10, 11, 13, 21, 31, 41, 42, 43, 45, 47, 50, 51, 53, 54, 56, 58, 60, 62, 64, 65, 70, 72, 73, 74, 78, 84, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 147, 148, 150, 151, 152, 153, 155, 156, 157, 158, 160, 165, 168, 169, 171, 172, 173, 176, 178, 179, 181, 184, 186], "theirs": [112, 113, 184], "them": [2, 3, 7, 9, 10, 11, 12, 13, 19, 23, 24, 38, 42, 43, 46, 47, 50, 51, 53, 54, 56, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 77, 78, 80, 81, 82, 84, 86, 89, 91, 93, 97, 98, 99, 104, 107, 110, 111, 112, 113, 114, 115, 117, 118, 121, 122, 123, 127, 129, 130, 132, 134, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 151, 154, 155, 158, 160, 161, 165, 167, 168, 172, 173, 175, 178, 179, 181, 182, 184], "themat": [149, 152, 158], "theme": [13, 27, 67, 90, 112, 113, 156], "themselv": [112, 113, 127, 128, 131, 148], "theorem": 139, "theoret": [11, 60, 90, 98, 112, 113, 127, 140, 144, 162, 169], "theori": [0, 2, 90, 97, 98, 112, 113, 120, 121, 130, 133, 140, 151, 156, 158, 162, 187], "theoris": [112, 113], "theorist": [112, 113], "theoriz": [112, 113], "ther": 102, "therapeut": [112, 113], "therapi": [112, 113], "theravada": [112, 113], "thereaft": [112, 113], "therebi": [13, 43, 50, 51, 53, 58, 60, 78, 112, 113, 117, 166], "therefor": [11, 13, 39, 42, 52, 100, 114, 116, 119, 129, 131, 144, 146, 153, 167], "thermal": [112, 113], "thermostat": 50, "thesauri": 157, "thesauru": 138, "thesi": [2, 88], "theta": [85, 100, 106, 129, 148], "theta_": 152, "theta_d": 152, "thi": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 20, 22, 23, 24, 25, 26, 29, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 167, 168, 170, 171, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187], "thick": [112, 113], "thicket": [112, 113], "thin": [25, 151], "thing": [43, 51, 78, 79, 82, 98, 100, 112, 113, 175, 179, 180, 184, 186], "think": [25, 38, 88, 98, 112, 113, 116, 131, 137, 153, 164, 173, 174, 179, 180], "thinker": [112, 113], "thiogalactopyranosid": 143, "third": [62, 78, 79, 89, 112, 113, 114, 116, 131], "thirteenth": [112, 113], "thirti": [112, 113], "thirtieth": [112, 113], "thisislongtext": 146, "thoma": [0, 112, 113, 152], "thompso": 109, "thompson": [109, 112, 113], "thoreau": [112, 113], "thorough": [47, 90, 137, 173], "thoroughfar": [112, 113], "thoroughli": 13, "those": [6, 24, 25, 37, 39, 46, 47, 53, 60, 63, 65, 89, 91, 93, 94, 96, 98, 110, 112, 113, 114, 115, 116, 117, 121, 122, 123, 131, 134, 137, 148, 156, 157, 160, 179, 182], "though": [10, 24, 27, 28, 50, 98, 112, 113, 118, 140, 146, 151, 157, 164], "thought": [21, 50, 56, 99, 112, 113, 117, 122, 131, 151], "thoughtfulli": 54, "thousand": [112, 113, 121], "thread": 15, "threadpoolctl": 151, "threat": [64, 78, 79, 135], "three": [6, 7, 10, 11, 53, 57, 58, 70, 77, 78, 79, 89, 96, 98, 100, 101, 103, 104, 106, 112, 113, 115, 116, 117, 118, 121, 128, 129, 131, 133, 140, 141, 143, 144, 146, 148, 150, 152, 157, 175, 179, 181, 182, 183], "threshold": [89, 98, 131, 146], "thrive": 84, "through": [1, 3, 4, 7, 9, 10, 11, 17, 18, 20, 22, 39, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 65, 73, 74, 77, 78, 82, 83, 86, 88, 89, 91, 92, 93, 101, 102, 108, 109, 110, 111, 112, 113, 114, 117, 118, 121, 122, 128, 129, 131, 137, 138, 139, 140, 145, 152, 153, 156, 160, 162, 167, 169, 172, 173, 177, 178, 186, 187], "throughout": [10, 46, 53, 64, 86, 90, 112, 113, 172], "throughput": 56, "thu": [10, 13, 24, 41, 43, 45, 53, 57, 58, 60, 94, 107, 112, 113, 115, 116, 134, 153, 172, 185], "thudm": [6, 131], "thunder": [23, 112, 113], "thunderstorm": [112, 113], "thur": 102, "thursdai": [102, 109, 153], "thyssenkrupp": [112, 113], "ti": [13, 102, 112, 113, 153], "tial": 102, "tibetan": 141, "tic": 102, "ticket": [60, 78, 135, 168], "tide": [112, 113], "tie": 153, "tier": [112, 113], "tiger": [112, 113], "tight": 120, "tiiuae": 46, "tild": [85, 127, 148], "tilt": 131, "timber": [112, 113], "timdettm": 46, "time": [0, 3, 7, 8, 9, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 25, 29, 31, 41, 42, 47, 50, 51, 53, 54, 55, 56, 58, 60, 64, 65, 66, 72, 75, 77, 78, 87, 89, 90, 92, 94, 95, 98, 102, 106, 107, 110, 111, 112, 113, 116, 117, 118, 120, 121, 122, 127, 129, 131, 133, 134, 137, 138, 139, 140, 141, 145, 146, 152, 153, 156, 158, 159, 160, 161, 164, 165, 167, 168, 171, 172, 173, 174, 178, 179, 183, 186], "time_budget": [30, 36], "timeli": 13, "timelin": [170, 173], "timestamp": [16, 25, 31, 96], "timestep": [10, 98], "ting": 102, "tinghui": [0, 7], "tingwu": [0, 7], "tini": 52, "tion": 102, "tire": [15, 112, 113, 150], "tired": [112, 113], "tissu": [112, 113], "titl": [22, 24, 25, 26, 27, 31, 32, 33, 44, 68, 69, 77, 95, 112, 113, 117, 121, 137, 140, 156, 175, 176, 177, 178, 179, 180, 183], "tl": [78, 79, 105], "tlog": 153, "tloo": 108, "tlook": 108, "tmp": [20, 104, 111, 112, 113, 136], "tn": [15, 17, 102], "tner": 108, "tnt": 117, "to_dat": [24, 33], "to_dateparm": 33, "to_datetim": [24, 31, 95], "to_dict": 33, "to_replac": 31, "to_year": 35, "toarrai": 159, "toast": 159, "tobia": 0, "toc": 108, "tock": 108, "todai": [6, 50, 78, 91, 98, 107, 112, 113, 120, 124, 129, 143, 153, 156, 159, 172], "todd": 0, "toddler": [112, 113], "todens": 151, "toe": [112, 113], "tog": [0, 7], "togeth": [2, 4, 7, 10, 19, 38, 56, 65, 66, 72, 74, 99, 101, 102, 107, 109, 112, 113, 114, 117, 127, 129, 131, 144, 149, 151, 155, 156, 157, 160, 161, 172, 173, 178, 184], "toggl": 1, "toi": [98, 112, 113, 148], "toilet": [112, 113], "token": [0, 2, 8, 9, 10, 17, 18, 20, 22, 31, 33, 47, 50, 53, 56, 78, 79, 89, 92, 93, 97, 98, 100, 101, 115, 117, 118, 125, 126, 127, 130, 131, 133, 134, 137, 139, 145, 146, 149, 150, 151, 153, 154, 156, 158, 177], "token_classif": 52, "token_freq": [108, 109], "token_reg": 102, "token_to_id": 112, "token_type_id": [105, 111, 113], "tokeniz": 102, "tokenization_t5": 31, "tokenization_utils_bas": 31, "tokenize_funct": [111, 112], "tokenized_dataset": [112, 113], "tokenized_text": [102, 108, 109, 144], "tokenizer_config": [112, 113], "tokenizer_name_or_path": 52, "tokenizer_obj": [112, 113], "tokenizer_object": [112, 113], "tokenizers_parallel": 18, "tokyo": [101, 112, 113], "told": [172, 177], "toler": [112, 113], "toll": [112, 113], "tolstoi": [112, 113], "tom": [112, 113], "toma": 0, "tombigbe": [112, 113], "toml": 81, "tommi": [112, 113], "tomorrow": [98, 129], "tomoto": 153, "tomotopi": [0, 2, 130, 149], "ton": [112, 113], "tonam": 22, "tone": [2, 37, 38, 89, 112, 113, 120, 131, 135, 138], "tone_col": [32, 35], "tone_column": 32, "tone_data": 32, "tone_data_finbert": [31, 32], "tone_data_lm": [31, 32, 33], "tone_data_t5": [31, 32], "tones_q": 35, "tong": 8, "tongu": 50, "tonic": 60, "too": [11, 24, 54, 96, 98, 104, 112, 113, 127, 137, 138, 155, 167, 174, 177, 178], "took": [112, 113, 117, 118, 137, 145, 151], "tool": [2, 6, 7, 10, 13, 38, 42, 43, 45, 46, 50, 51, 52, 53, 54, 56, 58, 59, 60, 62, 63, 64, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 86, 94, 97, 99, 106, 107, 111, 112, 113, 115, 122, 127, 130, 131, 133, 136, 142, 145, 149, 151, 153, 158, 163, 164, 166, 168, 169, 170, 171, 172, 174], "toolbar": 1, "toolbox": 7, "toolkit": [41, 54, 61, 107, 131, 133], "toolset": [53, 63], "top": [1, 9, 47, 57, 66, 67, 68, 74, 78, 79, 100, 102, 107, 111, 112, 113, 115, 121, 126, 134, 137, 146, 148, 150, 151, 153, 156, 161, 177, 178, 179, 183, 184], "top_k": 98, "top_n": 153, "top_p": 98, "top_word": 151, "topic": [0, 2, 13, 20, 21, 22, 47, 50, 56, 61, 70, 72, 81, 88, 94, 96, 97, 99, 112, 113, 120, 121, 127, 130, 131, 156, 168, 174], "topic_cv_merg": 15, "topic_cved_filenam": 15, "topic_dist": 153, "topic_id": 153, "topic_model": 153, "topic_pr": 15, "topic_term_dist": 153, "topic_valid_preds_df": 17, "topic_word": 151, "topographi": [175, 176, 177, 178, 180], "topologi": [43, 112, 113], "torch": [111, 112, 113, 128, 129], "tornado": [112, 113], "toronto": [96, 98, 118], "torresani": 0, "toss": 133, "total": [7, 10, 15, 16, 22, 52, 54, 101, 104, 112, 113, 114, 120, 121, 122, 129, 131, 133, 134, 146, 148, 151, 153, 156, 158, 159, 168], "total_flo": [111, 113], "total_length": 112, "total_loss": 129, "total_sum": [108, 109], "touch": [50, 89, 117, 176, 178], "tour": [112, 113], "tourett": [112, 113], "tourism": [112, 113], "tourist": [112, 113], "tournament": [112, 113], "toutanova": 0, "tove": 184, "tow": [112, 113], "toward": [0, 2, 10, 11, 39, 43, 45, 47, 54, 55, 58, 73, 89, 97, 99, 106, 112, 113, 117, 120, 144, 158], "town": [112, 113, 120], "toxic": [84, 99], "toxin": [112, 113], "toyota": [112, 113, 153], "tp": [15, 17, 153], "tp_add": 15, "tqdm": [24, 101, 102, 104, 109, 111, 112, 113, 115, 129, 133, 136, 137, 142], "tqdmwarn": [101, 102, 104, 109, 111, 112, 113, 115, 137], "tr": [96, 102], "trac": 102, "trace": [54, 112, 113], "traceabl": [65, 112, 113, 160, 170], "traceback": 104, "track": [0, 7, 13, 17, 18, 23, 31, 39, 56, 60, 65, 66, 67, 71, 72, 75, 76, 92, 98, 102, 112, 113, 115, 120, 131, 135, 139, 160, 161, 167, 168, 173, 174, 175, 177, 181, 182, 183, 186], "tractabl": 147, "traction": [60, 78, 112, 113], "trad": 102, "trade": [2, 11, 46, 51, 93, 102, 112, 113, 116, 129, 133, 153], "trademark": 94, "tradeoff": 121, "trader": [112, 113, 129], "tradit": [3, 4, 7, 9, 13, 40, 42, 47, 53, 55, 57, 64, 72, 75, 78, 101, 106, 112, 113, 115, 117, 127, 152, 157, 172, 173], "tradition": [13, 93], "traffic": [4, 41, 56, 77, 78, 83, 112, 113], "tragedian": [112, 113], "trail": [7, 112, 113], "train": [0, 2, 5, 6, 7, 8, 11, 12, 13, 16, 18, 19, 25, 29, 30, 31, 34, 36, 37, 38, 39, 43, 47, 48, 50, 51, 53, 55, 56, 58, 60, 64, 71, 72, 73, 74, 75, 76, 81, 84, 85, 86, 87, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 105, 107, 108, 109, 115, 117, 118, 120, 122, 123, 131, 133, 134, 135, 139, 140, 141, 147, 151, 152, 153, 157, 168, 170, 186], "train_batch_s": [15, 17, 18, 20, 23, 31, 52], "train_data": [29, 34, 133], "train_dataset": [111, 112, 113], "train_dreambooth": 52, "train_epoch_loss": 52, "train_extremely_large_corpu": [104, 106], "train_from_iter": [112, 146], "train_loss": [17, 18, 23, 111, 113], "train_ppl": 52, "train_runtim": [111, 113], "train_samples_per_second": [111, 113], "train_siz": 133, "train_steps_per_second": [111, 113], "train_test_split": [111, 137], "train_text_encod": 52, "train_unsupervis": 125, "trainabl": [51, 52, 53], "trained_model": 15, "trainer": [15, 23, 46, 104, 111, 112, 113], "trainer_interfac": [104, 106], "trainer_spec": [104, 106], "training_arg": [111, 112, 113], "training_loss": [111, 113], "trainingargu": [111, 112, 113], "trainoutput": [111, 113], "trait": [112, 113, 121], "trajectori": [7, 10], "tran": 102, "transact": [0, 7, 41, 50, 78], "transcend": [47, 112, 113], "transcrib": [73, 131], "transcript": [25, 31, 37, 102, 112, 113, 120, 121, 133], "transcultur": [112, 113], "transfer": [0, 2, 6, 7, 11, 13, 47, 52, 56, 77, 78, 89, 94, 97, 99, 100, 101, 110, 112, 113, 116, 117, 124, 131, 151], "transform": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 20, 22, 23, 31, 39, 40, 43, 46, 47, 49, 52, 54, 55, 58, 72, 73, 78, 84, 87, 89, 92, 94, 97, 98, 99, 101, 103, 105, 106, 107, 111, 112, 113, 115, 116, 127, 131, 135, 137, 140, 144, 147, 149, 151, 155, 159, 165, 166, 171, 172], "transform_a_data_to_metadata": 153, "transform_label": [29, 34], "transformer_block": 53, "transformer_block_adapt": 53, "transformer_block_ia3": 53, "transformer_block_llama_adapt": 53, "transformer_block_prefix_tun": 53, "transformers_neuron_view": 115, "transfoxl": 98, "transgress": [112, 113], "transit": [7, 57, 58, 77, 78, 80, 90, 112, 113], "translat": [0, 7, 8, 9, 41, 47, 51, 54, 61, 87, 93, 94, 98, 99, 100, 106, 112, 113, 116, 117, 118, 123, 127, 132, 134, 136, 137, 140, 143, 145, 155, 156, 157, 173, 178, 180, 181, 184], "transliter": [112, 113, 116], "transmiss": [0, 78, 79], "transmissionrisk_": 120, "transmit": [78, 112, 113, 120], "transpar": [0, 54, 60, 72, 75, 78, 86, 93, 112, 113, 131, 170, 172], "transport": [78, 79, 112, 113, 168], "transpos": [53, 89, 117], "trap": [112, 113], "trat": 108, "trauma": [112, 113], "travel": [112, 113], "travers": [44, 55, 112, 113, 122], "travi": [65, 66, 160, 161], "tre": 146, "treasur": [112, 113], "treasury_5": 24, "treasury_yield_url": 24, "treat": [53, 102, 106, 112, 113, 117, 118, 121, 129, 134, 144, 147, 152, 155, 157, 158], "treat_whitespace_as_suffix": [104, 106], "treati": [112, 113], "treatment": [50, 99, 106, 112, 113], "tree": [70, 74, 92, 101, 112, 113, 123, 129, 131, 139, 145, 146, 149, 175], "treebank": [123, 131, 140], "treeless": [112, 113], "trello": [76, 168, 170], "tremend": [112, 113], "trend": [2, 13, 41, 42, 50, 58, 79, 90, 94, 99, 112, 113, 119, 131, 133, 135, 142, 151, 152, 167], "treng": 108, "trengt": 108, "trength": 108, "trent": [112, 113], "trg": [0, 7], "tri": [47, 102, 112, 113, 118, 148, 176, 184], "triad": [112, 113], "trial": [6, 112, 113, 131], "triangl": [112, 113], "triangul": 7, "triangular": [112, 113], "tribal": [112, 113], "tribe": [4, 112, 113], "tribun": 120, "trick": 144, "trigger": [24, 53, 66, 72, 74, 161, 184], "trigram": [133, 134, 144], "trigram_model": 134, "trigram_prob": 133, "trillion": [50, 60, 118, 140], "trim": [18, 112, 113], "trimap": 8, "tripadvisor": 137, "trivia": [112, 113], "trivial": [60, 184], "trl": 52, "troi": [112, 113], "troop": [112, 113], "tropic": [112, 113], "troubleshoot": [65, 66, 90, 160, 161, 165], "trt": 15, "tru": [102, 108], "truck": [47, 112, 113], "true": [4, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 46, 52, 53, 61, 74, 77, 94, 95, 96, 98, 101, 102, 104, 105, 106, 108, 109, 111, 112, 113, 115, 117, 124, 128, 129, 133, 136, 137, 138, 140, 143, 144, 145, 146, 150, 151, 152, 153, 156, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "true_label": 136, "trump": [109, 153], "truncat": [31, 111, 112, 113, 118], "truncated_normal_initi": 113, "trust": [13, 30, 36, 43, 77, 78, 79, 99, 102, 112, 113, 131, 137, 172], "trustworthi": 94, "truth": [56, 65, 67, 89, 160], "truthfulqa": [86, 99], "try": [9, 24, 30, 36, 52, 73, 104, 112, 113, 128, 129, 131, 137, 140, 151, 153, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186], "tryangular": 146, "tryfan": [178, 181, 182], "tsne": 29, "tti": 108, "ttin": 108, "tting": 102, "tu": 102, "tubervil": [112, 113], "tucker": [112, 113], "tug": 117, "tumbl": 153, "tunabl": 152, "tune": [2, 7, 10, 11, 13, 15, 36, 42, 43, 48, 54, 56, 58, 72, 76, 84, 85, 87, 89, 92, 94, 97, 98, 99, 100, 101, 107, 110, 112, 113, 116, 123, 131, 133, 137, 139, 148], "tunnel": [77, 78, 83], "tupl": [134, 142], "tur": 102, "ture": [50, 94, 134, 187], "turkish": [96, 116], "turn": [39, 43, 65, 73, 74, 92, 112, 113, 115, 117, 127, 129, 131, 134, 160], "turner": [112, 113], "tuscaloosa": [112, 113], "tuskege": [112, 113], "tutor": 1, "tutori": [43, 82], "tv": [15, 22], "tw": [102, 153], "twa": 184, "tweepi": 13, "tweet": [13, 116], "twelv": 172, "twenti": [112, 113], "twentieth": [112, 113], "twice": [98, 112, 113, 129, 136], "twin": [112, 113], "twitter": [13, 120, 122, 135, 142], "twitter_complaint": 52, "two": [6, 7, 10, 11, 15, 26, 43, 53, 60, 62, 63, 65, 67, 68, 70, 72, 73, 77, 78, 79, 89, 92, 93, 96, 98, 99, 100, 101, 105, 106, 110, 111, 112, 113, 114, 115, 117, 121, 122, 123, 127, 128, 131, 133, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 160, 167, 168, 172, 175, 176, 178, 181, 183, 184], "twofold": 147, "txt": [15, 16, 20, 22, 46, 62, 77, 101, 104, 106, 113, 115, 122, 125, 140, 153], "ty": 102, "tydiqa": 116, "tym": 15, "type": [1, 5, 6, 9, 10, 15, 23, 24, 25, 31, 32, 33, 34, 35, 42, 43, 46, 50, 51, 53, 54, 55, 60, 61, 74, 79, 80, 82, 83, 89, 94, 98, 99, 100, 101, 103, 105, 111, 112, 113, 114, 116, 117, 121, 124, 131, 132, 133, 134, 137, 138, 140, 141, 145, 146, 147, 148, 152, 153, 155, 157, 166, 167, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186], "type_vocab_s": 113, "typic": [7, 9, 10, 46, 47, 51, 53, 56, 58, 59, 65, 67, 72, 77, 78, 79, 81, 89, 90, 91, 92, 93, 94, 98, 99, 101, 103, 105, 106, 112, 113, 116, 117, 120, 121, 122, 123, 131, 137, 139, 140, 143, 147, 151, 154, 160, 179], "typo": 184, "typograph": 10, "tyrant": [112, 113], "u": [10, 11, 41, 80, 98, 102, 105, 106, 109, 111, 112, 113, 114, 117, 120, 121, 125, 126, 127, 131, 133, 134, 137, 138, 140, 141, 143, 144, 145, 148, 151, 152, 153, 155, 156, 158, 175, 179, 181, 182, 186], "u18": 151, "u_": [148, 150], "u_mass": [150, 153], "uab": [112, 113], "uart": 108, "uarter": 108, "ubuntu": [61, 65, 76, 80, 160], "uc": 84, "uci": [148, 150], "ue": 102, "uesdai": 109, "uf": [177, 183, 186], "ugarit": [112, 113], "ui": [58, 170], "uid": 82, "uk": [0, 96, 112, 113, 175, 176, 177, 178, 180, 183], "ukasz": 0, "ukrain": [112, 113], "ukrainian": 96, "ulm": 108, "ultim": [1, 56, 64, 81, 94, 98, 103, 112, 113, 117, 135], "ultra": 7, "ultraviolet": [112, 113], "um": [102, 141], "umap": 139, "umar": [0, 7], "umbrella": 101, "uml": 170, "un": [102, 108, 109, 143, 146], "unabl": [30, 36, 112, 113, 117, 133, 137, 138], "unachiev": [112, 113], "unaffect": [112, 113], "unalt": [78, 79], "unambigu": [9, 89, 101, 106], "unanim": [31, 112, 113, 168], "unansw": [1, 90], "unauthor": [65, 75, 78, 79, 122, 160], "unavoid": [112, 113], "unbalanc": 94, "unbias": 54, "uncas": [105, 115], "uncensor": 121, "unceremoni": [112, 113], "uncertain": [58, 120, 138], "uncertainti": [0, 2, 31, 54, 121, 133, 138], "uncertanti": 146, "unchalleng": 60, "unchang": [51, 112, 113, 176, 180], "unchart": 3, "uncial": [112, 113], "unclear": [112, 113, 117, 156], "uncommit": 182, "uncommon": [91, 146], "uncondit": [10, 11], "unconfirm": [112, 113], "uncontrol": 167, "unconvent": [112, 113], "uncorr": 113, "uncov": [18, 151, 152], "und": 96, "undefin": 148, "under": [31, 47, 51, 56, 61, 63, 68, 69, 70, 84, 85, 89, 102, 107, 111, 112, 113, 116, 121, 133, 141, 151, 152, 153, 157, 171, 173], "under_sampl": 137, "underbrac": 127, "underdiagnos": [112, 113], "underestim": 42, "underexplor": 90, "underfit": 111, "underflow": 133, "underfund": [112, 113], "undergird": [112, 113], "undergo": [47, 53, 99], "undergradu": [112, 113, 120], "underground": [112, 113], "underinvest": [112, 113], "underli": [3, 9, 43, 49, 50, 51, 53, 54, 56, 60, 61, 73, 81, 85, 94, 96, 131, 138, 139, 140, 149, 152, 153, 173], "underlin": [2, 43], "undermin": 98, "underperform": [116, 118], "underpin": 157, "underrepres": [89, 94, 112, 113, 131], "undersampl": 137, "underscor": [43, 51, 53, 56, 60, 117], "underset": 107, "underspecif": 9, "underspecifi": 9, "understand": [0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 38, 39, 43, 44, 46, 47, 48, 50, 52, 53, 54, 56, 58, 60, 62, 64, 65, 67, 69, 71, 72, 76, 77, 78, 80, 81, 84, 86, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122, 123, 127, 130, 132, 133, 134, 135, 137, 138, 140, 141, 145, 146, 149, 151, 152, 154, 155, 156, 157, 158, 160, 162, 165, 166, 167, 168, 170, 172, 173, 179, 180, 187], "understood": [9, 112, 113, 133, 139, 148, 158, 167, 172, 173], "underw": 47, "underwai": [112, 113], "underwat": 89, "underwhelm": 129, "undesir": [96, 112, 113], "undo": [174, 176, 181], "undocu": [112, 113], "undon": 174, "undoubtedli": [3, 53], "unemp": [26, 27, 28, 29], "unemp_diff_prev": [26, 27, 28, 29, 30, 34, 36], "unemp_diff_year": [26, 27, 28, 29], "unemploi": [112, 113], "unemploy": [112, 113], "unep": 17, "unequ": [13, 112, 113], "uneven": [112, 113], "unexpect": [3, 60, 101, 121, 144, 168, 171], "unfair": [13, 60, 131], "unfamiliar": [140, 157], "unfeas": [112, 113], "unfilt": [94, 118], "unforeseen": [10, 55], "unfortun": 137, "unfreez": [47, 118], "unfrozen": 47, "unfruit": 54, "ungoogl": 140, "ungooglif": 140, "unhealthi": 146, "uni": [100, 102], "unicod": [106, 112, 113], "unicodedata": 105, "unidentifi": [112, 113], "unidirect": 100, "unifi": [0, 51, 100, 117], "uniform": [9, 56, 86, 96, 98, 112, 113, 139], "unigram": [2, 97, 103, 106, 129, 133, 134, 144], "unigram_model_train": [104, 106], "unigram_t5_token": 104, "unigram_token": 104, "unigram_tokenizer_path": 104, "unigramtrain": 104, "unimagin": 127, "unincorpor": [112, 113], "uninform": [144, 147], "unintellig": [78, 79], "unintend": [60, 99], "uninterest": [89, 98], "union": [89, 112, 113], "uniqu": [3, 6, 10, 11, 15, 18, 23, 25, 47, 51, 53, 60, 70, 72, 73, 75, 77, 78, 84, 91, 94, 102, 107, 109, 112, 113, 115, 118, 124, 125, 127, 131, 136, 137, 140, 141, 142, 144, 151, 152, 154, 155, 157, 172, 173, 175, 180], "unison": 67, "unistr": 105, "unit": [0, 9, 50, 58, 60, 63, 66, 72, 78, 89, 94, 103, 106, 107, 112, 113, 116, 120, 121, 131, 139, 140, 141, 143, 147, 153, 161, 167, 170, 172, 173, 185], "unitarian": [112, 113], "united_st": 150, "unitedhealth": [112, 113], "uniti": [112, 113], "univers": [7, 43, 51, 54, 89, 98, 101, 104, 112, 113, 121, 138, 142, 145, 151], "unix": [2, 61, 67, 71, 79], "unjust": [112, 113], "unk": [104, 106, 108, 109, 112, 113, 116, 134, 144], "unk_id": [104, 106], "unk_piec": [104, 106], "unk_surfac": [104, 106], "unk_token": [104, 112, 113], "unknown": [4, 15, 21, 22, 96, 101, 102, 104, 106, 108, 109, 112, 113, 117, 140, 145], "unknown_token": 102, "unkonwn": 146, "unlabel": [50, 60, 114, 116], "unlabl": 118, "unless": [112, 113, 146], "unlik": [7, 9, 10, 25, 43, 50, 53, 54, 85, 89, 97, 98, 100, 106, 112, 113, 127, 130, 141, 145, 146, 152, 172, 173, 177], "unlock": [1, 2, 54, 58, 78, 80, 94, 131], "unmanag": 164, "unnatur": [7, 11, 98], "unnecessari": [112, 113, 143, 164], "unnois": 10, "unnorm": 114, "unnormalis": 129, "unoffici": [10, 112, 113], "unord": 139, "unpack": [1, 51], "unparallel": 117, "unpreced": [39, 112, 113], "unpredict": [58, 72], "unread": 78, "unrealist": [112, 113], "unrel": [10, 11, 112, 113, 157], "unreleas": [6, 131], "unreli": 158, "unrepres": 131, "unresolv": 173, "unrest": 60, "unround": [112, 113], "unsatisfi": 118, "unschedul": [24, 25, 26, 27, 28, 32], "unsecur": 77, "unseen": [9, 13, 51, 106, 111, 123, 133, 134, 140, 152], "unseen_doc": 153, "unselect": [112, 113], "unspecifi": 10, "unstag": [176, 182], "unstress": [112, 113], "unstructur": [39, 40, 41, 42, 47, 57, 58, 131, 143, 149, 152], "unsupervis": [0, 8, 39, 51, 74, 81, 94, 99, 100, 106, 114, 121, 123, 126, 131, 146, 147, 149, 151, 157], "unsupport": [112, 113], "unsurprisingli": 116, "unterthin": 0, "unthreshold": 89, "until": [6, 10, 54, 89, 98, 107, 109, 112, 113, 117, 118, 131, 134, 137, 143, 146, 149, 173], "untrack": [177, 182], "untrain": 7, "unus": [62, 116], "unusu": [91, 112, 113], "unvari": [112, 113], "unveil": 10, "unweight": [115, 120], "unzip": [133, 136], "up": [1, 3, 4, 6, 7, 9, 10, 11, 12, 39, 43, 47, 53, 54, 56, 60, 62, 66, 67, 69, 76, 79, 80, 83, 86, 89, 90, 94, 96, 99, 101, 102, 111, 112, 113, 114, 116, 117, 118, 121, 124, 125, 127, 128, 129, 131, 133, 134, 137, 140, 143, 144, 145, 149, 151, 153, 156, 157, 161, 170, 172, 175, 176, 177, 178, 182, 183, 184, 185, 186], "upa": [112, 113], "upd": 102, "updat": [1, 9, 10, 13, 14, 47, 53, 54, 55, 56, 61, 65, 69, 70, 75, 78, 86, 89, 94, 101, 102, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 118, 122, 131, 133, 136, 137, 142, 151, 152, 160, 167, 170, 172, 174, 175, 176, 177, 178, 182, 184, 186], "update_files_info": 18, "update_info": 18, "update_label_error": 18, "upfront": 173, "upg": 102, "upgrad": [31, 82, 102, 112, 124, 133, 136, 137, 142, 151, 168], "upload": [46, 70, 73, 186], "upon": [43, 45, 47, 48, 55, 58, 65, 66, 71, 88, 90, 98, 112, 113, 114, 117, 118, 160, 161, 167, 168, 173], "upper": [7, 69, 112, 113, 116, 117, 130, 143], "uppercas": [106, 112, 113, 116], "upsampl": [10, 89], "upscal": 89, "upsid": 153, "upstream": [69, 181], "uptick": 129, "upward": 120, "ur": [96, 102, 112, 113], "ural": [112, 113, 141], "urban": [7, 47, 112, 113], "urc": 108, "urdu": 96, "urg": 168, "uri": [18, 25, 31, 42, 129, 146, 153], "url": [0, 44, 46, 70, 73, 77, 95, 96, 112, 113, 122, 124, 146, 178], "urllib": 122, "ursdai": 109, "us": [0, 2, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 23, 24, 25, 27, 28, 31, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 54, 57, 58, 59, 60, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 84, 85, 86, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 161, 162, 165, 166, 167, 168, 170, 171, 173, 175, 177, 178, 179, 181, 182, 183, 185, 186, 187], "us_equities_news_sampl": [129, 146, 153], "usa": [112, 113, 120], "usabl": [39, 78, 97, 124, 130, 135, 166], "usag": [2, 15, 16, 22, 51, 56, 60, 66, 67, 71, 81, 84, 86, 100, 112, 113, 130, 131, 132, 133, 140, 145, 157, 161, 177], "use_all_vocab": [104, 106], "use_cpu": 52, "use_fp16": 46, "use_int4": 46, "use_lora": 52, "use_name_as_subdir": 18, "use_peft": 46, "used_vocab": 153, "used_vocab_freq": 153, "useless": 146, "usenet": 151, "user": [0, 1, 7, 9, 10, 43, 46, 47, 52, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 89, 92, 93, 94, 99, 101, 112, 113, 115, 121, 122, 124, 131, 132, 135, 142, 148, 149, 151, 156, 160, 161, 166, 167, 170, 173, 174, 175, 178, 179, 186], "user_instal": [101, 102, 104, 109, 111, 112, 113, 115, 137], "user_proxi": 43, "usermod": [81, 82], "usernam": [46, 77, 81, 82, 83, 177, 183], "username_to_remov": 82, "userproxyag": 43, "usg": [112, 113], "uspto": [94, 121], "usr": [80, 111, 112, 113], "ustri": 108, "usual": [23, 47, 68, 105, 111, 112, 113, 116, 120, 127, 133, 134, 135, 137, 139, 140, 141, 144, 147, 157, 177, 178], "uszkoreit": 0, "utf": [104, 113, 116, 125], "uti": 102, "util": [3, 7, 10, 11, 15, 16, 18, 21, 22, 25, 31, 39, 43, 44, 45, 47, 48, 51, 52, 53, 56, 58, 60, 61, 64, 65, 70, 78, 81, 89, 94, 96, 100, 102, 112, 113, 115, 117, 121, 124, 131, 132, 133, 138, 144, 148, 149, 152, 153, 160, 162, 166, 167, 168], "utilis": [112, 113], "utilitarian": [60, 112, 113], "utlo": 108, "utloo": 108, "utlook": 108, "utm_sourc": [6, 131], "utmost": [2, 78], "utopian": [112, 113], "ux": 170, "uz": 96, "uzbek": 96, "v": [0, 10, 39, 54, 58, 62, 79, 90, 98, 100, 102, 107, 109, 112, 113, 121, 125, 129, 133, 134, 137, 138, 140, 146, 148, 150, 151, 171, 177, 186], "v0": [52, 61], "v1": [0, 52, 77, 80, 118, 182], "v5": 31, "va": 129, "vaccin": [112, 113], "vader_lexicon": 136, "vadersenti": 136, "vae": [8, 12], "vagu": [23, 56], "val": [102, 146], "valenc": 136, "valid": [2, 7, 15, 19, 22, 30, 36, 38, 39, 56, 57, 72, 75, 76, 78, 81, 84, 85, 89, 90, 95, 96, 116, 120, 145, 165, 168, 170, 173, 174], "valid_data": [15, 22], "valid_data_dir": 15, "valid_dataset": [17, 111, 113], "valid_existing_data": 17, "valid_existing_topic_data": 17, "valid_pol_fil": 15, "valid_tokenized_dataset": 113, "valid_topic_fil": 15, "vallei": [17, 112, 113], "valohai": [72, 75], "valproic": [112, 113], "valu": [2, 3, 6, 9, 10, 11, 15, 16, 21, 22, 23, 24, 29, 31, 32, 35, 36, 39, 41, 47, 50, 53, 55, 56, 60, 72, 77, 78, 89, 90, 93, 96, 98, 102, 111, 112, 113, 114, 115, 117, 118, 120, 125, 126, 133, 134, 137, 140, 144, 146, 148, 152, 153, 154, 156, 157, 158, 159, 172, 173], "valuabl": [2, 39, 41, 46, 50, 66, 70, 90, 94, 99, 103, 106, 116, 117, 135, 136, 138, 139, 145, 148, 149, 152, 161], "value_count": 15, "vamp": 109, "van": [0, 102], "vanguard": [112, 113], "vanish": [50, 53, 117, 139], "vapor": [112, 113], "var": [61, 120], "vari": [7, 39, 43, 51, 60, 77, 98, 101, 112, 113, 120, 134, 141, 143, 152, 158, 170], "variabl": [7, 9, 16, 17, 18, 20, 21, 22, 23, 30, 41, 46, 61, 65, 80, 90, 98, 106, 112, 113, 115, 121, 127, 140, 146, 153, 160], "varialbl": [25, 26, 27, 28, 31, 32, 33, 34, 35, 36], "varianc": [127, 149], "variant": [7, 50, 53, 79, 96, 100, 103, 106, 107, 112, 113, 115, 118, 131, 158], "variat": [7, 10, 12, 51, 55, 89, 112, 113, 115, 117, 120, 122, 131, 140, 152], "varieti": [0, 6, 39, 47, 51, 54, 56, 60, 74, 86, 95, 97, 112, 113, 114, 117, 118, 140, 141, 170], "variou": [3, 7, 8, 9, 10, 12, 13, 38, 39, 42, 43, 45, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 70, 72, 74, 75, 78, 81, 82, 86, 87, 89, 90, 92, 94, 95, 96, 98, 99, 101, 104, 105, 106, 107, 112, 113, 114, 115, 116, 117, 121, 122, 123, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 147, 148, 151, 152, 154, 158, 160, 161, 162, 164, 167, 168, 170, 173, 181, 182], "various": [112, 113], "vase": 10, "vast": [3, 4, 9, 13, 47, 53, 54, 56, 78, 94, 99, 114, 127, 131, 133, 140], "vastli": 47, "vaswani": [0, 53, 54, 114, 117], "vatt": 0, "vbg": 145, "vbn": 145, "vbz": 145, "vc": [174, 175, 176, 177, 180, 181, 182, 183, 185, 186], "ve": [61, 95, 98, 102, 111, 112, 113, 134, 137, 151, 176, 177, 178, 181, 184], "vec": [148, 158], "vector": [0, 2, 9, 10, 11, 47, 50, 53, 57, 58, 78, 89, 100, 103, 115, 116, 117, 120, 125, 126, 127, 128, 129, 130, 135, 137, 138, 139, 140, 147, 148, 149, 151, 154, 159], "vega": [112, 113], "vegan": [112, 113], "veget": [112, 113], "vehicl": [54, 60, 112, 113, 138], "vein": 67, "veloc": [7, 39, 65, 160], "ven": 102, "venkatesh": [0, 7], "ventur": 57, "venu": [112, 113], "venv": 43, "ver": 102, "vera": 29, "verac": 39, "verag": 102, "verb": [121, 131, 140, 141, 145], "verbal": [112, 113], "verbos": [16, 17, 18, 20, 21, 22, 24, 25, 29, 30, 31, 36, 56, 112, 113, 146, 153, 181], "verg": 117, "veri": [4, 11, 25, 53, 54, 97, 98, 103, 112, 113, 117, 118, 125, 129, 130, 134, 137, 140, 151, 155, 157, 159, 173, 174, 175, 176, 177, 183], "verif": [13, 56, 78, 79, 173], "verifi": [54, 60, 77, 79, 111, 113, 122, 173, 178], "vers": 57, "versa": [93, 157], "versatil": [3, 7, 8, 10, 43, 50, 51, 54, 55, 60, 70, 74, 89, 94, 99, 106, 107, 117, 122], "version": [1, 2, 9, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 43, 46, 50, 52, 54, 55, 62, 65, 71, 72, 73, 74, 75, 76, 81, 85, 89, 96, 111, 112, 113, 115, 117, 118, 121, 136, 142, 146, 151, 153, 160, 162, 168, 170, 173, 175, 177, 178, 180, 181, 182, 186], "versu": [112, 113, 137, 140], "vertic": [112, 113, 179], "vet": [94, 108], "veterinari": [112, 113], "veterinarian": 150, "veto": [112, 113], "vetr": 102, "vh": 151, "vi": [79, 90, 96, 102], "via": [11, 13, 36, 43, 47, 50, 58, 60, 61, 74, 76, 78, 89, 98, 106, 112, 113, 125, 127, 171, 179, 186], "viabil": [51, 166], "viabl": [47, 51, 70, 112, 113], "vibe": 7, "vice": [25, 31, 93, 157], "vicin": 120, "victori": [54, 112, 113], "victorian": 10, "victoryland": [112, 113], "vicuna": 84, "video": [0, 6, 89, 98, 112, 113, 117, 122], "videotap": [112, 113], "vie": 102, "vienna": [112, 113], "vietnam": [112, 113], "vietnames": [96, 116], "view": [1, 3, 6, 9, 13, 22, 37, 39, 61, 95, 102, 112, 113, 114, 115, 127, 128, 129, 131, 134, 140, 147, 149, 152, 174], "viewer": [112, 113], "viewpoint": 9, "viewsourc": 21, "vigor": [112, 113], "vigour": [112, 113], "vii": [79, 90], "viii": 79, "villag": [4, 98], "villega": 0, "vim": [175, 177], "vinai": 0, "vincent": 0, "ving": 102, "violat": 134, "violenc": [112, 113], "violent": [112, 113], "violet": 17, "violin": 7, "violinist": 7, "virtu": 11, "virtual": [4, 7, 43, 49, 51, 63, 78, 82, 83, 92, 99, 106, 115], "virtualenv": [101, 102, 104, 109, 115, 133, 136, 137, 142, 151], "visibl": [1, 65, 112, 113, 118, 160, 167, 173], "visigoth": [112, 113], "visio": 170, "vision": [0, 3, 7, 8, 9, 10, 12, 51, 89, 90, 92, 112, 113, 127, 131, 167], "visit": [1, 70, 112, 113, 177, 178, 181, 183], "visitor": [112, 113], "visual": [2, 3, 7, 8, 10, 11, 12, 13, 15, 17, 18, 23, 24, 25, 26, 27, 28, 32, 33, 37, 38, 41, 42, 43, 58, 66, 89, 90, 92, 97, 98, 112, 113, 114, 117, 131, 134, 137, 138, 139, 145, 161, 171], "visualis": 184, "vit": [10, 89, 117], "vital": [2, 7, 13, 51, 56, 77, 78, 90, 117, 165], "vitamin": [112, 113], "viterbi": 109, "vivid": [7, 112, 113], "vmax": [26, 32], "vmin": [26, 32], "vo": 102, "voc_siz": 129, "vocab": [101, 102, 104, 106, 108, 109, 113, 115, 129, 146, 151, 153], "vocab_in": 102, "vocab_out": 102, "vocab_s": [104, 106, 109, 112, 113, 128, 129], "vocab_token": 102, "vocaboulari": 116, "vocabulari": [9, 60, 102, 103, 104, 106, 112, 113, 116, 125, 127, 128, 129, 133, 134, 139, 140, 147, 148, 150, 151, 154, 155, 157, 158, 159], "vocabulary_output_piece_scor": [104, 106], "vocal": [17, 112, 113], "vocat": [112, 113], "voic": [2, 17, 71, 75, 86, 92, 101, 116, 131, 135, 137, 172], "voicegpt": 73, "vol": [102, 112, 113, 130], "volatil": [113, 120, 173], "volcano": 4, "volcker": [24, 25, 32], "volum": [0, 39, 47, 54, 94, 99, 119, 149, 157], "volume3": 0, "voluntari": [112, 113], "vortex": 17, "vote": [25, 31, 112, 113, 121], "voter": [112, 113, 135, 145], "vow": [112, 113], "vowel": [112, 113], "voxel": 9, "vp": [141, 145], "vpn": [2, 71, 78, 79, 81], "vq": [6, 131], "vqa": 131, "vr": [51, 89], "vsp": 0, "vulner": [13, 64, 78, 79, 86, 112, 113, 131, 170], "vv": [142, 143, 181, 182, 186], "vx": [142, 143], "w": [0, 7, 15, 17, 18, 20, 21, 22, 23, 53, 98, 100, 102, 104, 106, 107, 109, 112, 113, 125, 127, 128, 129, 130, 133, 134, 137, 144, 147, 148, 150, 151, 152, 153, 156, 158], "w1": 151, "w3c": 39, "w3krkvu5": 18, "w3krkvu5sync": 18, "w_": [98, 100, 107, 127, 133, 134, 152], "w_0": [98, 133], "w_1": [53, 100, 127, 133, 134, 144, 148], "w_2": [53, 127, 133, 134, 144, 148], "w_3": [133, 134, 148], "w_4": [134, 148], "w_a": 53, "w_b": 53, "w_i": [100, 127, 129, 133, 134, 144, 146, 148], "w_j": [127, 129, 148], "w_k": [53, 133], "w_n": [133, 148], "w_out": 102, "w_q": 53, "w_t": [98, 129], "w_v": 53, "wa": [6, 9, 10, 24, 31, 47, 50, 56, 60, 65, 70, 73, 78, 84, 89, 94, 96, 98, 100, 101, 103, 104, 107, 112, 113, 114, 116, 117, 118, 121, 125, 126, 127, 128, 129, 131, 137, 138, 140, 143, 151, 152, 153, 157, 160, 181, 183, 184, 185, 186, 187], "waai": [112, 113], "wabm": [112, 113], "waff": [112, 113], "wage": [35, 112, 113], "wai": [7, 9, 10, 11, 41, 43, 45, 46, 47, 50, 53, 54, 58, 60, 65, 67, 72, 74, 78, 87, 89, 92, 93, 94, 98, 99, 101, 102, 103, 104, 105, 106, 107, 111, 112, 113, 116, 117, 118, 120, 127, 128, 129, 131, 133, 134, 138, 140, 144, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 174, 175, 177, 178, 181, 182, 184], "waiq": [112, 113], "wait": [17, 18, 23, 68, 73, 101, 112, 113, 122, 149, 185], "waka": [112, 113], "wala": [112, 113], "wale": [178, 180, 181, 182], "walk": [7, 61, 102, 108, 109, 112, 113, 137, 140], "walker": 121, "wall": [6, 10, 102, 112, 113, 117, 120, 131, 151], "wallac": [112, 113], "walsh": 0, "wandb": [15, 17, 18, 23, 31, 71], "wandb_dis": 18, "wandb_project": 18, "wander": 31, "wane": 50, "wang": [0, 7], "want": [11, 24, 25, 31, 47, 61, 65, 68, 69, 77, 82, 96, 98, 105, 108, 109, 110, 111, 112, 113, 114, 117, 129, 133, 134, 137, 141, 145, 146, 148, 151, 153, 156, 158, 160, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184], "war": [102, 112, 113, 117, 120], "ward": [102, 112, 113], "warehous": 39, "warm": [111, 112, 113], "warmer": [112, 113], "warmth": [112, 113], "warmup": [46, 89], "warmup_ratio": 46, "warmup_step": 111, "warn": [13, 15, 16, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 98, 101, 104, 111, 113, 115, 153], "warrant": [60, 112, 113], "warranti": 182, "warren": [112, 113], "warrior": [112, 113], "washington": [43, 112, 113, 120], "wasn": [6, 55], "wast": [112, 113], "wat": [102, 112, 113], "watch": [65, 101, 112, 113, 160], "water": [17, 112, 113], "waterfal": [23, 112, 113, 165, 168, 171, 172], "waterman": 121, "watermark": 85, "waterwai": [112, 113], "watson": 50, "wave": [18, 57, 112, 113, 184], "wavelength": [112, 113], "wavi": [112, 113], "wayn": [112, 113], "wbiq": [112, 113], "wbma": [112, 113], "wbmm": [112, 113], "wbrc": [112, 113], "wc": 156, "wcdma": 18, "wciq": [112, 113], "wcov": [112, 113], "wdbb": [112, 113], "wdfx": [112, 113], "wdhn": [112, 113], "wdiq": [112, 113], "we": [2, 5, 6, 11, 25, 35, 45, 46, 47, 51, 52, 56, 60, 61, 62, 64, 68, 70, 73, 74, 77, 78, 81, 82, 83, 84, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 124, 126, 128, 129, 130, 131, 133, 134, 136, 137, 140, 142, 143, 144, 148, 150, 151, 152, 153, 154, 155, 156, 158, 159, 168, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186], "weak": [60, 103, 107, 117, 138, 142, 145, 153, 157], "weaken": [112, 113, 138, 153], "weaker": [13, 112, 113, 150, 153], "weakest": 150, "wealth": [47, 112, 113, 131, 149], "wealthi": 131, "weapon": 60, "wear": [112, 113], "weather": [13, 112, 113, 153], "weaviat": 60, "web": [0, 18, 39, 43, 44, 46, 50, 60, 62, 65, 66, 74, 77, 89, 90, 96, 98, 112, 113, 118, 123, 130, 131, 140, 142, 151, 160, 161, 170, 174, 177, 183], "web1": [65, 160], "web2": [65, 160], "webpag": 118, "websit": [13, 37, 44, 83, 92, 94, 98, 112, 113, 121, 122, 125, 126, 131, 140, 174, 178, 183, 186], "webster": 120, "webtext": [118, 123], "webtext2": 94, "wed": 113, "wedg": [112, 113], "wedn": 102, "wee": 102, "weed": [112, 113], "week": [48, 102, 112, 113, 129, 131, 137, 153], "weekli": 102, "weevil": [112, 113], "wei": [0, 7, 54, 99], "weigh": [53, 56, 112, 113, 117, 153], "weight": [7, 15, 17, 18, 23, 30, 31, 36, 46, 50, 51, 52, 53, 60, 71, 73, 84, 89, 96, 100, 108, 110, 111, 112, 113, 114, 115, 117, 120, 126, 127, 129, 133, 136, 137, 139, 145, 148, 149, 153, 159, 168, 182], "weight_decai": [46, 111], "weimin": 0, "weiq": [112, 113], "weissenborn": 0, "weitl": [112, 113], "welcom": [25, 131, 143, 156], "well": [1, 2, 7, 9, 10, 13, 14, 39, 43, 46, 47, 53, 54, 56, 61, 65, 72, 73, 74, 78, 79, 88, 94, 97, 98, 99, 101, 103, 104, 106, 107, 111, 112, 113, 116, 117, 118, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 138, 139, 140, 143, 145, 148, 153, 160, 164, 166, 167, 168, 171, 173, 174, 176, 179, 187], "welleck": 98, "welsh": [96, 178, 180, 181], "went": [100, 115, 131, 134, 140, 141], "wenzek": 96, "were": [7, 9, 10, 11, 15, 17, 18, 23, 29, 31, 50, 51, 56, 84, 89, 93, 96, 98, 101, 103, 107, 111, 112, 113, 117, 118, 121, 128, 129, 134, 143, 144, 145, 151, 153, 175, 177, 178, 186], "west": [112, 113, 179], "western": [96, 112, 113], "wet": 153, "wetumpka": [112, 113], "weygandt": [0, 7], "wfiq": [112, 113], "wfna": [112, 113], "wgiq": [112, 113], "wgww": [112, 113], "wh": [102, 151, 152], "what": [4, 6, 10, 11, 35, 53, 54, 57, 89, 98, 101, 102, 112, 113, 114, 117, 126, 134, 137, 151, 152, 157, 165, 166, 167, 168, 170, 171, 175, 177, 179, 182, 184, 186], "whatev": 175, "whdf": [112, 113], "wheel": [136, 138], "when": [0, 6, 7, 9, 10, 11, 13, 15, 17, 18, 23, 24, 31, 42, 43, 46, 47, 51, 53, 56, 58, 60, 65, 66, 67, 70, 72, 73, 74, 77, 89, 93, 94, 98, 99, 101, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 122, 127, 131, 133, 134, 136, 137, 138, 139, 140, 141, 144, 148, 150, 151, 152, 153, 154, 156, 158, 160, 161, 172, 173, 174, 176, 178, 179, 181, 183, 186], "whenev": [81, 89, 153, 175, 186], "where": [1, 2, 3, 4, 7, 8, 9, 10, 11, 39, 43, 46, 47, 50, 51, 53, 54, 56, 58, 60, 61, 64, 65, 66, 72, 78, 89, 94, 98, 99, 100, 101, 106, 108, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 123, 125, 126, 127, 128, 129, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 146, 148, 149, 152, 154, 155, 157, 158, 160, 161, 167, 172, 173, 174, 175, 177, 179, 181, 185], "wherea": [9, 60, 70, 112, 113, 116, 148, 172], "wherein": [50, 60], "wherev": 90, "whernsid": 186, "whether": [7, 11, 53, 100, 103, 107, 112, 113, 114, 117, 121, 129, 131, 135, 146, 148, 151, 186], "which": [2, 6, 7, 8, 9, 10, 11, 12, 13, 24, 31, 39, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 67, 68, 72, 73, 74, 75, 77, 78, 81, 82, 84, 85, 87, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 167, 170, 172, 173, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186], "while": [2, 6, 7, 9, 10, 11, 39, 40, 41, 42, 43, 47, 50, 51, 52, 53, 54, 56, 58, 60, 63, 65, 67, 70, 72, 75, 77, 78, 80, 81, 84, 86, 89, 92, 93, 94, 96, 98, 99, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 126, 127, 129, 131, 133, 134, 135, 137, 138, 139, 140, 142, 144, 145, 147, 148, 149, 150, 152, 153, 155, 157, 159, 160, 172, 173, 174, 175], "whilst": [112, 113], "whiq": [112, 113], "whisker": 7, "whisper": 52, "white": [85, 103, 112, 113, 115, 120, 129, 138], "whitespac": [104, 105, 113, 140, 147], "whl": [46, 133, 136, 137, 151], "whnt": [112, 113], "who": [1, 4, 8, 46, 47, 65, 70, 77, 78, 98, 112, 113, 117, 120, 121, 131, 137, 151, 152, 153, 160, 172, 178], "whole": [56, 72, 89, 93, 98, 100, 111, 112, 113, 131, 135, 138, 151, 155, 173, 177, 178, 182], "whom": [112, 113, 117, 120], "whose": [98, 112, 113, 116, 117, 134], "why": [9, 54, 65, 98, 99, 102, 112, 113, 116, 137, 143, 151, 152, 160, 168, 181, 183], "whylab": 60, "wi": 102, "wiat": [112, 113], "wide": [6, 7, 8, 9, 10, 12, 13, 50, 51, 53, 54, 56, 63, 66, 74, 77, 78, 79, 87, 89, 90, 93, 94, 98, 99, 101, 105, 107, 110, 111, 112, 113, 114, 116, 117, 118, 122, 123, 131, 134, 135, 138, 139, 148, 149, 151, 152, 157, 161], "widen": 50, "wider": [51, 53, 99, 112, 113, 114, 116, 129, 153], "widespread": [51, 78, 99, 112, 113], "widget": 73, "width": [10, 11, 96, 98, 137], "wie": 118, "wiiq": [112, 113], "wiki": [104, 112, 113, 122, 174, 179], "wiki_filepath": [104, 113], "wiki_ko": 104, "wikipedia": [94, 96, 104, 110, 112, 113, 118, 122, 123, 131], "wild": [86, 112, 113], "wildcard": 182, "wildcat": [112, 113], "wildflow": 17, "wilhelm": [112, 113], "willi": 0, "william": [31, 112, 113], "win": [54, 102, 112, 113, 145], "wind": 18, "windblown": [112, 113], "windom": [112, 113], "window": [33, 58, 61, 62, 70, 86, 89, 111, 126, 129, 148, 155, 156, 158, 174, 175, 178, 184], "window_s": [129, 156], "wine": 157, "wing": [102, 112, 113], "winn": 102, "winner": 54, "winter": [18, 112, 113], "wip": 182, "wise": [7, 53, 89], "wish": [10, 31, 47, 68], "wit": [112, 113, 114], "with_prior_preserv": 52, "withdraw": [112, 113], "within": [0, 7, 8, 11, 13, 44, 47, 51, 53, 54, 55, 56, 60, 65, 66, 78, 85, 87, 89, 90, 111, 112, 113, 114, 115, 117, 122, 124, 132, 133, 137, 139, 148, 149, 152, 154, 158, 160, 161, 168, 172, 173, 175], "without": [1, 6, 7, 10, 39, 45, 46, 47, 50, 51, 52, 53, 54, 56, 60, 61, 68, 69, 70, 74, 77, 78, 79, 81, 82, 85, 89, 91, 96, 98, 99, 100, 101, 106, 110, 112, 113, 116, 117, 118, 121, 122, 127, 131, 134, 137, 139, 141, 143, 146, 157, 158, 164, 173, 182, 186], "wiya": [112, 113], "wkrg": [112, 113], "wmt": 123, "wncf": [112, 113], "wng": 108, "wngr": 108, "wngra": 108, "wngrad": 108, "wngrade": 108, "wnl": 151, "wocki": 184, "wocky_rebas": 184, "wolff": [112, 113], "woman": [10, 98, 157], "wombo": [6, 131], "women": [112, 113], "won": [89, 105, 108, 109, 112, 113, 131, 134, 183], "wonder": [112, 113, 121], "wood": [112, 113], "woodpeck": [112, 113], "wor": [102, 106], "word": [0, 2, 9, 10, 11, 25, 31, 49, 53, 56, 78, 87, 89, 91, 93, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 110, 112, 113, 114, 117, 118, 120, 123, 125, 126, 130, 131, 132, 135, 136, 137, 141, 145, 147, 148, 149, 150, 151, 152, 159, 171], "word2id": 150, "word2vec": [2, 50, 100, 125, 127, 130, 139, 154, 157], "word_count": 134, "word_emb": 128, "word_freq": [108, 109], "word_given": 102, "word_given_known": 102, "word_given_unknown": 102, "word_list": [128, 129, 151], "word_loss": [108, 109], "word_to_id": [128, 129], "word_to_ix": 129, "word_token": [102, 133, 137, 143, 144], "wordcloud": 137, "wordnet": 151, "wordnetlemmat": [137, 151], "wordpiec": [2, 97, 100, 103, 106, 113, 115, 147], "wordpiece_bert_token": 104, "wordpiece_token": 104, "wordpiece_tokenizer_path": 104, "wordpieces_prefix": 113, "wordpiecetrain": 104, "words_pmi": 156, "words_ppmi": 156, "words_to_vector": 129, "wore": [112, 113], "work": [2, 3, 7, 8, 9, 10, 13, 39, 43, 45, 50, 52, 53, 55, 56, 57, 62, 64, 69, 70, 72, 75, 76, 78, 81, 82, 84, 86, 90, 91, 94, 97, 98, 99, 101, 102, 103, 104, 106, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 124, 127, 129, 130, 131, 133, 134, 137, 139, 145, 147, 153, 155, 156, 157, 158, 162, 164, 172, 173, 178, 179, 180, 181, 182, 184, 185, 187], "work_dir": 43, "workabl": 172, "workd": 100, "workdir": 62, "worker": [21, 112, 113, 137], "worker_": 21, "worker_1": 21, "worker_2": 21, "worker_3": 21, "worker_df": 21, "worker_dict": 21, "worker_id": 21, "worker_lf": 21, "workflow": [2, 43, 46, 52, 60, 62, 64, 66, 71, 72, 73, 75, 77, 98, 161, 165, 187], "workforc": [60, 112, 113], "working_dir": [175, 178, 180, 181, 182, 183, 185, 186], "workingmen": [112, 113], "workload": [60, 74, 75, 173], "workshop": 123, "workspac": [15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 46, 124, 153, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "workspace_dir": [18, 124], "workstat": 60, "world": [1, 2, 3, 5, 6, 7, 13, 38, 41, 43, 48, 51, 52, 54, 55, 56, 57, 60, 72, 75, 78, 84, 86, 88, 89, 90, 94, 97, 98, 99, 101, 106, 112, 113, 117, 120, 127, 130, 134, 135, 143, 147, 152, 153, 156, 175, 177], "worldview": [112, 113], "worldwid": [112, 113], "worri": [25, 52, 153], "wors": [112, 113, 129, 137], "worth": [0, 106, 117, 127], "worthwhil": [11, 151], "wou": 25, "would": [7, 10, 15, 46, 47, 60, 96, 98, 106, 107, 112, 113, 115, 117, 127, 131, 133, 134, 139, 140, 141, 143, 144, 148, 152, 153, 156, 157, 158, 175, 181, 182, 184], "wouldn": [47, 89, 98, 131], "wound": [112, 113], "wpa": [112, 113], "wpmi": [112, 113], "wrangl": 109, "wrangler": 109, "wrgx": [112, 113], "write": [2, 43, 54, 69, 72, 87, 88, 94, 98, 99, 104, 112, 113, 137, 140, 164, 172, 174, 175, 177, 178, 179, 182, 183, 186], "writefil": [174, 175, 176, 177, 178, 181, 182, 183, 186], "writer": [60, 112, 113], "written": [2, 9, 13, 74, 85, 88, 90, 92, 96, 97, 99, 112, 113, 121, 122, 131, 132, 140, 146, 153, 164, 165, 168], "wrong": [54, 153], "wrote": [112, 113], "wsfa": [112, 113], "wt": 129, "wtb": 0, "wto": [112, 113], "wtto": [112, 113], "wtvy": [112, 113], "wu": [0, 54, 100], "wvtm": [112, 113], "www": [0, 6, 24, 37, 52, 71, 83, 98, 131], "wyddfa": 178, "wzdx": [112, 113], "x": [9, 10, 11, 15, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 34, 36, 53, 65, 85, 100, 102, 106, 107, 108, 109, 112, 113, 114, 127, 128, 129, 137, 144, 146, 147, 150, 152, 153, 158, 160, 182], "x0": 10, "x1": 10, "x2": 10, "x25519": 77, "x86": 175, "x_": [106, 107, 126, 146], "x_1": [106, 127], "x_2": 106, "x_col": [29, 34], "x_i": [106, 114, 127, 129, 158], "x_j": [127, 129], "x_l": 127, "x_n": [106, 146], "x_re": 137, "x_test": 137, "x_train": [29, 137], "x_train_balanc": 137, "xa0": [112, 113], "xa0137": [112, 113], "xbc": 0, "xcr": 0, "xd": 170, "xed": 102, "xenial": 81, "xgb_limitdepth": 36, "xgboost": [13, 36], "xgboostmodelartifact": 74, "xh": 96, "xhosa": 96, "xiao": 0, "xiaohua": 0, "xiaoti": 0, "xie": [0, 7], "xingyu": [0, 7], "xini": [0, 7], "xinxin": [0, 7], "xl": [6, 100, 116, 131], "xla": 15, "xlabel": [27, 95, 137, 140, 156], "xlm": 98, "xlnet": [0, 98], "xmax": 33, "xmin": 33, "xml": [122, 124, 147], "xml_text": 124, "xml_text_list": 124, "xnli": [94, 116], "xp": 172, "xpec": 108, "xpect": 108, "xplore": 90, "xsv": [142, 143], "xt": [10, 108], "xt1": 10, "xt2": 10, "xti": 10, "xtick_param": 25, "xticklabel": 137, "xu": [0, 140], "xue": [0, 7, 96, 116], "xwi": [0, 7], "xxl": [52, 116], "xy": 129, "xytext": 129, "x\u209c": 10, "y": [10, 24, 26, 27, 28, 29, 32, 33, 34, 54, 61, 80, 81, 82, 100, 102, 106, 108, 109, 112, 113, 114, 127, 129, 137, 146, 150, 153, 158, 178, 181, 182], "y_": 106, "y_col": [29, 34], "y_dev": [29, 34], "y_i": [106, 158], "y_pred": 137, "y_re": 137, "y_test": [29, 34, 137], "y_train": [29, 34, 137], "y_train_balanc": 137, "ya": 108, "yadm": 67, "yaml": [15, 16, 18, 21, 23, 52, 63, 65, 66, 67, 70, 81, 160, 161], "yang": [0, 7, 100], "yanqi": 0, "yard": 118, "yazoo": [112, 113], "ydy": 0, "ye": [25, 31, 65, 70, 106, 131, 160, 182], "year": [3, 4, 6, 12, 24, 32, 33, 35, 47, 78, 90, 93, 94, 98, 102, 112, 113, 114, 119, 120, 121, 129, 134, 137, 141, 151, 153, 168], "yearli": [112, 113, 120], "yellen": [24, 25, 31], "yellow": [112, 113, 141], "yellowhamm": [112, 113], "yelp": [131, 137], "yelp_review_ful": 137, "yen": 153, "yet": [11, 50, 51, 53, 65, 67, 80, 89, 90, 112, 113, 114, 133, 138, 140, 143, 154, 160, 174, 177, 181, 182], "yeyati": 100, "yi": [0, 96, 102], "yiddish": 96, "yiel": 102, "yield": [3, 7, 9, 11, 13, 42, 51, 53, 102, 112, 113, 114, 117, 125, 127, 129, 145, 148, 153, 158], "yieldal": 24, "yihe": 0, "yime": 0, "yin": 0, "yj": [104, 111, 112, 113, 174, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186], "yjlee": [95, 101, 102, 108, 109, 115, 133, 134, 136, 137, 142, 143, 151, 156, 174, 178, 186], "ylabel": [27, 95, 137, 140], "ylgnbu": [26, 32], "ylim": 33, "yml": [65, 70, 160], "ymp": 109, "yo": [70, 96], "yogatama": 0, "yokohama": [112, 113], "yonatan": [0, 7], "yoonho": 0, "yop": 143, "yope": 143, "york": [98, 106, 112, 113, 120, 130, 140, 144, 148, 153], "yoruba": 96, "yoshua": 0, "you": [0, 4, 9, 10, 15, 17, 18, 23, 24, 25, 31, 43, 44, 46, 53, 54, 61, 62, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 80, 81, 82, 83, 84, 90, 94, 95, 96, 97, 98, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 121, 124, 125, 127, 129, 133, 134, 136, 137, 138, 139, 140, 141, 142, 144, 145, 147, 148, 151, 153, 155, 156, 157, 160, 168, 171, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186], "young": [0, 112, 113, 174, 175, 176, 181, 185], "younger": [112, 113], "your": [4, 10, 20, 31, 43, 61, 62, 64, 65, 66, 67, 70, 72, 74, 77, 80, 81, 82, 83, 96, 97, 98, 101, 102, 104, 105, 107, 111, 112, 113, 124, 125, 131, 137, 145, 147, 151, 156, 160, 161, 168, 171, 178, 181, 183, 184, 185, 186], "your_api_key_her": 124, "your_email": 77, "your_project_nam": 82, "your_repo_nam": [81, 82], "your_usernam": [68, 81, 82], "yournam": 174, "yourself": [81, 90, 145, 178, 186], "yourusernam": 69, "youth": [112, 113], "youtub": 7, "yp": 24, "ypiii": 143, "yr": 178, "ytd": 43, "yticklabel": 137, "yuan": 0, "yuki": 37, "yuki678": 37, "yum": 61, "yun": [112, 113], "yunh": 0, "yunrong": [0, 7], "yuri": 0, "yzksu5zdwd": 0, "z": [9, 100, 102, 109, 112, 113, 153], "z_": 152, "z_k": 9, "zack": [102, 153], "zani": 17, "zap": 170, "zapatista": [112, 113], "zcp": [0, 7], "zd": 10, "zebra": 157, "zellig": 0, "zendesk": 170, "zenith": [112, 113], "zenodo": 0, "zero": [0, 2, 7, 9, 11, 15, 24, 53, 78, 89, 97, 98, 99, 112, 113, 115, 116, 134, 148, 149, 158], "zero3_init_flag": 52, "zero3_save_16bit_model": 52, "zero_grad": [128, 129], "zero_stag": 52, "zettlemoy": 100, "zh": 96, "zhai": 0, "zhang": [0, 7, 53], "zheng": 0, "zhihui": 0, "zhilin": 0, "zhongang": [0, 7], "zhou": [0, 7, 112, 113], "zhuang": [112, 113], "zi": 10, "zi1": 10, "zi2": 10, "zihang": 0, "zip": [1, 16, 21, 25, 31, 70, 129, 133, 136, 146, 153], "zipf": 131, "zipp": 137, "ziwei": [0, 7], "zolna": 0, "zone": [112, 113, 153], "zoo": [112, 113, 118], "zoom": 89, "zoph": 0, "zou": [0, 7], "zsh": 67, "zsl": 101, "zt": 10, "zt0": 10, "zu": [96, 151], "zulu": 96, "zuo": [0, 7], "zurich": 151, "zurvan": 151, "zvi": 151, "zwaartepunten": 151, "zwak": 151, "zwakk": 151, "zware": 151, "zwart": 151, "zyxel": 151, "\u00b3": 53, "\u00b5": 20, "\u00e0": [112, 113], "\u00e1": [112, 113], "\u00e2": [112, 113], "\u00e3": [112, 113], "\u00e4": [112, 113], "\u00e5": [112, 113], "\u00e5ngstr\u00f6m": [112, 113], "\u00e5rup": 136, "\u00e6": [112, 113], "\u00e7": [0, 7], "\u00e9": [0, 102, 109], "\u00f6": [0, 148], "\u00fc": 105, "\u0101": [112, 113], "\u0103": [112, 113], "\u0105": [112, 113], "\u0121": 105, "\u0121are": 105, "\u0121how": 105, "\u0121you": 105, "\u0131": 0, "\u0142": 0, "\u01ce": [112, 113], "\u01df": [112, 113], "\u01e1": [112, 113], "\u01fb": [112, 113], "\u0201": [112, 113], "\u0203": [112, 113], "\u0227": [112, 113], "\u0250": [112, 113], "\u0251": [112, 113], "\u0252": [112, 113], "\u028c": [112, 113], "\u03ac\u03b9": 2, "\u03b1": [112, 113, 134, 152], "\u03b1\u00b2": 134, "\u03b1\u1f50\u03c4\u03cc\u03c2": [112, 113], "\u03b2": 143, "\u03b7": 10, "\u03b8i": [112, 113], "\u03bcg": 143, "\u03bcm": [112, 113], "\u0430": [112, 113], "\u0561": [112, 113], "\u1d44": [112, 113], "\u1d8f": [112, 113], "\u1e01": [112, 113], "\u1e9a": [112, 113], "\u1ea1": [112, 113], "\u1ea3": [112, 113], "\u1ea5": [112, 113], "\u1ea7": [112, 113], "\u1ea9": [112, 113], "\u1eab": [112, 113], "\u1ead": [112, 113], "\u1eaf": [112, 113], "\u1eb1": [112, 113], "\u1eb3": [112, 113], "\u1eb5": [112, 113], "\u1eb7": [112, 113], "\u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1": 2, "\u2153": [112, 113], "\u2460": 22, "\u2c65": [112, 113], "\u3053\u3093\u306b\u3061\u306f": 106, "\u3053\u3093\u306b\u3061\u306f\u4e16\u754c": 106, "\u4e16\u754c": 106, "\u53bb": 141, "\u53bb\u6211": 141, "\u6211": 141, "\u6211\u53bb": 141, "\u6211\u5f00\u59cb\u5199": 140, "\u6545": 20, "\u6df1\u5733": 21, "\u7f8e": 20, "\u7f8e\uc11c": 21, "\u8bf4": 140, "\u8f9b\u4e11\u5e74": 15, "\ua7bb": [112, 113], "\uac00": [15, 16, 18, 20, 141, 146], "\uac00\uacf5\uc2dd\ud488": 16, "\uac00\ub2a5": 17, "\uac00\ub2a5\uc131": 21, "\uac00\ub2a5\uc131\uacfc": 20, "\uac00\ub2a5\uc131\uc740": [17, 20], "\uac00\ub2a5\ud558\ub2e4": 20, "\uac00\ub2a5\ud55c": 16, "\uac00\ub2e4": [141, 146], "\uac00\ub729\uc774\ub098": [16, 20], "\uac00\ub85c\ub9c9\uc544": 142, "\uac00\ubc29": 146, "\uac00\ubc29\uc5d0": 146, "\uac00\ubc29\uc740": 146, "\uac00\ubc29\uc744": 146, "\uac00\ubc29\uc774": 146, "\uac00\uc6b4\ub370": 20, "\uac00\uc785\uc774": [16, 20], "\uac00\uc785\uc790": 15, "\uac00\uc785\ud55c\ub2e4\uace0": [16, 20], "\uac00\uc790": 141, "\uac00\uc7a5": [15, 20], "\uac00\uc804": [15, 22], "\uac00\uc871": 16, "\uac00\uce58\ub294": 20, "\uac01": [16, 20], "\uac01\uac01": 18, "\uac01\uad11\ubc1b": 15, "\uac04": 21, "\uac04\uc2e0\ud788": 22, "\uac08\ub4f1\uc758": 21, "\uac10\uc18c\uac00": 20, "\uac10\uc18c\uc138\ub85c": 16, "\uac10\uc18c\ud55c\ub2e4\ub294": 17, "\uac10\uc5fc\uc99d": 15, "\uac10\ucdb0\uac00\uace0": 16, "\uac10\ud0c4\uc0ac": 141, "\uac14\ub2e4": [141, 146], "\uac14\uc5c8\ub2e4": 141, "\uac15\ub989\uc6d0\uc8fc\ub300": 20, "\uac15\uc138": 20, "\uac15\uc138\ub97c": 20, "\uac15\uc870": 21, "\uac15\ud654": [17, 18, 20], "\uac15\ud654\uc5d0\ub3c4": 15, "\uac15\ud654\ud558\uaca0\ub2e4": 15, "\uac16\ub294": 15, "\uac19\ub2e4": 17, "\uac19\uc740": 20, "\uac1c\ubc1c": 17, "\uac1c\ubc1c\uc790": 17, "\uac1c\ubc1c\ud560": 15, "\uac1c\uc120\uacfc": [15, 17], "\uac1c\uc2dc": 16, "\uac1c\uc778": 20, "\uac1c\uc815\uc548\uae4c\uc9c0": 20, "\uac1c\ucd5c": 21, "\uac1c\ucd5c\ud588\ub2e4\uace0": 15, "\uac1c\ud3b8": 20, "\uac24\ub7ed\uc2dcz\ud3f4\ub4dc3\uc640": 15, "\uac24\ub7ed\uc2dcz\ud50c\ub9bd3": 15, "\uac70\ub798\ub294": 17, "\uac70\ub798\ub97c": 17, "\uac70\ub798\ube44\uc6a9": 17, "\uac70\ub9ac\ub450\uae30": 16, "\uac70\uce5c": [16, 20], "\uac74\uac15": 15, "\uac78\uc5b4\uc628": 16, "\uac78\uccd0": 15, "\uac80\uc0c9": 17, "\uac80\ud1a0\ub97c": [16, 20], "\uac83\uc73c\ub85c": [15, 17, 20], "\uac83\uc744": [15, 17], "\uac83\uc774": [15, 17, 20], "\uac83\uc774\ub77c\ub294": 20, "\uac83\uc774\uba70": 17, "\uac8c\ud2f0\uc774\ubbf8\uc9c0\ubc45\ud06c": 15, "\uaca9\uc6d4\uac04\uc73c\ub85c": 16, "\uaca9\uc790\uac00": 17, "\uacaa\uc5c8\uc73c\ub098": 21, "\uacac\uc81c": 18, "\uacb0\uacfc": 141, "\uacb0\ub860\uc740": 20, "\uacb0\uc815\ub41c": 16, "\uacb0\uc815\ub41c\ub2e4": 17, "\uacb0\uc815\ud588\ub2e4": 15, "\uacbd\uad6c\uc6a9": 21, "\uacbd\uae30": [20, 142], "\uacbd\uae30\uc0c1\ud669\uc5d0": 142, "\uacbd\ub0a8\ub3c4\uc640": 21, "\uacbd\ubcf4\ub97c": 142, "\uacbd\uc601\uc9c4": 15, "\uacbd\uc601\uc9c4\ub2e8": 124, "\uacbd\uc6b0": [17, 20], "\uacbd\uc790\ub144": 22, "\uacbd\uc7c1": [15, 18], "\uacbd\uc7c1\ub825": [15, 17], "\uacbd\uc81c": [20, 21], "\uacbd\uc81c\uae30\uc0c1\ub3c4": [15, 22], "\uacbd\uc81c\ub294": 15, "\uacbd\uc81c\uc131\uc7a5\ub960": 15, "\uacc4\uc18d": 15, "\uacc4\uc18d\ub418\ub294": 16, "\uacc4\uc5f4\uc0ac": [16, 17, 20], "\uacc4\uc5f4\uc0ac\ub4e4\uc774": [15, 17], "\uacc4\uc5f4\uc0ac\ub97c": 20, "\uacc4\uc5f4\uc0ac\ub9c8\ub2e4": 20, "\uacc4\ud68d\uc774\ub2e4": 15, "\uace0": [15, 16, 17, 20, 143], "\uace0\uac1d": 17, "\uace0\ub9bd\uc5b4": 141, "\uace0\ubc1c\uad8c": [15, 17], "\uace0\uc131\uc7a5": 18, "\uace0\uc218\ud558\ub294": 16, "\uace0\uc6a9": [15, 17, 18, 20, 22, 23], "\uace0\uc6b0": 141, "\uace0\ud615\uc5f0": 15, "\uace8\uc774": 21, "\uacf1": 141, "\uacf5": [15, 17, 22], "\uacf5\uac1c": 95, "\uacf5\uacfc\ub300\ud559\uc5d0\uc11c": 15, "\uacf5\uae09\ub9dd": [15, 17, 18, 20, 22, 23], "\uacf5\uae09\ud55c\ub2e4": 21, "\uacf5\ub3d9": 15, "\uacf5\ub3d9\ucde8\uc7ac\ub2e8": 21, "\uacf5\ub85c": 15, "\uacf5\uc720": [16, 17], "\uacf5\uc7a5\uc774": [20, 21], "\uacf5\uc815\uac70\ub798\ubc95\uc740": [15, 17], "\uacfc": [15, 17, 141, 142], "\uacfc\uac70": 16, "\uacfc\ub294": 17, "\uacfc\uc790": 141, "\uacfc\uc790\ub97c": 141, "\uacfc\uc81c": 15, "\uacfc\uc81c\ub3c4": 15, "\uacfc\uc81c\ub97c": 15, "\uacfc\ud559": 17, "\uad00\uacc4": 17, "\uad00\uacc4\uc0ac\uac00": [16, 20], "\uad00\uacc4\uc5b8": 141, "\uad00\uacc4\uc790": 17, "\uad00\uacc4\uc790\ub294": 16, "\uad00\ub828": [15, 17], "\uad00\ub9ac": 17, "\uad00\uc7a5\uacfc": 20, "\uad00\uce21": 20, "\uad00\uce21\ub418\uc5c8\ub2e4": 142, "\uad00\ud615\uc0ac": 141, "\uad0c": 142, "\uad11\ubc94\uc704": 17, "\uad50\uc218": 20, "\uad50\uc721": [15, 17], "\uad50\uc721\uc744": 15, "\uad50\ucc29\uc5b4": 141, "\uad6c\uac15\uc720\uc0b0\uade0": 15, "\uad6c\uacbd\ubbfc": 21, "\uad6c\uae00": 18, "\uad6c\ub3c4": 20, "\uad6c\ub9e4\ub825": 20, "\uad6c\ubb38": 141, "\uad6c\uc131\ub418\uace0": 15, "\uad6c\uc131\ub418\uba70": 15, "\uad6c\uc778\ub09c": 17, "\uad6c\uc870\uc801": 18, "\uad6d\uac00": 17, "\uad6d\uac00\uc5d0": 142, "\uad6d\ub0b4": [16, 18, 20, 21, 22, 95], "\uad6d\uba74": 18, "\uad6d\ucc45\uc0ac\uc5c5": 18, "\uad74\uc808\uc5b4": 141, "\uad8c\uce60\uc2b9": 15, "\uaddc\uaca9": 18, "\uaddc\uce59": 141, "\uadf8": [17, 141], "\uadf8\uac04": 21, "\uadf8\ub3d9\uc548": 17, "\uadf8\ub7f0\ub370": 16, "\uadf8\ub7fc\uc5d0\ub3c4": 17, "\uadf8\ub8f9": [16, 20], "\uadf8\ub8f9\ub0b4": [15, 17], "\uadf8\ub8f9\uc73c\ub85c": [15, 17], "\uadf8\ub8f9\uc758": [16, 20], "\uadf8\ub97c": 141, "\uadf8\ub9b0\uc5d0\ub108\uc9c0": 21, "\uadf8\uc5b4\ub77c": 141, "\uadf8\uc5b4\uc11c": 141, "\uadf8\uce58\uc9c0": 16, "\uadf8\ud574": 16, "\uadfc\uac70\ub294": 20, "\uadfc\uba74": 15, "\uae00\ub85c\ubc8c": [15, 17, 21, 22], "\uae08": 142, "\uae08\ub144\ub3c4": 15, "\uae08\ub9ac": 142, "\uae08\ub9ac\uc815\ucc45\uc744": 142, "\uae08\uc735": 15, "\uae08\uc735_\uc7ac\ud14c\ud06c": 21, "\uae08\uc735\uc704\uc6d0": 16, "\uae08\uc735\uc704\uc6d0\uc7a5\uc774": 16, "\uae08\uc735\uc9c0\uc8fc": 20, "\uae08\uc735\ud22c\uc790": 21, "\uae08\ud1b5\uc704": 142, "\uae08\ud1b5\uc704\ub294": 142, "\uae09": 17, "\uae0b\uace0": 141, "\uae0b\ub2e4": 141, "\uae30": [21, 104, 142], "\uae30\uac04": 20, "\uae30\ub2a5": 17, "\uae30\ub2a5\uc131": 15, "\uae30\ub2a5\uc744": 21, "\uae30\ub300\uac10\uc774": 20, "\uae30\ub300\ud574\ubcfc": 20, "\uae30\ub85d\uc73c\ub85c": 16, "\uae30\ub85d\ud55c": 15, "\uae30\ub85d\ud560": 15, "\uae30\ubcf8\uc138\uc158": 21, "\uae30\uc220": [15, 17, 18], "\uae30\uc220\uc744": 15, "\uae30\uc220\ud601\uc2e0": 18, "\uae30\uc5c5": [15, 16, 17, 18, 20, 21, 22, 23], "\uae30\uc5c5\ub4e4\ub3c4": 16, "\uae30\uc5c5\ub4e4\uc758": 16, "\uae30\uc5c5\ub4e4\uc774": 16, "\uae30\uc5c5\uc724\ub9ac": [15, 17, 18, 20, 22, 23], "\uae30\uc5c5\uc744": 16, "\uae30\uc5c5\uc774\uc775\uc740": 20, "\uae30\uc790": [15, 16, 17, 20, 21], "\uae30\uc870\uc5f0\uc124\uc5d0\uc11c": 21, "\uae30\uc874": 17, "\uae30\ud55c\uc778": 20, "\uae30\ud68c": 15, "\uae30\ud6c4\ubcc0\ud654": [15, 17, 18, 20, 22, 23], "\uae40": 21, "\uae40\ub3d9\uad00": 21, "\uae40\ubbfc\uc601": 15, "\uae40\uc131\ubbfc": 15, "\uae40\uc131\uc740": 21, "\uae40\uce58\ub97c": 133, "\uae40\ud76c\uc6a9": 15, "\uae4a\uc5b4\uc9c0\uba74\uc11c": 21, "\uae4c\uc9c0\ub3c4": 18, "\ub04c\uc5b4\ubaa8\uc73c\ub294": 20, "\ub05d\ub0b4\uace0": 15, "\ub098": [104, 141], "\ub098\uac00": 142, "\ub098\uac00\uae38": 16, "\ub098\uac00\ub2e4": 146, "\ub098\uac14\ub2e4": 146, "\ub098\ub294": 141, "\ub098\uc11c\uaca0\ub2e4\uace0": 15, "\ub098\uc11c\ub294": 20, "\ub098\uc11c\uc11c": 15, "\ub098\uc120": 16, "\ub098\uc628\ub2e4": 20, "\ub098\uc654\ub2e4": 16, "\ub098\uc774": 104, "\ub098\uce74": 17, "\ub098\ud0c0\ub0b4\ub294": 20, "\ub09c\uc774\ub3c4\uac00": 17, "\ub09c\uc774\ub3c4\ub294": 17, "\ub09c\ud56d": 18, "\ub0a8\uc131\ub4e4\ub85c\ubd80\ud130": [16, 20], "\ub0a9\ubd80": 20, "\ub0a9\ubd80\ub97c": 20, "\ub0a9\ubd80\ud558\ub294": 20, "\ub0a9\ubd80\ud574\uc57c": 20, "\ub0ac\uc9c0\ub9cc": 20, "\ub0b4": 15, "\ub0b4\uac00": 95, "\ub0b4\ub144": 20, "\ub0b4\ub144\uc5d0\ub294": 15, "\ub0b4\ub144\uc5d0\ub3c4": 15, "\ub0b4\ub193\uc740": 16, "\ub0b4\ub194\uc57c": 15, "\ub0b4\ub514\ub518": 17, "\ub0b4\ub9d8\uc744": 95, "\ub0b4\ubd80\uc120": 15, "\ub0b4\uc138\uc6b4": 20, "\ub0b4\uc57c": 20, "\ub0b4\uc77c\uc2e0\ubb38": 15, "\ub0b4\uc9c0": 17, "\ub0b8\ub2e4": 15, "\ub0c9\uc7a5\uace0": [15, 22], "\ub108": 141, "\ub108\ub294": 141, "\ub110\ub9ac": 18, "\ub118\uac8c": 20, "\ub118\ub294": 20, "\ub118\ub294\ub2e4": 20, "\ub118\uc5b4\uc120": 18, "\ub118\uc5b4\uc130\uc73c\ub098": 20, "\ub118\uc744": 20, "\ub124\ud2b8\uc6cc\ud06c": 17, "\ub125\uc3d8": [16, 20], "\ub125\uc3d8\ub294": [16, 20], "\ub144": 18, "\ub144\uc774": 18, "\ub155": 104, "\ub178\ub3d9\ubd80": 17, "\ub178\ub3d9\uc870\ud569": 15, "\ub178\ub4dc\uac00": 17, "\ub178\ub4dc\ub4e4\uc5d0\uac8c": 17, "\ub178\ub77c": 141, "\ub178\ub797": 141, "\ub178\ub825\ud558\ub294": 22, "\ub178\ub825\ud560": 15, "\ub178\uc0ac": 18, "\ub178\uc870": [15, 18], "\ub178\uc870\uc704\uc6d0\uc7a5": 15, "\ub17c\ub780": 15, "\ub192\ub2e4": 20, "\ub192\uc73c\uba70": 17, "\ub192\uc740": [17, 20], "\ub274\uc2a4": 22, "\ub290\ub9b0": 17, "\ub294": [16, 17, 18, 141, 142, 146], "\ub298\uc5b4\ub098\uace0": 16, "\ub298\uc5b4\ub098\ub294": 20, "\ub298\uc5b4\ub0a0": 20, "\ub2a5\ub825": 17, "\ub2c8": [104, 141], "\ub2c8\ub2e4": 104, "\ub2e4": [15, 16, 17, 104, 141, 142, 146], "\ub2e4\uace0": 142, "\ub2e4\ub098\uc640": 95, "\ub2e4\ub974\uace0": [15, 17], "\ub2e4\ub978": [15, 17], "\ub2e4\uc2dc": 16, "\ub2e4\uc591\ud55c": 15, "\ub2e4\uc74c": 15, "\ub2e4\uc74c\uacfc": 17, "\ub2e4\uc74c\ub0a0\uc778": 142, "\ub2e4\uc74c\ub2ec\ubd80\ud130": 15, "\ub2e4\uc774\ub809\ud2b8": 21, "\ub2e4\ud589\ud788\ub3c4": 142, "\ub2e8\uc21c": 141, "\ub2ec": 16, "\ub2ec\uae4c\uc9c0": 15, "\ub2ec\ub77c": 15, "\ub2f4\uae34": 16, "\ub2f4\ub2f9\ud55c": 21, "\ub2f4\ud654": 141, "\ub2f9": 17, "\ub2f9\uc2dc": 16, "\ub2f9\uc7a5": 20, "\ub300\uaddc\ubaa8": 15, "\ub300\uae30\uc5c5": 17, "\ub300\uae30\uc5c5\uc774": 16, "\ub300\ub85c": [15, 17], "\ub300\ub9cc": 142, "\ub300\uba85\uc0ac": 141, "\ub300\ubc95": 17, "\ub300\ubd80\ubd84\uc774": [16, 20], "\ub300\ube44": 20, "\ub300\uc0c1": [21, 141], "\ub300\uc0c1\uc73c\ub85c": [15, 16, 21], "\ub300\uc120": 20, "\ub300\uc138": 20, "\ub300\uc2e0": 16, "\ub300\uc5ec\uc0ac\uc5c5\uc744": 21, "\ub300\uc678\uc801\uc73c\ub85c": 16, "\ub300\uc6a9\ub7c9": 17, "\ub300\uc751\ud558\uae30": 17, "\ub300\uc751\ud574": 15, "\ub300\uc911": 17, "\ub300\uccb4\ud558\ub294": 16, "\ub300\ud1b5\ub839\uc774": [16, 20], "\ub300\ud45c": [15, 22], "\ub300\ud45c\uac00": 15, "\ub300\ud45c\ub294": 21, "\ub300\ud559": 21, "\ub300\ud55c": 21, "\ub300\ud55c\ubbfc\uad6d": 22, "\ub300\ud55c\uc81c\uad6d\uc744": 15, "\ub300\ud574\uc11c\ub294": [15, 17], "\ub300\ud615": [15, 22], "\ub300\ud615\ub9c8\ud2b8": 16, "\ub300\ud615\uc8fc": 20, "\ub354": [16, 17, 20, 21], "\ub354\uc6b1": 15, "\ub370\uc774\ud130": [15, 17], "\ub3c4": 17, "\ub3c4\uad6c": 17, "\ub3c4\ub2ec\ud558\uc9c0": 142, "\ub3c4\uc2dc": 15, "\ub3c4\uc6b0": 141, "\ub3c4\uc785": [15, 18], "\ub3c5": 22, "\ub3c5\ub9bd\uc5b8": 141, "\ub3cc\ud30c\uc5d0": 20, "\ub3d5": 141, "\ub3d5\uae30": 16, "\ub3d9\uad6d\uc81c\uc57d": 15, "\ub3d9\ubc18\uc131\uc7a5": [15, 17, 18, 20, 22, 23], "\ub3d9\uc0ac": [18, 141], "\ub3d9\uc2dc\ub300\ub97c": 21, "\ub3d9\ud559\uac1c\ubbf8\uc6b4\ub3d9": 16, "\ub3d9\ud574\uc548": 142, "\ub3d9\ud574\uc548\uc744": 142, "\ub3d9\ud654\uc57d\ud488": 15, "\ub3d9\ud654\uc57d\ud488\uc740": 15, "\ub3d9\ud654\uc57d\ud488\uc758": 15, "\ub3d9\ud654\uc57d\ud488\uc774": 15, "\ub418\uba74": 15, "\ub418\uc5c8\uace0": 16, "\ub41c": [17, 18], "\ub454\ud654\ud558\uba74\uc11c": 21, "\ub4a4\uc5d0\uc11c": 17, "\ub4dc\ub9ac\uae30": 15, "\ub4e3": 141, "\ub4e4": [17, 18, 141, 146], "\ub4e4\uace0": 146, "\ub4e4\ub2e4": 146, "\ub4e4\uc5b4\uac00\uba74\uc11c": 18, "\ub4e4\uc5b4\uac00\uba74\uc11c\ub4e4\uc5b4\uac00\uba74\uc11c": 18, "\ub4e4\uc5b4\uac00\uc11c": 141, "\ub4e4\uc5b4\uac00\uc168\ub2e4": 146, "\ub4e4\uc5b4\uac00\uc2e0\ub2e4": 146, "\ub4e4\uc5b4\uac14\ub2e4": 146, "\ub4e4\uc5ec\ub2e4\ubcfc": 20, "\ub4ef": 20, "\ub4f1": [15, 16, 17, 18, 20, 21, 22, 142], "\ub4f1\ub3c4": 15, "\ub4f1\ub85d\uc744": 16, "\ub4f1\uc5d0\uc11c\ub294": [15, 22], "\ub4f1\uc73c\ub85c": 18, "\ub4f1\uc744": [15, 16, 17], "\ub4f1\uc7a5\ud588\ub2e4": 16, "\ub4f1\uc7a5\ud588\uc73c\uba70": 16, "\ub514\uc2a4\ud50c\ub808\uc774": [15, 22], "\ub514\uc9c0\ud138": [15, 17, 21], "\ub514\ud53c\uc9c0": 95, "\ub525\ub7ec\ub2dd": 15, "\ub530": 15, "\ub530\ub77c\uc11c": 142, "\ub530\ub77c\uc7a1\uc744": 17, "\ub530\ub974": 15, "\ub530\ub974\uba74": [16, 21], "\ub54c": 15, "\ub54c\ub9c8\ub2e4": 17, "\ub54c\ubb38\uc5d0": 20, "\ub54c\ubb38\uc774": 17, "\ub54c\ubb38\uc774\ub2e4": 20, "\ub5a8\uc5b4\uc9c4": 142, "\ub5a8\uc5b4\uc9c4\ub370\ub2e4": 142, "\ub610": 21, "\ub610\ud55c": 16, "\ub77c\uc774\ube0c": 17, "\ub7ec": 16, "\ub7ec\uc2dc\uc544\uac00": [16, 20], "\ub7f0": 17, "\ub85c": [15, 17, 18, 142], "\ub85c\uace0": 16, "\ub85c\uadf8": 141, "\ub85c\ubd07": 15, "\ub86f\ub370": 17, "\ub86f\ub370\uc1fc\ud551\uacfc": 22, "\ub86f\ub370\uce60\uc131\uc74c\ub8cc\uc758": 15, "\ub8cc": 15, "\ub958": 21, "\ub97c": [15, 17, 18, 20, 21, 104, 141, 143], "\ub9ac\uc11c\uce58\uc13c\ud130\uc7a5\uc740": 20, "\ub9ac\uc6c0\ubbf8\uc220\uad00": 20, "\ub9ac\ucc54": 16, "\ub9c8\ub2e4": 15, "\ub9c8\ub828\uc744": 20, "\ub9c8\ub828\ud55c\ub2e4\ub294": [16, 20], "\ub9c8\uc2a4\ud06c": 15, "\ub9c8\uc774\ub2dd": 15, "\ub9c8\ucf00\ud305": 15, "\ub9cc\ub4e0": 18, "\ub9cc\uba85": 18, "\ub9cc\uba85\uc744": 18, "\ub9cc\uc5d0": [16, 18, 21], "\ub9cc\ud558\ub2e4": 20, "\ub9cc\ud558\ub2e4\ub294": 20, "\ub9ce\uac8c\ub294": 17, "\ub9ce\ub2e4": 16, "\ub9ce\uc740": 20, "\ub9d0": [15, 17], "\ub9d0\ud588\ub2e4": [15, 20], "\ub9db\uc788\ub294": 15, "\ub9de\uace0": 18, "\ub9de\ubb3c\ub824": 20, "\ub9de\ucdb0": [16, 20], "\ub9e4\uac01\ud558\uae30": 21, "\ub9e4\ub144": 16, "\ub9e4\uc6b0": 18, "\ub9e4\uc6d4": 16, "\ub9e4\ucd9c": 15, "\uba38\ub2c8\ud22c\ub370\uc774": [20, 21], "\uba39": [21, 141], "\uba39\uac70\ub9ac\uc5d0": 17, "\uba39\uace0": 95, "\uba39\ub2e4": [131, 141], "\uba39\uc2b5\ub2c8\ub2e4": 133, "\uba39\uc5c8\ub2e4": 141, "\uba39\uc73c\ub7ec": 141, "\uba3c\uc800": [15, 17], "\uba40\ud2f0\ubbf8\ub514\uc5b4": 17, "\uba40\ud2f0\ubbf8\ub514\uc5b4\uacf5\ud559\uacfc": 20, "\uba70": [15, 17, 20], "\uba74\uc81c\ub97c": 21, "\uba85": 141, "\uba85\ubaa9": 17, "\uba85\ubd84": 21, "\uba85\uc0ac": 141, "\uba85\uc608": 15, "\uba85\uc608\ud68c\ubcf5": 15, "\uba85\uc608\ud68c\uc7a5\uc740": 16, "\uba85\ucf8c\ud558\uac8c": 20, "\ubaa8\ub378\uc778": 22, "\ubaa8\ub378\uc785\ub2c8\ub2e4": 142, "\ubaa8\ub450\uac00": 16, "\ubaa8\ubc14\uc77c": 16, "\ubaa8\ubc14\uc77ctv": 17, "\ubaa8\ubc94\uc0ac\ub840\ub85c": 21, "\ubaa8\ud1a0\uac00": 17, "\ubaa9\ud45c\ub85c": 17, "\ubab0\ub9ac\ube0c": 17, "\ubab8\uac12\uc774": 17, "\ubabb\ud558\ub294": 21, "\ubabb\ud558\ub358": 17, "\ubabb\ud588\uae30": 20, "\ubb34\uc0b0\ub420": 21, "\ubb34\uc5ed\ubd84\uc7c1\uacfc": [15, 22], "\ubb34\uc5ed\ubd84\uc7c1\uc774\ub77c\ub294": 22, "\ubb35\ubb35\ud788": 22, "\ubb36\uc5ec\uc9c0\ub294": [15, 17], "\ubb38": 104, "\ubb38\uc7a5": [104, 141], "\ubb38\uc7a5\ubd80\ud638": 141, "\ubb38\uc7a5\uc740": 104, "\ubb38\uc7a5\uc785\ub2c8\ub2e4": 104, "\ubb38\uc7ac\uc778": [16, 20], "\ubb38\uc81c\ub294": 20, "\ubb38\ud654\uacf5\ubcf4\ubd80\uc5d0": 16, "\ubb3c\uac00": 142, "\ubb3c\uac00\uc548\uc815\uacfc": 142, "\ubb3c\ub860": 20, "\ubb3c\ub958\ub300\ub780\uacfc": 15, "\ubbf8": [15, 16, 22, 141], "\ubbf8\uad6d": [17, 21], "\ubbf8\ub2c8\uc2a4\ud0c1": 16, "\ubbf8\ub798": [15, 17], "\ubbf8\ub798\ub97c": 16, "\ubbf8\ub798\uc5d0\uc14b": [15, 21], "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c": 15, "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c\uacfc": 21, "\ubbf8\ub798\uc5d0\uc14b\uc99d\uad8c\uc740": 21, "\ubbf8\ub9e4\uac01": [16, 20], "\ubbf8\ub9e4\uac01\uc774": [16, 20], "\ubbf8\uc548\ud588\uc5b4\uc694": 22, "\ubbf8\uc57c\ucf54\ud56d\uc5d0": 142, "\ubbf8\ucce4\ub2e4": 16, "\ubbf8\ud761": 18, "\ubbfc\ucca9\ud55c": 15, "\ubc00\uc811\ud558\uac8c": 20, "\ubc0f": [15, 17, 21, 124], "\ubc14\ub780\ub2e4": 16, "\ubc14\ub78c\uc774": 16, "\ubc14\uc774\uc624": 15, "\ubc14\uc774\uc624\uac00\uc2a4": 15, "\ubc14\uc774\uc624\ub294": 15, "\ubc14\uc774\uc624\ub514\uc824": 15, "\ubc15\uc0ac": [15, 21], "\ubc15\uc18c\uc5f0": 20, "\ubc18\ub3c4\uccb4": [15, 18, 22], "\ubc18\ub3c4\uccb4\uc0b0\uc5c5": 20, "\ubc18\uba74": 18, "\ubc18\uc601\ud55c\ub2e4": 17, "\ubc1b\uc558\ub2e4": 17, "\ubc1b\uc740": 17, "\ubc1c": 15, "\ubc1c\uad74": 15, "\ubc1c\uad74\ud558\uace0": 15, "\ubc1c\uad74\ud560": 15, "\ubc1c\uad74\ud574": 15, "\ubc1c\ub839\ud558\uc600\ub2e4": 142, "\ubc1c\ub9de\ucd94\uae30": 15, "\ubc1c\ub9de\ucdb0": 16, "\ubc1c\uc790\ucde8\uc774\uc790": 16, "\ubc1c\uc804": 18, "\ubc1c\ud45c\ud588\uc73c\uba70": 16, "\ubc1c\ud589\ub410\ub2e4": 16, "\ubc1c\ud589\ub418\uae30": 16, "\ubc1c\ud589\ub418\ub358": 16, "\ubc1c\ud589\ud55c": 16, "\ubc1c\ud589\ud588\ub2e4": 16, "\ubc1d\uc558\ub2e4": [15, 22], "\ubc1d\ud614": 142, "\ubc1d\ud614\ub2e4": [15, 16, 20, 142], "\ubc25": 131, "\ubc25\uc744": 131, "\ubc29": 146, "\ubc29\uc2dd": 18, "\ubc29\uc548\uc5d0": 146, "\ubc29\uc5d0": 146, "\ubc29\uc5ed\ubb3c\ud488\uc9c0\uc6d0\uae08": 15, "\ubc29\uc5ed\uc9c0\uc6d0\uae08": 15, "\ubc29\uc73c\ub85c": 146, "\ubc29\uc740": 146, "\ubc29\uc744": 146, "\ubc29\uce68\uc774\ub2e4": 15, "\ubc29\ud5a5\uc744": [15, 17], "\ubc30\ub2f9": 20, "\ubc30\uc6b0": 143, "\ubc30\uc6b0\uace0": 143, "\ubc30\uc6b0\ub294": 22, "\ubc30\uc7ac\ud6c8": 15, "\ubc30\ud130\ub9ac": [17, 21], "\ubc30\ud130\ub9ac\ub97c": 17, "\ubc31\uc2e0": 21, "\ubc31\uc2e0\uae30\uc5c5": 21, "\ubc88\uc9f8": 22, "\ubc8c\uc368\ubd80\ud130": 20, "\ubc95\uc778\uc138": 21, "\ubc97\uc5b4\ub0ac\ub2e4\ub294": 20, "\ubca0\ud2b8\ub0a8": 20, "\ubca4\ucc98\uae30\uc5c5\uac00\ub4e4\ud55c\ud14c": 22, "\ubca4\ucc98\uae30\uc5c5\ud611\ud68c": 17, "\ubcc0\uacbd\ud588\uc73c\uba70": 16, "\ubcc0\ub3d9\ud558\ub294": 17, "\ubcc0\uc218\ub85c": 22, "\ubcc0\ud638\uc0ac\ub294": 21, "\ubcc0\ud638\uc0ac\ub97c": 20, "\ubcc0\ud654": 18, "\ubcc0\ud654\uac00": 20, "\ubcc0\ud654\uc5d0": 15, "\ubcc0\ud654\ud560": 15, "\ubcc4\uc138\ud558\uba74\uc11c": 20, "\ubcd1\ud589": 142, "\ubcf4": 21, "\ubcf4\ub0b4\uc918": 141, "\ubcf4\ub2c8": 20, "\ubcf4\ub984": 15, "\ubcf4\uc600\ub2e4": 20, "\ubcf4\uc720\ud55c": 20, "\ubcf4\uc774\uace0": 20, "\ubcf4\uc778\ub2e4": 20, "\ubcf4\uc870": 15, "\ubcf4\ud1b5\uc8fc": 15, "\ubcf4\ud5d8\uc5c5\ubc95": 20, "\ubcf5\uc0ac": 95, "\ubcf5\uc7a1\ud55c": 20, "\ubcf8\uaca9\ud654\ub2e4": 20, "\ubcf8\uaca9\ud654\ud558\uba74\uc11c": 16, "\ubd24\ub2e4": [15, 20], "\ubd80\ub044\ub7fd\uace0": 22, "\ubd80\ub2f4\ub960\uc740": 21, "\ubd80\ub2f4\uc774": [16, 20], "\ubd80\ubb38": 22, "\ubd80\uc0ac": 141, "\ubd80\uc591": 20, "\ubd80\uc778": 20, "\ubd80\uc7ac": 18, "\ubd80\ud638": 141, "\ubd80\ud68c\uc7a5": 20, "\ubd80\ud68c\uc7a5\uc740": [16, 21], "\ubd80\ud68c\uc7a5\uc758": 20, "\ubd81\ubbf8\ub098": 20, "\ubd81\ubbf8\uc9c0\uc5ed": 15, "\ubd84\uc0ac": [17, 21], "\ubd84\uc11d": 141, "\ubd84\uc11d\uc758\uacac": 124, "\ubd84\uc11d\uc774\ub2e4": 20, "\ubd84\uc11d\ud55c": [15, 17], "\ubd84\uc57c": [15, 21], "\ubd84\uc57c\uc5d0\uc11c": 15, "\ubd84\uc57c\uc5d0\uc11c\ub3c4": 21, "\ubd84\uc704\uae30\uc5d0": [16, 20], "\ubd84\ud560": 20, "\ubd84\ud560\ud560": 21, "\ubd88\uac00\ud53c\ud560": 20, "\ubd88\uace0": 16, "\ubd88\uacf5\uc815": [15, 17, 18, 20, 22, 23], "\ubd88\uacfc\ud55c": 18, "\ubd88\uaddc\uce59": 141, "\ubd88\ub9ac\ub294": 20, "\ubd88\ud544\uc694": 17, "\ubd88\ud655\uc2e4\uc131": 17, "\ubd88\ud655\uc2e4\uc131\uc744": 20, "\ube14\ub85d": 17, "\ube14\ub85d\uc5d0": 17, "\ube14\ub85d\uc774": 17, "\ube44": 17, "\ube44\ub86f\ud558\uc5ec": 142, "\ube44\uc5b4\ub9cc": 17, "\ube44\uc6a9\ubd80\ub2f4": 21, "\ube44\uc804\uacf5\uc790\ub4e4\ub3c4": 17, "\ube45": 22, "\ube45\ub370\uc774\ud130": 15, "\ube45\ub370\uc774\ud130\ub97c": 15, "\ube60\ub974\uac8c": 15, "\ube60\ub97c\uc218\ub85d": 17, "\ube60\uc9c4": 21, "\ubfd0\ub9cc": [16, 17, 20], "\uc0ac": [20, 141], "\uc0ac\uace0": [16, 20], "\uc0ac\uacfc": 131, "\uc0ac\uadf8": 16, "\uc0ac\ub0b4": 16, "\uc0ac\ub791": 141, "\uc0ac\ub791\ud558\ub2c8": 141, "\uc0ac\ub791\ud558\ub2e4": 141, "\uc0ac\ubcf4": 16, "\uc0ac\ubcf4\uac00": 16, "\uc0ac\ubcf4\ub294": 16, "\uc0ac\ubcf4\ub3c4": 16, "\uc0ac\ubcf4\ub85c": 16, "\uc0ac\ubcf4\ub97c": 16, "\uc0ac\ubcf4\uc5d0": 16, "\uc0ac\ubcf4\uc5d0\ub3c4": 16, "\uc0ac\uc5c5": 17, "\uc0ac\uc5c5\uad6c\uc870\uc640\ub3c4": 20, "\uc0ac\uc5c5\ubd80": 17, "\uc0ac\uc5c5\ubd80\ubb38\uc778": 21, "\uc0ac\uc5c5\uc744": 17, "\uc0ac\uc5c5\uc774\ub77c": 17, "\uc0ac\uc5c5\ud611\ub825": 21, "\uc0ac\uc5c5\ud654": 18, "\uc0ac\uc678\uc774\uc0ac": 20, "\uc0ac\uc678\uc774\uc0ac\ub85c": 20, "\uc0ac\uc6a9": 15, "\uc0ac\uc6a9\uc790": 18, "\uc0ac\uc7a5": 15, "\uc0ac\uc7a5\uc740": 17, "\uc0ac\uc9c4": [15, 16, 20, 22], "\uc0ac\ucd94\uc704": 20, "\uc0ac\ud68c\uacc4": 17, "\uc0ac\ud68c\uacf5\ud5cc": [15, 17, 18, 20, 21, 22, 23], "\uc0ac\ud68c\uc801": 16, "\uc0b0\uc5c5": 15, "\uc0b0\uc5c5\uc7ac\ud574": 18, "\uc0b0\uc5c5\ud1b5\uc0c1\uc790\uc6d0\ubd80\ub294": 21, "\uc0b0\uc5c5\ud3d0\uae30\ubb3c": 15, "\uc0b0\uc5c5\ud601\uba85\uacfc": 15, "\uc0b0\ucd9c": 17, "\uc0b0\ucd9c\uc758": 17, "\uc0b0\ud559\uc7a5\ud559\uc0dd": 15, "\uc0b0\ud559\ud611\ub825": 15, "\uc0b0\ud559\ud611\ub825\uc13c\ud130": 15, "\uc0b0\ud559\ud611\ub825\uc13c\ud130\ub294": 15, "\uc0b0\ud559\ud611\ub825\uc744": 15, "\uc0b6\ud130\uc5d0\uc11c": 22, "\uc0bc\uc131": 20, "\uc0bc\uc131sd": 20, "\uc0bc\uc131sdi\ub294": 17, "\uc0bc\uc131\uacfc": [15, 22], "\uc0bc\uc131\uadf8\ub8f9": 20, "\uc0bc\uc131\uadf8\ub8f9\uc758": 20, "\uc0bc\uc131\uadf8\ub8f9\uc8fc": 20, "\uc0bc\uc131\ubb3c\uc0b0": 20, "\uc0bc\uc131\ubc14\uc774\uc624\ub85c\uc9c1\uc2a4\uac00": 21, "\uc0bc\uc131\uc0dd\uba85": 20, "\uc0bc\uc131\uc0dd\uba85\ubc95": 20, "\uc0bc\uc131\uc804\uc790": [18, 20, 124], "\uc0bc\uc131\uc804\uc790\uac00": 15, "\uc0bc\uc131\uc804\uc790\ub294": 20, "\uc0bc\uc131\uc804\uc790\uc11c\ube44\uc2a4": 17, "\uc0bc\uc131\uc804\uc790\uc640": [20, 21], "\uc0bc\uc131\uc99d\uad8c": 20, "\uc0c1\ub300\uc801\uc73c\ub85c": 15, "\uc0c1\ubc18\uae30": 20, "\uc0c1\uc0dd": [15, 17, 18, 20, 22, 23], "\uc0c1\uc18d": 20, "\uc0c1\uc18d\uc138": 20, "\uc0c1\uc18d\uc138\ub97c": 20, "\uc0c1\uc18d\uc138\ub9cc": 20, "\uc0c1\uc2b9": 15, "\uc0c1\uc2b9\uc744": 20, "\uc0c1\uc2b9\uc7a5": 20, "\uc0c1\uc2b9\ud3ed\uc744": 15, "\uc0c1\uc6a9\ud654": 18, "\uc0c1\uc7a5\uc801\uaca9\uc131": 16, "\uc0c1\ud0dc\uc5d0": 21, "\uc0c1\ud488\uc774\ub2e4": 16, "\uc0c1\ud669": [17, 142], "\uc0c8": 22, "\uc0c8\ub85c\uc6b4": 17, "\uc0c8\ubcbd": 142, "\uc0c8\ud574\uac00": [15, 22], "\uc0c8\ud574\uc5d0": 15, "\uc0d8": 104, "\uc0d8\ud50c": 104, "\uc0dd\uac01\ud55c": 17, "\uc0dd\uaca8\ub09c": 17, "\uc0dd\uc0b0": [15, 20], "\uc0dd\uc0b0\uacfc": 20, "\uc0dd\uc0b0\uae30\uc220": 17, "\uc0dd\uc0b0\uc740": 20, "\uc0dd\uc0b0\uc758": 21, "\uc0dd\ud65c\ud3d0\uae30\ubb3c": 15, "\uc11c\ubc84\uc5d0": 141, "\uc11c\ube44\uc2a4": 18, "\uc11c\uc18c\uc815": 15, "\uc11c\uc220": 141, "\uc11c\uc6b8": [16, 21, 22], "\uc11c\uc6b8\ub300": 15, "\uc11c\uc6b8\ub300\ub294": 15, "\uc11c\uc6b8\ub300\uc640": 15, "\uc11c\uc6b8\uc2dc": 16, "\uc11d": [15, 21], "\uc120": [15, 16], "\uc120\ub3c4\ud560": 15, "\uc120\uc21c\ud658": 20, "\uc120\uc5b4\ub9d0\uc5b4\ubbf8": 141, "\uc120\uc804": 21, "\uc120\uc815\ud574": 15, "\uc120\uc9c0\uae09": 15, "\uc120\uc9c4\uad6d": 20, "\uc120\ud0dd\ud55c": [16, 20], "\uc120\ud3ec\ud558\uae30": 15, "\uc124\ub9bd": [15, 17], "\uc124\ub9bd\ub41c": 21, "\uc124\uba85": 22, "\uc12c\uc5d0\uc11c": 142, "\uc131": 16, "\uc131\uacf5": 17, "\uc131\uacfc\ub294": 16, "\uc131\uc7a5": [15, 17], "\uc131\uc7a5\uc138": 15, "\uc131\uc7a5\uc774": 21, "\uc131\uc7a5\ud3ed\uc740": 20, "\uc131\uc7a5\ud558\uace0": 15, "\uc131\ud615\ud0c4": 15, "\uc138": 104, "\uc138\uacc4": [15, 17, 20, 21], "\uc138\uacc4\ub294": 22, "\uc138\uacc4\uc801\uc778": [15, 20], "\uc138\ub300": 18, "\uc138\uc0c1": 15, "\uc138\uc694": 143, "\uc138\ud0c1\uae30": [15, 22], "\uc13c\uc11c": 18, "\uc148\ubc95\uc774": 20, "\uc167\ub2e4\uc6b4\uc73c\ub85c": 20, "\uc18c\uaddc\ubaa8": 142, "\uc18c\ub9c8\ud56d\uc5d0": 142, "\uc18c\ube44\ub294": 20, "\uc18c\ube44\uc790": [15, 17, 18, 20, 22, 23], "\uc18c\uc1a1": [15, 17, 18, 20, 22, 23], "\uc18c\uc2dd\uae4c\uc9c0": [16, 20], "\uc18c\uc2dd\uc5d0": [16, 20], "\uc18c\uc561\uc73c\ub85c": 16, "\uc18c\uc758": 15, "\uc18c\ud1b5\uc218\ub2e8\uc774\ub2e4": 16, "\uc18c\ud1b5\uc5d0": 16, "\uc18c\ud1b5\uc758": 16, "\uc18c\ud504\ud2b8\uc6e8\uc5b4": 15, "\uc18c\ud615": 15, "\uc18d": 17, "\uc18d\ub3c4\uac00": 17, "\uc18d\ub3c4\ub294": [15, 17], "\uc18d\ub3c4\ub97c": 15, "\uc18d\ub3c4\uc758": 17, "\uc18d\ucd9c\ud558\uace0": [16, 20], "\uc190\uc2e4\ubcf4\uc0c1": 15, "\uc190\uc7a1\uace0": 15, "\uc1a1\uc2e0\ub41c\ub2e4": 17, "\uc1fc\ud551": [16, 20], "\uc218": [15, 18, 20, 22], "\uc218\uae09": 20, "\uc218\ub2e8\uc774\ub2e4": 16, "\uc218\ub825": 15, "\uc218\ub825\ubc1c\uc804": 15, "\uc218\ub85d\ub410\ub2e4": 16, "\uc218\ub97c": 17, "\uc218\uc0ac": 141, "\uc218\uc18c\ub97c": 21, "\uc218\uc18c\uc804\uae30\ucc28": [16, 20], "\uc218\uc218\ub8cc": 21, "\uc218\uc2dd\uc5b8": 141, "\uc218\uc5b5": 17, "\uc218\uc694": [15, 17, 20], "\uc218\uc694\uac00": 17, "\uc218\uc694\uc608": [16, 20], "\uc218\uc775\uc744": 17, "\uc218\uc900": 18, "\uc218\ucc9c\ub9cc": 17, "\uc218\ucd9c": [16, 20], "\uc218\ucd9c\uc774": 16, "\uc218\ud589\ud558\uace0": 15, "\uc218\ud589\ud558\ub294": 15, "\uc218\ud589\ud560": 15, "\uc21c\uc11c\ub294": 17, "\uc21c\uc218": 95, "\uc220\ubd80": 141, "\uc2a4": 104, "\uc2a4\uc2a4\ub85c": 15, "\uc2a4\ud2b8": 104, "\uc2a4\ud338\uacfc": 16, "\uc2a4\ud3ec\uce20\uc720\ud2f8\ub9ac\ud2f0\ucc28\ub7c9": 22, "\uc2a4\ud3ec\uce20\uce74": 95, "\uc2a4\ud53c\ud2b8\uc640": 17, "\uc2b5\ub2c8\ub2e4": 143, "\uc2b9\uc778": 21, "\uc2b9\uc9c4": 17, "\uc2dc": 15, "\uc2dc\uac00\ucd1d\uc561": 20, "\uc2dc\uacc4\ubc29\ud5a5\uc73c\ub85c": 20, "\uc2dc\uacc4\uc81c\ub85c": 21, "\uc2dc\uae30\ub97c": 21, "\uc2dc\ub098\ub9ac\uc624\ubcc4": 20, "\uc2dc\ub0b4": 16, "\uc2dc\ub3c4\uc5d0": 16, "\uc2dc\uba58\ud2b8": 15, "\uc2dc\uc2a4\ud15c\uc758": 15, "\uc2dc\uc791": 18, "\uc2dc\uc791\uc810\uc5d0": 20, "\uc2dc\uc791\ud588\uc73c\uba70": 16, "\uc2dc\uc7a5": [16, 18, 20], "\uc2dc\uc7a5\uc5d0": [16, 17, 20], "\uc2dc\uc7a5\uc5d0\uc11c": [15, 22], "\uc2dc\uc7a5\uc5d0\uc11c\ub294": 20, "\uc2dc\uc7a5\uc740": 22, "\uc2dc\uc7a5\uc774": 15, "\uc2dc\uc808\uc778": 16, "\uc2dc\ucf1c": 15, "\uc2dc\ud589\ud574\uc624\ub358": 16, "\uc2dd\ud488\uc758\uc57d\ud488\uc548\uc804\ucc98\uac00": 21, "\uc2e0": 15, "\uc2e0\uace0": 20, "\uc2e0\uace0\uac00": 20, "\uc2e0\uace0\uc11c": 17, "\uc2e0\uaddc": [15, 17], "\uc2e0\ub144\uae30\ud68d": 15, "\uc2e0\ub144\uc0ac\ub97c": 15, "\uc2e0\ub2e4": 146, "\uc2e0\ub3d9\uc900": 20, "\uc2e0\uc0c1\ud6c8": 15, "\uc2e0\uc124": 15, "\uc2e0\uc124\ud558\uace0": 15, "\uc2e0\uc57d\ud6c4\ubcf4\ubb3c\uc9c8": 15, "\uc2e0\uc5d0\ub108\uc9c0\ub294": 15, "\uc2e0\uc784": 20, "\uc2e0\uc7ac\uc0dd\uc5d0\ub108\uc9c0": 18, "\uc2e0\uc885": 15, "\uc2e0\uccad\uc11c\ub97c": [16, 20], "\uc2e0\ucd95\ub144": 15, "\uc2e0\ud559\ucca0": 21, "\uc2e0\ud55c\uae08\uc735": 20, "\uc2e0\ud55c\uae08\uc735\uc758": 20, "\uc2e0\ud55c\uae08\uc735\uc9c0\uc8fc": 15, "\uc2e0\ud55c\uc740\ud589": 15, "\uc2e4\uc2dc": 15, "\uc2e4\uc801": 20, "\uc2e4\uc801\uc774": 20, "\uc2e4\uc815": 18, "\uc2e4\uc81c": 17, "\uc2e4\uc9c8\uc2ec\uc0ac": 16, "\uc2e4\ud328": 18, "\uc2e4\ud589": 17, "\uc2ec\ud654": 17, "\uc2f6\uc5b4\uc11c": 95, "\uc4f0\ub808\uae30": 15, "\uc4f4": 95, "\uc544": 141, "\uc544\ub2c8\ub77c": [16, 17, 20], "\uc544\ubb34\ub3c4": [16, 20], "\uc544\ubc84\uc9c0": 146, "\uc544\ubc84\uc9c0\uac00": 146, "\uc544\ubc84\uc9c0\uac00\uac00\ubc29\uc744\ub4e4\uace0\uac00\uc2e0\ub2e4": 146, "\uc544\ubc84\uc9c0\uac00\ubc29\uc5d0\ub4e4\uc5b4\uac00\uc2e0\ub2e4": 146, "\uc544\ubc84\uc9c0\ub294": 146, "\uc544\uc2dc\uc544\uacbd\uc81c": [15, 21], "\uc544\uc2dc\uc544\ub098\ud56d\uacf5": 21, "\uc544\uc8fc\uacbd\uc81c": [16, 20], "\uc544\uc9c1": [18, 20], "\uc545\ud654\ub41c": [16, 20], "\uc548": [20, 104], "\uc548\ub155": 143, "\uc548\ub155\ud558\uc138\uc694": [104, 142, 143], "\uc548\ub4dc\ub85c\uc774\ub4dc": 18, "\uc548\ubcd1\ub355": 16, "\uc548\uc5d0": [15, 17], "\uc548\uc804\uad00\ub9ac": [15, 17, 18, 20, 22, 23], "\uc548\uc815": 142, "\uc548\ud568": 18, "\uc54a\uace0": 16, "\uc54a\uc558\ub2e4": 142, "\uc54c\ub798\uc2a4\uce74": 142, "\uc54c\ub824\uc84c\ub2e4": 20, "\uc54c\ub9ac\ub294": 16, "\uc55e\uc11c": [15, 17], "\uc55e\uc11c\ub098\uac00\ub294": 21, "\uc55e\uc904": 21, "\uc560\ub110\ub9ac\uc2a4\ud2b8\ub294": 20, "\uc560\ud50c": 18, "\uc560\ud50c\ub9ac\ucf00\uc774\uc158": 17, "\uc561\uc218\uac00": 20, "\uc561\uc815\ud45c\uc2dc\uc7a5\uce58": 15, "\uc571": 16, "\uc57c\uae30": 17, "\uc57d": [15, 21, 142], "\uc57d\uc18d\ud588\ub2e4": 15, "\uc591\uadf9\uc81c": 17, "\uc591\ub300\uadfc": 17, "\uc591\uc0c1\uc744": 20, "\uc591\uc131": 15, "\uc591\uc131\ud558\uae30": 15, "\uc591\uc2ec\uc801\uc778": 17, "\uc591\uce21\uc740": 15, "\uc5b4": 141, "\uc5b4\uac04": 141, "\uc5b4\ub824\uc6b4": 21, "\uc5b4\ub9d0": 141, "\uc5b4\ub9d0\uc5b4\ubbf8": 141, "\uc5b4\ubbf8": 141, "\uc5b8": 141, "\uc5bd\ud600": 20, "\uc5c4\uaca9\ud55c": 20, "\uc5c5\uacc4": [15, 22], "\uc5c5\uacc4\uc5d0": 21, "\uc5c5\ubb34": 15, "\uc5c5\ubb34\ud611\uc57d": 21, "\uc5c5\uc885\ub3c4": [15, 17], "\uc5c5\uc885\ubcc4": [15, 22], "\uc5c5\uc885\ubcc4\ub85c": [16, 20], "\uc5c5\uc885\uc740": [16, 20], "\uc5c5\uccb4\uc758": [15, 22], "\uc5c6\ub294": 17, "\uc5c6\ub2e4": 17, "\uc5c6\uc5b4": 17, "\uc5c6\uc774": 17, "\uc5c8": 141, "\uc5d0": [15, 16, 17, 18, 20, 21, 142, 146], "\uc5d0\uac8c": [15, 17], "\uc5d0\ub108\uc9c0\uacbd\uc81c\uc5f0\uad6c\uc6d0": 15, "\uc5d0\ub108\uc9c0\ubd80\ubb38": 21, "\uc5d0\ub108\uc9c0\uc6d0": [15, 17], "\uc5d0\uc11c": [15, 18, 21, 142], "\uc5d0\uc11c\uc758": 17, "\uc5d0\uce58\uc5d0\ud504\uc54c": 16, "\uc5ec\uae30\uc5d0": 20, "\uc5ec\ub825\uc740": 17, "\uc5ec\uc131": 20, "\uc5ec\ud30c\ub97c": [16, 20], "\uc5ed\ub3d9\uc801\uc774\uba74\uc11c": 22, "\uc5ed\ub7c9\uc744": 15, "\uc5ed\uc0ac\uc801": 20, "\uc5ed\ud560": 21, "\uc5ed\ud560\uc744": 16, "\uc5f0": [16, 20], "\uc5f0\uad6c": [17, 18], "\uc5f0\uad6c\uac1c\ubc1c": 15, "\uc5f0\ub8cc": 15, "\uc5f0\ub8cc\uc720": 15, "\uc5f0\ub8cc\uc804\uc9c0\uc640": 15, "\uc5f0\ubd80\uc5f0\ub0a9\uc81c\ub3c4\ub97c": 20, "\uc5f0\uc548": 142, "\uc5f0\ud569": 16, "\uc5f0\ud569\ub274\uc2a4": 16, "\uc5f4": [15, 21], "\uc5f4\ub3c4\uac00": 142, "\uc5f4\ub9ac\ub294": 21, "\uc5f4\ud48d\uc774": 16, "\uc601\uad6d\ud45c\uc900\ud611\ud68c": 21, "\uc601\ubb38": 22, "\uc601\uc5c5\uc774\uc775": 22, "\uc601\uc5c5\uc774\uc775\uc740": 20, "\uc601\uc5c5\uc774\uc775\uc774": 20, "\uc601\uc5ed\uc5d0\uc11c": 15, "\uc601\uc785\ud560": 20, "\uc601\uc791\ubb38": 22, "\uc601\ud5a5\uc744": 16, "\uc608\uace0": 17, "\uc608\uc0c1": 18, "\uc608\uc0c1\ub41c\ub2e4": 20, "\uc608\uc815\uc774\ub2e4": [15, 20], "\uc624": 22, "\uc624\ub294": 21, "\uc624\ub298\ubd80\ud130": 22, "\uc624\ub974": 141, "\uc624\ub978\ucabd": 21, "\uc624\uc2a4\ud15c": 16, "\uc624\uc2a4\ud15c\uc784\ud50c\ub780\ud2b8": 16, "\uc624\uc804": 15, "\uc624\ud53c\uc2a4": 21, "\uc624\ud6c4": [16, 21, 142], "\uc628": 22, "\uc628\ub77c\uc778": 16, "\uc62c": 141, "\uc62c\ub77c": 141, "\uc62c\ud574": [15, 20], "\uc640": 18, "\uc640\uc774\ube0c\ub85c": 18, "\uc65c": 17, "\uc678": 17, "\uc678\uad6d\uc778\uacfc": 20, "\uc678\uc2dd\uc5c5\uacc4\uc5d0": 16, "\uc678\ud658\uc704\uae30\ub294": 16, "\uc67c\ucabd": 20, "\uc694": 104, "\uc694\ub3d9\uce58\uace0": 20, "\uc694\uc778": 20, "\uc694\uc778\ub4e4\uc774": [15, 17], "\uc694\uccad": 15, "\uc6a9\uc5b8": 141, "\uc6b0\ub4dc": 15, "\uc6b0\ub824\ub3c4": 15, "\uc6b0\ub9ac\uae08\uc735": 20, "\uc6b0\ub9ac\uae08\uc735\uc740": 20, "\uc6b0\ub9ac\ub098\ub77c": [15, 16], "\uc6b0\ub9ac\ub098\ub77c\ub294": 142, "\uc6b0\uc544": 22, "\uc6b0\ud06c\ub77c": 16, "\uc6b4\uc218\uc7a5\ube44": [16, 20], "\uc6b4\uc218\ucc3d\uace0": [16, 20], "\uc6b4\uc601": 15, "\uc6b4\uc601\ub418\ub294": 20, "\uc6b4\uc601\ub41c\ub2e4": 15, "\uc6b4\uc601\ube44": 17, "\uc6b4\uc601\ud558\ub294": 15, "\uc6b4\uc6a9": 21, "\uc6b4\uc6a9\ud558\ub294": [16, 20], "\uc6b8\uc0b0": 21, "\uc6c0\uc9c1\uc784": 20, "\uc6c0\uc9c1\uc784\uc744": 20, "\uc6cc\ub099": 20, "\uc6cc\uc2f1\ud134": 21, "\uc6d0\ubb38": 141, "\uc6d0\uc5d0\uc11c": 17, "\uc6d0\uc744": 17, "\uc6d0\uc790\ub825\ubc1c\uc804": 18, "\uc6d0\uccad": 17, "\uc6d0\ud574\ub85c": 142, "\uc6d0\ud654": 20, "\uc6d4\uac04": 16, "\uc6d4\uac04\uc73c\ub85c": 16, "\uc704": [104, 142], "\uc704\uae30": 18, "\uc704\ubd80\ud130": 20, "\uc704\uc6d0\uc7a5": 15, "\uc704\uc7a5": 17, "\uc704\ud55c": [16, 17, 20, 104], "\uc704\ud574": [15, 16, 17, 20], "\uc704\ud574\uc11c": 15, "\uc704\ud5d8": [15, 17], "\uc704\ud5d8\uc131": 17, "\uc720\uac00\uac00": 15, "\uc720\ub300\uae38": 16, "\uc720\ub3d9\uc131\ubcf4\ub2e4\ub294": 20, "\uc720\ub7fd": 21, "\uc720\ub7fd\ubc1c": 20, "\uc720\uc758": 142, "\uc720\uc758\ud558\ub294": 142, "\uc720\uc8fc": 15, "\uc720\uc9c0\ud558\ub294": 17, "\uc720\ud1b5": 22, "\uc720\ud1b5\uae30\uc5c5": 22, "\uc720\ud1b5\ub300\uc804": 22, "\uc721\uc131\uacfc": 15, "\uc721\uc131\ud558\ub294": 15, "\uc73c\ub85c": [17, 18, 20, 22, 146], "\uc73c\ub85c\ub9cc": 17, "\uc73c\ub85c\uc11c": 17, "\uc740": [15, 16, 17, 18, 104, 141, 146], "\uc740\ud589": 21, "\uc744": [15, 16, 17, 21, 131, 141, 142, 146], "\uc751": 17, "\uc758": [15, 17, 18, 20, 21, 142], "\uc758\ubb38\ud615": 141, "\uc758\ubbf8": 141, "\uc758\ud574": 17, "\uc774": [15, 16, 17, 18, 21, 104, 141, 146], "\uc774\uac74\ud76c": 20, "\uc774\uaca8\ub0b4\uace0": [16, 20], "\uc774\uaca8\ub0b4\ub9ac\ub77c\ub294": 15, "\uc774\uaddc\ud638": 16, "\uc774\ub0a0": 16, "\uc774\ub2e4": 17, "\uc774\ub300\ub85c\ub9cc": 15, "\uc774\ub3d9\uc5d0": 17, "\uc774\ub3d9\ucc2c": 16, "\uc774\ub3d9\ud1b5\uc2e0": 18, "\uc774\ub3d9\ud1b5\uc2e0\ub9dd": 18, "\uc774\ub3d9\ud1b5\uc2e0\uc0ac": 18, "\uc774\ub3d9\ud1b5\uc2e0\uc0ac\uc5c5\uc790": 18, "\uc774\ub77c\uba70": [16, 20], "\uc774\ub904\uc9c8": 20, "\uc774\ub974": 141, "\uc774\ub974\uae30\uae4c\uc9c0": 16, "\uc774\ub974\ub7ec": 141, "\uc774\ub978\ubc14": [16, 20], "\uc774\ub97c": 15, "\uc774\ub984\uc740": 16, "\uc774\ub9c8\ud2b8\uc758": 22, "\uc774\ubbf8": 21, "\uc774\uc0ac\uc758": 124, "\uc774\uc0ac\ud68c\ub97c": 17, "\uc774\uc0c1": [15, 18, 20, 142], "\uc774\uc0c1\uc758": 15, "\uc774\uc18c\uc740": 21, "\uc774\uc288": 15, "\uc774\uc5b4": 16, "\uc774\uc5d0": [16, 20], "\uc774\uc640": 21, "\uc774\uc6c5\uc5f4": 16, "\uc774\uc6d0\ub9cc": 16, "\uc774\uc74c\ud504\ub77c\uc774\ube57\uc5d0\ucffc\ud2f0": 21, "\uc774\uc775": 20, "\uc774\uc775\uc5d0": 17, "\uc774\uc775\uc744": 17, "\uc774\uc7ac\uc6a9": 20, "\uc774\uc804\uc744": 20, "\uc774\uc815\ud55c": 17, "\uc774\ucc3d\ud5cc": 21, "\uc774\ud2c0\uac04": 17, "\uc774\ud6c4": [15, 21], "\uc778": [15, 17, 18], "\uc778\uacf5\uc9c0\ub2a5": [15, 18], "\uc778\ub3c4\uac00": 21, "\uc778\ub825": 15, "\uc778\ub825\uc720\ucd9c": 15, "\uc778\ubb38": 17, "\uc778\uc0ac\ub3cc": 15, "\uc778\uc1c4": 16, "\uc778\uc218\uc804\uc774": 21, "\uc778\uc7ac": 15, "\uc778\uc7ac\ub97c": 15, "\uc778\uc801": 21, "\uc778\uc801\uc790\ubcf8": 18, "\uc778\uc99d\ud6c4": 21, "\uc778\ud130\ubdf0": 15, "\uc778\ud130\ubdf0\ub3c4": 16, "\uc778\ud154": 18, "\uc778\ud55c": 15, "\uc77c": 15, "\uc77c\uac00\uac00": 20, "\uc77c\uac00\uc758": 20, "\uc77c\uae30\uc7a5": 16, "\uc77c\ubcf8": [16, 142], "\uc77c\ubcf8\uae30\uc0c1\uccad\uacfc": 142, "\uc77c\ubd80": [17, 20], "\uc77c\uc0c1\ud654\ub41c": 15, "\uc77c\uc5b4\ub098\uae30": 18, "\uc77c\uc5b4\ub098\uae30\uc77c\uc5b4\ub098\uae30": 18, "\uc784\uc0b0\uc5f0\ub8cc": 15, "\uc784\uc2dc\uc801\uc73c\ub85c": 16, "\uc784\uc9c1\uc6d0\ub4e4\uc744": 15, "\uc785": 104, "\uc785\ub2c8\ub2e4": 104, "\uc785\uc548": 17, "\uc785\uc548\uc790": 17, "\uc785\uc99d\ud558\uae30\ub85c": 17, "\uc787": 141, "\uc787\uce58": 15, "\uc788": 143, "\uc788\ub294": [15, 16, 17], "\uc788\ub2e4": [15, 16, 20, 146], "\uc788\ub2e4\ub294": 20, "\uc788\uc2b5\ub2c8\ub2e4": 143, "\uc788\uc5b4": [15, 20], "\uc788\uc5b4\ub3c4": 17, "\uc788\uc5c8\ub2e4": 146, "\uc788\uc744": 15, "\uc788\uc74c": 18, "\uc790\uad6d": 21, "\uc790\uae08\uc744": [16, 20], "\uc790\uae0d\uc2ec\uc744": 16, "\uc790\ub140\ub4e4\uc774": 20, "\uc790\ub3d9\ucc28": 22, "\uc790\ub8cc": 17, "\uc790\ubb38": 17, "\uc790\ubcf8\uae08": 21, "\uc790\uc0b0\uad00\ub9ac": 21, "\uc790\uc0b0\ud615\uc131\uc744": 16, "\uc790\uc5f0\uc5b4": 143, "\uc790\uc6d0": 17, "\uc790\uccb4": 17, "\uc790\ucde8\ub97c": 16, "\uc791\uc544\ub3c4": 20, "\uc791\uc5c5": 17, "\uc791\uc6a9": 18, "\uc791\uc6a9\ud560": 20, "\uc798\ubabb": 17, "\uc7a1": 141, "\uc7a1\ub2e4": 141, "\uc7a5": 104, "\uc7a5\uad00": 15, "\uc7a5\uad00\uc774": 15, "\uc7a5\uae30\uc801\uc73c\ub85c": 17, "\uc7a5\ub0a8": 16, "\uc7a5\ub144\uce35": [16, 20], "\uc7a5\uc740": 104, "\uc7a5\ucc29\ud55c": 17, "\uc7ac": 16, "\uc7ac\ub7c9\uc131\uc5d0": [15, 17], "\uc7ac\ubb34\uad6c\uc870\ub3c4": [15, 17], "\uc7ac\uc0dd\uc5d0\ub108\uc9c0\ub294": 15, "\uc7ac\uc0dd\uc5d0\ub108\uc9c0\uc758": [15, 17], "\uc7ac\uc6d0": 20, "\uc7ac\uc815\ube44\ub85c": 17, "\uc7ac\uc815\ud655\uc7a5": 20, "\uc7ac\ud574": [15, 17, 18, 20, 22, 23], "\uc800": 104, "\uc800\uae08\ub9ac": 20, "\uc800\ub294": [133, 142], "\uc800\uc7a5": 15, "\uc800\uc7a5\ud574\uc11c": 141, "\uc801": 17, "\uc801\uc6a9\ud560": 15, "\uc804": [15, 20, 21, 22], "\uc804\uac1c\ud558\uace0": 17, "\uc804\uad6d": 16, "\uc804\uae30": 95, "\uc804\uae30\uc804\uc790": [16, 20], "\uc804\uae30\ucc28": 21, "\uc804\ub0a0\ubd80\ud130": 17, "\uc804\ub2f4\uc870\uc9c1\uc744": 15, "\uc804\ub77d\uc801": 21, "\uc804\ub7b5\ubd80\ubb38": 21, "\uc804\ub7b5\uc801": 21, "\uc804\ub9dd": [15, 18, 22], "\uc804\ub9dd\ub418\uace0": 15, "\uc804\ub9dd\uc744": 15, "\uc804\ub9dd\uc774": 20, "\uc804\ub9dd\uc774\ub2e4": 20, "\uc804\uba74\uc801\uc778": 20, "\uc804\ubb34\ub294": 16, "\uc804\ubb38": 20, "\uc804\ubd80": 21, "\uc804\uc138\uacc4": 18, "\uc804\uc5ed\uc5d0\uc11c": 142, "\uc804\uc6a9": 18, "\uc804\uc6a9\ucc28\ub85c": [16, 20], "\uc804\uc778": [15, 22], "\uc804\uc790\uc5c5\uacc4\ub294": 20, "\uc804\uc7c1": 18, "\uc804\uc9c0\uc0ac\uc5c5\ubd80\ubb38\uc740": 17, "\uc804\uccb4": [15, 17], "\uc804\ud1b5": [15, 17], "\uc804\ud30c\ub418\uba74\uc11c": 142, "\uc804\ud574\uc9c0\uba74\uc11c": [16, 20], "\uc804\ud654": 15, "\uc804\ud658": 15, "\uc804\ud658\uc5d0": 15, "\uc804\ud658\uc774\ub77c\ub294": 15, "\uc804\ud658\ud588\ub2e4": 16, "\uc804\ud6c4\ud558\uc5ec": 22, "\uc808\ubc18\ubc16\uc5d0": 20, "\uc810\ub3c4": 20, "\uc810\uc2ec": 141, "\uc810\uc744": 17, "\uc810\uccd0\ubcf8\ub2e4": 20, "\uc811\uadfc": 17, "\uc815\uae30": 20, "\uc815\uae30\uac04\ud589\ubb3c": 16, "\uc815\ub3c4\ub85c": 15, "\uc815\uba74\uc2b9\ubd80\ub85c": 15, "\uc815\ubcf4": [16, 17], "\uc815\ubcf4\uacf5\uc2dc": 18, "\uc815\ubcf4\ud1b5\uc2e0\uae30": 16, "\uc815\ubd80": 18, "\uc815\ubd80\uac00": 16, "\uc815\ubd80\ub294": 15, "\uc815\uc0c1\ud654": 20, "\uc815\uc0c1\ud654\ub294": 20, "\uc815\uc0c1\ud68c\uc758": 21, "\uc815\uc138\ud76c": 21, "\uc815\uc81c": 15, "\uc815\ucc45": [17, 18, 20, 142], "\uc815\ucc45\uae08\uc735": 16, "\uc81c": 15, "\uc81c71\uc870\uc5d0\uc11c": [15, 17], "\uc81c\uac01\uac01": 22, "\uc81c\uacf5": [15, 17], "\uc81c\uae30\ud55c": 17, "\uc81c\ub124\uc2dc\uc2a4\uc758": 22, "\uc81c\ub3c4": 15, "\uc81c\ub3c4\ub97c": 15, "\uc81c\uc548": 15, "\uc81c\uc678": 15, "\uc81c\uc870": 17, "\uc81c\uc870\uc5c5\uc758": 21, "\uc81c\ucd9c\ud558\uba74": [16, 20], "\uc81c\ud488\uc744": 15, "\uc81c\ud638\ub97c": 16, "\uc870\ub2ec\uc2dc\uc7a5": 17, "\uc870\ub2ec\uccad": 17, "\uc870\ub825": 15, "\uc870\uc0ac": 141, "\uc870\uc120\uc774": 15, "\uc870\uc9c1": 17, "\uc870\uc9c1\uc73c\ub85c": 15, "\uc870\uce58": 15, "\uc870\ud604\uc900": 15, "\uc880": 141, "\uc885\uc774": 16, "\uc885\ud569\uc801": 17, "\uc88b\uc544": 20, "\uc88c\uc6b0\ud560": [15, 17], "\uc8fc\uac00": 20, "\uc8fc\uac00\uac00": [15, 20], "\uc8fc\ub825\uc0b0\uc5c5\uc778": 21, "\uc8fc\ubb38\ud588\ub2e4": 15, "\uc8fc\uc2dd": [16, 20], "\uc8fc\uc694": [15, 17, 21], "\uc8fc\uc758\ubcf4\uc640": 142, "\uc8fc\uc8fc": 17, "\uc8fc\uc8fc\uc640": 21, "\uc8fc\uc8fc\ud658\uc6d0": 18, "\uc8fc\ucd1d\uc5d0\uc11c": 20, "\uc8fc\ucd95\uc73c\ub85c": 16, "\uc904\uace7": 17, "\uc904\uc5b4\ub4e4\uace0": 20, "\uc911": [15, 16, 18, 20, 22], "\uc911\uac04\uc9c0\uc8fc\ud68c\uc0ac\uc778": 21, "\uc911\uad6d": [15, 20, 21, 22], "\uc911\uae30\ubd80": 15, "\uc911\ub2e8\ud558\uac70\ub098": 16, "\uc911\uc18c\uae30\uc5c5": 17, "\uc911\uc18c\ubca4\ucc98\uae30\uc5c5\ubd80": 15, "\uc911\uc2ec\uc73c\ub85c": [16, 20], "\uc911\uc5d0\ub3c4": 16, "\uc911\uc720\ub85c": 15, "\uc911\uc774\ub2e4": 15, "\uc911\uc774\ub77c\ub294": 17, "\uc99d\uac00\ub97c": 20, "\uc99d\uac00\uc728\uc740": [15, 17], "\uc99d\uac00\ud558\uace0": [15, 17], "\uc99d\uac00\ud55c\ub2e4": 17, "\uc99d\uac00\ud560": 20, "\uc99d\uad8c": 17, "\uc99d\uad8c\uc0ac": 17, "\uc99d\uad8c\uc0ac\ub4e4\uc758": [16, 20], "\uc99d\uba85": 17, "\uc99d\uc2dc\ub294": 20, "\uc99d\uc2dc\ub85c": 20, "\uc9c0": [15, 17, 20, 21], "\uc9c0\ub09c": [15, 16, 17, 18, 20, 21], "\uc9c0\ub09c\ud574": [15, 16, 20, 22], "\uc9c0\ubc29\uc790\uce58\ub2e8\uccb4\uc5d0": 16, "\uc9c0\ubc30\uad6c\uc870": [15, 17, 18, 20, 21, 22, 23], "\uc9c0\ubc30\uad6c\uc870\ub294": 20, "\uc9c0\ubc30\uad6c\uc870\uc5d0": 20, "\uc9c0\ubd84": 20, "\uc9c0\ubd84\uc744": 20, "\uc9c0\ubd84\uc774": 20, "\uc9c0\uc18d\uac00\ub2a5\uacbd\uc601\uc758": 21, "\uc9c0\uc218\ud568\uc218\uc801\uc73c\ub85c": 17, "\uc9c0\uc2dd": 17, "\uc9c0\uc5ed": 21, "\uc9c0\uc5ed\uc5d0": 20, "\uc9c0\uc5ed\uc758": [15, 17], "\uc9c0\uc5ed\uc801": 17, "\uc9c0\uc5f4": 15, "\uc9c0\uc6d0": [15, 17], "\uc9c0\uc9c4\ubc1c\uc0dd\uc704\uce58\ub85c\ubd80\ud130": 142, "\uc9c0\uc9c4\ud574\uc77c": 142, "\uc9c0\uc9c4\ud574\uc77c\uacfc": 142, "\uc9c0\uc9c4\ud574\uc77c\uc740": 142, "\uc9c0\uc9c4\ud574\uc77c\uc774": 142, "\uc9c0\ud0a4\uae30": 15, "\uc9c0\ud45c": 17, "\uc9c1\uc6d0": 17, "\uc9c1\uc6d0\ub4e4": 15, "\uc9c1\uc804": 16, "\uc9c4\uc559\uc9c0\ub85c\ubd80\ud130": 142, "\uc9c4\uc9dc\ub85c": 22, "\uc9c4\ud589\ub41c": 17, "\uc9c4\ud589\ud558\uace0": 15, "\uc9c8\uc8fc\ud558\uace0": [16, 20], "\uc9d1": 146, "\uc9d1\uc548\uc5d0": 146, "\uc9d1\uc73c\ub85c": 146, "\uc9d1\uc911\ud558\uace0": 15, "\uc9d1\uc911\ud588\ub2e4": 17, "\ucc28\uc138\ub300": 18, "\ucc28\uc774\ub098\ud50c\ub77c\uc2a4": 21, "\ucc28\uc9c0\ud55c\ub2e4": 20, "\ucc3d\uac04\ub410\ub2e4": 16, "\ucc3d\ub9bd": 16, "\ucc3d\uc5c5": 16, "\ucc3d\uc6d0\uc2dc\ub294": 21, "\ucc3d\ucd9c": 18, "\ucc44\uad8c\uc2dc\uc7a5\uc5d0\uc11c": [16, 20], "\ucc44\ud0dd": 18, "\ucc45\uc784": 17, "\ucc45\uc790": 16, "\ucc98\ub9ac": 143, "\ucc98\ub9ac\ub97c": 143, "\ucc98\ubd84\ud558\ub294": 20, "\ucc98\uc74c\uc73c\ub85c": 16, "\ucc9c\ubb38\ud559\uc801\uc778": 20, "\uccab": [21, 22], "\uccab\ubc1c\uc744": 17, "\uccab\ud574": 20, "\uccad\ub144": 22, "\uccad\ub144\uce35\uc758": 16, "\uccad\ub144\ud76c\ub9dd\uc801\uae08\uc740": 16, "\uccb4\uacb0\ud55c": 21, "\uccb4\uc5b8": 141, "\uccb4\uc778\uc744": 17, "\uccb4\uc81c": 20, "\ucd08\uae30": 18, "\ucd1d": [17, 21], "\ucd1d\uc218": 20, "\ucd1d\uc561": [16, 20], "\ucd5c": 20, "\ucd5c\uace0\uc6b4\uc601\ucc45\uc784\uc790": 16, "\ucd5c\uadfc": [15, 16, 17, 18, 21], "\ucd5c\uadfc\ub3c4": 15, "\ucd5c\ub300": [16, 20], "\ucd5c\uc545\uc758": 15, "\ucd5c\uc7ac\ud64d": 20, "\ucd5c\uc885": [16, 20], "\ucd5c\ucd08": 95, "\ucd5c\ucd08\ub85c": [16, 20], "\ucd5c\ucd08\uc758": 15, "\ucd94": 17, "\ucd94\uac00": 15, "\ucd94\uac00\ub420": 17, "\ucd94\uac00\uc801": 15, "\ucd94\uc815\ub41c\ub2e4": 20, "\ucd94\uc9c4": [15, 17], "\ucd94\ucc9c": 20, "\ucd9c\ub801": 22, "\ucd9c\ubc94\ud558\uba70": 17, "\ucd9c\uc2dc\ud55c": 15, "\ucd9c\ud310": 17, "\ucda9": 21, "\ucda9\ub0a8": 21, "\ucda9\ubd84\ud788": 20, "\ucde8\ub4dd": 21, "\ucde8\uc5c5\uc790": [15, 17], "\ucde8\uc5c5\uc790\uc218\ub294": [15, 17], "\ucde8\uc784\ud588\ub2e4": 16, "\uce21\uba74\ub3c4": 16, "\uce58\ub8cc\uc81c": 21, "\uce58\uc19f\uc790": 17, "\uce5c\ud658\uacbd\ucc28\uac00": 17, "\uce60\ub808": 142, "\uce60\uc131\uc0ac\uc774\ub2e4": 15, "\uce68\uacf5": 16, "\uce69": 15, "\uce6d": 17, "\uce74\ub9c8\uc774\uc2dc\ud56d\uc5d0": 142, "\uce74\uce74\uc624\ucee4\uba38\uc2a4": 15, "\uce94\ud584": 16, "\uce98\ub9ac\ud3ec\ub2c8\uc544": 142, "\ucea0\ud398\uc778\uc5d0": 16, "\ucee4\uba38\uc2a4": 17, "\ucee4\uc9c0\uace0": [16, 20], "\ucee8\uc18c\uc2dc\uc5c4": 17, "\ucee8\uc18c\uc2dc\uc5c4\uc5d0": 21, "\ucef4\ud4e8\ud305": 17, "\ucf54\ub85c\ub098": 20, "\ucf54\ub85c\ub09819": [15, 16, 20, 21], "\ucf54\ub85c\ub09819\ub85c": 15, "\ucf54\ub85c\ub09819\uc758": 15, "\ucf54\ub85c\ub098\ubc14\uc774\ub7ec\uc2a4": 15, "\ucf54\ub9ac\uc544\uc138\uc77c\ud398\uc2a4\ud0c0": [16, 20], "\ucf54\uc2a4\ud53c": 20, "\ucf54\uc624\ub871": 16, "\ucf54\uc624\ub871\uadf8\ub8f9": 16, "\ucf54\uc624\ub871\uadf8\ub8f9\uc774\ub2e4": 16, "\ucf54\uc624\ub871\ub274\uc2a4\uc5d0\uc11c": 16, "\ucf54\uc624\ub871\ub274\uc2a4\uc600\ub2e4": 16, "\ucf54\uc624\ub871\ub9cc\uc758": 16, "\ucf54\uc624\ub871\uc0ac\ubcf4\ub85c": 16, "\ucf54\uc624\ub871\uc758": 16, "\ucf54\uc624\ub871\uc778\ub354\uc2a4\ud2b8\ub9ac": 16, "\ucf54\uc624\ub871\uc778\uc740": 16, "\ud06c": 104, "\ud06c\ub2e4": 20, "\ud06c\ub808\uc13c\ud2b8\uc2dc\ud2f0\uc5d0\uc11c": 142, "\ud06c\ub9bc": 15, "\ud070": [15, 18, 20], "\ud074\ub77c\uc6b0\ub4dc": [15, 17], "\ud074\ub77c\uc774\ubc0b": [16, 20], "\ud0a4\uc6cc\ub4dc\ub294": 20, "\ud0a4\uc6cc\uc57c": 17, "\ud0a4\uc6cc\uc654": 16, "\ud0ac\ub9b0": 15, "\ud0c0\uc774\uce78": 95, "\ud0d0\ubc29\uae30\uc0ac\uac00": 16, "\ud0d3\uc5d0": 21, "\ud0dc\uc591": 15, "\ud0dc\uc591\uad11": 15, "\ud0dc\ud3c9\uc591": 142, "\ud0dc\ud3c9\uc591\uc9c0\uc9c4\ud574\uc77c\uacbd\ubcf4\uc13c\ud130\ub294": 142, "\ud0dd\uc2dc\uc5d0": 21, "\ud130\ub110\uc744": 15, "\ud131\uac78\uc774\ud55c": 22, "\ud14c": 104, "\ud14c\uc2a4\ud2b8": 104, "\ud14c\uc2a4\ud2b8\ud558\uae30": 104, "\ud14c\uc774\ube14\uc744": [16, 20], "\ud1a0": 104, "\ud1a0\ud06c": 104, "\ud1a0\ud06c\ub098\uc774\uc800\ub97c": 104, "\ud1a4": 21, "\ud1b5": 142, "\ud1b5\uc2e0\uc2dc\uc7a5": 18, "\ud1b5\ud55c": [15, 21], "\ud1b5\ud574": [15, 16, 17], "\ud1f4\uc784\uc744": 16, "\ud22c\uc378\ud50c\ub808\uc774\uc2a4": 95, "\ud22c\uc790": [16, 20], "\ud22c\uc790\ub9cc": 17, "\ud22c\uc790\uc790": 17, "\ud22c\uc790\uc790\ub97c": 21, "\ud22c\uc9c0": 15, "\ud2b8": 104, "\ud2b8\ub799\ud130": 15, "\ud2b9\uc218\ud55c": [15, 17], "\ud2b9\uc9d1\ud638\ub97c": 16, "\ud2b9\ud5c8\uc2ec\ud310\uc6d0": 17, "\ud2b9\ud788": [15, 17, 20], "\ud2f0\uc640\uc774\uc5e0": 15, "\ud30c\ub098\uc18c\ub2c9\uacfc": 17, "\ud30c\uc6b4\ub4dc\ub9ac": 17, "\ud30c\uc77c": 141, "\ud30c\ud2b8\ub108\uc2ed": 21, "\ud310\ub2e8": 17, "\ud310\ub2e8\ub418\uba74": 17, "\ud310\ub9e4\ub300": 16, "\ud310\ucf5c": 15, "\ud328\ubc00\ub9ac": 21, "\ud32c\ub370\ubbf9": 20, "\ud32c\ub370\ubbf9\uc744": 15, "\ud32c\ub370\ubbf9\uc774\ub77c\ub294": 15, "\ud380\ub354\uba58\ud138": [15, 17], "\ud38c\ud504": 15, "\ud3a0\ub81b": 15, "\ud3b8\uacfc": 15, "\ud3b8\uc911": 18, "\ud3bc\uccd0": 142, "\ud3bc\uccd0\ub098\uac00\uae30\ub85c": 142, "\ud3c9\uac00\ub41c\ub2e4": 20, "\ud3c9\uade0": 17, "\ud3c9\uade0\uce58\ub97c": 17, "\ud3d0\uac00\uc2a4": 15, "\ud3d0\uae30\ubb3c\ub85c": 15, "\ud3d0\uae30\ubb3c\uc740": 15, "\ud3d0\ubaa9\uc7ac": 15, "\ud3d0\ubaa9\uc7ac\ub85c": 15, "\ud3ec\ub974\uc250": 95, "\ud3ec\ub974\uc250\ucf54\ub9ac\uc544": 95, "\ud3ec\ud568": 15, "\ud3ec\ud568\ub410\ub2e4": 17, "\ud3ec\ud568\ud55c": 15, "\ud3f4\ub780\ub4dc": 21, "\ud45c\uc900": 15, "\ud478\ub4dc\ud14c\ud06c": 16, "\ud478\ub974\ub978": 21, "\ud488\uc0ac": 141, "\ud488\uc9c8": 15, "\ud48d\ub825": 15, "\ud504": 20, "\ud504\ub85c\uadf8\ub7a8": 15, "\ud50c": 104, "\ud50c\ub7ab\ud3fc": 17, "\ud53c\ud50c": 15, "\ud544\uc218\uc801": 17, "\ud544\uc694": 15, "\ud544\uc694\uac00": 20, "\ud558": [104, 141, 142, 143], "\ud558\uaca0\ub2e4": 15, "\ud558\uace0": 18, "\ud558\uace0\uc790": 18, "\ud558\uae30": [17, 104], "\ud558\ub098\uac00": 16, "\ud558\ub098\uae08\uc735": 20, "\ud558\ub098\uc600\uc9c0\ub9cc": 18, "\ud558\ub294": [17, 20], "\ud558\ub2c8": 141, "\ud558\ub2e4": 17, "\ud558\ub4dc\uc6e8\uc5b4": 17, "\ud558\ub77d\ud55c": [16, 20], "\ud558\ubc18\uae30": 20, "\ud558\uc218\uc2ac\ub7ec\uc9c0": 15, "\ud558\uc5ec": 141, "\ud558\uc640\uc774": 142, "\ud558\uc9c0\ub9cc": [16, 20], "\ud559\ubd80\uc0dd": 21, "\ud55c": [16, 17, 104], "\ud55c\uad6d": [16, 18, 20], "\ud55c\uad6dm": 21, "\ud55c\uad6d\uac70\ub798\uc18c\ub294": 16, "\ud55c\uad6d\uac70\ub798\uc18c\uc5d0": 15, "\ud55c\uad6d\uacfc": 20, "\ud55c\uad6d\uc5b4\uc758": 141, "\ud55c\uad6d\ud22c\uc790\uc99d\uad8c\uc740": 16, "\ud55c\ub2e4": [15, 17], "\ud55c\ubbf8": 21, "\ud55c\uc0d8\uc740": 21, "\ud55c\ud654\uc194\ub8e8\uc158": 21, "\ud55c\ud654\uc194\ub8e8\uc158\uc740": 21, "\ud55c\ud654\uc194\ub8e8\uc158\uc758": 21, "\ud55c\ud654\ud050\uc140\uc774": 21, "\ud560": [17, 18, 20], "\ud568": 18, "\ud568\uaed8": [16, 21], "\ud569\uc791\uc0ac": 17, "\ud574": [16, 17, 18], "\ud574\ub2e4": 15, "\ud574\ub2f9\ub41c\ub2e4": 20, "\ud574\ub3c4": 20, "\ud574\uc18c": 21, "\ud574\uc678": 15, "\ud574\uc678\uacbd\uc81c": 15, "\ud574\uc678\uc5d0\uc11c\ub3c4": [16, 20], "\ud574\uc678\uc8fc\uc2dd": 16, "\ud574\uc678\uc9c0\uc0ac": 16, "\ud574\uc678\uc9c4\ucd9c\uc774": 16, "\ud575\uc2ec": 15, "\ud575\uc2ec\uacfc\uc81c\ub97c": 15, "\ud588": 142, "\ud588\ub2e4": [15, 16, 17], "\ud588\ub2e4\uace0": [17, 142], "\ud589\uc0ac": [16, 20, 21], "\ud589\uc0ac\uc758": [15, 17], "\ud589\uc704\uc790": 141, "\ud5a5\ubc29\uc744": 20, "\ud5a5\uc0c1": 17, "\ud5a5\ud6c4": [15, 17], "\ud5cc\ubc95\uc7ac\ud310\uc18c\ub294": [15, 17], "\ud5e4\ub7f4\ub4dc\uacbd\uc81c": [17, 21], "\ud601\uc2e0": [17, 18], "\ud601\uc2e0\uc744": 15, "\ud604": 15, "\ud604\uae08\ubc30\ub2f9\uc744": 15, "\ud604\ub300\uae00\ub85c\ube44\uc2a4\uc640": 21, "\ud604\ub300\ubaa8\ube44\uc2a4\uac00": 16, "\ud604\ub300\ucc28": 20, "\ud604\ub300\ucc28\uac00": 17, "\ud604\uc0c1\uc740": 20, "\ud604\uc7ac": [16, 18, 20], "\ud604\uc7ac\ub294": 21, "\ud604\uc9c0\uc2dc\uac04": 21, "\ud604\ud669": [16, 20], "\ud611\ub825\uc5c5\uccb4": 17, "\ud611\ub825\uc744": 15, "\ud611\ub825\ud574\ub098\uac04\ub2e4\ub294": 15, "\ud611\uc0c1": [16, 20], "\ud611\uc57d\uc2dd\uc744": 15, "\ud615": 17, "\ud615\uc6a9\uc0ac": 141, "\ud615\ud0dc": 16, "\ud615\ud0dc\uc18c": 141, "\ud638\ub791\uc774\ucc98\ub7fc": 15, "\ud638\uc7ac\ub85c": 20, "\ud64d\ub77c\ud76c": 20, "\ud64d\uc740\ud0dd": 15, "\ud654\uc7a5\ud488": 15, "\ud654\ud559\ubd84\uc57c": 21, "\ud654\ud569": 15, "\ud655": [16, 20], "\ud655\ub300": 20, "\ud655\ubcf4": [17, 21], "\ud655\ubcf4\ub97c": 17, "\ud655\uc0b0": [16, 20, 21], "\ud655\uc0b0\uacfc": 15, "\ud658\uacbd": [16, 17, 20], "\ud658\uacbd\uc601\ud5a5": [15, 17, 18, 20, 22, 23], "\ud658\uacbd\uc815\ubcf4": 17, "\ud658\uacbd\ud601\uc2e0": [15, 17, 18, 20, 22, 23], "\ud658\uc728": 22, "\ud65c\ub3d9": 17, "\ud65c\uc6a9": 17, "\ud65c\uc6a9\ud55c\ub2e4\uace0": 20, "\ud669\uc724\uc8fc": 21, "\ud68c": 15, "\ud68c\ub2f4": 16, "\ud68c\ubcf5": [15, 20], "\ud68c\ubcf5\uc774\ub2e4": 20, "\ud68c\ubcf5\ud558\uc9c0": 20, "\ud68c\uc0ac": 109, "\ud68c\uc0ac\uc758": 15, "\ud68c\uc0ac\ucc44": [16, 20], "\ud68c\uc7a5": 16, "\ud68c\uc7a5\uacfc": 21, "\ud68c\uc7a5\uc740": 16, "\ud68c\uc7a5\uc758": 20, "\ud68c\uc7a5\uc774": [15, 16, 20], "\ud6a8\uacfc\uc801": 17, "\ud6a8\ub2a5": 15, "\ud6a8\uc131\uadf8\ub8f9": 15, "\ud6c4": [16, 20, 141], "\ud6c4\uba74": 22, "\ud6c4\ubcf4": [15, 20], "\ud6c4\ubcf4\ub294": 20, "\ud6c4\ubcf4\uc778": 20, "\ud6c4\uc18d": [15, 17], "\ud6c4\uc2dc\ub4dc": 15, "\ud6c8\ub828": 17, "\ud750\ub984\uc5d0": 15, "\ud751\uc561": 15, "\ud765\ud589\ub3c4": 15, "\ud76c\ub85c\uc560\ub77d\uc774": 16, "\ud76c\ub9dd": 20, "\ud76c\ub9dd\uc744": 15, "\ud76c\ubc15": 20, "\ufb01": 105, "\uff41\uff42\uff43\uff41\uff42\uff43\uff11\uff12\uff13\u1100\u1161\u1102\u1161\u1103\u1161": 105, "\uff41\uff42\uff43\uff41\uff42\uff43\uff11\uff12\uff13\uac00\ub098\ub2e4": 105, "\ud835\udc43": 98, "\ud835\udc47": 98, "\ud835\udc4a0": 98, "\ud835\udf03": 127}, "titles": ["Bibliography", "LectureBot for \u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1.\u03ac\u03b9", "Introduction", "Art and Music in Light of AI", "A Brave New World", "AI Art (Generative AI)", "Introduction", "Motion Capture and Motion Synthesis", "Robot Drawing System", "DALL\u00b7E 1", "DALL\u00b7E 2", "Imagen", "Text-to-Image Models", "Alternative Data Sources for Central Banks", "Central Banks", "Putting them together in a pipeline", "Building <code class=\"docutils literal notranslate\"><span class=\"pre\">econ_news_kr</span></code> corpus", "Cross validating datasets", "Improving classification datasets", "ESG Ratings", "Predicting ESG Categories and Polarities", "Preparing training datasets", "Preparing active learning data", "Training Classifiers for ESG Ratings", "Preparing Numerical Data", "Preparing Textual Data", "EDA on Numerical Data", "EDA on Numerical Data", "Create Training Datasets", "Visualizing Features", "Checking Baseline with AutoML", "Predicting Sentiments of FOMC Corpus", "EDA on Sentiments: Correlation", "EDA on Sentiment Data", "Visualize Features", "Monetary Policy Shocks", "Predicting the next decisions with tones", "Textual Analysis of FOMC contents", "Data Science for Economics and Finance", "Technical Challenges", "Introduction", "Data Science in Economics", "Data Analytics Methods", "AutoGen", "AutoGen AutoScraper Agent", "AI Agents", "Fine-Tuning LLMs with Hugging Face AutoTrain", "LLM Fine-tuning", "Large Language Models", "Introduction", "Large Language Models?", "Parameter-Efficient Fine-Tuning (PEFT)", "PEFT in HuggingFace Libraries", "PEFT for LLMs", "Q-Learning", "Q-Star (Q*)", "Retrieval Augmented Generation (RAG)", "LLM App Ecosystem", "LLM Application Architectures", "LLM Stacks", "Generative AI Infrastructure Stack", "<code class=\"docutils literal notranslate\"><span class=\"pre\">containerd</span></code>", "Docker", "Containerization", "DevSecOps", "GitOps", "DevOps", "Dotfiles", "Github\u2019s Fork &amp; Pull Workflow", "GitHub Workflow", "Project Templating Tools", "Machine Learning Systems Design", "Introduction to MLOps", "Deploy a Voice-Based Chatbot with BentoML, LangChain, and Gradio", "Introduction to BentoML", "LLMOps", "MLOps Project", "SSH, GPG, and AGE", "Authentication, Encryption, and Signing", "Security Management", "Unix Password Managers", "Simple MLOps Pipeline", "Server Setup &amp; Usage", "VPN Connectivity", "Meet the Camelids: A Family of LLMs", "DetectGPT", "GPT-4", "Generative Language Models", "Advances in AI and NLP", "Segment Anything", "Writing a Thesis", "How to Spot Machine-Written Texts", "Conversational AI and Chatbots", "Reinforcement Learning with Human Feedback (RLHF)", "Datasets", "Lab: Exploratory Data Analysis (EDA)", "mC4 Dataset", "Deep Learning for NLP", "Decoding and Search Strategies", "Large Language Models", "Pretrained Language Models", "Zero Shot and Prompt Engineering", "BPE Step-by-Step Implementation", "Tokenization", "Lab: Training Tokenizers", "Tokenization Pipeline", "SentencePiece Tokenizer", "Subword Tokenization", "Unigram Step-by-Step Implementation", "WordPiece Step-by-Step Implementation", "Training Language Models", "Lab: Finetuining a MLM", "Lab: Pretraining LMs - CLM", "Lab: Pretraining LMs - MLM", "BERT: Bidirectional Encoder Representations from Transformers", "BERT: Visualizing Attention", "ByT5: Towards a token-free future with pre-trained byte-to-byte models", "Transformers", "T5: Text-To-Text Transfer Transformer", "NLP Applications", "Research Part I", "Research Part II", "Text Data Collection", "Datasets", "Lab: Crawling DART Data", "FastText", "GloVe", "Word Embeddings", "Neural Language Models", "Word2Vec", "Introduction to NLP", "Introduction", "Language Models", "N-gram Language Models", "Usage of Language Models", "Sentiment Analysis", "Lab: Lexicon-based Sentiment Analysis", "Lab: ML-based Sentiment Classification", "Lexicon-Based Methods", "Machine Learning-Based Methods", "Tokenization", "Tokenization in Korean", "Lab: Korean Text Processing", "Lab: Tokenization and Pre-processing", "N-grams for Tokenization", "Part-of-Speech Tagging and Parsing", "Word Segmentation and Association", "Understanding the Basics", "Topic Coherence Measures", "Topic Modeling", "Lab: Topic Coherence", "Lab: Topic Modeling", "Topic Modeling Methodologies", "Lab: Tomotopy", "Bags of Words Model", "Vector Representation", "Lab: Word Similarity", "Vector Semantics", "Word Similarity", "TF-IDF Model", "GitOps", "DevOps", "Software Engineering", "Introduction", "Software Engineering?", "Software Processes", "Requirements Engineering (RE)", "Software Development Life Cycle (SDLC)", "Software Engineering Proposal Guideline", "Project Proposal", "Steps in Software Engineering Projects", "Project Proposal Template", "Agile Software Development", "Software Process Models", "0. Introduction to version control", "1. Solo work with git", "2. Fixing mistakes", "3. Publishing", "4. Collaboration", "5. Fork and Pull", "6. Git Theory", "7. Branches", "8. Advanced git concepts", "9. Publishing from GitHub", "10. Rebasing", "11. Debugging With git bisect", "12. Working with multiple remotes", "Version Control Systems"], "titleterms": {"": [6, 11, 51, 52, 53, 54, 57, 68, 73, 82, 115, 122, 131, 133, 140, 174, 178], "0": [72, 129, 174], "1": [4, 9, 13, 44, 45, 46, 61, 65, 68, 69, 70, 72, 76, 81, 82, 83, 89, 91, 104, 128, 129, 131, 142, 143, 145, 148, 157, 160, 166, 167, 168, 171, 175, 179], "10": [4, 69, 81, 168, 171, 184], "11": [4, 81, 168, 171, 185], "12": [4, 168, 171, 186], "2": [4, 6, 10, 11, 13, 44, 45, 46, 61, 65, 68, 69, 70, 72, 76, 81, 82, 83, 91, 104, 128, 129, 142, 143, 145, 148, 157, 160, 166, 167, 168, 171, 176, 179], "3": [4, 13, 44, 45, 46, 61, 65, 68, 69, 70, 76, 81, 82, 83, 91, 104, 128, 129, 131, 142, 143, 145, 148, 157, 160, 166, 167, 168, 171, 177, 179], "3d": 7, "4": [4, 13, 44, 45, 46, 61, 65, 68, 69, 76, 81, 82, 83, 86, 91, 104, 128, 129, 143, 145, 160, 166, 167, 168, 171, 178, 179], "5": [4, 13, 45, 46, 61, 65, 68, 69, 76, 81, 82, 83, 104, 145, 160, 166, 167, 168, 171, 179], "51": 99, "6": [4, 13, 45, 65, 68, 69, 76, 81, 82, 145, 160, 167, 168, 171, 179, 180], "67": 99, "7": [4, 45, 65, 68, 69, 81, 82, 160, 167, 168, 171, 179, 181], "7b": 46, "8": [4, 65, 68, 69, 81, 82, 160, 168, 171, 179, 182], "9": [4, 69, 81, 82, 168, 171, 183], "A": [4, 11, 50, 54, 70, 77, 78, 84, 89, 90, 107, 116, 117, 118, 124, 147, 175, 176, 181], "And": [21, 116], "In": [50, 116], "Not": 117, "Of": 116, "One": 101, "The": [3, 10, 50, 51, 57, 70, 73, 85, 90, 94, 114, 116, 118, 121, 122, 131, 137, 140, 147, 151, 157, 165, 167, 172, 173, 175, 178, 180, 183], "To": [116, 118], "With": 185, "aaron": 6, "abil": 99, "ablat": 116, "about": [2, 175, 177], "acceler": 52, "accept": 179, "access": [81, 82, 124], "accessor": 146, "achiev": 54, "acquir": 94, "across": [50, 51], "activ": [22, 168], "actual": [26, 115], "ad": [80, 109, 142, 177], "adapt": [51, 52, 54, 74], "add": [24, 82, 175, 182], "addit": [15, 53, 80], "adjust": 121, "adopt": 53, "advanc": [8, 51, 54, 55, 88, 182], "advantag": [41, 42, 54, 151], "advent": 50, "affix": 140, "afinn": 136, "after": 181, "ag": [77, 80], "agent": [43, 44, 45, 58, 117], "agglutin": 141, "aggreg": [31, 148], "agil": [167, 172, 173], "agricultur": 13, "ai": [3, 5, 43, 45, 51, 53, 54, 55, 57, 60, 74, 75, 78, 88, 90, 92], "aihub": 122, "albert": 100, "algorithm": [90, 107, 139, 146, 149, 151], "align": [86, 93], "all": [57, 117], "alloc": 152, "alpaca": 84, "alphago": 54, "altern": [13, 39, 42, 70, 168, 170, 171], "amazon": 4, "ambigu": [89, 131, 138], "among": 138, "an": [8, 15, 16, 17, 50, 62, 82, 127, 134, 184, 185], "analys": 31, "analysi": [11, 13, 37, 53, 95, 111, 119, 135, 136, 137, 138, 141, 147, 152, 166, 167], "analyt": [13, 42, 50], "analyz": 95, "annot": 145, "ansibl": [65, 160], "answer": [50, 131], "antarctica": 4, "antipatch": 176, "anyth": 89, "api": 122, "app": [57, 70, 73], "appli": 81, "applic": [10, 13, 42, 50, 51, 54, 56, 58, 60, 78, 99, 119, 131, 135, 151, 152], "approach": [44, 47, 51, 89, 91, 168, 171], "ar": [3, 50, 99, 116, 117, 127, 140], "architectur": [9, 11, 42, 50, 51, 53, 54, 58, 73, 100, 114, 116, 117, 118, 129, 168, 171], "area": [131, 175, 176], "aren": 140, "art": [3, 5, 6, 147], "articl": 146, "artifact": [73, 74], "artist": [3, 50], "ascend": 50, "assess": [13, 38, 51, 56, 168, 171], "assist": [50, 86, 131], "associ": 146, "assum": 1, "assumpt": [107, 131, 133], "atom": 157, "attend": 114, "attent": [50, 53, 114, 115, 117], "attribut": 9, "audio": 7, "augment": [56, 58], "authent": [78, 177], "auto": [30, 36], "autoencod": 9, "autogen": [43, 44, 45], "autom": [50, 72], "automat": 185, "automl": 30, "autonom": 58, "autoregress": 100, "autoscrap": 44, "autotrain": 46, "avail": [56, 86], "aw": 74, "azur": 74, "b": [77, 78, 90], "background": [168, 171], "backoff": 134, "backup": 67, "bad": 140, "bag": [115, 129, 154], "balanc": 51, "bang": 167, "bank": [13, 14], "bare": [65, 160], "bart": 100, "base": [7, 51, 53, 56, 73, 91, 120, 136, 137, 138, 139], "baselin": [30, 118], "basic": [51, 62, 82, 95, 106, 147, 153], "batch": 74, "bbpe": 107, "beam": 98, "befor": 81, "bench": 99, "benchmark": 116, "benefit": [42, 46, 65, 66, 70, 110, 160, 161, 173], "bentocloud": 73, "bentoml": [73, 74], "bentoservic": 74, "bert": [100, 104, 114, 115, 155], "best": [56, 64, 65, 75, 109, 160, 172], "better": 11, "between": [26, 61, 80, 82, 106], "beyond": 131, "bia": 138, "bibliographi": 0, "bidirect": 114, "big": [52, 99, 167], "bigram": [102, 133], "billion": 89, "biometr": 78, "bird": 11, "bisect": 185, "bitfit": 51, "bits_and_byt": 52, "blank": 140, "block": 53, "blockchain": 78, "board": 121, "bodi": 7, "book": 130, "boundari": 146, "bpe": [102, 104, 106, 107], "branch": [68, 69, 146, 179, 181, 183], "brave": 4, "breakthrough": 54, "brown": 134, "budget": [168, 171], "build": [1, 16, 17, 21, 29, 34, 56, 61, 62, 94, 96, 128, 129, 138], "buildkit": 61, "built": 175, "byt5": 116, "byte": [104, 107, 116], "c": [77, 78, 90], "c4": 118, "calcul": [107, 133, 148, 156], "calendar": 24, "call": 122, "camelid": 84, "can": 131, "capabl": [52, 54, 93, 99], "capit": 147, "caption": 11, "captur": [7, 157], "card": 86, "carri": 175, "cascad": 11, "case": [13, 51, 52, 54, 61, 172], "categor": 127, "categori": [15, 20, 22, 23, 100, 166], "causal": 100, "cbow": 129, "cd": [66, 75, 161], "central": [13, 14], "centralis": 186, "ceremoni": 172, "chain": [54, 58, 101], "chairperson": 24, "challeng": [13, 39, 41, 42, 50, 51, 54, 55, 56, 58, 72, 78, 90, 92, 94, 110, 135, 140, 172], "chang": [68, 69, 82, 116, 175, 176, 177, 178, 179, 181, 182], "charact": [7, 103, 109, 125], "characterist": [45, 164], "charaterist": 9, "chatbot": [73, 92, 131], "chatwrapp": 73, "check": [20, 30], "chinchilla": 99, "chip": 60, "choos": [90, 145], "chosen": 90, "chrome": 1, "chunk": 25, "ci": [66, 75, 161], "class": [24, 25, 73], "classfici": [17, 23], "classic": 151, "classif": [10, 18, 45, 116, 137, 141], "classifi": [11, 15, 23], "clean": [56, 118, 181, 182], "cli": 70, "clip": 10, "clipdraw": 10, "clm": 112, "clone": [68, 69, 82, 179], "cloud": [60, 74], "cluster": [139, 149], "cnn": [13, 139], "co": 126, "code": [15, 16, 22, 44, 50, 66, 124, 159, 161, 175, 178], "codex": 131, "cognit": 50, "coher": [148, 150, 153], "colab": 52, "colaboratori": 177, "collabor": [3, 68, 75, 86, 178, 179], "colleagu": 178, "collect": [90, 94, 122, 145], "colloc": 144, "coloss": 118, "combin": 138, "command": [61, 62], "commit": [68, 69, 175, 177, 178, 179], "common": [118, 122, 147], "compani": [15, 16, 22, 124], "compar": [25, 27, 33, 52, 53, 104], "comparison": [11, 53, 70, 77, 96, 118, 151, 159], "complex": 164, "complianc": [13, 75], "compon": [52, 54, 61, 62, 75, 92, 168], "compos": 62, "composit": 146, "comprehens": 90, "comput": [50, 51, 52, 78, 108, 109, 150], "con": [116, 184], "concept": [42, 51, 53, 74, 132, 180, 182], "conceptu": 54, "concern": [50, 53], "conclud": 57, "conclus": [3, 9, 11, 13, 45, 46, 47, 51, 52, 53, 54, 55, 56, 58, 62, 64, 68, 73, 75, 77, 78, 80, 81, 82, 83, 86, 89, 90, 94, 95, 107, 116, 117, 147, 155, 156, 157, 159, 168, 170, 171, 172], "condit": 11, "conduct": 90, "configur": [56, 65, 66, 67, 81, 83, 160, 161, 174, 175], "confirm": 148, "conflict": [176, 178], "confound": 121, "confront": 3, "conjug": 141, "conjunct": 51, "connect": [82, 83], "consider": [13, 39, 42, 46, 54, 171, 179], "constitu": 145, "constraint": [13, 50], "construct": 96, "consult": 90, "consum": 52, "contain": [61, 62], "container": [63, 66, 161], "containerd": [61, 81], "content": [5, 37, 38, 45, 47, 51, 54, 71, 88, 97, 110, 130, 171, 177], "context": [50, 54, 56, 129, 138, 158], "contextu": [9, 100], "continu": [66, 72, 75, 129, 161, 172], "contrast": [10, 51, 129], "control": [7, 9, 66, 67, 161, 174, 187], "convers": [43, 92], "convolut": [13, 139], "cookiecutt": 70, "copier": 70, "core": [51, 53, 62, 74], "corpor": 124, "corpora": [122, 131], "corpu": [16, 25, 31, 118, 122, 123, 131, 134, 138, 153], "correct": 175, "correl": [26, 32, 152], "corrupt": 118, "cosin": [148, 149, 158], "cost": [50, 164], "cot": 54, "count": [26, 102, 133, 138], "countri": 120, "countvector": 159, "cours": [2, 5, 38, 48, 71, 88, 97, 130, 162], "cover": 176, "crawl": [94, 118, 122, 124], "creat": [27, 28, 56, 61, 62, 68, 69, 70, 78, 81, 82, 112, 113, 129, 145, 177, 179], "creativ": [3, 50], "credit": 187, "crisi": 165, "cross": [17, 18, 116], "crowdwork": 21, "ctm": 152, "ctr": 61, "current": [51, 53, 54], "curvatur": 91, "custom": 58, "cybersecur": 78, "cycl": 167, "d": [77, 78, 90], "dall": [6, 9, 10, 11], "danc": 7, "dart": 124, "data": [13, 15, 16, 20, 21, 22, 24, 25, 26, 27, 28, 32, 33, 36, 38, 39, 41, 42, 53, 56, 57, 60, 72, 89, 90, 94, 95, 96, 111, 112, 113, 122, 124, 129, 137, 145, 150, 151], "databas": [56, 60], "dataset": [17, 18, 21, 23, 28, 32, 33, 46, 56, 94, 95, 96, 102, 104, 108, 109, 111, 112, 113, 118, 123, 137, 153], "deal": 131, "debt": 72, "debug": [58, 185], "deciph": 121, "decis": [24, 26, 27, 36], "decod": [9, 10, 50, 89, 98, 102, 117, 118], "decomposit": 151, "deconstruct": 114, "dedic": 82, "deep": [11, 97, 139, 140], "deeplabcut": 7, "deepspe": 52, "default": 177, "defin": [46, 90, 112, 113, 129, 140, 145, 167], "definit": [45, 51, 54], "deliber": 121, "delimit": 115, "deliver": [168, 171], "deliveri": [66, 72, 161], "dens": [127, 157], "depend": 145, "deploi": 73, "deploy": [46, 60, 74, 75, 167], "descript": [5, 38, 48, 71, 88, 96, 97, 130, 162, 173], "design": [56, 71, 167], "detail": [9, 10, 61, 83, 107, 116, 137], "detect": [8, 85, 91], "detectgpt": 85, "detector": 121, "develop": [8, 57, 76, 90, 165, 167, 172, 173], "devop": [65, 66, 72, 160, 161], "devsecop": 64, "dictionari": [138, 142], "differ": [47, 56, 70, 80, 106, 140, 143, 179], "differenti": [43, 120], "difficult": 131, "difficulti": 141, "diffus": [7, 10, 11, 52, 121], "digit": 78, "dilemma": 13, "dimension": [9, 139, 144, 149], "direct": [13, 51, 148], "directli": 178, "directori": [82, 182], "dirichlet": 152, "disadvantag": 70, "disagr": 138, "disambigu": 56, "disclosur": 124, "discret": 9, "discuss": 51, "displai": 174, "disrupt": 121, "distinct": 43, "distribut": [25, 27, 78, 95, 157, 158, 178, 186], "dive": [11, 81], "divers": 7, "do": [117, 127, 131, 132, 145, 157, 174], "doc2vec": 155, "docker": [62, 74], "dockerfil": [61, 62], "document": [76, 124, 149, 153, 155, 174], "doe": [72, 115, 131, 154], "domain": [50, 51, 94], "dot": 158, "dotfil": 67, "download": [1, 83, 124], "downstream": 52, "draw": [6, 8, 9], "drawback": 173, "driven": [7, 172, 173], "drop": 116, "dropout": [106, 107], "dtm": 152, "dump": 122, "duplic": 56, "dynam": [7, 11, 122, 146, 152, 164], "e": [6, 9, 10, 11, 78], "each": 168, "eas": 24, "easi": 114, "econ": 36, "econ_news_kr": 16, "econom": [13, 24, 33, 38, 41, 42, 120], "ecosystem": 57, "eda": [26, 27, 28, 32, 33, 95, 137], "edg": 8, "edit": [7, 178], "editor": 175, "educ": 50, "effect": [24, 120], "effici": [51, 52], "ekonlpi": 142, "ekorpkit": [122, 131, 153], "electra": 100, "elicit": 166, "elimin": 56, "email": 174, "embed": [50, 56, 100, 127, 129, 139, 155, 157], "emerg": [51, 58, 99], "encod": [10, 11, 50, 89, 102, 104, 107, 108, 109, 114, 117, 118], "encrypt": 78, "end": 72, "endogen": 120, "engin": [10, 50, 58, 62, 89, 98, 101, 137, 139, 162, 164, 166, 168, 170, 173], "english": [116, 140], "enhanc": [43, 47, 56], "ensur": 56, "entiti": 56, "entropi": [133, 146], "environ": [16, 95, 111, 112, 113], "error": 18, "esg": [13, 19, 20, 23], "esg_cv_polarity_kr": 17, "esg_cv_topics_kr": 17, "esg_polarity_kr": [17, 23], "esg_top": 18, "esg_topics_improv": [17, 23], "esg_valid_topics_kr": 17, "estim": [7, 107, 129, 133], "etc": 140, "ethic": [13, 50, 54, 131], "evalu": [17, 46, 56, 90, 91, 129, 133, 145, 146, 148], "even": 52, "event": 24, "everybodi": 7, "everyon": 122, "everyth": 148, "evolut": [45, 50, 54], "evolutionari": 57, "exactli": 140, "exampl": [43, 44, 45, 52, 69, 107, 133, 134, 142, 143, 147, 153, 159, 174, 175, 179, 184, 185], "execut": [43, 168, 171], "exercis": [156, 174], "exist": 51, "expect": 13, "experi": [56, 116], "experiment": 90, "explain": 115, "explor": 70, "exploratori": [95, 137], "extens": [1, 50], "extern": 9, "extract": [102, 124], "ey": 11, "face": [46, 53, 96], "factor": [151, 152], "factual": 56, "falcon": 46, "famili": [84, 100], "fast": [8, 74, 184], "fasttext": [125, 155], "feasibl": 166, "featur": [1, 29, 30, 34, 36, 43, 70, 80, 137, 139, 179], "fed": [24, 32], "feedback": [47, 90, 93, 179], "fetch": 21, "few": 101, "file": [62, 65, 160, 175, 177, 178, 182], "filter": [15, 16, 22], "final": [48, 76], "financ": 38, "financi": [13, 50, 78, 124], "finbert": [31, 36], "find": [18, 109, 124, 181], "fine": [46, 47, 50, 51, 53, 60, 75, 114, 118], "finetuin": 111, "finetun": [10, 52, 100, 110], "firm": 120, "first": [107, 175], "fix": [176, 179], "flame": 7, "flow": 8, "focu": 70, "focus": 115, "fomc": [24, 25, 31, 37, 121], "fork": [68, 69, 179], "form": [7, 178], "format": [50, 111, 112, 113, 118, 125, 140], "forticli": 83, "forward": 184, "foundat": [50, 51, 54, 60], "framework": [43, 50, 60, 67, 74, 76, 118, 172], "free": [7, 11, 116], "french": 143, "from": [1, 7, 9, 21, 24, 47, 70, 80, 99, 106, 114, 121, 124, 133, 134, 179, 181, 183], "frontmatt": 183, "full": 52, "function": [7, 21, 35, 43, 54, 74, 128, 129, 166], "fundament": 54, "further": [15, 54, 171], "futur": [13, 51, 54, 78, 92, 116, 172], "fzf": 80, "game": [97, 130], "gap": 90, "gato": 117, "gener": [5, 6, 7, 8, 11, 21, 50, 51, 56, 58, 60, 70, 80, 85, 87, 89, 116, 131, 132, 133, 138, 146], "generalist": 117, "genesi": 50, "geometr": 148, "geospati": 13, "get": [24, 46, 52, 61, 153, 175], "gh": 183, "git": [77, 174, 175, 177, 178, 180, 182, 185], "github": [1, 68, 69, 77, 81, 82, 174, 177, 178, 179, 183, 186], "gitop": [65, 67, 160], "give": 178, "glide": 10, "glove": [126, 155], "glue": 116, "gnu": 77, "goal": [5, 48, 97, 130, 131, 147, 162], "good": [140, 164, 181], "googl": [1, 53, 74, 177], "got": 54, "gpg": 77, "gpt": [6, 86, 100, 104, 131], "grab": 181, "grade": [48, 71, 88, 97, 130, 162], "gradio": 73, "gram": [125, 129, 133, 144], "grammat": 141, "graph": [54, 180], "grayscal": 8, "greedi": 98, "ground": 39, "groundtruth": 54, "group": 82, "gru": 50, "guanaco": 84, "guard": 77, "guid": [8, 74, 77], "guidanc": 11, "guidelin": 168, "h2o": 74, "hallasan": 4, "hallucin": 58, "handl": [90, 138], "hannanum": 142, "hard": 131, "hardwar": 52, "harvard": 138, "hash": [144, 175], "have": [1, 94], "head": [114, 117, 176], "healthcar": [50, 78], "here": 175, "hidden": [72, 129], "hierarch": 129, "high": [94, 106, 144], "highli": 56, "highlight": [51, 106], "histori": 176, "home": 186, "host": [60, 186], "how": [3, 11, 54, 61, 65, 66, 72, 89, 91, 116, 117, 133, 140, 154, 157, 160, 161, 174], "hug": [46, 53, 96], "huge": 134, "huggingfac": 52, "human": [7, 47, 91, 93], "hunk": 182, "hypothesi": 157, "i": [8, 11, 47, 51, 56, 65, 78, 93, 103, 106, 107, 116, 117, 120, 127, 131, 138, 140, 141, 142, 145, 147, 153, 154, 158, 159, 160, 173, 174, 181], "iac": [66, 161], "ibm": 131, "idea": 129, "ident": 115, "identifi": 90, "idf": 159, "ignor": 182, "ii": [8, 51, 56, 78, 121, 142], "iii": [8, 51, 56, 78, 142], "illustr": 43, "imag": [6, 10, 11, 12, 61, 62, 89, 117, 131], "imagen": 11, "imageri": 13, "impact": 51, "implement": [54, 64, 72, 81, 90, 102, 105, 108, 109, 117], "implic": [51, 54, 55], "import": [22, 51, 53, 56, 57, 64, 77, 90, 103, 123, 157, 164], "improv": [18, 54, 56, 86, 126, 129], "impuls": 35, "includ": 175, "incorpor": 138, "increment": [167, 173], "index": 128, "indic": [13, 24], "indirect": 148, "individu": [56, 99], "industri": [51, 70, 120], "infer": [9, 43, 52, 60, 75, 152, 153], "inferenc": 52, "inflat": 13, "inflect": 141, "influenc": 121, "info": [15, 16, 22], "inform": [56, 124, 144, 148, 156, 158], "infrastructur": [39, 60, 66, 75, 86, 161], "initi": [50, 80, 102, 108, 109], "initialis": 174, "input": [117, 118, 129, 147], "inquir": 138, "inquiri": 138, "insight": 54, "inspect": 61, "instal": [1, 43, 46, 61, 62, 65, 70, 80, 81, 82, 83, 104, 115, 124, 153, 160], "instanc": 95, "institut": 122, "instruct": 44, "instructor": 50, "int8": 52, "integr": [13, 39, 51, 52, 54, 66, 75, 80, 161, 172], "interact": [45, 182], "interdisciplinari": 131, "interest": 90, "intern": [9, 122], "interpret": [13, 41], "intricaci": 140, "introduct": [2, 3, 6, 7, 8, 13, 40, 42, 49, 51, 54, 56, 57, 61, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 82, 84, 85, 89, 90, 92, 93, 94, 103, 107, 111, 112, 113, 123, 124, 130, 131, 135, 137, 145, 148, 149, 152, 155, 156, 157, 163, 168, 170, 172, 174], "invalid": [15, 17, 22], "inventori": [65, 160], "iot": 78, "isol": 141, "issu": [99, 122, 131, 133], "iter": [54, 107, 167, 173], "iv": [8, 51, 56, 78], "j": 1, "jean": 6, "jeopardi": 131, "joint": 133, "just": 140, "justifi": 90, "k": 98, "kei": [1, 42, 43, 46, 51, 54, 61, 64, 70, 75, 78, 80, 114, 116, 172, 186], "kera": 74, "kkma": 142, "knowledg": 140, "komoran": 142, "korean": [122, 131, 141, 142, 143, 146], "kss": 142, "kubernet": [61, 74, 81], "lab": [46, 95, 104, 111, 112, 113, 124, 136, 137, 142, 143, 150, 151, 153, 156], "label": [18, 20, 21, 60], "labelmodel": 21, "labelstudio": [21, 22], "lambda": 74, "landscap": 75, "langchain": 73, "languag": [7, 13, 48, 50, 54, 56, 60, 87, 91, 93, 96, 99, 100, 107, 110, 114, 122, 128, 131, 132, 133, 134, 141, 143], "larg": [11, 48, 50, 51, 52, 54, 56, 60, 93, 99], "latent": 152, "latest": 1, "law": 140, "layer": [51, 57, 60, 127, 129], "layout": 183, "lda": [152, 153], "leader": 179, "learn": [3, 5, 7, 13, 22, 38, 47, 48, 50, 51, 54, 71, 72, 74, 76, 78, 88, 93, 97, 101, 115, 116, 117, 118, 130, 138, 139, 140, 151, 162], "learner": 101, "lectur": [56, 97], "lecturebot": 1, "ledger": 78, "legal": 122, "legisl": 121, "lemmat": 147, "length": [95, 118], "level": [72, 106, 107, 116, 120, 175, 178, 180], "leverag": 50, "lexic": 157, "lexicon": [136, 138], "librari": [46, 52, 70, 96, 104], "lie": 176, "life": 167, "light": 3, "lightgbm": 74, "lightweight": 89, "likelihood": 133, "limit": [41, 50, 51, 54, 56, 86, 110, 154], "line": 61, "lingual": 116, "linguist": [138, 140, 141], "list": [62, 82], "literatur": 90, "live": 7, "liwc": 138, "llama": 84, "llm": [43, 45, 46, 47, 50, 52, 53, 54, 56, 57, 58, 59, 75, 84, 93, 94, 99, 101], "llmop": 75, "lm": [31, 36, 112, 113], "load": [15, 16, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 56, 95, 104, 111, 112, 113, 125, 137, 150, 153], "local": [73, 186], "log": [66, 161, 175], "long": 140, "loop": 54, "lora": [51, 52], "loss": [89, 108, 128, 129], "low": [51, 94, 131], "lower": 24, "lstm": 50, "machin": [3, 6, 13, 51, 71, 72, 76, 78, 85, 91, 116, 117, 131, 138, 139, 140], "made": 186, "main": [70, 129], "mainten": [75, 167], "make": [68, 69, 179], "manag": [39, 50, 61, 65, 66, 67, 78, 79, 80, 82, 144, 160, 161, 164, 166, 172], "mani": 140, "manner": 56, "manual": [1, 185], "mar": 4, "marg": 96, "mariana": 4, "markdown": 174, "market": [13, 24], "markov": 133, "mask": [89, 100], "masteri": 54, "match": [121, 146], "matrix": [126, 127, 146, 151, 152, 158], "matter": 72, "maximum": [133, 146], "mbart": 96, "mbert": 96, "mc4": [95, 96], "md": 124, "mdm": 7, "mean": 148, "measur": [120, 148], "mecab": 142, "mechan": [50, 53, 54, 114, 117], "media": 13, "median": 148, "medium": 52, "meet": 84, "merg": [32, 68, 69, 102, 109, 178, 181, 184], "metadata": 25, "metal": [65, 160], "method": [42, 50, 51, 52, 53, 58, 91, 103, 118, 138, 139, 140, 172], "methodologi": [13, 90, 99, 118, 152, 172], "microk8": 81, "migrat": 80, "mine": 121, "minut": 121, "miss": [27, 28], "mistak": [175, 176], "ml": [6, 30, 36, 51, 72, 137], "mle": 133, "mlm": [111, 113], "mlop": [72, 76, 81, 82], "mmlu": 99, "mobil": 78, "model": [6, 7, 8, 10, 11, 12, 13, 17, 21, 23, 41, 48, 50, 51, 52, 54, 56, 58, 60, 73, 75, 76, 87, 90, 91, 93, 96, 99, 100, 105, 107, 108, 110, 111, 112, 113, 116, 118, 125, 128, 129, 132, 133, 134, 137, 139, 145, 147, 148, 149, 151, 152, 153, 154, 155, 159, 165, 167, 168, 171, 173], "modifi": [111, 138], "modul": [65, 160], "modular": [65, 160], "monetari": [35, 121], "monitor": [13, 58, 66, 75, 81, 161], "more": [51, 131], "morph": 140, "morphem": 140, "morpholog": 141, "motion": 7, "motiondiffus": 7, "motiv": 151, "mountain": 4, "mpqa": 138, "mt5": 116, "multi": [43, 45, 114, 117, 118], "multilingu": 94, "multimod": 117, "multipl": [9, 50, 127, 177, 186], "muse": 3, "music": 3, "must": 94, "mutual": [144, 148, 156, 158], "n": [125, 133, 144], "naiv": 146, "name": 174, "nation": 122, "natur": [7, 13, 50, 164], "necess": 42, "necessari": [46, 82, 104], "need": [117, 127, 132, 145, 167], "neg": [129, 151, 152], "negat": 138, "net": 131, "network": [7, 11, 13, 54, 120, 127, 139, 178], "neural": [7, 13, 54, 127, 128, 131, 139], "neuro": 55, "new": [4, 41, 68, 69, 70, 82, 146, 176, 177, 179], "newer": 70, "next": [36, 45, 47, 51, 54, 66, 67, 69, 75, 81, 92, 94, 99, 103, 115, 117, 119, 123, 127, 132, 135, 140, 149, 155, 161, 175], "nlp": [13, 51, 88, 94, 97, 119, 123, 130, 131, 138, 143], "nltk": 133, "nmf": [151, 152], "nmt": 106, "node": 1, "nois": [116, 129], "non": [151, 152, 166], "nonconflict": 178, "normal": [105, 148], "note": 97, "noth": 175, "now": 7, "nucleu": 98, "number": [25, 106, 147], "numer": [24, 26, 27, 28], "object": [8, 9, 38, 44, 71, 76, 88, 100, 118, 125, 168, 171, 173], "observ": 60, "obtain": [83, 107, 178], "occurr": [107, 126], "offlin": [74, 122], "okt": 142, "onc": 177, "ongo": 56, "oov": 144, "op": 57, "open": 142, "openai": [53, 131], "openassist": 46, "opendartread": 124, "oper": [76, 77, 102], "opportun": 90, "optim": [56, 108, 128, 129], "orchestr": [60, 66, 161], "organ": [76, 90], "origin": 114, "other": [47, 106, 115, 131, 142], "our": 175, "out": [15, 16, 22, 144, 153, 181], "outcom": [38, 76], "outlin": [48, 162, 173], "output": [13, 118, 129, 147], "over": 126, "overal": 56, "overfit": 51, "overview": [43, 51, 53, 54, 61, 76, 86, 110, 122, 124, 140, 152, 172], "own": [94, 138], "p": 98, "page": [122, 183], "pair": [104, 107, 109], "paper": 99, "paradigm": 165, "paragraph": 147, "paramet": [51, 52], "pars": 145, "part": [56, 120, 121, 141, 142, 143, 145], "partial": 50, "partnership": 3, "pass": 80, "passag": 80, "password": [80, 82], "pattern": 115, "peft": [51, 52, 53], "pencil": 8, "perform": [47, 51, 52, 56, 86, 136], "period": 33, "permiss": 178, "permut": 100, "perplex": [96, 133], "person": 50, "perspect": 9, "perturb": 85, "phase": [7, 168, 173], "physic": 7, "pine": 153, "pipelin": [15, 31, 51, 56, 72, 81, 82, 105, 131, 147], "plai": [54, 177], "plan": [76, 167, 172, 173], "platform": 50, "playbook": [65, 160], "playground": 57, "plm": 100, "plot": [26, 33, 35], "plsa": 152, "plugin": [65, 80, 160], "pmi": [148, 156, 158], "po": [141, 145], "point": 172, "pointwis": [144, 148, 156, 158], "polar": [15, 17, 20, 22, 23], "polici": [35, 52, 54, 120, 121], "polit": 120, "popular": [123, 139], "pork": 121, "posit": 158, "post": 105, "posterior": 9, "postprocess": [25, 105], "potenti": [18, 54, 55], "power": 117, "ppmi": 158, "practic": [51, 64, 65, 75, 77, 78, 133, 146, 156, 160, 172, 179], "pre": [10, 105, 109, 114, 116, 143, 147], "predetermin": 106, "predict": [13, 15, 20, 22, 31, 36, 50, 115, 129], "prepar": [15, 16, 17, 18, 21, 22, 23, 24, 25, 46, 56, 102, 104, 108, 109, 111, 112, 113, 124, 129], "preprocess": [26, 27, 28, 90], "prerequisit": [38, 71, 81, 82, 88], "preserv": 78, "pretrain": [100, 110, 111, 112, 113], "previou": 115, "price": 133, "principl": [54, 64, 75], "prior": [10, 153], "privaci": [13, 53, 77, 78], "privat": 177, "prm": 54, "pro": [116, 184], "probabilist": [21, 152], "probabl": [107, 133, 148], "problem": [55, 56, 85, 117, 151, 173], "process": [8, 13, 50, 54, 56, 90, 105, 109, 140, 142, 143, 147, 151, 165, 166, 168, 171, 173], "product": [120, 158], "program": [146, 165, 174], "project": [5, 48, 51, 70, 76, 82, 97, 130, 167, 169, 170, 171, 172], "prompt": [10, 50, 51, 53, 57, 58, 89, 98, 101], "promptabl": 89, "propos": [5, 168, 169, 171], "proprietari": 94, "prospect": 54, "protect": [39, 80], "protocol": 78, "prototyp": 167, "proven": 39, "public": [70, 94, 124], "publish": [177, 181, 183], "pull": [62, 68, 69, 179], "punctuat": 147, "push": [68, 69, 178, 179], "put": [15, 148], "python": [44, 105, 159], "pytorch": 74, "q": [54, 55], "qualiti": [13, 39, 53, 56, 94, 164], "quantit": 24, "quantiti": 39, "quantum": 78, "queri": [56, 57, 114], "question": [50, 131], "quick": [53, 124], "r": 96, "rad": 167, "rag": [56, 58], "rage": 80, "random": [85, 151], "rank": 51, "ranker": 52, "rate": [19, 23, 24, 26, 27, 32, 118], "rational": 42, "raw": 106, "re": [18, 166], "read": 54, "real": [13, 45, 50, 131], "reason": [50, 101], "rebas": 184, "recap": 173, "record": 25, "recurr": 139, "recurs": 146, "reduct": [139, 149], "redund": 56, "refer": [0, 3, 7, 8, 11, 37, 54, 57, 58, 60, 68, 74, 84, 86, 89, 100, 115, 116, 118, 130, 134, 146, 176], "referenc": [91, 186], "regardless": 175, "registri": 62, "regular": 106, "regulatori": 13, "reinforc": [7, 47, 93], "reject": 178, "relat": [96, 115, 131, 133, 138], "relationship": 61, "releas": 1, "relev": [51, 90], "remark": 57, "remot": [177, 186], "remov": [62, 82], "reparameter": 53, "repeat": 109, "repo": 179, "report": 86, "repositori": [1, 68, 69, 81, 82, 174, 177, 179, 185], "repres": 157, "represent": [114, 131, 155, 157], "request": [68, 69, 179], "requir": [76, 166, 167], "research": [51, 86, 90, 120, 121, 131], "reset": 176, "resolut": 11, "resolv": [89, 178], "resourc": [13, 71, 81, 131, 168, 171], "respons": [35, 56, 75], "result": [9, 11, 33, 99, 116], "retriev": [56, 58, 80], "revert": 176, "review": [53, 90, 175, 176], "revis": 180, "reward": 54, "rewrit": 176, "reykjavik": 4, "risk": [13, 33, 50, 120, 168, 171], "rlhf": [47, 52, 93], "rnn": [50, 139], "roberta": 100, "robot": 8, "robust": 11, "role": [50, 57, 65, 160, 172, 173], "rubrix": 18, "rule": [24, 26], "run": [61, 62, 65, 74, 160], "safeti": [60, 86], "sam": 89, "same": 178, "sampl": [9, 96, 98, 107, 129, 134, 146], "sampler": 11, "satellit": 13, "save": [18, 27, 28, 52, 73, 111, 112, 113, 125, 153], "scalabl": [56, 164], "scale": [51, 56, 118, 172], "scenario": 61, "scienc": [38, 41, 72], "scikit": [74, 151], "scope": [90, 168, 171, 174], "score": [31, 33, 108, 109, 150], "scrape": [13, 122], "scrum": 172, "sdlc": 167, "search": [54, 98], "second": 107, "secret": [65, 160], "section": [14, 25, 40, 49, 59, 124, 163, 169, 173, 187], "secton": 25, "secur": [13, 53, 75, 77, 78, 79], "see": [99, 175], "seek": 90, "segment": [8, 89, 142, 146, 147, 148], "select": 53, "self": [47, 50, 53, 54, 117], "semant": [8, 42, 138, 152, 157], "semiconductor": 60, "sentenc": [25, 31, 106, 115, 134, 141, 142, 143, 147], "sentencepiec": [104, 106], "sentiment": [13, 31, 32, 33, 111, 135, 136, 137, 138], "sentiwordnet": 138, "sequenc": [133, 147], "serengeti": 4, "serv": [56, 73, 74], "server": [21, 82, 83, 186], "servic": [50, 62, 73, 78], "set": [27, 29, 30, 34, 36, 46, 65, 77, 81, 82, 95, 129, 145, 160, 174], "setup": [76, 80, 82, 136, 142], "sfv": 7, "share": [39, 67, 177], "shell": 77, "shock": 35, "shortcom": [131, 151], "shot": [10, 50, 85, 101], "should": 146, "sidestep": 131, "sign": [77, 78], "signal": 54, "signatur": 78, "signific": [51, 90], "silicon": 4, "similar": [148, 149, 156, 157, 158], "simpl": [61, 80, 81, 82], "singular": 151, "site": 24, "size": 118, "sketch": 8, "skill": 7, "skip": 129, "small": 52, "smooth": [134, 158], "snorkel": 21, "so": 117, "social": [13, 178], "societ": 50, "soft": 53, "softmax": 129, "softwar": [82, 162, 164, 165, 166, 167, 168, 170, 171, 172, 173], "solo": [174, 175], "solut": [50, 54, 55, 58, 72], "solv": [55, 185], "some": [147, 177, 179], "somewher": 174, "sota": 118, "sourc": [1, 13, 41, 90, 120, 122], "space": [9, 155], "span": 118, "spars": [51, 157], "sparsiti": 131, "special": [94, 109], "specif": [44, 50, 51, 138, 166, 168, 171], "speech": [141, 142, 145], "spell": 140, "spiral": [167, 173], "split": [25, 109], "splitter": 142, "spot": 91, "spotlight": 51, "squad": 131, "squash": 184, "sr": 166, "ssh": [77, 81, 82, 83, 186], "stabil": 13, "stack": [59, 60], "stage": [167, 175], "standalon": 43, "standard": [53, 56, 70, 100], "star": 55, "start": [46, 52, 61, 62, 124, 153, 175], "stash": 182, "state": 94, "statement": 124, "static": [11, 122], "statist": [91, 95, 138, 140], "statu": 175, "stem": [140, 147], "step": [46, 72, 102, 104, 108, 109, 128, 129, 143, 170], "stewardship": 39, "stock": 133, "stop": 62, "stopword": 147, "storag": 52, "store": 1, "stori": 172, "strategi": [50, 54, 56, 98, 140, 181], "stroke": 8, "structur": [9, 53, 90, 140], "struggl": 10, "studi": [51, 54, 116, 118, 131, 166, 172], "stupid": 134, "subject": 138, "subset": 50, "subword": [103, 106, 107, 147], "sudoer": 82, "summar": 50, "summari": [42, 56, 86, 98, 128, 134, 136, 150, 166, 167, 168, 171, 172], "sun": 4, "super": 11, "superglu": 116, "supersens": 138, "supervis": [47, 50, 54, 60, 117, 139], "supervisor": 90, "support": [52, 74, 96], "surfac": 140, "surround": 99, "svd": 151, "sweat": 121, "switch": 82, "symbol": [55, 106, 157], "sync": 69, "synchron": 67, "synset": 138, "syntax": 138, "synthes": [51, 90], "synthesi": 7, "synthet": [60, 116], "system": [1, 8, 33, 50, 56, 65, 67, 71, 72, 76, 86, 122, 160, 168, 171, 187], "systemat": 118, "t": 140, "t5": [11, 31, 36, 100, 104, 118], "tabl": [5, 71, 88, 97, 130, 171], "tackl": 140, "tag": [141, 142, 145, 182], "tagger": 145, "tail": 140, "take": 131, "target": [13, 24, 129], "task": [46, 52, 99, 116, 118, 131, 137], "taylor": [24, 26], "team": [76, 81, 82, 174, 178, 179], "technic": [10, 39, 44, 54, 72, 86, 106, 116, 168, 171], "techniqu": [8, 47, 51, 53, 54, 55, 58, 131, 135, 139, 147, 172], "technologi": [41, 42, 51, 78, 121], "tell": [175, 177], "templat": [70, 171], "tensorflow": 74, "term": [5, 56, 97, 130], "terminologi": 58, "test": [65, 160, 167, 172], "text": [6, 7, 10, 11, 12, 50, 85, 91, 95, 104, 109, 118, 120, 121, 122, 131, 142, 147, 174], "textblob": 136, "textbook": [38, 71, 130], "textual": [13, 25, 37, 119], "tf": 159, "than": 11, "them": 15, "theori": 180, "thesi": 90, "thi": [117, 174], "think": 170, "third": 107, "thought": [54, 58, 101], "three": [9, 94], "threshold": 11, "through": [13, 94], "time": [13, 151], "timebox": 172, "timelin": [6, 168, 171], "timesform": 117, "timestamp": 95, "timestep": 11, "tingu": 6, "titl": 171, "todai": 94, "togeth": [15, 148], "token": [102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 116, 140, 141, 142, 143, 144, 147], "tomotopi": 153, "tone": [34, 36], "tool": [3, 41, 57, 61, 65, 66, 67, 70, 160, 161], "top": 98, "topic": [15, 17, 90, 139, 148, 149, 150, 151, 152, 153], "tot": 54, "toward": 116, "track": 176, "tradit": [41, 51, 131, 139, 147], "train": [9, 10, 15, 17, 21, 23, 27, 28, 46, 52, 54, 89, 100, 104, 106, 110, 111, 112, 113, 114, 116, 125, 126, 128, 129, 137, 145], "tranform": 117, "transact": 13, "transfer": [50, 51, 118], "transform": [50, 51, 53, 100, 114, 117, 118, 139, 153], "translat": [50, 131], "transmiss": 120, "transpar": 121, "treasuri": 24, "tree": 54, "trench": 4, "trend": [51, 78], "triangular": 146, "truncat": 151, "truth": 39, "tta": 55, "ttc": 55, "tune": [46, 47, 50, 51, 52, 53, 60, 75, 114, 118], "tunnel": 4, "tutori": 174, "tweetqa": 116, "two": [129, 177], "type": [13, 78, 90, 92, 122, 123, 135, 143, 170], "typo": 140, "u": 24, "ubuntu": 82, "ugli": 140, "ui": 73, "uncertainti": [9, 33, 120, 146], "unclip": 10, "underfit": 51, "undersea": 4, "understand": [51, 55, 68, 131, 143, 144, 147, 148], "unicod": 105, "unifi": 118, "unigram": [104, 107, 108], "uniqu": 106, "unix": 80, "unknown": [131, 134, 146], "unlabel": 118, "unmodel": 131, "unseen": 153, "unstag": 175, "unsupervis": [118, 139], "up": [46, 65, 77, 81, 82, 95, 160, 174, 179, 181], "updat": [80, 81, 82, 145], "upgrad": 153, "us": [1, 3, 7, 13, 18, 21, 52, 53, 56, 61, 62, 65, 70, 77, 82, 83, 93, 96, 116, 125, 126, 129, 133, 134, 136, 144, 145, 151, 153, 160, 174, 176, 184], "usag": [69, 70, 80, 82, 106, 115, 134], "user": [82, 172], "util": [13, 50, 73], "v": [8, 43, 47, 51, 53, 56, 65, 78, 93, 94, 122, 126, 127, 160, 165, 167, 172, 173, 184], "vader": 136, "vae": 9, "valid": [17, 18, 65, 111, 112, 113, 160, 166], "vallei": 4, "valu": [27, 28, 54, 151], "variabl": [129, 131], "variant": [54, 140, 146], "variat": 9, "varieti": 146, "vatt": 117, "vault": [65, 160], "vc": 178, "vector": [8, 56, 60, 114, 144, 155, 157, 158], "venic": 4, "verifi": [61, 78], "version": [66, 67, 114, 161, 174, 187], "versu": [72, 186], "vertex": 53, "vi": [51, 56, 78], "via": 83, "vicu\u00f1a": 84, "video": 7, "view": 11, "vii": [51, 56, 78], "virtual": [50, 131], "vision": 117, "visual": [9, 29, 34, 115, 129, 150, 153, 156], "vocabulari": [107, 108, 109, 144], "voic": 73, "volum": 62, "vpn": 83, "vq": 9, "vqgan": 10, "wai": 179, "waterfal": [167, 173], "watson": 131, "we": [117, 127, 132, 145, 146, 157, 174], "web": [1, 13, 42, 70, 78, 94, 122], "weight": 11, "well": 90, "what": [47, 50, 65, 93, 99, 103, 106, 107, 115, 116, 127, 131, 140, 141, 145, 147, 153, 154, 158, 159, 160, 173, 174, 181], "when": [121, 129], "whitespac": 106, "who": 53, "whole": [97, 130], "why": [7, 11, 72, 74, 93, 103, 107, 117, 127, 131, 132, 144, 145, 146, 164, 174], "win": 131, "wise": 51, "within": 121, "without": 16, "word": [50, 100, 103, 108, 109, 115, 116, 121, 127, 128, 129, 133, 134, 138, 139, 140, 142, 143, 144, 146, 153, 154, 155, 156, 157, 158], "word2vec": [126, 129, 155], "wordnet": 138, "wordpiec": [104, 107, 109], "work": [11, 54, 61, 65, 66, 89, 146, 154, 160, 161, 174, 175, 176, 177, 186], "workflow": [65, 67, 68, 69, 82, 160, 175], "world": [4, 45, 50, 131], "write": [21, 50, 65, 90, 160], "written": 91, "xgboost": 74, "xlm": 96, "xlnet": 100, "xml": 24, "xsum": 116, "yaml": 183, "yeoman": 70, "yield": 24, "yml": 62, "you": [1, 117, 131], "your": [1, 46, 68, 69, 90, 94, 138, 174, 175, 176, 177, 179, 182], "yubikei": 80, "zero": [10, 50, 85, 101], "zipf": 140, "\u03ac\u03b9": 1, "\u1f10\u03bd\u03c4\u03b5\u03bb\u03ad\u03c7\u03b5\u03b9\u03b1": 1, "\ud65c\uc6a9": 141}})