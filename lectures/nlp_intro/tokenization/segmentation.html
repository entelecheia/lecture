

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Word Segmentation and Association &#8212; ἐντελέχεια.άι</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-examples.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/js/hoverxref.js"></script>
    <script src="../../../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../../../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/chatgpt.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/nlp_intro/tokenization/segmentation';</script>
    <link rel="canonical" href="https://lecture.entelecheia.ai/lectures/nlp_intro/tokenization/segmentation.html" />
    <link rel="shortcut icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Word Embeddings" href="../embeddings/index.html" />
    <link rel="prev" title="Tokenization" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>


  <div class="bd-header-announcement container-fluid bd-header-announcement">
    <div class="bd-header-announcement__content"><p>
  <strong>Announcement:</strong>
  You can install the accompanying AI tutor <a href="https://chrome.google.com/webstore/detail/lecturebot-for-%E1%BC%90%CE%BD%CF%84%CE%B5%CE%BB%CE%AD%CF%87%CE%B5%CE%B9%CE%B1/lfgfgbomindbccgidgalhhndggddpagd" target="_blank">here</a>.
  <a class="reference external" href="https://chrome.google.com/webstore/detail/lecturebot-for-%E1%BC%90%CE%BD%CF%84%CE%B5%CE%BB%CE%AD%CF%87%CE%B5%CE%B9%CE%B1/lfgfgbomindbccgidgalhhndggddpagd" target="_blank"><img alt="chrome-web-store-image" src="https://img.shields.io/chrome-web-store/v/lfgfgbomindbccgidgalhhndggddpagd" /></a>
</p>
</div>
  </div>

  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">ἐντελέχεια.άι</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Introduction to NLP</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../intro/index.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../research/index.html">Research Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lm/index.html">Language Models</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../datasets/corpus.html">Corpus and Text Data Collection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../datasets/lab-dart.html">Lab: Crawling DART Data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../topic/index.html">Topic Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../topic/coherence.html">Topic Coherence Measures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../topic/coherence-practice.html">Topic Coherence in Practice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../topic/tomotopy.html">Tomotopy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sentiments/index.html">Sentiment Analysis</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">Tokenization</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Word Segmentation and Association</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../embeddings/index.html">Word Embeddings</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp_deep/index.html">Deep Learning for NLP</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_deep/llms/index.html">Large Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/llms/zeroshot.html">Zero Shot and Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/llms/decoding.html">Decoding and Search Strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/llms/plms.html">Pretrained Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_deep/transformers/index.html">Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/transformers/bert.html">BERT: Bidirectional Encoder Representations from Transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/transformers/bertviz.html">BERT: Visualizing Attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/transformers/t5.html">T5: Text-To-Text Transfer Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/transformers/byt5.html">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_deep/datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/datasets/lab-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_deep/tokenization/index.html">Tokenization</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_deep/tokenization/sentencepiece.html">SentencePiece Tokenizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_deep/rlhf.html">Reinforcement Learning with Human Feedback (RLHF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_deep/detectGPT.html">How to Spot Machine-Written Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_deep/lab3-train-tokenizers.html">Lab 3: Training Tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_deep/lab4-pretraining-lms.html">Lab 4: Pretraining Language Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp_advances/index.html">Advances in AI and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_advances/thesis.html">Writing a Thesis</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_advances/gpt/index.html">Generative Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/detectGPT.html">DetectGPT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/gpt4.html">GPT-4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/camelids.html">Meet the Camelids: A Family of LLMs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_advances/sam/index.html">Segment Everything</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_advances/motion-capture-and-synthesis/index.html">Motion Capture and Motion Synthesis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../aiart/index.html">AI Art (Generative AI)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/intro/index.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/brave/index.html">A Brave New World</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/aiart/index.html">Art and Music in Light of AI</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../aiart/text-to-image/index.html">Text-to-Image Models</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/dalle1.html">DALL·E 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/dalle2.html">DALL·E 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/imagen.html">Imagen</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/textual-inversion.html">Textual Inversion (Dreambooth)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/speech/index.html">Automatic Speech Recognition (Whisper)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../aiart/music/index.html">Text to Music</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/music/image2music.html">Image to Music</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/robot/index.html">Robot Drawing System</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mlops/index.html">Machine Learning Systems Design</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mlops/intro.html">Introduction to MLOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mlops/project.html">MLOps Project</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/devops/index.html">DevOps</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/devops/gitops.html">GitOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/devops/devsecops.html">DevSecOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/devops/llmops.html">LLMOps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/dotfiles/index.html">Dotfiles</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai">Dotfiles Repository</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/dotfiles/dotdrop.html">Dotdrop</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/dotdrop/">Dotdrop Setup Script</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/github/">GitHub Setup Scripts</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/ssh-gpg-age/">SSH, GPG, and Age Setup Scripts</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/pass/">Pass and Passage Scripts</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/doppler/">Doppler Usage</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/dockerfiles/">Dockerfiles Scripts</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/security/index.html">Security Management</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/auth-enc-sign.html">Authentication, Encryption, and Signing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/age-gpg-ssh.html">SSH, GPG, and AGE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/pass.html">Unix Password Managers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/github/index.html">Github’s Fork &amp; Pull Workflow</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/github/template.html">Project Templating Tools</a></li>
<li class="toctree-l3"><a class="reference external" href="https://hyperfast-python.entelecheia.ai/">Hyperfast Python Template</a></li>
<li class="toctree-l3"><a class="reference external" href="https://hyperfast-template.entelecheia.ai/">Hyperfast Template</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/containerization/index.html">Containerization</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/containerization/docker.html">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/containerization/containerd.html"><code class="docutils literal notranslate"><span class="pre">containerd</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mlops/simple-pipeline/index.html">Simple MLOps Pipeline</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ds/index.html">Data Science for Economics and Finance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../about/lecture-bot.html">LectureBot for ἐντελέχεια.άι</a></li>
<li class="toctree-l1"><a class="reference external" href="https://entelecheia.me">entelecheia.me</a></li>
<li class="toctree-l1"><a class="reference external" href="https://course.entelecheia.ai">course.entelecheia.ai</a></li>
<li class="toctree-l1"><a class="reference external" href="https://research.entelecheia.ai">research.entelecheia.ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about/index.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/entelecheia/lecture/blob/main/book/lectures/nlp_intro/tokenization/segmentation.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/lectures/nlp_intro/tokenization/segmentation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Word Segmentation and Association</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation">Word Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-should-we-segment-words">Why should we segment words?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-segment-variants">Generating segment variants</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-recursive-algorithm">Naive Recursive Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-programming">Dynamic Programming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triangular-matrix">Triangular Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-matching-algorithm">Maximum Matching Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unknown-words">Unknown Words</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-compositions">Evaluation of Compositions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertainty-of-word-boundaries">Uncertainty of word boundaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accessor-variety">Accessor Variety</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#branching-entropy">Branching Entropy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation-in-practice">Word Segmentation in Practice</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation-for-korean">Word Segmentation for Korean</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-news-article-samples">Working with news article samples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="word-segmentation-and-association">
<h1>Word Segmentation and Association<a class="headerlink" href="#word-segmentation-and-association" title="Permalink to this heading">#</a></h1>
<p><img alt="" src="../../../_images/entelecheia_associaltion_vs_segmentation.png" /></p>
<section id="word-segmentation">
<h2>Word Segmentation<a class="headerlink" href="#word-segmentation" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Word segmentation</strong> is the task of splitting a string of characters into words.</p></li>
<li><p>Word segmentation is important for a machine to understand the meaning of a sentence.</p></li>
<li><p>In English, we can split a string of characters into words by spaces.</p></li>
<li><p>However, in languages like Chinese and Janpanese, there is no space between words.</p></li>
<li><p>Even in English, there are some cases where no space is used between words.</p></li>
<li><p>Humans can easily segment a string of characters into words, even though there is no space between words.</p></li>
<li><p>For example, we can easily segment the string of characters <code class="docutils literal notranslate"><span class="pre">Ilikechocolate</span></code> into words <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">like</span> <span class="pre">chocolate</span></code>.</p></li>
</ul>
</section>
<section id="why-should-we-segment-words">
<h2>Why should we segment words?<a class="headerlink" href="#why-should-we-segment-words" title="Permalink to this heading">#</a></h2>
<p>There are many applications that require word segmentation, even in English.</p>
<ul class="simple">
<li><p>Normalizing English compound nouns that are variably written for search engines.</p>
<ul>
<li><p>For example, <code class="docutils literal notranslate"><span class="pre">ice</span> <span class="pre">cream</span></code> and <code class="docutils literal notranslate"><span class="pre">ice-cream</span></code> should be segmented into <code class="docutils literal notranslate"><span class="pre">icecream</span></code>.</p></li>
</ul>
</li>
<li><p>Word segmentation for compounds: Both orginal words and split words should be in the dictionary.</p></li>
<li><p>Typing errors may be corrected by word segmentation.</p></li>
<li><p>Conversion errors: During conversion, some spaces may be lost.</p></li>
<li><p>OCR errors: OCRed text may contain errors.</p></li>
<li><p>Keyword extraction from URL addresses, domain names, table column description or programming variables that are written without spaces.</p></li>
<li><p>For password analysis, the extraction of terms from passwords can be required.</p></li>
<li><p>Automatic CamelCasing of programming variables.</p></li>
<li><p>Speech recognition: Speech recognition systems may not properly recognize spaces between words.</p></li>
</ul>
</section>
<section id="generating-segment-variants">
<h2>Generating segment variants<a class="headerlink" href="#generating-segment-variants" title="Permalink to this heading">#</a></h2>
<p>We can generate all possible segment variants of a string of characters. Each distinct segment variant is called a <strong>composition</strong>.</p>
<ul class="simple">
<li><p>En a string of length <span class="math notranslate nohighlight">\(n\)</span>, there are <span class="math notranslate nohighlight">\(n-1\)</span> possible positions to split the string.</p></li>
<li><p>Each of the <span class="math notranslate nohighlight">\(n-1\)</span> positions can be used as word boundary.</p></li>
<li><p>Therefore, there are <span class="math notranslate nohighlight">\(2^{n-1}\)</span> possible compositions.</p></li>
</ul>
<p>The compositions have to be evaluated to find the best segmentation.</p>
<ul class="simple">
<li><p>The best segmentation is the one that has the highest probability.</p></li>
</ul>
<section id="naive-recursive-algorithm">
<h3>Naive Recursive Algorithm<a class="headerlink" href="#naive-recursive-algorithm" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The naive recursive algorithm is to generate all possible compositions and evaluate them.</p></li>
<li><p>The time complexity of the naive recursive algorithm is <span class="math notranslate nohighlight">\(O(2^n)\)</span>.</p></li>
<li><p>The naive recursive algorithm is not efficient for long strings.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>


<span class="k">def</span> <span class="nf">segment_naive</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">string</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[[</span><span class="n">string</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">string</span><span class="p">[:</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="n">rest</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">rest</span> <span class="ow">in</span> <span class="n">segment_naive</span><span class="p">(</span><span class="n">string</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
        <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">segment_naive</span><span class="p">(</span><span class="s2">&quot;isit&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;isit&#39;],
 [&#39;i&#39;, &#39;sit&#39;],
 [&#39;i&#39;, &#39;s&#39;, &#39;it&#39;],
 [&#39;i&#39;, &#39;s&#39;, &#39;i&#39;, &#39;t&#39;],
 [&#39;i&#39;, &#39;si&#39;, &#39;t&#39;],
 [&#39;is&#39;, &#39;it&#39;],
 [&#39;is&#39;, &#39;i&#39;, &#39;t&#39;],
 [&#39;isi&#39;, &#39;t&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">segment_naive</span><span class="p">(</span><span class="s2">&quot;가방에&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;가방에&#39;], [&#39;가&#39;, &#39;방에&#39;], [&#39;가&#39;, &#39;방&#39;, &#39;에&#39;], [&#39;가방&#39;, &#39;에&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;thisislongtext&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">segment_naive</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14 8192
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;아버지가방에들어가신다&quot;</span>  <span class="c1"># Father goes into the bag or Father enters the room</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">segment_naive</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11 1024
</pre></div>
</div>
</div>
</div>
</section>
<section id="dynamic-programming">
<h3>Dynamic Programming<a class="headerlink" href="#dynamic-programming" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Dynamic programming is a technique to solve a problem by breaking it into subproblems and storing the results of subproblems to avoid computing the same results again.</p></li>
<li><p>The time complexity of dynamic programming is <span class="math notranslate nohighlight">\(O(n)\)</span>.</p></li>
<li><p>For long strings, dynamic programming is much more efficient than the naive recursive algorithm.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">segment</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">string</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">first</span><span class="p">,</span> <span class="n">rest</span> <span class="o">=</span> <span class="n">string</span><span class="p">[:</span><span class="n">end</span><span class="p">],</span> <span class="n">string</span><span class="p">[</span><span class="n">end</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">first</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">first</span><span class="p">]</span> <span class="o">+</span> <span class="n">segment</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">string</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="triangular-matrix">
<h3>Triangular Matrix<a class="headerlink" href="#triangular-matrix" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The dynamic programming algorithm can be implemented using a triangular matrix.</p></li>
<li><p>The tryangular matrix algorithm uses nested loops and a circular buffer to store the results of subproblems.</p></li>
<li><p>A triangular matrix of parts with increasing length is generated and organized in a circular buffer.</p></li>
<li><p>This allows a constant amount of memory to be used for the algorithm.</p></li>
</ul>
</section>
<section id="maximum-matching-algorithm">
<h3>Maximum Matching Algorithm<a class="headerlink" href="#maximum-matching-algorithm" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>If we have all known words in a dictionary, we can use the maximum matching algorithm to segment a sentence.</p></li>
<li><p>The maximum matching algorithm is a greedy algorithm that finds the longest matching word from the dictionary.</p></li>
<li><p>The algorithm is as follows:</p>
<ol class="arabic simple">
<li><p>Find the longest matching word from the dictionary.</p></li>
<li><p>If the word is found, add the word to the result and remove the word from the input.</p></li>
<li><p>If the word is not found, add the first character to the result and remove the first character from the input.</p></li>
<li><p>Repeat 1-3 until the input is empty.</p></li>
</ol>
</li>
</ul>
</section>
<section id="unknown-words">
<h3>Unknown Words<a class="headerlink" href="#unknown-words" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>We can not rely on the dictionary to segment all words.</p></li>
<li><p>There are uncommon words, new words, misspelled words, foreign words, proper nouns, slang words, etc.</p></li>
<li><p>Even in these cases, we want to segment the words into meaningful parts.</p></li>
<li><p>Therefore, we have to estimate the probability of any possible segmentation.</p></li>
</ul>
</section>
</section>
<section id="evaluation-of-compositions">
<h2>Evaluation of Compositions<a class="headerlink" href="#evaluation-of-compositions" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>Generally, we can evaluate a composition by calculating the probability of the composition.</p></li>
<li><p>Word probabilities can be estimated from a corpus:</p>
<div class="math notranslate nohighlight">
\[
  P(w_i) = \frac{c(w_i)}{N}
  \]</div>
<p>where <span class="math notranslate nohighlight">\(c(w_i)\)</span> is the count of word <span class="math notranslate nohighlight">\(w_i\)</span> and <span class="math notranslate nohighlight">\(N\)</span> is the total number of words in the corpus.</p>
</li>
<li><p>However, for unkonwn words, we have to use other criteria to evaluate the composition.</p></li>
<li><p>At word boundary, the uncertainty of the segmentation increases.</p></li>
<li><p>By measuring the uncertainty, we can evaluate the composition.</p></li>
</ul>
</section>
<section id="uncertainty-of-word-boundaries">
<h2>Uncertainty of word boundaries<a class="headerlink" href="#uncertainty-of-word-boundaries" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The uncertainty of word boundaries can be measured by the entropy of the word boundary.</p></li>
<li><p><span id="id1">[<a class="reference internal" href="../../../about/index.html#id20" title="Zellig S Harris. From phoneme to morpheme. In Papers in structural and transformational linguistics, pages 32–67. Springer, 1970. URL: http://www.eecs.qmul.ac.uk/~mpurver/papers/griffiths-et-al15qitl.pdf.">Harris, 1970</a>]</span> said that if the uncertainty of successive tokens increases, the location is a word boundary.</p></li>
<li><p><span id="id2">[<a class="reference internal" href="../../../about/index.html#id18" title="Haodi Feng, Kang Chen, Xiaotie Deng, and Weimin Zheng. Accessor variety criteria for chinese word extraction. Computational linguistics, 30(1):75–93, 2004. URL: https://aclanthology.org/J04-1004.pdf.">Feng <em>et al.</em>, 2004</a>]</span> proposed a statistical criterion called accessor variety (AV) to measure how likely a sub-sequence is a word, and then to find the best segmentation pattern that maximizes a target function of accessor variety and the length of the sub-sequence as variants.</p></li>
<li><p><span id="id3">[<a class="reference internal" href="../../../about/index.html#id19" title="Zhihui Jin and Kumiko Tanaka-Ishii. Unsupervised segmentation of Chinese text by use of branching entropy. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, 428–435. Sydney, Australia, July 2006. Association for Computational Linguistics. URL: https://aclanthology.org/P06-2056.">Jin and Tanaka-Ishii, 2006</a>]</span> proposed branching entropy as another criterion for unsupervised segmentation.</p></li>
<li><p>Both criteria share a similar assumption as in the fundamental work by Harris, 1970, that the uncertainty of successive tokens increases at word boundaries.</p></li>
<li><p>The latter is the countinous version of the former.</p></li>
</ul>
<p><img alt="" src="../../../_images/branching_entropy_uncertainty.png" /></p>
<section id="accessor-variety">
<h3>Accessor Variety<a class="headerlink" href="#accessor-variety" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>The accessor variety (AV) defines that the uncertainty of a sub-sequence is the number of different words that can be formed by adding a sub-sequence to the sub-sequence.</p></li>
<li><p>For the forward accessor variety, it is the number of different words that can be formed by adding a sub-sequence to the right side of the sub-sequence.</p></li>
<li><p>For the following sub-sequence, the forward accessor variety of <code class="docutils literal notranslate"><span class="pre">hope</span></code> is 2, because <code class="docutils literal notranslate"><span class="pre">hope</span></code> can be followed by <code class="docutils literal notranslate"><span class="pre">less</span></code> or <code class="docutils literal notranslate"><span class="pre">fully</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;hopeful&quot;</span><span class="p">:</span> <span class="mi">100</span>
<span class="s2">&quot;hopeless&quot;</span><span class="p">:</span> <span class="mi">80</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p>The backward accessor variety is the number of different words that can be formed by adding a sub-sequence to the left side of the sub-sequence.</p></li>
<li><p>For example, the backward accessor variety of <code class="docutils literal notranslate"><span class="pre">less</span></code> is 3, because <code class="docutils literal notranslate"><span class="pre">hopeless</span></code>, <code class="docutils literal notranslate"><span class="pre">useless</span></code>, and <code class="docutils literal notranslate"><span class="pre">pointless</span></code> can be formed by adding <code class="docutils literal notranslate"><span class="pre">less</span></code> to the left side of <code class="docutils literal notranslate"><span class="pre">less</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;hopeless&quot;</span><span class="p">:</span> <span class="mi">80</span>
<span class="s2">&quot;unless&quot;</span><span class="p">:</span> <span class="mi">160</span>
<span class="s2">&quot;pointless&quot;</span><span class="p">:</span> <span class="mi">70</span>
</pre></div>
</div>
</li>
<li><p>Depending on the language, the forward accessor variety or the backward accessor variety may be more suitable for segmentation.</p></li>
<li><p>Threshold values can be used to determine the word boundaries.</p></li>
<li><p>The threshold values can be determined by the corpus.</p></li>
</ul>
</section>
<section id="branching-entropy">
<h3>Branching Entropy<a class="headerlink" href="#branching-entropy" title="Permalink to this heading">#</a></h3>
<p><strong>Assumption 1</strong>: The uncertainty of successive tokens increases at word boundaries.</p>
<ul>
<li><p>Given a set of elements <span class="math notranslate nohighlight">\(X\)</span> and a set of n-gram sequences <span class="math notranslate nohighlight">\(X_n\)</span>, the conditional entropy of an element occuring after an n-gram sequence <span class="math notranslate nohighlight">\(X_n\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
  H(X|X_n) = -\sum_{x_n \in X_n} P(x_n) \sum_{x \in X} P(x|x_n) \log P(x|x_n)
  \]</div>
<p>where <span class="math notranslate nohighlight">\(P(x) = P(X=x)\)</span>, <span class="math notranslate nohighlight">\(P(x|x_n) = P(X=x|X_n=x_n)\)</span>, and <span class="math notranslate nohighlight">\(P(X=x)\)</span> indicates the probability of an element <span class="math notranslate nohighlight">\(x\)</span> occuring in <span class="math notranslate nohighlight">\(X\)</span>.</p>
</li>
<li><p><span class="math notranslate nohighlight">\(H(X|X_n)\)</span> decreases as <span class="math notranslate nohighlight">\(n\)</span> increases, meaning that <span class="math notranslate nohighlight">\(X\)</span> will become more predictable as <span class="math notranslate nohighlight">\(X_n\)</span> becomes longer.</p></li>
<li><p>The latter half of the equation, the entropy of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(X_n\)</span>, indicates the average information of branching out from a specific n-gram sequence <span class="math notranslate nohighlight">\(X_n\)</span>:</p>
<div class="math notranslate nohighlight">
\[
  H(X|X_n=x_n) = -\sum_{x \in X} P(x|x_n) \log P(x|x_n)
  \]</div>
</li>
<li><p>This local entropy is the branching entropy of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(X_n\)</span>, and denoted as <span class="math notranslate nohighlight">\(h(x_n)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
  h(x_n) = -\sum_{x \in X} P(x|x_n) \log P(x|x_n)
  \]</div>
</li>
</ul>
<p><strong>Assumption 2</strong>: If the entropy of successive tokens is high or increasing, the location is a word boundary.</p>
<ul>
<li><p>Generally, as the length of the n-gram sequence increases, the entropy of the n-gram sequence decreases.</p>
<div class="math notranslate nohighlight">
\[
  h(x_n) \geq h(x_{n-1})
  \]</div>
</li>
<li><p>If <span class="math notranslate nohighlight">\(x_n\)</span> is the prefix of <span class="math notranslate nohighlight">\(x_{n+1}\)</span>, the branching entropy of <span class="math notranslate nohighlight">\(x_n\)</span> will likely be smaller than that of <span class="math notranslate nohighlight">\(x_{n+1}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
  h(x_n) &lt; h(x_{n+1})
  \]</div>
</li>
<li><p>There are three boundary conditions to decide whether <span class="math notranslate nohighlight">\(x_n\)</span> is a word boundary:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(B_{max}\)</span>: If <span class="math notranslate nohighlight">\(h(x_n) &gt; \text{val}_{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(B_{increase}\)</span>: <span class="math notranslate nohighlight">\(h(x_n) &gt; h(x_{n-1})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(B_{ordinary}\)</span>: <span class="math notranslate nohighlight">\(h(x_n) &gt; \text{val}_{ordinary}\)</span></p></li>
</ol>
</li>
</ul>
<p><img alt="" src="../../../_images/branching_entropy.png" /></p>
</section>
</section>
<section id="word-segmentation-in-practice">
<h2>Word Segmentation in Practice<a class="headerlink" href="#word-segmentation-in-practice" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;like apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;likes pineapples and apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dislikes Apple and pineapple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;People dislike pineapples.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;An apple makes people healthy.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Pine trees make pineapple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Pineapple unhealthy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;likeness of apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dislikeness of pineapples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;health of pineapple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;healthiness of apple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;display of pineapples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unhealthy of apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unhealthiness of pineapples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unlike apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;kindness of apples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;kind of pineapples&quot;</span><span class="p">,</span>
    <span class="s2">&quot;apple tree&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pineapple tree&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format=&#39;retina&#39;
<span class="kn">from</span> <span class="nn">ekorpkit.tokenizers.branching</span> <span class="kn">import</span> <span class="n">BranchingEntropyTokenizer</span>

<span class="n">bet</span> <span class="o">=</span> <span class="n">BranchingEntropyTokenizer</span><span class="p">()</span>
<span class="n">bet</span><span class="o">.</span><span class="n">train_from_iterator</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">min_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0c7806920cc34df28f2e0ca9d107a75f", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total words: 29
Top 10 words: [(&#39;▁of&#39;, 9), (&#39;▁apples&#39;, 6), (&#39;▁pineapples&#39;, 5), (&#39;▁pineapple&#39;, 5), (&#39;▁apple&#39;, 4), (&#39;▁and&#39;, 2), (&#39;▁people&#39;, 2), (&#39;▁unhealthy&#39;, 2), (&#39;▁tree&#39;, 2), (&#39;▁like&#39;, 1)]
Total words after filtering: 29
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "7d975cb362a24fa1bc2442a308c63237", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total subwords: 543
Top 10 subwords: [(&#39;▁&#39;, 114), (&#39;e&#39;, 63), (&#39;p&#39;, 59), (&#39;l&#39;, 37), (&#39;a&#39;, 33), (&#39;s&#39;, 30), (&#39;i&#39;, 27), (&#39;n&#39;, 26), (&#39;pl&#39;, 24), (&#39;ple&#39;, 23)]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f7930052bc1c4886987b98c336523cbe", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "bee21fc74ed4416a9634182314f06a41", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequence</span> <span class="o">=</span> <span class="n">texts</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">sequence</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">pre_tokenize</span><span class="p">(</span><span class="n">sequence</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dislikes apple and pineapple
[&#39;▁dislikes&#39;, &#39;▁apple&#39;, &#39;▁and&#39;, &#39;▁pineapple&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;pineapples&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">bet</span><span class="o">.</span><span class="n">find_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;p&#39;, 0.5250355693505371, 0.0),
 (&#39;i&#39;, 0.3496905752250248, -0.1753449941255123),
 (&#39;n&#39;, 0.3496905752250248, 0.0),
 (&#39;e&#39;, 0.44914649901267, 0.09945592378764523),
 (&#39;a&#39;, 0.3499656090752427, -0.0991808899374273),
 (&#39;p&#39;, 0.3499656090752427, 0.0),
 (&#39;p&#39;, 0.3499656090752427, 0.0),
 (&#39;l&#39;, 0.3499656090752427, 0.0),
 (&#39;e&#39;, 0.6764449241372277, 0.32647931506198496),
 (&#39;s&#39;, 0.5144984575880421, -0.16194646654918554)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/af09e769dea1f8fa572155f4b84df116656b0cb0182458dec6aa1a94d69646f2.png" src="../../../_images/af09e769dea1f8fa572155f4b84df116656b0cb0182458dec6aa1a94d69646f2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4b36486a717ab2df2f960832828af14cc1fd1b371fd786ec73d41cf8c1884922.png" src="../../../_images/4b36486a717ab2df2f960832828af14cc1fd1b371fd786ec73d41cf8c1884922.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="n">tokenized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[(&#39;▁like&#39;,), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁like&#39;, &#39;s&#39;), (&#39;▁pineapple&#39;, &#39;s&#39;), (&#39;▁and&#39;,), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁dis&#39;, &#39;like&#39;, &#39;s&#39;), (&#39;▁apple&#39;,), (&#39;▁and&#39;,), (&#39;▁pineapple&#39;,)],
 [(&#39;▁people&#39;,), (&#39;▁dis&#39;, &#39;like&#39;), (&#39;▁pineapple&#39;, &#39;s.&#39;)],
 [(&#39;▁an&#39;,), (&#39;▁apple&#39;,), (&#39;▁make&#39;, &#39;s&#39;), (&#39;▁people&#39;,), (&#39;▁health&#39;, &#39;y.&#39;)],
 [(&#39;▁pine&#39;,), (&#39;▁tree&#39;, &#39;s&#39;), (&#39;▁make&#39;,), (&#39;▁pineapple&#39;,)],
 [(&#39;▁pineapple&#39;,), (&#39;▁un&#39;, &#39;health&#39;, &#39;y&#39;)],
 [(&#39;▁like&#39;, &#39;ness&#39;), (&#39;▁of&#39;,), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁dis&#39;, &#39;like&#39;, &#39;ness&#39;), (&#39;▁of&#39;,), (&#39;▁pineapple&#39;, &#39;s&#39;)],
 [(&#39;▁health&#39;,), (&#39;▁of&#39;,), (&#39;▁pineapple&#39;,)],
 [(&#39;▁health&#39;, &#39;iness&#39;), (&#39;▁of&#39;,), (&#39;▁apple&#39;,)],
 [(&#39;▁dis&#39;, &#39;play&#39;), (&#39;▁of&#39;,), (&#39;▁pineapple&#39;, &#39;s&#39;)],
 [(&#39;▁un&#39;, &#39;health&#39;, &#39;y&#39;), (&#39;▁of&#39;,), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁un&#39;, &#39;health&#39;, &#39;iness&#39;), (&#39;▁of&#39;,), (&#39;▁pineapple&#39;, &#39;s&#39;)],
 [(&#39;▁un&#39;, &#39;like&#39;), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁kind&#39;, &#39;ness&#39;), (&#39;▁of&#39;,), (&#39;▁apple&#39;, &#39;s&#39;)],
 [(&#39;▁kind&#39;,), (&#39;▁of&#39;,), (&#39;▁pineapple&#39;, &#39;s&#39;)],
 [(&#39;▁apple&#39;,), (&#39;▁tree&#39;,)],
 [(&#39;▁pineapple&#39;,), (&#39;▁tree&#39;,)]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="n">tokenized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;▁like&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁likes&#39;, &#39;▁pine&#39;, &#39;appl&#39;, &#39;es&#39;, &#39;▁a&#39;, &#39;nd&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁dis&#39;, &#39;likes&#39;, &#39;▁ap&#39;, &#39;ple&#39;, &#39;▁a&#39;, &#39;nd&#39;, &#39;▁pine&#39;, &#39;ap&#39;, &#39;ple&#39;],
 [&#39;▁people&#39;, &#39;▁dis&#39;, &#39;like&#39;, &#39;▁pineapples.&#39;],
 [&#39;▁an&#39;, &#39;▁ap&#39;, &#39;ple&#39;, &#39;▁makes&#39;, &#39;▁people&#39;, &#39;▁healthy.&#39;],
 [&#39;▁pine&#39;, &#39;▁tre&#39;, &#39;es&#39;, &#39;▁make&#39;, &#39;▁pine&#39;, &#39;ap&#39;, &#39;ple&#39;],
 [&#39;▁pine&#39;, &#39;ap&#39;, &#39;ple&#39;, &#39;▁unhealthy&#39;],
 [&#39;▁like&#39;, &#39;ness&#39;, &#39;▁of&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁dis&#39;, &#39;like&#39;, &#39;ness&#39;, &#39;▁of&#39;, &#39;▁pine&#39;, &#39;appl&#39;, &#39;es&#39;],
 [&#39;▁health&#39;, &#39;▁of&#39;, &#39;▁pine&#39;, &#39;ap&#39;, &#39;ple&#39;],
 [&#39;▁healthi&#39;, &#39;ness&#39;, &#39;▁of&#39;, &#39;▁ap&#39;, &#39;ple&#39;],
 [&#39;▁display&#39;, &#39;▁of&#39;, &#39;▁pine&#39;, &#39;appl&#39;, &#39;es&#39;],
 [&#39;▁unhealthy&#39;, &#39;▁of&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁un&#39;, &#39;healthi&#39;, &#39;ness&#39;, &#39;▁of&#39;, &#39;▁pine&#39;, &#39;appl&#39;, &#39;es&#39;],
 [&#39;▁un&#39;, &#39;like&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁kind&#39;, &#39;ness&#39;, &#39;▁of&#39;, &#39;▁appl&#39;, &#39;es&#39;],
 [&#39;▁ki&#39;, &#39;nd&#39;, &#39;▁of&#39;, &#39;▁pine&#39;, &#39;appl&#39;, &#39;es&#39;],
 [&#39;▁ap&#39;, &#39;ple&#39;, &#39;▁tree&#39;],
 [&#39;▁pine&#39;, &#39;ap&#39;, &#39;ple&#39;, &#39;▁tree&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">naive_segment</span><span class="p">(</span><span class="s2">&quot;ilikeanapple&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;i&#39;, &#39;like&#39;, &#39;an&#39;, &#39;apple&#39;]
</pre></div>
</div>
</div>
</div>
<section id="word-segmentation-for-korean">
<h3>Word Segmentation for Korean<a class="headerlink" href="#word-segmentation-for-korean" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;아버지가 방에 들어가신다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;아버지는 방에 들어가셨다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방을 들다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;방을 나가다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방을 들고 나갔다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방이 방에 있었다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방은 방안에 있다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방은 방에 있었다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방을 방으로 들고 들어갔다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;가방을 들고 집으로 갔다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;방은 집안에 있다&quot;</span><span class="p">,</span>
    <span class="s2">&quot;집으로 가다&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ekorpkit.tokenizers.branching</span> <span class="kn">import</span> <span class="n">BranchingEntropyTokenizer</span>

<span class="n">bet</span> <span class="o">=</span> <span class="n">BranchingEntropyTokenizer</span><span class="p">()</span>
<span class="n">bet</span><span class="o">.</span><span class="n">train_from_iterator</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">min_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0eb989311e5b4d91845965a7fa54958f", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total words: 23
Top 10 words: [(&#39;▁방에&#39;, 4), (&#39;▁가방을&#39;, 4), (&#39;▁들고&#39;, 3), (&#39;▁있었다&#39;, 2), (&#39;▁가방은&#39;, 2), (&#39;▁있다&#39;, 2), (&#39;▁집으로&#39;, 2), (&#39;▁아버지가&#39;, 1), (&#39;▁들어가신다&#39;, 1), (&#39;▁아버지는&#39;, 1)]
Total words after filtering: 23
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "88dc71606a93432ca700953159b2d6b2", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total subwords: 201
Top 10 subwords: [(&#39;▁&#39;, 70), (&#39;방&#39;, 15), (&#39;가&#39;, 12), (&#39;다&#39;, 12), (&#39;다▁&#39;, 12), (&#39;▁방&#39;, 8), (&#39;▁가&#39;, 8), (&#39;▁들&#39;, 7), (&#39;들&#39;, 7), (&#39;▁가방&#39;, 7)]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "19acad82ffb942108d1f592a667d18af", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "f8c24622ac594b8395e64128f7cb4791", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">branching_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="n">tokenized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;▁아버지&#39;, &#39;가&#39;, &#39;▁방에&#39;, &#39;▁들어가신다&#39;],
 [&#39;▁아버지&#39;, &#39;는&#39;, &#39;▁방에&#39;, &#39;▁들어가셨다&#39;],
 [&#39;▁가방&#39;, &#39;을&#39;, &#39;▁들다&#39;],
 [&#39;▁방을&#39;, &#39;▁나가다&#39;],
 [&#39;▁가방&#39;, &#39;을&#39;, &#39;▁들고&#39;, &#39;▁나갔다&#39;],
 [&#39;▁가방&#39;, &#39;이&#39;, &#39;▁방에&#39;, &#39;▁있었다&#39;],
 [&#39;▁가방&#39;, &#39;은&#39;, &#39;▁방안에&#39;, &#39;▁있다&#39;],
 [&#39;▁가방&#39;, &#39;은&#39;, &#39;▁방에&#39;, &#39;▁있었다&#39;],
 [&#39;▁가방&#39;, &#39;을&#39;, &#39;▁방으로&#39;, &#39;▁들고&#39;, &#39;▁들어갔다&#39;],
 [&#39;▁가방&#39;, &#39;을&#39;, &#39;▁들고&#39;, &#39;▁집으로&#39;, &#39;▁갔다&#39;],
 [&#39;▁방은&#39;, &#39;▁집안에&#39;, &#39;▁있다&#39;],
 [&#39;▁집으로&#39;, &#39;▁가다&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">,</span> <span class="n">branching_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span>
<span class="p">]</span>
<span class="n">tokenized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;▁아버지가&#39;, &#39;▁방에&#39;, &#39;▁들어가신다&#39;],
 [&#39;▁아버지는&#39;, &#39;▁방에&#39;, &#39;▁들어가셨다&#39;],
 [&#39;▁가&#39;, &#39;방을&#39;, &#39;▁들다&#39;],
 [&#39;▁방을&#39;, &#39;▁나가다&#39;],
 [&#39;▁가&#39;, &#39;방을&#39;, &#39;▁들고&#39;, &#39;▁나갔다&#39;],
 [&#39;▁가방이&#39;, &#39;▁방에&#39;, &#39;▁있었다&#39;],
 [&#39;▁가&#39;, &#39;방은&#39;, &#39;▁방안에&#39;, &#39;▁있다&#39;],
 [&#39;▁가&#39;, &#39;방은&#39;, &#39;▁방에&#39;, &#39;▁있었다&#39;],
 [&#39;▁가&#39;, &#39;방을&#39;, &#39;▁방&#39;, &#39;으로&#39;, &#39;▁들고&#39;, &#39;▁들어갔다&#39;],
 [&#39;▁가&#39;, &#39;방을&#39;, &#39;▁들고&#39;, &#39;▁집&#39;, &#39;으로&#39;, &#39;▁갔다&#39;],
 [&#39;▁방은&#39;, &#39;▁집안에&#39;, &#39;▁있다&#39;],
 [&#39;▁집&#39;, &#39;으로&#39;, &#39;▁가다&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">naive_segment</span><span class="p">(</span><span class="s2">&quot;아버지가방에들어가신다&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;아버지가&#39;, &#39;방에&#39;, &#39;들어가신다&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">naive_segment</span><span class="p">(</span><span class="s2">&quot;아버지가가방을들고가신다&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;아버지가&#39;, &#39;가방을&#39;, &#39;들고&#39;, &#39;가&#39;, &#39;신다&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="o">=</span><span class="s2">&quot;아버지가&quot;</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/ee41d1db4177ac43e03fe1101a782139db9aebd43b3df8d89c9a7eb53e39ea4a.png" src="../../../_images/ee41d1db4177ac43e03fe1101a782139db9aebd43b3df8d89c9a7eb53e39ea4a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="o">=</span><span class="s2">&quot;가방은&quot;</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f434f6725e667e93910c4d7da9270a018daea035d9542926bb3f23ab27a3e0fd.png" src="../../../_images/f434f6725e667e93910c4d7da9270a018daea035d9542926bb3f23ab27a3e0fd.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="o">=</span><span class="s2">&quot;가방은&quot;</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/7e63acf5a1b356141e942b5220df6cf852ba47ac4633039fd46282bce1ceee98.png" src="../../../_images/7e63acf5a1b356141e942b5220df6cf852ba47ac4633039fd46282bce1ceee98.png" />
</div>
</div>
</section>
<section id="working-with-news-article-samples">
<h3>Working with news article samples<a class="headerlink" href="#working-with-news-article-samples" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ekorpkit</span> <span class="kn">import</span> <span class="n">eKonf</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">uri</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/entelecheia/ekorpkit-book/raw/main/assets/data/us_equities_news_sampled.zip&quot;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s2">&quot;us_equities_news_sampled.parquet&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">cached_path</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">text</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ekorpkit.tokenizers.branching</span> <span class="kn">import</span> <span class="n">BranchingEntropyTokenizer</span>

<span class="n">bet</span> <span class="o">=</span> <span class="n">BranchingEntropyTokenizer</span><span class="p">()</span>
<span class="n">bet</span><span class="o">.</span><span class="n">train_from_iterator</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">min_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b0ee5772dfa64b41b178329f96d6f421", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total words: 107685
Top 10 words: [(&#39;▁the&#39;, 715895), (&#39;▁to&#39;, 334075), (&#39;▁of&#39;, 314837), (&#39;▁in&#39;, 278030), (&#39;▁and&#39;, 274910), (&#39;▁a&#39;, 259527), (&#39;▁s&#39;, 169595), (&#39;▁for&#39;, 133255), (&#39;▁is&#39;, 130552), (&#39;▁on&#39;, 113286)]
Total words after filtering: 107685
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5238024027d04a5d9c653bf44b5a3387", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total subwords: 3019773
Top 10 subwords: [(&#39;▁&#39;, 26177132), (&#39;e&#39;, 7246161), (&#39;t&#39;, 5334633), (&#39;a&#39;, 4971213), (&#39;o&#39;, 4428694), (&#39;n&#39;, 4415394), (&#39;i&#39;, 4397713), (&#39;s&#39;, 4366700), (&#39;r&#39;, 4125315), (&#39;l&#39;, 2404918)]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5a38b3b7e51444a69b5bb5d97713a8d2", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "8a96d7f8e1fc4e61ae1e51ff40f257de", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;../data/tokenizers/&quot;</span><span class="p">,</span> <span class="s2">&quot;branching&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;../data/tokenizers/branching/vocab.json&#39;,
 &#39;../data/tokenizers/branching/config.json&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ekorpkit.tokenizers.branching</span> <span class="kn">import</span> <span class="n">BranchingEntropyTokenizer</span>

<span class="n">bet</span> <span class="o">=</span> <span class="n">BranchingEntropyTokenizer</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;../data/tokenizers/&quot;</span><span class="p">,</span> <span class="s2">&quot;branching&quot;</span><span class="p">,</span> <span class="n">branching_threshold</span><span class="o">=</span><span class="mf">0.2</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "735b57d1fe0e4ed7a79c95105a932e7a", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "03c0262d4c8e40878c3549dc4f264f6e", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequence</span> <span class="o">=</span> <span class="s2">&quot;Investment opportunities in the company.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;▁invest&#39;, &#39;ment&#39;), (&#39;▁oppo&#39;, &#39;rtunit&#39;, &#39;ies&#39;), (&#39;▁in&#39;,), (&#39;▁the&#39;,), (&#39;▁company.&#39;,)]
[(&#39;▁invest&#39;, &#39;ment&#39;), (&#39;▁opportun&#39;, &#39;ities&#39;), (&#39;▁in&#39;,), (&#39;▁the&#39;,), (&#39;▁company.&#39;,)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print(bet.tokenize(texts[3], flatten=False, direction=&quot;forward&quot;, branching_threshold=0.3))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;investments&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">bet</span><span class="o">.</span><span class="n">find_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;▁invest&#39;, &#39;ments&#39;)]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;i&#39;, 1.0095287438501144, 0.0),
 (&#39;n&#39;, 1.1515486269045268, 0.14201988305441238),
 (&#39;v&#39;, 0.45972611324043794, -0.6918225136640888),
 (&#39;e&#39;, 0.4509164703468697, -0.008809642893568226),
 (&#39;s&#39;, 0.35903206546025535, -0.09188440488661437),
 (&#39;t&#39;, 0.9522316236050686, 0.5931995581448133),
 (&#39;m&#39;, 0.3465757022785438, -0.6056559213265249),
 (&#39;e&#39;, 0.3465757022785438, 0.0),
 (&#39;n&#39;, 0.3465757022785438, 0.0),
 (&#39;t&#39;, 0.6160316441204637, 0.26945594184191995),
 (&#39;s&#39;, 0.3519227033342969, -0.2641089407861668)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/b698e9dc5831e95a10892c40f241352b46996a27955cb0eea1bc9ca4383b25f2.png" src="../../../_images/b698e9dc5831e95a10892c40f241352b46996a27955cb0eea1bc9ca4383b25f2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;investments&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bet</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">bet</span><span class="o">.</span><span class="n">find_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;▁invest&#39;, &#39;ments&#39;)]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;i&#39;, 0.3561165131571915, -0.009533638447234705),
 (&#39;n&#39;, 0.3465828747099568, 0.026795502159956852),
 (&#39;v&#39;, 0.37337837686991365, -0.026795591191855372),
 (&#39;e&#39;, 0.3465827856780583, 0.13506944700263662),
 (&#39;s&#39;, 0.4816522326806949, 0.21807907607263988),
 (&#39;t&#39;, 0.6997313087533348, 0.624865765838529),
 (&#39;m&#39;, 1.3245970745918638, -0.1795732287232441),
 (&#39;e&#39;, 1.1450238458686197, -0.3379381071100026),
 (&#39;n&#39;, 0.8070857387586171, 0.5204781480063937),
 (&#39;t&#39;, 1.3275638867650108, 0.3191691594567949),
 (&#39;s&#39;, 1.6467330462218057, 0.0)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bet</span><span class="o">.</span><span class="n">plot_local_entropy</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/6c9bef3bc133a8b342ee8f2c8a130c7e37c4cec2b80e4c8396adac7989ebbde8.png" src="../../../_images/6c9bef3bc133a8b342ee8f2c8a130c7e37c4cec2b80e4c8396adac7989ebbde8.png" />
</div>
</div>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://lovit.github.io/nlp/2018/04/09/branching_entropy_accessor_variety/">Uncertanty to word boundary; Accessor Variety &amp; Branching Entropy</a></p></li>
<li><p><a class="reference external" href="https://medium.com/towards-data-science/fast-word-segmentation-for-noisy-text-2c2c41f9e8da">Fast Word Segmentation of Noisy Text</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/lecture",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/nlp_intro/tokenization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tokenization</p>
      </div>
    </a>
    <a class="right-next"
       href="../embeddings/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Word Embeddings</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation">Word Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-should-we-segment-words">Why should we segment words?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-segment-variants">Generating segment variants</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-recursive-algorithm">Naive Recursive Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-programming">Dynamic Programming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#triangular-matrix">Triangular Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-matching-algorithm">Maximum Matching Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unknown-words">Unknown Words</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-compositions">Evaluation of Compositions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertainty-of-word-boundaries">Uncertainty of word boundaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accessor-variety">Accessor Variety</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#branching-entropy">Branching Entropy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation-in-practice">Word Segmentation in Practice</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word-segmentation-for-korean">Word Segmentation for Korean</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-news-article-samples">Working with news article samples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://entelecheia.me" target="_blank">Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>