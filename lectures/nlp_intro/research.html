

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Research Applications &#8212; ἐντελέχεια</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-examples.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/js/hoverxref.js"></script>
    <script src="../../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/chatgpt.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/nlp_intro/research';</script>
    <link rel="canonical" href="https://lecture.entelecheia.ai/lectures/nlp_intro/research.html" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Language Models" href="language_models.html" />
    <link rel="prev" title="Getting started with ekorpkit" href="ekorpkit.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">ἐντελέχεια</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Introduction to NLP</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Research Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="language_models.html">Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="topic.html">Topic Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="topic_models.html">Topic Models </a></li>
<li class="toctree-l2"><a class="reference internal" href="topic_coherence.html">Topic Coherence Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="sentiments.html">Sentiment Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="word_segmentation.html">Word Segmentation and Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="vectorization.html">Vector Semantics and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="word_embeddings.html">Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab2-corpus-eda.html">Lab 2: EDA on Corpora</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp_deep/index.html">Deep Learning for NLP</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/zeroshot.html">Zero Shot, Prompt, and Search Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/rlhf.html">Reinforcement Learning with Human Feedback (RLHF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/transformers.html">Transformers </a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/t5.html">T5: Text-To-Text Transfer Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/sentencepiece.html">SentencePiece Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/byt5.html">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/plms.html">Pretrained Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab3-train-tokenizers.html">Lab 3: Training Tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab4-pretraining-lms.html">Lab 4: Pretraining Language Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nlp_advances/index.html">Advances in AI and NLP</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../aiart/index.html">AI Art (Generative AI)</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../aiart/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/project-themes.html">Project Themes - A Brave New World</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/robot_drawings.html">Robot Drawing Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle1.html">DALL·E 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle2.html">DALL·E 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/imagen.html">Imagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/textual-inversion.html">Textual Inversion (Dreambooth)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/whisper.html">Automatic Speech Recognition (Whisper)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/text2music.html">Text to Music</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/image2music.html">Image to Music</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mlops/index.html">Machine Learning Systems Design</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mlops/intro.html">Introduction to MLOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/devops.html">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/dev-env.html">Development Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/dotfiles.html">Dotfiles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ds/index.html">Data Science for Economics and Finance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://entelecheia.me">entelecheia.me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about/index.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/entelecheia/lecture/blob/main/book/lectures/nlp_intro/research.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>



<a href="https://github.com/entelecheia/lecture" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/nlp_intro/research.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Research Applications</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#textual-analysis">Textual analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#firm-level-political-risk-measurement-and-effects-hassan2019firm">Firm-Level Political Risk: Measurement and Effects <span class="xref cite cite-p">hassan2019firm</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-and-transmission-of-country-risk-hassan2021sources">Sources and Transmission of Country Risk <span class="xref cite cite-p">hassan2021sources</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-and-methodology">Data and Methodology</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-based-network-industries-and-endogenous-product-differentiation-hoberg2016text">Text-Based Network Industries and Endogenous Product Differentiation <span class="xref cite cite-p">hoberg2016text</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-economic-policy-uncertainty-epu">Measuring Economic Policy Uncertainty (EPU)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-diffusion-of-disruptive-technologies">The Diffusion of Disruptive Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parts-of-speech-predict-loan-repayment">Parts of Speech Predict Loan Repayment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#legislative-influence-detectors">“Legislative Influence Detectors”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-pork-to-policy">From Pork to Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-modeling-federal-reserve-bank-transcripts">Topic modeling Federal Reserve Bank transcripts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-matching-for-causal-inference">Text matching for causal inference</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="research-applications">
<h1>Research Applications<a class="headerlink" href="#research-applications" title="Permalink to this heading">#</a></h1>
<p><img alt="research" src="../../_images/entelecheia_economic_research.png" /></p>
<section id="textual-analysis">
<h2>Textual analysis<a class="headerlink" href="#textual-analysis" title="Permalink to this heading">#</a></h2>
<p>Textual analysis has gained significant popularity in recent years, especially in the field of asset pricing, macroeconomics, and other related fields. This approach involves analyzing large volumes of text to extract meaningful insights and information, which can be used to inform decision-making.</p>
<p>One of the primary reasons for the growing popularity of textual analysis is that it enables researchers to measure economic concepts that are otherwise hard or impossible to measure. For example, sentiments, emotions, and attitudes can be extracted from social media posts, news articles, and other textual data to provide insights into consumer behavior, market trends, and other economic indicators.</p>
<p>Interestingly, the simplest applications of textual analysis have proven to be the most successful so far. Many cutting-edge methods of machine learning, such as deep learning and neural networks, are not always necessary and can even be counter-productive, similar to kitchen-sink regressions that are prone to over-fitting.</p>
<p>Therefore, the advice for researchers interested in textual analysis is to keep it simple and stay close to the text. This means reading a lot of relevant texts and using basic techniques to extract insights. The frontier of this field is more in learning from new data rather than using fancy techniques.</p>
<ul class="simple">
<li><p>Textual analysis is increasingly popular in asset pricing, macroeconomics, and other fields.</p></li>
<li><p>It enables researchers to measure economic concepts that are otherwise hard or impossible to measure.</p></li>
<li><p>Simple applications of textual analysis have been the most successful so far.</p></li>
<li><p>Many cutting-edge methods of machine learning are not necessary and can even be counter-productive.</p></li>
<li><p>The advice is to keep it simple, stay close to the text, and read a lot.</p></li>
<li><p>The frontier of the field is in learning from new data rather than using fancy techniques.</p></li>
</ul>
<p><img alt="textual" src="../../_images/entelecheia_textual_analysis.png" /></p>
</section>
<section id="firm-level-political-risk-measurement-and-effects-hassan2019firm">
<h2>Firm-Level Political Risk: Measurement and Effects <span id="id1">[<a class="reference internal" href="../../about/index.html#id44" title="Tarek A Hassan, Stephan Hollander, Laurence Van Lent, and Ahmed Tahoun. Firm-level political risk: measurement and effects. The Quarterly Journal of Economics, 134(4):2135–2202, 2019.">Hassan <em>et al.</em>, 2019</a>]</span><a class="headerlink" href="#firm-level-political-risk-measurement-and-effects-hassan2019firm" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The paper develops a measure of political risk for individual US firms based on the share of their earnings conference calls devoted to political risks.</p></li>
<li><p>The measure is validated by correctly identifying calls with extensive conversations on political risks and correlating with the firm’s actions and stock market volatility.</p></li>
<li><p>Firms exposed to political risk retrench hiring and investment and actively lobby and donate to politicians.</p></li>
<li><p>The variation in the measure is mainly at the firm level, and the dispersion of firm-level political risk increases during high aggregate political risk times.</p></li>
<li><p>Firms that spend more time discussing risks associated with a given political topic tend to increase lobbying on that topic in the following quarter.</p></li>
</ul>
<p><strong>Conference Call Transcripts</strong></p>
<ul class="simple">
<li><p>The dataset includes 326,247 earnings conference call transcripts from 11,943 firms headquartered in 84 different countries, spanning from 2002 to 2020.</p></li>
<li><p>Conference calls occur typically four times a year after earnings releases.</p></li>
<li><p>The calls consist of a management presentation followed by a Q&amp;A session with the firm’s analysts.</p></li>
<li><p>On average, the Q&amp;A session involves 0-70 questions and lasts approximately 45 minutes.</p></li>
</ul>
<p><strong>Measure of Political Risk</strong></p>
<ul class="simple">
<li><p>The measure of political risk is computed by counting the number of occurrences of political bigrams in conjunction with a synonym for risk or uncertainty and dividing it by the total number of bigrams in the transcript.</p></li>
<li><p>The formula for the measure is given as:</p></li>
<li><p><span class="math notranslate nohighlight">\(PRisk_{it} = \frac{1}{B_{it}}\sum_{b}^{B_{it}}{1[ b \in \mathbb{P}\setminus\mathbb{N}] \times 1[|b-r| \lt 10] \times f_{b,\mathbb{P}}/B_{\mathbb{P}}}\)</span></p></li>
<li><p>where <span class="math notranslate nohighlight">\(r\)</span> is the position of the nearest synonym of risk or uncertainty, <span class="math notranslate nohighlight">\(b = 0,1,\ldots B_{it}\)</span> are the bigrams contained in the call of firm <span class="math notranslate nohighlight">\(i\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> denotes the set of political bigrams.</p></li>
<li><p>The formula applies the “<span class="math notranslate nohighlight">\(tf \times idf\)</span>” method to calculate the weight of the bigrams in measuring political risk.</p></li>
</ul>
<figure class="align-default" id="fig-synonyms">
<a class="reference internal image-reference" href="../../_images/2.png"><img alt="../../_images/2.png" src="../../_images/2.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Synonyms for “risk” or “uncertainty”</span><a class="headerlink" href="#fig-synonyms" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Measuring news about the mean: <span class="math notranslate nohighlight">\(PSentiment_{it}\)</span></strong></p>
<ul class="simple">
<li><p>The measure of news about the mean is calculated using the same approach to measure the mean of political news.</p></li>
<li><p>The sentiment of political news is measured by counting positive and negative words used in conjunction with a political bigram.</p></li>
<li><p>The formula for measuring news about the mean is given as:</p></li>
<li><p><span class="math notranslate nohighlight">\(PSentiment_{i,t} = \frac{1}{B_{it}} \sum_{b}^{B_{it}} \Big( 1[ b \in \mathbb{P}\setminus\mathbb{N}] \times \frac{f_{b,\mathbb{P}}}{B_{\mathbb{P}}} \times \sum_{c=b-10}^{b+10} S(c) \Big)\)</span>,</p></li>
<li><p>where <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> denotes the set of political bigrams, <span class="math notranslate nohighlight">\(S\)</span> assigns sentiment to each word in the vicinity of the bigram, and <span class="math notranslate nohighlight">\(B_{it}\)</span> represents the total number of bigrams in the transcript.</p></li>
<li><p>The correlation between the measure of political risk and the measure of news about the mean is negative, with <span class="math notranslate nohighlight">\(Corr(PRisk_{it}, PSentiment_{it}) = −0.095^{***}\)</span>.</p></li>
</ul>
<p><strong><span class="math notranslate nohighlight">\(PRisk_{it}\)</span></strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(PRisk_{it}\)</span> is a measure that identifies conversations related to risks associated with political topics.</p></li>
<li><p>The bigrams with the highest scores are intuitively linked to politics, such as “the constitution,” “public opinion,” “interest groups,” and “the FAA.”</p></li>
<li><p>The transcripts with the highest <span class="math notranslate nohighlight">\(PRisk_{it}\)</span> values are typically centered around discussions about ballot initiatives, legislation, regulation, government expenditure, and other politically relevant topics.</p></li>
</ul>
<figure class="align-default" id="fig-highest-prisk">
<a class="reference internal image-reference" href="../../_images/4.png"><img alt="../../_images/4.png" src="../../_images/4.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Transcripts with the highest <span class="math notranslate nohighlight">\(PRisk_{it}\)</span></span><a class="headerlink" href="#fig-highest-prisk" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Example: Duke Energy Corporation</strong></p>
<figure class="align-default" id="fig-duke-energy">
<a class="reference internal image-reference" href="../../_images/5.png"><img alt="../../_images/5.png" src="../../_images/5.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">A coal company’s <span class="math notranslate nohighlight">\(PRisk_{it}\)</span></span><a class="headerlink" href="#fig-duke-energy" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="sources-and-transmission-of-country-risk-hassan2021sources">
<h2>Sources and Transmission of Country Risk <span id="id2">[<a class="reference internal" href="../../about/index.html#id45" title="Tarek Alexander Hassan, Jesse Schreger, Markus Schwedeler, and Ahmed Tahoun. Sources and transmission of country risk. Technical Report, National Bureau of Economic Research, 2021.">Hassan <em>et al.</em>, 2021</a>]</span><a class="headerlink" href="#sources-and-transmission-of-country-risk-hassan2021sources" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The paper uses textual analysis of earnings conference calls held by listed firms globally to measure country risk.</p></li>
<li><p>The firm-country-quarter-level data is used to identify spikes in perceived country risk, known as “crises,” and their pattern of transmission to foreign firms.</p></li>
<li><p>The pattern of transmission during crises usually follows a gravity structure, but it changes significantly during crises.</p></li>
<li><p>Elevated perceptions of a country’s riskiness by foreign and financial firms lead to significant falls in local asset prices, capital outflows, and reductions in firm-level investment and employment.</p></li>
<li><p>Risk transmitted from foreign countries also affects the investment decisions of domestic firms.</p></li>
<li><p>The cross-country pattern of interest rates and currency risk premia can be explained by the heterogeneous currency loadings on perceived global risk.</p></li>
</ul>
<section id="data-and-methodology">
<h3>Data and Methodology<a class="headerlink" href="#data-and-methodology" title="Permalink to this heading">#</a></h3>
<p>For each of 56 countries assemble a training library, <span class="math notranslate nohighlight">\(\mathbb{T}^{C}\)</span></p>
<ul class="simple">
<li><p>The training library consists of all “Country Commerce” reports published by the Economist Intelligence Unit from 2002 to 2016 and all names of the country, names of towns with more than 15,000 inhabitants in 2018, and administrative subdivisions from <a class="reference external" href="http://geonames.org">geonames.org</a> and CIA World Factbook.</p></li>
<li><p><span class="math notranslate nohighlight">\(tf \times idf\)</span> is used to identify bigrams that are indicative of discussions of each country.</p></li>
<li><p>A bigram is considered indicative of discussions of country <span class="math notranslate nohighlight">\(C\)</span> if it is frequent in <span class="math notranslate nohighlight">\(C\)</span>’s training library and rarely used in other countries’ libraries.</p></li>
</ul>
<p><strong>Four Dimensions of <span class="math notranslate nohighlight">\(CountryRisk_{i,c,t}\)</span></strong></p>
<ol class="arabic">
<li><p>Risk a given set of firms K associates with country c:</p>
<p><span class="math notranslate nohighlight">\(CountryRisk_{c,t}^{K} = \frac{1}{N_K}\sum CountryRisk_{i,c,t}\)</span></p>
</li>
<li><p>Foreign risks perceived by firm i at time t:</p>
<p><span class="math notranslate nohighlight">\(ForeignRisk_{i,t} = \sum_{c \ne d(i)} CountryRisk_{i,c,t}\)</span></p>
</li>
<li><p>Transmission of risk from o to d at time t:</p>
<p><span class="math notranslate nohighlight">\(TransmissionRisk_{o \to d,t} = \frac{1}{N_d}\sum CountryRisk_{i,o,t}\)</span></p>
</li>
<li><p>Global Risk at time t:</p>
<p><span class="math notranslate nohighlight">\(GlobalRisk_{t} = \frac{1}{N_I}\frac{1}{N_C}\sum_{i \in I}\sum_{c \in C} CountryRisk_{i,c,t}\)</span></p>
</li>
</ol>
<p><strong>Measuring Exposure, Sentiment, and Firm Risk</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(CountryExposure_{i,c,t}\)</span> : tf × idf weighted share of words related to country c</p></li>
<li><p><span class="math notranslate nohighlight">\(CountrySentiment_{i,c,t}\)</span> : tf × idf weighted sum of tone words toward country c (Loughran &amp; McDonald 2011) (Proxy for positive/negative news about country c)</p></li>
<li><p><span class="math notranslate nohighlight">\(FirmRisk_{i,t}\)</span> : Unweighted count of risk words. (Proxy for overall risk faced by the firm)</p></li>
</ul>
<figure class="align-default" id="fig-country-risk-greece">
<a class="reference internal image-reference" href="../../_images/7.png"><img alt="../../_images/7.png" src="../../_images/7.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Financial and non-financial risk: Greece</span><a class="headerlink" href="#fig-country-risk-greece" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="fig-country-risk-thailand">
<a class="reference internal image-reference" href="../../_images/8.png"><img alt="../../_images/8.png" src="../../_images/8.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Financial and non-financial risk: Thailand</span><a class="headerlink" href="#fig-country-risk-thailand" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="fig-country-risk-global">
<a class="reference internal image-reference" href="../../_images/9.png"><img alt="../../_images/9.png" src="../../_images/9.png" style="height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Financial and non-financial risk: Global</span><a class="headerlink" href="#fig-country-risk-global" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="text-based-network-industries-and-endogenous-product-differentiation-hoberg2016text">
<h2>Text-Based Network Industries and Endogenous Product Differentiation <span id="id3">[<a class="reference internal" href="../../about/index.html#id46" title="Gerard Hoberg and Gordon Phillips. Text-based network industries and endogenous product differentiation. Journal of Political Economy, 124(5):1423–1465, 2016.">Hoberg and Phillips, 2016</a>]</span><a class="headerlink" href="#text-based-network-industries-and-endogenous-product-differentiation-hoberg2016text" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The paper studies how firms differ from their competitors using time-varying measures of product similarity based on text-based analysis of firm 10-K product descriptions.</p></li>
<li><p>The time-varying set of product similarity measures enables the generation of new industries in which firms can have their own distinct set of competitors.</p></li>
<li><p>The new sets of competitors explain specific discussion of high competition, rivals identified by managers as peer firms, and changes to industry competitors following exogenous industry shocks.</p></li>
<li><p>The study finds evidence that firm R&amp;D and advertising are associated with subsequent differentiation from competitors, consistent with theories of endogenous product differentiation.</p></li>
<li><p>Cosine similarity is the most popular way of calculating similarity.</p></li>
<li><p>The formula for cosine similarity is <span class="math notranslate nohighlight">\( S_{i,j} = c_i \cdot c_j \)</span>, where <span class="math notranslate nohighlight">\(c_i\)</span> is the normalized representative vector of words for document <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p>This approach provides a creative way of figuring out who is competing with whom, using text-based analysis of firm 10-K product descriptions to measure product similarity and identify distinct sets of competitors.</p></li>
</ul>
<p><strong>Product Descriptions to Vector</strong></p>
<ul class="simple">
<li><p>Product descriptions are converted to vectors by only keeping nouns (according to <a class="reference external" href="http://webster.com">webster.com</a>) and proper nouns, while dropping the most commonly used nouns.</p></li>
<li><p>The resulting vector (<span class="math notranslate nohighlight">\(c_i\)</span>) consists of binary values for included words.</p></li>
<li><p>The cosine similarity between all firm-year pairs results in a large matrix with firm-year as rows and columns.</p></li>
<li><p>The firm-year pairs are clustered year by year to form yearly industry clusters.</p></li>
</ul>
<p><strong>Results</strong></p>
<ul class="simple">
<li><p>The study uses text-based analysis of firm 10-K product descriptions to track changes in industries and identify competitors.</p></li>
<li><p>This approach can be used to form industry definitions and track who is competing with whom.</p></li>
<li><p>One drawback of using 10-K’s is that they are only available for US firms, limiting the generalizability of the findings.</p></li>
</ul>
<figure class="align-default" id="fig-product-similarity">
<a class="reference internal image-reference" href="../../_images/10.png"><img alt="../../_images/10.png" src="../../_images/10.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Industry clusters based on product similarity</span><a class="headerlink" href="#fig-product-similarity" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="measuring-economic-policy-uncertainty-epu">
<h2>Measuring Economic Policy Uncertainty (EPU)<a class="headerlink" href="#measuring-economic-policy-uncertainty-epu" title="Permalink to this heading">#</a></h2>
<p><img alt="h:500px" src="../../_images/11.png" /></p>
<p><strong>This proxy for Economic Policy Uncertainty (EPU) comes from computer searches of newspapers</strong></p>
<ul class="simple">
<li><p>US index: 10 major papers get monthly counts of articles with:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">E</span></code> {economic or economy}, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P</span></code> {regulation or deficit or federal reserve or congress or legislation or white house}, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">U</span></code> {uncertain or uncertainty}</p></li>
</ul>
</li>
<li><p>Divide the count for each month by the count of all articles</p></li>
<li><p>Normalize and sum 10 papers to get the U.S monthly index</p></li>
</ul>
<p><strong>Constructing the US News-Based EPU Index</strong></p>
<p><strong>Newspapers:</strong></p>
<ul class="simple">
<li><p>Boston Globe</p></li>
<li><p>Chicago Tribune</p></li>
<li><p>Dallas Morning News</p></li>
<li><p>Los Angeles Times</p></li>
<li><p>Miami Herald</p></li>
<li><p>New York Times</p></li>
<li><p>SF Chronicle</p></li>
<li><p>USA Today</p></li>
<li><p>Wall Street Journal</p></li>
<li><p>Washington Post</p></li>
</ul>
<p><strong>Validation: Running Detailed Human Audits</strong></p>
<p>10 undergraduates read ≈ 10,000 newspaper articles to date using a 63-page audit guide to code articles if they discuss “economic uncertainty” and “economic policy uncertainty”</p>
<p><img alt="h:500px" src="../../_images/12.png" /></p>
<p><strong>US News-based economic policy uncertainty index</strong></p>
<p><img alt="h:500px" src="../../_images/13.png" /></p>
<p><strong>Twitter text uncertainty measures</strong></p>
<p><img alt="h:500px" src="../../_images/13.png" /></p>
<p><strong>“world uncertainty index” covering 143 countries from Economist Intelligence Unit text</strong></p>
<p><img alt="h:500px" src="../../_images/15.png" /></p>
<p><strong>Global average of all 143 countries</strong></p>
<p><img alt="h:500px" src="../../_images/16.png" /></p>
</section>
<section id="the-diffusion-of-disruptive-technologies">
<h2>The Diffusion of Disruptive Technologies<a class="headerlink" href="#the-diffusion-of-disruptive-technologies" title="Permalink to this heading">#</a></h2>
<p>Bloom, Kalyani, Lerner, and Tahoun (2021), The Diffusion of Disruptive Technologies</p>
<ul class="simple">
<li><p>Construct text-based measures of exposure to 20 different technologies at the firm, patent, and job-level, 2002-19.</p></li>
<li><p>Use these novel data to study the spread of new technologies across firms, regions, occupations, and skill-levels.</p></li>
</ul>
<p><strong>Five Stylized Facts on Disruptive Technologies</strong></p>
<ol class="arabic simple">
<li><p>Development &amp; initial employment in disruptive technologies is geographically highly concentrated.</p></li>
<li><p>Over time, hiring associated with new technologies gradually spreads: “region broadening.”</p></li>
<li><p>Over time, skill level in tech jobs declines sharply: “skill broadening.”</p></li>
<li><p>Low-skill jobs associated with a given technology spread out significantly faster than high-skill jobs.</p></li>
<li><p>Pioneer locations retain long-lasting advantage in high-skilled jobs.</p></li>
</ol>
<p><strong>Data Sources</strong></p>
<ol class="arabic simple">
<li><p>Full text of USPTO patents (1976-2016)</p>
<ul class="simple">
<li><p>Typically follow a research paper format – invention title, abstract, claim, description.</p></li>
</ul>
</li>
<li><p>Transcripts of Earnings Conference Calls (2002-19)</p>
<ul class="simple">
<li><p>Discussions of 300k+ quarterly earnings by 12k publicly listed firms.</p></li>
<li><p>Typically contains management presentation followed by analyst Q &amp; A.</p></li>
</ul>
</li>
<li><p>Full text of 200 M+ online job postings from BG (2007, 2010-19).</p>
<ul class="simple">
<li><p>Scraped from job forums (e.g., <a class="reference external" href="http://Glassdoor.com">Glassdoor.com</a>) and employer websites.</p></li>
<li><p>Geo-coded and assigned to SOC Codes</p></li>
</ul>
</li>
</ol>
<p><strong>Step 1: Identify Technical Bigrams from Patents</strong></p>
<p>Identify two-word combinations (bigrams) that are indicative of discussion of novel technologies.</p>
<ol class="arabic simple">
<li><p>Extract all (17 mil+) bigrams US patents (1976-2016)</p></li>
<li><p>Remove any bigrams that were commonly in use prior to 1970 (Corpus of Historical American English)</p></li>
<li><p>Keep bigrams which account for at least 1000 citations.</p></li>
</ol>
<blockquote>
<div><p>List of 35,063 ‘technical bigrams’ associated with influential inventions.</p>
</div></blockquote>
<p><strong>Top Bigrams in Patents</strong></p>
<p><img alt="h:500px" src="../../_images/17.png" /></p>
<p><strong>Step 2: Identify Disruptive Technologies from Earnings Calls</strong></p>
<p>Identify technical bigrams that are discussed in EC with increasing frequency (keep those at &lt;10% of max in first year) – Total 305.</p>
<p><img alt="h:500px" src="../../_images/18.png" /></p>
<p><strong>Technical vs non-technical bigrams</strong></p>
<p>Non technical bigrams = bigrams in earnings calls and NOT in patents</p>
<p><img alt="h:500px" src="../../_images/19.png" /></p>
<p><strong>Step 3: Bigrams to Technologies</strong></p>
<p>Two alternative approaches</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">“Supervised”</span></code>: Group bigrams with similar meaning to measure the spread of 29 specific technologies, add `synonyms’ and manually audit each bigram. (Main specification)</p>
<ul>
<li><p>Smart Devices - mobile devices; smartphone tablet; android phones; smart phones …</p></li>
<li><p>3d printing - 3d printer; 3d printing; additive manufacturing; d printed</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">“Unsupervised”</span></code>: Treat each tech bigram as a separate technology without any further intervention. (Robustness check)</p></li>
</ul>
<p><strong>Technology Exposure</strong></p>
<p>Measure technology exposure at the patent, earnings call, and job level as</p>
<p><span class="math notranslate nohighlight">\( \text{exposure}_{i,\tau,t} = 1\{b_{t} \in D_{i,t}\} \)</span></p>
<p>where <span class="math notranslate nohighlight">\(D_{i,t}\)</span> is the set of bigrams contained in a job posting/earnings call posted at time <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(b_{\tau}\)</span> is a bigram associated with technology <span class="math notranslate nohighlight">\(\tau\)</span>.</p>
<p><strong>Example Jobs Exposed to Smart Devices</strong></p>
<p><img alt="h:500px" src="../../_images/21.png" /></p>
<ul class="simple">
<li><p>On average, each technical bigram appears in 59,013 job postings. Compare to 157 average mentions of top non-technical bigrams from earnings calls.</p></li>
</ul>
<p><strong>Define an Emergence Year for each Technology</strong></p>
<ol class="arabic simple">
<li><p>Measure the share of earnings calls mentioning a technology</p></li>
<li><p>Define a “technology year of emergence” as year in earnings calls when <code class="docutils literal notranslate"><span class="pre">the</span> <span class="pre">time</span> <span class="pre">series</span> <span class="pre">first</span> <span class="pre">attains</span> <span class="pre">at</span> <span class="pre">least</span> <span class="pre">10%</span> <span class="pre">of</span> <span class="pre">its</span> <span class="pre">maximum</span></code>.</p></li>
</ol>
<p><img alt="h:500px" src="../../_images/22.png" /></p>
<p><strong>Share Exposed Firms and Job Postings – Corr. 80%</strong></p>
<p><img alt="h:500px" src="../../_images/23.png" /></p>
<p><strong>Pioneer Locations</strong></p>
<p>Define pioneer locations as ones which account for 50% of technology patents 10 years before emergence year.</p>
<p><img alt="h:500px" src="../../_images/24.png" /></p>
<p><strong>Broadening over Time and Pioneer Locations</strong></p>
<p><img alt="h:500px" src="../../_images/25.png" /></p>
</section>
<section id="parts-of-speech-predict-loan-repayment">
<h2>Parts of Speech Predict Loan Repayment<a class="headerlink" href="#parts-of-speech-predict-loan-repayment" title="Permalink to this heading">#</a></h2>
<p><em>Netzer, Lemaire, and Herzenstein (2019), “When Words Sweat”</em></p>
<p>Imagine you consider lending $2,000 to one of two borrowers on a crowdfunding website. The borrowers are identical in terms of demographic and financial characteristics. However, the text they provided when applying for a loan differs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Borrower #1:

“I am a hard working person, married for 25 years, and have two wonderful boys.
Please let me explain why I need help.
I would use the $2,000 loan to fix our roof.
Thank you, god bless you, and I promise to pay you back.”

Borrower #2:

“While the past year in our new place has been more than great,
the roof is now leaking and I need to borrow $2,000 to cover the cost of the repair.
I pay all bills (e.g., car loans, cable, utilities) on time.”
</pre></div>
</div>
<p>Which borrower is more likely to default?</p>
<p>“Loan requests written by defaulting borrowers are more likely to include words (or themes) related to the borrower’s family, financial and general hardship, mentions of god, and the near future, as well as pleading lenders for help, and using verbs in present and future tenses.”</p>
<p><strong>Loan Application Words Predicting Repayment</strong></p>
<p><img alt="h:500px" src="../../_images/26.png" /></p>
<p><img alt="h:500px" src="../../_images/27.png" /></p>
</section>
<section id="legislative-influence-detectors">
<h2>“Legislative Influence Detectors”<a class="headerlink" href="#legislative-influence-detectors" title="Permalink to this heading">#</a></h2>
<p>by Burgess et al</p>
<p>The two largest interest group associations: ALEC (on the conservative side) and ALICE (on the liberal side)</p>
<p><img alt="h:500px" src="../../_images/28.png" /></p>
<p><img alt="h:500px" src="../../_images/29.png" /></p>
<p><strong>Compare bill texts across states in two-step process:</strong></p>
<ul class="simple">
<li><p>find candidates using elasticsearch (tf-idf similarlity);</p></li>
<li><p>compare candidates using text reuse score.</p></li>
</ul>
</section>
<section id="from-pork-to-policy">
<h2>From Pork to Policy<a class="headerlink" href="#from-pork-to-policy" title="Permalink to this heading">#</a></h2>
<p><img alt="h:500px" src="../../_images/30.jpeg" /></p>
<p><img alt="h:500px" src="../../_images/31.png" /></p>
</section>
<section id="topic-modeling-federal-reserve-bank-transcripts">
<h2>Topic modeling Federal Reserve Bank transcripts<a class="headerlink" href="#topic-modeling-federal-reserve-bank-transcripts" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Analyze speech transcripts from FOMC (Federal Open Market Committee).</p>
<ul>
<li><p>private discussions among committee members at Federal Reserve (U.S. Central Bank)</p></li>
<li><p>150 meetings, 20 years, 26,000 speeches, 24,000 unique words.</p></li>
</ul>
</li>
<li><p>Pre-processing:</p>
<ul>
<li><p>drop stopwords, stems; vocab = 10,000 words</p></li>
</ul>
</li>
<li><p>LDA:</p>
<ul>
<li><p>K = 40 topics selected for interpretability / topic coherence.</p></li>
</ul>
</li>
</ul>
<p><img alt="h:500px" src="../../_images/32.png" /></p>
<p><strong>Pro-Cyclical Topics</strong></p>
<p><img alt="h:500px" src="../../_images/33.png" /></p>
<p><strong>Counter-Cyclical Topics</strong></p>
<p><img alt="h:500px" src="../../_images/34.png" /></p>
<p><strong>Effect of Transparency</strong></p>
<p><img alt="h:500px" src="../../_images/35.png" /></p>
<ul class="simple">
<li><p>In 1993, there was an unexpected transparency shock where transcripts became public.</p></li>
<li><p>Increasing transparency results in:</p>
<ul>
<li><p>higher discipline / technocratic language (probably beneﬁcial)</p></li>
<li><p>higher conformity (probably costly)</p></li>
</ul>
</li>
<li><p>Highlights tradeoffs from transparency in bureaucratic organizations.</p></li>
</ul>
</section>
<section id="text-matching-for-causal-inference">
<h2>Text matching for causal inference<a class="headerlink" href="#text-matching-for-causal-inference" title="Permalink to this heading">#</a></h2>
<p>Application to online censorship in China by Roberts, Stewart, and Nielsen (2018)</p>
<ul class="simple">
<li><p>Construct a corpus of chinese social media posts, some of which are censored.</p>
<ul>
<li><p>593 bloggers, 150,000 posts, 6 months</p></li>
</ul>
</li>
<li><p>They use a variation of propensity score matching to identify almost identical posts, some of which were censored, and some of which were not.</p></li>
<li><p>Outcome:</p>
<ul>
<li><p>Using text of subsequent posts, measure how likely they are to be censored (how censorable)</p></li>
<li><p>Can see whether censorship has a deterrence or backlash eﬀect.</p></li>
</ul>
</li>
</ul>
<p><strong>Censorship has a backlash eﬀect</strong></p>
<p><img alt="h:500px" src="../../_images/36.png" /></p>
<ul class="simple">
<li><p>Bloggers who are censored respond with more censorable content.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/lecture",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/nlp_intro"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ekorpkit.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Getting started with ekorpkit</p>
      </div>
    </a>
    <a class="right-next"
       href="language_models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Language Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#textual-analysis">Textual analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#firm-level-political-risk-measurement-and-effects-hassan2019firm">Firm-Level Political Risk: Measurement and Effects <span class="xref cite cite-p">hassan2019firm</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-and-transmission-of-country-risk-hassan2021sources">Sources and Transmission of Country Risk <span class="xref cite cite-p">hassan2021sources</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-and-methodology">Data and Methodology</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-based-network-industries-and-endogenous-product-differentiation-hoberg2016text">Text-Based Network Industries and Endogenous Product Differentiation <span class="xref cite cite-p">hoberg2016text</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-economic-policy-uncertainty-epu">Measuring Economic Policy Uncertainty (EPU)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-diffusion-of-disruptive-technologies">The Diffusion of Disruptive Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parts-of-speech-predict-loan-repayment">Parts of Speech Predict Loan Repayment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#legislative-influence-detectors">“Legislative Influence Detectors”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-pork-to-policy">From Pork to Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-modeling-federal-reserve-bank-transcripts">Topic modeling Federal Reserve Bank transcripts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-matching-for-causal-inference">Text matching for causal inference</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://entelecheia.me">Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>