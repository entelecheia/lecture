

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Large Language Models &#8212; ἐντελέχεια.άι</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-examples.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/js/hoverxref.js"></script>
    <script src="../../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/chatgpt.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/nlp_deep/llms';</script>
    <link rel="canonical" href="https://lecture.entelecheia.ai/lectures/nlp_deep/llms.html" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Zero Shot and Prompt Engineering" href="zeroshot.html" />
    <link rel="prev" title="Introduction" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>


  <div class="bd-header-announcement container-fluid bd-header-announcement">
    <div class="bd-header-announcement__content"><p>
  <strong>Announcement:</strong>
  You can install the accompanying AI tutor <a href="https://chrome.google.com/webstore/detail/lecturebot-for-%E1%BC%90%CE%BD%CF%84%CE%B5%CE%BB%CE%AD%CF%87%CE%B5%CE%B9%CE%B1/lfgfgbomindbccgidgalhhndggddpagd">here</a>.
</p>
</div>
  </div>

  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">ἐντελέχεια.άι</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp_intro/index.html">Introduction to NLP</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/research.html">Research Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/language_models.html">Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/topic_modeling.html">Topic Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/topic_coherence.html">Topic Coherence Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/sentiments.html">Sentiment Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/word_segmentation.html">Word Segmentation and Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/vectorization.html">Vector Semantics and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/word_embeddings.html">Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/lab2-corpus-eda.html">Lab 2: EDA on Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_intro/lab4-tomotopy.html">Lab 4: Topic Modeling Tools- Tomotopy</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Deep Learning for NLP</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="zeroshot.html">Zero Shot and Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="decoding.html">Decoding and Search Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers.html">Transformers </a></li>
<li class="toctree-l2"><a class="reference internal" href="rlhf.html">Reinforcement Learning with Human Feedback (RLHF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="detectGPT.html">How to Spot Machine-Written Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="t5.html">T5: Text-To-Text Transfer Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="sentencepiece.html">SentencePiece Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="byt5.html">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></li>
<li class="toctree-l2"><a class="reference internal" href="plms.html">Pretrained Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab3-train-tokenizers.html">Lab 3: Training Tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab4-pretraining-lms.html">Lab 4: Pretraining Language Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp_advances/index.html">Advances in AI and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp_advances/thesis.html">Writing a Thesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_advances/detectGPT.html">DetectGPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_advances/gpt4.html">GPT-4</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../aiart/index.html">AI Art (Generative AI)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../aiart/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/aiart.html">Art and Music in Light of AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle1.html">DALL·E 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle2.html">DALL·E 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/imagen.html">Imagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/textual-inversion.html">Textual Inversion (Dreambooth)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/whisper.html">Automatic Speech Recognition (Whisper)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/text2music.html">Text to Music</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/image2music.html">Image to Music</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/robot_drawings.html">Robot Drawing Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/project-themes.html">Project Themes - A Brave New World</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mlops/index.html">Machine Learning Systems Design</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mlops/intro.html">Introduction to MLOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/project.html">MLOps Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/devops.html">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/gitops.html">GitOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/devsecops.html">DevSecOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/dotfiles.html">Dotfiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/auth-enc-sign.html">Authentication, Encryption, and Signing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/age-gpg-ssh.html">SSH, GPG, and AGE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/github.html">Github’s Fork &amp; Pull Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ds/index.html">Data Science for Economics and Finance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../about/lecture-bot.html">LectureBot for ἐντελέχεια.άι</a></li>
<li class="toctree-l1"><a class="reference external" href="https://entelecheia.me">entelecheia.me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about/index.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/nlp_deep/llms.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Large Language Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">What are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities-of-llms">Capabilities of LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methodologies">Methodologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#surrounding-issues">Surrounding Issues</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergent-abilities-of-large-language-models">Emergent abilities of large language models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#big-bench-67-tasks">BIG-Bench (67 tasks):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mmlu-51-tasks-see-chinchilla-paper-for-results">MMLU (51 tasks; see Chinchilla paper for results):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#individual-emergent-tasks-from-papers">Individual emergent tasks from papers:</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="large-language-models">
<h1>Large Language Models<a class="headerlink" href="#large-language-models" title="Permalink to this heading">#</a></h1>
<section id="what-are-large-language-models">
<h2>What are Large Language Models?<a class="headerlink" href="#what-are-large-language-models" title="Permalink to this heading">#</a></h2>
<p>Large Language Models (LLMs) are a type of deep learning model specifically designed for natural language processing (NLP) tasks. These models are trained on vast amounts of text data to learn complex language patterns, structures, and semantic relationships. As a result, they are capable of understanding and generating human-like text, making them suitable for a wide range of applications, such as machine translation, text summarization, question-answering, sentiment analysis, and more.</p>
<p>Some key aspects of LLMs include:</p>
<ul class="simple">
<li><p>Architecture: LLMs are typically based on architectures like the Transformer, which has become the foundation for many state-of-the-art NLP models. The Transformer architecture is characterized by its self-attention mechanism, which enables the model to capture long-range dependencies and relationships between words in a sentence.</p></li>
<li><p>Pre-training: LLMs are pre-trained on massive datasets using unsupervised learning techniques, such as masked language modeling or causal language modeling. This pre-training phase enables the models to learn general language representations, including grammar, syntax, and semantics, as well as factual and contextual knowledge.</p></li>
<li><p>Fine-tuning: After pre-training, LLMs can be fine-tuned on specific tasks or domains using smaller labeled datasets. This process allows the models to adapt their general language understanding to the nuances and requirements of a particular task, resulting in better performance.</p></li>
<li><p>Transfer learning: LLMs are capable of leveraging knowledge learned during pre-training to perform well on a wide range of NLP tasks with minimal fine-tuning. This ability to transfer knowledge across tasks and domains is a key advantage of LLMs, as it reduces the need for large labeled datasets for each specific task.</p></li>
<li><p>Examples of LLMs: Some well-known LLMs include GPT-3 (OpenAI), BERT (Google), RoBERTa (Facebook), and T5 (Google). These models have achieved state-of-the-art results on various NLP benchmarks, demonstrating their versatility and effectiveness.</p></li>
</ul>
<p>LLMs have significantly advanced the field of NLP and have found numerous practical applications in areas such as chatbots, content generation, summarization, and sentiment analysis, among others. However, they also come with challenges, such as the need for vast computational resources during training, potential biases in the training data, and ethical concerns related to content generation.</p>
</section>
<section id="capabilities-of-llms">
<h2>Capabilities of LLMs<a class="headerlink" href="#capabilities-of-llms" title="Permalink to this heading">#</a></h2>
<p>Large Language Models (LLMs) have a wide range of capabilities that make them highly versatile and useful across many natural language processing (NLP) tasks. Some of the key capabilities of LLMs include:</p>
<ul class="simple">
<li><p>Language understanding: LLMs are trained on vast amounts of text data, enabling them to learn and understand complex language patterns, structures, and semantic relationships. This understanding allows LLMs to effectively process and interpret text in various contexts, making them suitable for tasks such as sentiment analysis, named entity recognition, and relationship extraction.</p></li>
<li><p>Text generation: LLMs can generate coherent and contextually relevant text based on a given input, which makes them valuable for applications like content generation, text summarization, and paraphrasing. By fine-tuning LLMs on specific domains, it is possible to generate text that meets the requirements of various use cases, such as news articles, marketing copy, or creative writing.</p></li>
<li><p>Question answering: LLMs have the ability to understand and extract information from text, allowing them to provide answers to specific questions. This capability is useful for tasks like reading comprehension, fact-checking, and building conversational agents that can provide useful information or support to users.</p></li>
<li><p>Translation: LLMs can learn to translate text between different languages, making them effective tools for machine translation. By training LLMs on parallel corpora, they can learn to map between languages and generate translations that are both accurate and fluent.</p></li>
<li><p>Zero-shot and few-shot learning: LLMs can perform tasks without having seen any specific examples during training (zero-shot) or with only a few examples (few-shot). This capability enables LLMs to generalize across tasks and domains with minimal data, which is particularly useful when labeled data is scarce or expensive to obtain.</p></li>
<li><p>Text classification: LLMs can classify text into categories based on their content, sentiment, or other attributes. This capability is useful for tasks like sentiment analysis, topic classification, and spam detection.</p></li>
<li><p>Sequence-to-sequence tasks: LLMs can be used for sequence-to-sequence tasks, such as abstractive summarization, dialogue generation, and code generation. These tasks involve transforming input sequences into output sequences, often with different lengths and structures.</p></li>
<li><p>Text completion and prediction: LLMs can predict missing words or phrases in a given text, enabling applications like autocomplete, spell-checking, and grammar correction.</p></li>
<li><p>Text similarity and clustering: LLMs can be used to measure the similarity between texts or to group similar texts together, which is useful for applications like document retrieval, duplicate detection, and content recommendation.</p></li>
</ul>
<p>These capabilities make LLMs highly versatile and applicable across a wide range of NLP tasks and domains. However, it is essential to carefully consider the limitations and potential biases of LLMs when using them in real-world applications.</p>
</section>
<section id="methodologies">
<h2>Methodologies<a class="headerlink" href="#methodologies" title="Permalink to this heading">#</a></h2>
<p>Large Language Models (LLMs) employ various methodologies during their development, encompassing architecture design, pre-training, fine-tuning, and transfer learning. These methodologies contribute to their ability to understand and generate human-like text effectively. Here, we outline the key methodologies employed by LLMs:</p>
<ul class="simple">
<li><p>Architecture design: LLMs typically use advanced neural network architectures, such as the Transformer, which has become the foundation for many state-of-the-art NLP models. Transformer-based architectures are characterized by their self-attention mechanism, which allows models to capture long-range dependencies and relationships between words in a sentence. Some popular architectures include GPT, BERT, RoBERTa, and T5.</p></li>
<li><p>Pre-training: LLMs undergo a pre-training phase on massive datasets using unsupervised learning techniques. This process involves training the model to predict masked or missing words in a sentence, allowing it to learn language patterns, grammar, syntax, semantics, and even factual information from the data. Pre-training on large-scale datasets enables LLMs to acquire general language representations that can be fine-tuned for specific tasks later.</p></li>
<li><p>Fine-tuning: After pre-training, LLMs can be adapted to specific tasks or domains using smaller labeled datasets. Fine-tuning involves training the model on task-specific data to adjust its learned representations and make them more suitable for the target task. This process can significantly improve the model’s performance on tasks such as sentiment analysis, question-answering, or machine translation.</p></li>
<li><p>Transfer learning: LLMs can leverage the knowledge they acquired during pre-training to perform well on various NLP tasks with minimal fine-tuning. Transfer learning refers to the ability of a model to apply its learned representations from one task or domain to another, reducing the need for large labeled datasets for each specific task. This capability is a key advantage of LLMs and is a primary reason behind their widespread adoption in NLP.</p></li>
<li><p>Task-specific methodologies: Depending on the target task, LLMs may incorporate additional methodologies to enhance their performance. For instance, sequence-to-sequence models like T5 employ an encoder-decoder architecture for tasks such as summarization or translation. Similarly, BERT and RoBERTa use masked language modeling during pre-training to learn bidirectional context, making them suitable for tasks that require understanding the context from both sides of a word or phrase.</p></li>
<li><p>Prompt engineering: To effectively use LLMs for a given task, prompt engineering techniques are often employed. This involves designing and refining inputs (prompts) to obtain better, more accurate, and contextually relevant outputs. Crafting effective prompts can significantly influence the quality of the generated responses and improve the model’s reliability and usefulness across various applications.</p></li>
</ul>
<p>These methodologies work in concert to enable LLMs to excel at diverse NLP tasks and adapt to new challenges with minimal data. However, the development and application of LLMs also raise concerns regarding computational resource requirements, potential biases, and ethical considerations that must be addressed for their responsible use.</p>
</section>
<section id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this heading">#</a></h2>
<p>Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. Their versatility has led to numerous practical applications in various domains. Some of the key applications of LLMs include:</p>
<ul class="simple">
<li><p>Machine translation: LLMs have significantly improved the quality of machine translation by learning to map between languages and generate translations that are both accurate and fluent. They can be fine-tuned to work with different language pairs, providing valuable tools for breaking language barriers in communication.</p></li>
<li><p>Sentiment analysis: LLMs can be used to classify text based on sentiment, such as positive, negative, or neutral. This application is useful for understanding customer opinions, analyzing product reviews, or monitoring social media trends.</p></li>
<li><p>Text summarization: LLMs can generate concise summaries of long articles or documents while maintaining key information and context. This application can aid in information retrieval, content curation, and making large volumes of text more accessible.</p></li>
<li><p>Question-answering systems: LLMs can understand and extract information from text to provide answers to specific questions. This capability has been used in developing virtual assistants, customer support chatbots, and knowledge base search systems.</p></li>
<li><p>Text generation and content creation: LLMs can generate contextually relevant and coherent text, making them valuable tools for content generation in fields like journalism, marketing, and creative writing.</p></li>
<li><p>Text classification and topic modeling: LLMs can classify documents into categories based on their content or automatically extract topics from large text collections. These applications are useful in document organization, search, and recommendation systems.</p></li>
<li><p>Named entity recognition and relationship extraction: LLMs can identify and categorize entities in text, such as people, organizations, or locations. They can also extract relationships between these entities, enabling applications like knowledge graph construction, information extraction, and data mining.</p></li>
<li><p>Paraphrasing and text simplification: LLMs can be used to rephrase text while preserving the original meaning, making it easier to understand or adapting it for specific audiences.</p></li>
<li><p>Code generation and programming assistance: LLMs can be fine-tuned to understand programming languages, providing assistance in tasks like code generation, code completion, and bug detection.</p></li>
<li><p>Conversational AI: LLMs are widely used in building chatbots and virtual assistants capable of understanding natural language and generating human-like responses. These conversational agents can be employed in various settings, such as customer support, personal assistance, or mental health support.</p></li>
<li><p>Language modeling and grammar correction: LLMs can be used to predict missing words or phrases in text, enabling applications like autocomplete, spell-checking, and grammar correction.</p></li>
</ul>
<p>These applications are just a glimpse of the potential uses of LLMs in various domains. As the field of natural language processing continues to advance, we can expect the development of even more innovative applications that leverage the capabilities of LLMs to address a wide range of challenges and problems.</p>
</section>
<section id="surrounding-issues">
<h2>Surrounding Issues<a class="headerlink" href="#surrounding-issues" title="Permalink to this heading">#</a></h2>
<p>Large Language Models (LLMs) have achieved remarkable success in various natural language processing tasks. However, their development and widespread use also bring up several surrounding issues that need to be carefully considered. Some of the key issues related to LLMs include:</p>
<ul class="simple">
<li><p>Resource requirements: Training LLMs requires vast amounts of computational resources, which can be both expensive and energy-intensive. This high resource demand can lead to centralization of AI research, limiting access to cutting-edge models for smaller organizations and researchers.</p></li>
<li><p>Data biases: LLMs are trained on massive datasets, which may contain biases present in the source data. These biases can result in unintended consequences, such as the model generating biased or offensive outputs. Addressing these biases is an ongoing challenge that involves careful dataset curation and model evaluation to mitigate potential harm.</p></li>
<li><p>Ethical concerns: LLMs can generate content that is indistinguishable from human-written text, raising concerns about their potential misuse in generating disinformation, fake news, or other malicious content. Ensuring responsible use of LLMs is essential for minimizing the risks associated with their capabilities.</p></li>
<li><p>Model interpretability: Understanding the decision-making process of LLMs can be challenging due to their complex architecture and the vast number of parameters involved. Improving interpretability and explainability of LLMs is important for ensuring trust in their predictions and facilitating their adoption in critical applications.</p></li>
<li><p>Deployment challenges: Deploying LLMs in real-world applications often requires significant computational resources and expertise. Simplifying the deployment process and making these models more accessible to a wider audience are ongoing challenges in the field.</p></li>
<li><p>Fairness and inclusivity: Ensuring that LLMs are fair and inclusive of various languages, dialects, and cultural perspectives is essential for building AI systems that work for everyone. Addressing issues related to the representation and treatment of minority languages and dialects in LLMs is a critical aspect of developing more equitable AI systems.</p></li>
<li><p>Environmental impact: The energy consumption associated with training LLMs has raised concerns about their environmental impact. Developing more energy-efficient training methods and promoting the use of renewable energy sources can help mitigate the environmental footprint of LLMs.</p></li>
<li><p>Legal and regulatory implications: The capabilities of LLMs and their potential applications raise legal and regulatory questions, such as intellectual property rights, content moderation, and liability for generated outputs. Developing legal and regulatory frameworks that address these challenges is crucial for fostering responsible innovation in the field of AI.</p></li>
</ul>
<p>Addressing these surrounding issues requires a collective effort from researchers, developers, policymakers, and other stakeholders in the AI community. By acknowledging and addressing these challenges, we can work towards the responsible development and use of LLMs in a way that maximizes their potential benefits while minimizing potential harm.</p>
</section>
<section id="emergent-abilities-of-large-language-models">
<h2>Emergent abilities of large language models<a class="headerlink" href="#emergent-abilities-of-large-language-models" title="Permalink to this heading">#</a></h2>
<p><span id="id1">Wei <em>et al.</em> [<a class="reference internal" href="../../about/index.html#id56" title="Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, and others. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022. URL: https://openreview.net/pdf?id=yzkSU5zdwD.">2022</a>]</span> defined an emergent ability as an ability that is “not present in small models but is present in large models.”</p>
<figure class="align-default" id="fig-llm-ablities">
<a class="reference internal image-reference" href="../../_images/llm_ablities.png"><img alt="../../_images/llm_ablities.png" src="../../_images/llm_ablities.png" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 46 </span><span class="caption-text">Eight examples of emergence in the few-shot prompting setting.</span><a class="headerlink" href="#fig-llm-ablities" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Emergence in large language models refers to abilities not present in small models but found in larger ones. Over 100 examples of emergent abilities have been discovered in models like GPT-3, Chinchilla, and PaLM. These abilities can be classified into two categories: emergent few-shot prompted tasks and emergent prompting strategies.</p>
<p>Emergent few-shot prompted tasks are tasks where small models perform at random chance, while large models perform well above-random. Sources for these tasks include BIG-Bench, the Massive Multitask Benchmark, and several papers showcasing individual tasks as emergent abilities.</p>
<p>Emergent prompting strategies are general prompting strategies that work only for sufficiently large-scale language models. Examples include instruction-following, scratchpad, chain-of-thought prompting, and leveraging explanations in prompting.</p>
<p>Promising future research directions include improving model architectures, enhancing data quality and quantity, optimizing prompting, exploring frontier tasks, and understanding why emergent abilities occur and if they can be predicted.</p>
<section id="big-bench-67-tasks">
<h3>BIG-Bench (67 tasks):<a class="headerlink" href="#big-bench-67-tasks" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>GPT-3 13B (2 tasks): hindu knowledge, modified arithmetic</p></li>
<li><p>GPT-3 175B (15 tasks): analytic entailment, codenames, etc.</p></li>
<li><p>LaMDA 137B (8 tasks): gender inclusive sentences german, repeat copy logic, etc.</p></li>
<li><p>PaLM 8B (3 tasks): auto debugging, sufficient information, parsinlu reading comprehension</p></li>
<li><p>PaLM 64B (14 tasks): anachronisms, ascii word recognition, etc.</p></li>
<li><p>PaLM 540B (25 tasks): analogical similarity, causal judgment, etc.</p></li>
</ul>
</section>
<section id="mmlu-51-tasks-see-chinchilla-paper-for-results">
<h3>MMLU (51 tasks; see Chinchilla paper for results):<a class="headerlink" href="#mmlu-51-tasks-see-chinchilla-paper-for-results" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Chinchilla 7B (7 tasks): Professional Medicine, High School Statistics, etc.</p></li>
<li><p>Chinchilla 70B (44 tasks): International Law, Human Aging, etc.</p></li>
</ul>
</section>
<section id="individual-emergent-tasks-from-papers">
<h3>Individual emergent tasks from papers:<a class="headerlink" href="#individual-emergent-tasks-from-papers" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>GPT-3 paper: 3 digit addition/subtraction (GPT-3 13B), 4-5 digit addition/substraction (GPT-3 175B), leveraging few-shot examples for word denoising (GPT-3 13B)</p></li>
<li><p>Gopher paper: Toxicity classification (Gopher 7.1B), TruthfulQA (Gopher 280B)</p></li>
<li><p>Patel &amp; Pavlick: grounded conceptual mappings (GPT-3 175B)</p></li>
<li><p>PaLM paper: Word in Context benchmark (PaLM 540B)</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/lecture",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/nlp_deep"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction</p>
      </div>
    </a>
    <a class="right-next"
       href="zeroshot.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Zero Shot and Prompt Engineering</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">What are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities-of-llms">Capabilities of LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methodologies">Methodologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#surrounding-issues">Surrounding Issues</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergent-abilities-of-large-language-models">Emergent abilities of large language models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#big-bench-67-tasks">BIG-Bench (67 tasks):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mmlu-51-tasks-see-chinchilla-paper-for-results">MMLU (51 tasks; see Chinchilla paper for results):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#individual-emergent-tasks-from-papers">Individual emergent tasks from papers:</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://entelecheia.me">Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>