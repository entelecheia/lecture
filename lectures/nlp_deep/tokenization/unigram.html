

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Unigram Step-by-Step Implementation &#8212; ἐντελέχεια.άι</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-examples.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/slide.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/js/hoverxref.js"></script>
    <script src="../../../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../../../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/nlp_deep/tokenization/unigram';</script>
    <link rel="canonical" href="https://lecture.entelecheia.ai/lectures/nlp_deep/tokenization/unigram.html" />
    <link rel="shortcut icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="SentencePiece Tokenizer" href="sentencepiece.html" />
    <link rel="prev" title="WordPiece Step-by-Step Implementation" href="wordpiece.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>


  <div class="bd-header-announcement container-fluid bd-header-announcement">
    <div class="bd-header-announcement__content"><p>
  <strong>Announcement:</strong>
  You can install the accompanying AI tutor <a href="https://chrome.google.com/webstore/detail/lecturebot-for-%E1%BC%90%CE%BD%CF%84%CE%B5%CE%BB%CE%AD%CF%87%CE%B5%CE%B9%CE%B1/lfgfgbomindbccgidgalhhndggddpagd" target="_blank">here</a>.
  <a class="reference external" href="https://chrome.google.com/webstore/detail/lecturebot-for-%E1%BC%90%CE%BD%CF%84%CE%B5%CE%BB%CE%AD%CF%87%CE%B5%CE%B9%CE%B1/lfgfgbomindbccgidgalhhndggddpagd" target="_blank"><img alt="chrome-web-store-image" src="https://img.shields.io/chrome-web-store/v/lfgfgbomindbccgidgalhhndggddpagd" /></a>
</p>
</div>
  </div>

  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">ἐντελέχεια.άι</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp_intro/index.html">Introduction to NLP</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_intro/intro/index.html">Introduction</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/apps/index.html">NLP Applications</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/apps/research1.html">Research Part I</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/apps/research2.html">Research Part II</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/lm/index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/lm/ngram.html">N-gram Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/lm/usage.html">Usage of Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/datasets/corpus.html">Text Data Collection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/datasets/lab-dart.html">Lab: Crawling DART Data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/topic/index.html">Topic Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/topic/methods.html">Topic Modeling Methodologies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/topic/lab-methods.html">Lab: Topic Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/topic/coherence.html">Topic Coherence Measures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/topic/lab-coherence.html">Lab: Topic Coherence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/topic/tomotopy.html">Lab: Tomotopy</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/sentiments/index.html">Sentiment Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/sentiments/lexicon.html">Lexicon-Based Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/sentiments/ml.html">Machine Learning-Based Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/sentiments/lab-lexicon.html">Lab: Lexicon-based Sentiment Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/sentiments/lab-ml.html">Lab: ML-based Sentiment Classification</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/tokenization/index.html">Tokenization</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/tokenization.html">Understanding the Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/pos.html">Part-of-Speech Tagging and Parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/ngrams.html">N-grams for Tokenization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/korean.html">Tokenization in Korean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/segmentation.html">Word Segmentation and Association</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/lab-tokenization.html">Lab: Tokenization and Pre-processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/tokenization/lab-korean.html">Lab: Korean Text Processing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/vectorization/index.html">Vector Representation</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/vectorization/semantics.html">Vector Semantics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/vectorization/bow.html">Bags of Words Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/vectorization/tf-idf.html">TF-IDF Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/vectorization/similarity.html">Word Similarity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/vectorization/lab-similarity.html">Lab: Word Similarity</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_intro/embeddings/index.html">Word Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/embeddings/nlm.html">Neural Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/embeddings/w2v.html">Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/embeddings/glove.html">GloVe</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_intro/embeddings/fasttext.html">FastText</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Deep Learning for NLP</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../llms/index.html">Large Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../llms/zeroshot.html">Zero Shot and Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llms/decoding.html">Decoding and Search Strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llms/plms.html">Pretrained Language Models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../transformers/index.html">Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../transformers/bert.html">BERT: Bidirectional Encoder Representations from Transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transformers/bertviz.html">BERT: Visualizing Attention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transformers/t5.html">T5: Text-To-Text Transfer Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transformers/byt5.html">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../datasets/mc4.html">mC4 Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../datasets/lab-eda.html">Lab: Exploratory Data Analysis (EDA)</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">Tokenization</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="subword.html">Subword Tokenization</a></li>
<li class="toctree-l3"><a class="reference internal" href="pipeline.html">Tokenization Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="bpe.html">BPE Step-by-Step Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="wordpiece.html">WordPiece Step-by-Step Implementation</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Unigram Step-by-Step Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="sentencepiece.html">SentencePiece Tokenizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="lab-train-tokenizers.html">Lab: Training Tokenizers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../training/index.html">Training Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../training/lab-pretrain-mlm.html">Lab: Pretraining LMs - MLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training/lab-pretrain-clm.html">Lab: Pretraining LMs - CLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training/lab-finetune-mlm.html">Lab: Finetuining a MLM</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../chatbots/index.html">Conversational AI and Chatbots</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../chatbots/rlhf.html">Reinforcement Learning with Human Feedback (RLHF)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chatbots/detectGPT.html">How to Spot Machine-Written Texts</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp_advances/index.html">Advances in AI and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_advances/thesis.html">Writing a Thesis</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../nlp_advances/gpt/index.html">Generative Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/detectGPT.html">DetectGPT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/gpt4.html">GPT-4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nlp_advances/gpt/camelids.html">Meet the Camelids: A Family of LLMs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp_advances/sam/index.html">Segment Anything</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../aiart/index.html">AI Art (Generative AI)</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/intro/index.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/brave/index.html">A Brave New World</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/aiart/index.html">Art and Music in Light of AI</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../aiart/text-to-image/index.html">Text-to-Image Models</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/dalle1.html">DALL·E 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/dalle2.html">DALL·E 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../aiart/text-to-image/imagen.html">Imagen</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/motion-capture-and-synthesis/index.html">Motion Capture and Motion Synthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aiart/robot/index.html">Robot Drawing System</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mlops/index.html">Machine Learning Systems Design</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mlops/intro.html">Introduction to MLOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mlops/project.html">MLOps Project</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/devops/index.html">DevOps</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/devops/gitops.html">GitOps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/devops/devsecops.html">DevSecOps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/dotfiles/index.html">Dotfiles</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai">Dotfiles Project</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/dotdrop/">Dotdrop Setup</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/github/">GitHub Setup</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/ssh-gpg-age/">SSH, GPG, and Age Setup</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/sops/">SOPS Usage</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/pass/">Pass and Passage Usage</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/doppler/">Doppler Usage</a></li>
<li class="toctree-l3"><a class="reference external" href="https://dotfiles.entelecheia.ai/usage/dockerfiles/">Dockerfiles Usage</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/security/index.html">Security Management</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/auth-enc-sign.html">Authentication, Encryption, and Signing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/age-gpg-ssh.html">SSH, GPG, and AGE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/security/pass.html">Unix Password Managers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/github/index.html">GitHub Workflow</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/github/fork-pull.html">Github’s Fork &amp; Pull Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/github/template.html">Project Templating Tools</a></li>
<li class="toctree-l3"><a class="reference external" href="https://hyperfast-python.entelecheia.ai/">Hyperfast Python Template</a></li>
<li class="toctree-l3"><a class="reference external" href="https://hyperfast-template.entelecheia.ai/">Hyperfast Template</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/containerization/index.html">Containerization</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/containerization/docker.html">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/containerization/containerd.html"><code class="docutils literal notranslate"><span class="pre">containerd</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/simple-pipeline/index.html">Simple MLOps Pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/simple-pipeline/server.html">Server Setup &amp; Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/simple-pipeline/vpn.html">VPN Connectivity</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mlops/llmops/index.html">LLMOps</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/llmops/bentoml.html">Introduction to BentoML</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mlops/llmops/bentochain.html">Deploy a Voice-Based Chatbot with BentoML, LangChain, and Gradio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsecon/index.html">Data Science for Economics and Finance</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../dsecon/intro/index.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/intro/introduction.html">Data Science in Economics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/intro/challenges.html">Technical Challenges</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/intro/methods.html">Data Analytics Methods</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../dsecon/cb/index.html">Central Banks</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/cb/altdata.html">Alternative Data Sources for Central Banks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../dsecon/fomc/index.html">Textual Analysis of FOMC contents</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/01_numerical_data.html">Preparing Numerical Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/02_textual_data.html">Preparing Textual Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/03_EDA_numericals1.html">EDA on Numerical Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/03_EDA_numericals2.html">EDA on Numerical Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/04_training_datasets.html">Create Training Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/05_features.html">Visualizing Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/06_AutoML.html">Checking Baseline with AutoML</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/07_predict_sentiments.html">Predicting Sentiments of FOMC Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/08_EDA_sentiments1.html">EDA on Sentiments: Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/08_EDA_sentiments2.html">EDA on Sentiment Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/09_visualize_features.html">Visualize Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/10_monetary_shocks.html">Monetary Policy Shocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/fomc/11_AutoML_with_tones.html">Predicting the next decisions with tones</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../dsecon/esg-ratings/index.html">ESG Ratings</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/prepare_datasets.html">Preparing training datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/improve_datasets.html">Improving classification datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/train_classifiers.html">Training Classifiers for ESG Ratings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/build_news_corpus.html">Building <code class="docutils literal notranslate"><span class="pre">econ_news_kr</span></code> corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/predict_esg_classes.html">Predicting ESG Categories and Polarities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/cross_validate_datasets.html">Cross validating datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/prepare_datasets_for_labeling.html">Preparing active learning data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dsecon/esg-ratings/all_in_one_pipeline.html">Putting them together in a pipeline</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../softeng/index.html">Software Engineering</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../softeng/intro/index.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/intro/introduction.html">Software Engineering?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/intro/processes.html">Software Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/intro/sdlc.html">Software Development Life Cycle (SDLC)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/intro/requirements.html">Requirements Engineering (RE)</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../softeng/proposal/index.html">Project Proposal</a><input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/proposal/steps.html">Steps in Software Engineering Projects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/proposal/guidelines.html">Software Engineering Proposal Guideline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/proposal/template.html">Project Proposal Template</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../softeng/vcs/index.html">Version Control Systems</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/00_introduction.html">0. Introduction to version control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/01_solo_work_with_git.html">1. Solo work with git</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/02_fixing_mistakes.html">2. Fixing mistakes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/03_publishing.html">3. Publishing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/04_collaboration.html">4. Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/05_fork_and_pull.html">5. Fork and Pull</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/06_git_theory.html">6. Git Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/07_branches.html">7. Branches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/08_advanced_git_concepts.html">8. Advanced git concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/09_github_pages.html">9. Publishing from GitHub</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/10_rebasing.html">10. Rebasing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../softeng/vcs/11_debugging_with_git_bisect.html">11. Debugging With git bisect</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../llms/index.html">Large Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../llms/intro/index.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../llms/intro/llms.html">Large Language Models?</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../llms/stack/index.html">LLM Stacks</a><input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-40"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../llms/stack/infra.html">Generative AI Infrastructure Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../llms/stack/architecture.html">LLM Application Architectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../llms/stack/app.html">LLM App Ecosystem</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../about/lecture-bot.html">LectureBot for ἐντελέχεια.άι</a></li>
<li class="toctree-l1"><a class="reference external" href="https://entelecheia.me">entelecheia.me</a></li>
<li class="toctree-l1"><a class="reference external" href="https://course.entelecheia.ai">course.entelecheia.ai</a></li>
<li class="toctree-l1"><a class="reference external" href="https://research.entelecheia.ai">research.entelecheia.ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about/index.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/entelecheia/lecture/blob/main/book/lectures/nlp_deep/tokenization/unigram.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/lectures/nlp_deep/tokenization/unigram.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Unigram Step-by-Step Implementation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">Dataset Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vocabulary-initialization">Vocabulary Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-initialization">Model Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-encoding">Word Encoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-computation">Loss Computation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-scores">Compute Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-optimization">Model Optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization">Tokenization</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="unigram-step-by-step-implementation">
<h1>Unigram Step-by-Step Implementation<a class="headerlink" href="#unigram-step-by-step-implementation" title="Permalink to this heading">#</a></h1>
<p>Unigram Language Model (ULM) is a subword tokenization algorithm, frequently used for Natural Language Processing (NLP) tasks. It’s a statistical language model which is trained to predict the next word in a sentence in the context of the previous words. Here, we will walk you through a detailed implementation of the Unigram algorithm using a financial news headlines dataset.</p>
<section id="dataset-preparation">
<h2>Dataset Preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this heading">#</a></h2>
<p>First, we need to load our dataset. We will use the <code class="docutils literal notranslate"><span class="pre">ashraq/financial-news</span></code> dataset from the Hugging Face Hub. We will use the <code class="docutils literal notranslate"><span class="pre">headline</span></code> column as our text data. We will randomly sample 1000 records from this dataset for our tokenization process. Here is how we can do this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;ashraq/financial-news&quot;</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">))[</span><span class="s2">&quot;headline&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found cached dataset parquet (/home/yjlee/.cache/huggingface/datasets/ashraq___parquet/ashraq--financial-news-89d6ac597a40e29e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
100%|██████████| 1/1 [00:00&lt;00:00, 54.01it/s]
Loading cached shuffled indices for dataset at /home/yjlee/.cache/huggingface/datasets/ashraq___parquet/ashraq--financial-news-89d6ac597a40e29e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-79cde8905e45a47f.arrow
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>


<span class="k">def</span> <span class="nf">pre_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">lowercase</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">initialize_vocab</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">pre_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lowercase</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">vocab</span>


<span class="n">word_freqs</span> <span class="o">=</span> <span class="n">initialize_vocab</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of words: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_freqs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of words: 3636
</pre></div>
</div>
</div>
</div>
</section>
<section id="vocabulary-initialization">
<h2>Vocabulary Initialization<a class="headerlink" href="#vocabulary-initialization" title="Permalink to this heading">#</a></h2>
<p>For Unigram, we need to initialize our vocabulary to something larger than the vocabulary size we want. We have to include all the basic characters (otherwise we won’t be able to tokenize every word). For the bigger substrings, we can use the most frequent substrings in the corpus:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">character_freqs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">subwords_freqs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)):</span>
        <span class="n">character_freqs</span><span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">freq</span>
        <span class="c1"># Loop through the subwords of length at least 2</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">subwords_freqs</span><span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">freq</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we sort subwords by frequency:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sorted_subwords</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">subwords_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sorted_subwords</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">len</span><span class="p">(</span><span class="n">sorted_subwords</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;in&#39;, 1092), (&#39;re&#39;, 706), (&#39;er&#39;, 690), (&#39;st&#39;, 675), (&#39;es&#39;, 673), (&#39;an&#39;, 629), (&#39;ar&#39;, 617), (&#39;al&#39;, 610), (&#39;on&#39;, 539), (&#39;ng&#39;, 504)]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>33925
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">token_freqs</span> <span class="o">=</span> <span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="n">character_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="n">sorted_subwords</span><span class="p">[:</span> <span class="mi">2000</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">character_freqs</span><span class="p">)]</span>
<span class="p">)</span>
<span class="n">token_freqs</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">freq</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">token_freqs</span><span class="p">}</span>
<span class="nb">len</span><span class="p">(</span><span class="n">token_freqs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2000
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-initialization">
<h2>Model Initialization<a class="headerlink" href="#model-initialization" title="Permalink to this heading">#</a></h2>
<p>Next, we create a Unigram model, where each token is associated with a negative log-likelihood:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span>

<span class="n">total_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">freq</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">token_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
<span class="n">model</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">freq</span> <span class="o">/</span> <span class="n">total_sum</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">token_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2000
</pre></div>
</div>
</div>
</div>
</section>
<section id="word-encoding">
<h2>Word Encoding<a class="headerlink" href="#word-encoding" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">encode_word</span></code> function is used to find the best segmentation of a word into subwords, using the Unigram model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">encode_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">best_segmentations</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;start&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;start&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)):</span>
        <span class="c1"># This should be properly filled by the previous steps of the loop</span>
        <span class="n">best_score_at_start</span> <span class="o">=</span> <span class="n">best_segmentations</span><span class="p">[</span><span class="n">start_idx</span><span class="p">][</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">token</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">model</span> <span class="ow">and</span> <span class="n">best_score_at_start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+</span> <span class="n">best_score_at_start</span>
                <span class="c1"># If we have found a better segmentation ending at end_idx, we update</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">best_segmentations</span><span class="p">[</span><span class="n">end_idx</span><span class="p">][</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="ow">or</span> <span class="n">best_segmentations</span><span class="p">[</span><span class="n">end_idx</span><span class="p">][</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">score</span>
                <span class="p">):</span>
                    <span class="n">best_segmentations</span><span class="p">[</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;start&quot;</span><span class="p">:</span> <span class="n">start_idx</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>

    <span class="n">segmentation</span> <span class="o">=</span> <span class="n">best_segmentations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">segmentation</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We did not find a tokenization of the word -&gt; unknown</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">],</span> <span class="kc">None</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">segmentation</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">segmentation</span><span class="p">[</span><span class="s2">&quot;start&quot;</span><span class="p">]</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">start</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tokens</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">word</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
        <span class="n">next_start</span> <span class="o">=</span> <span class="n">best_segmentations</span><span class="p">[</span><span class="n">start</span><span class="p">][</span><span class="s2">&quot;start&quot;</span><span class="p">]</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">next_start</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">word</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">score</span>


<span class="nb">print</span><span class="p">(</span><span class="n">encode_word</span><span class="p">(</span><span class="s2">&quot;iphone&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encode_word</span><span class="p">(</span><span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([&#39;i&#39;, &#39;ph&#39;, &#39;one&#39;], 21.168929786103597)
([&#39;app&#39;, &#39;le&#39;], 16.224036483432627)
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss-computation">
<h2>Loss Computation<a class="headerlink" href="#loss-computation" title="Permalink to this heading">#</a></h2>
<p>We then define a function to compute the loss of our model. The loss is the sum of the negative log-likelihoods of each word in the vocabulary, weighted by its frequency:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">word_loss</span> <span class="o">=</span> <span class="n">encode_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">freq</span> <span class="o">*</span> <span class="n">word_loss</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>136832.67116572068
</pre></div>
</div>
</div>
</div>
</section>
<section id="compute-scores">
<h2>Compute Scores<a class="headerlink" href="#compute-scores" title="Permalink to this heading">#</a></h2>
<p>We compute the scores by calculating the change in the loss when a token is removed from the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>


<span class="k">def</span> <span class="nf">compute_scores</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">model_loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># We always keep tokens of length 1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">model_without_token</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model_without_token</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">model_without_token</span><span class="p">)</span> <span class="o">-</span> <span class="n">model_loss</span>
    <span class="k">return</span> <span class="n">scores</span>


<span class="n">scores</span> <span class="o">=</span> <span class="n">compute_scores</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;app&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;le&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;investment&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;invest&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;ment&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>26.386676873022225
45.03959364909679
48.10544469070737
55.051404965808615
45.268116643244866
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-optimization">
<h2>Model Optimization<a class="headerlink" href="#model-optimization" title="Permalink to this heading">#</a></h2>
<p>We iteratively remove tokens from the model to improve its performance:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">percent_to_remove</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1800</span><span class="p">:</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">compute_scores</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">sorted_scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Remove percent_to_remove tokens with the lowest scores.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent_to_remove</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Removing </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sorted_scores</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">token_freqs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">sorted_scores</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">total_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">freq</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">token_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">freq</span> <span class="o">/</span> <span class="n">total_sum</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">token_freqs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Removing ngt
Removing gth
Removing rodu
Removing odu
Removing oduc
Removing oldings
Removing ldings
Removing lides
Removing artners
Removing rtners
Removing tners
Removing mbe
Removing expec
Removing xpec
Removing xpect
Removing resou
Removing resour
Removing resourc
Removing esou
Removing esour
Removing esourc
Removing esource
Removing -sta
Removing tars
Removing adin
Removing erna
Removing highe
Removing ighe
Removing igher
Removing ghe
Removing gher
Removing poin
Removing oint
Removing xt
Removing ainers
Removing quart
Removing quarte
Removing uart
Removing uarte
Removing uarter
Removing erage
Removing misse
Removing isses
Removing loser
Removing oser
Removing secto
Removing s&amp;
Removing sma
Removing tti
Removing outl
Removing outlo
Removing outloo
Removing utlo
Removing utloo
Removing utlook
Removing tloo
Removing tlook
Removing ighlights
Removing ghlights
Removing hlights
Removing lights
Removing ervi
Removing sday&#39;
Removing eh
Removing nder
Removing itio
Removing prod
Removing produ
Removing bon
Removing arkets
Removing rkets
Removing kets
Removing a&#39;
Removing rf
Removing orati
Removing oratio
Removing sset
Removing downg
Removing downgr
Removing downgra
Removing downgrad
Removing downgrade
Removing owng
Removing owngr
Removing owngra
Removing owngrad
Removing owngrade
Removing owngraded
Removing wng
Removing wngr
Removing wngra
Removing wngrad
Removing wngrade
Removing wngraded
Removing ngr
Removing ngra
Removing ngrad
Removing ngrade
Removing ngraded
Removing nor
Removing nke
Removing erge
Removing ya
Removing rgi
Removing trat
Removing omment
Removing mment
Removing enta
Removing isc
Removing ovi
Removing ema
Removing stren
Removing streng
Removing strengt
Removing treng
Removing trengt
Removing trength
Removing reng
Removing rengt
Removing rength
Removing iu
Removing osers
Removing sers
Removing isha
Removing ishar
Removing ishare
Removing ike
Removing dg
Removing nth
Removing ttin
Removing servi
Removing servic
Removing ervic
Removing ervice
Removing rvic
Removing rvice
Removing ndustry
Removing dustry
Removing ustry
Removing stry
Removing roun
Removing emi
Removing esd
Removing esda
Removing sk
Removing tfs
Removing righ
Removing e-
Removing corporati
Removing corporatio
Removing orporati
Removing orporatio
Removing orporation
Removing rporati
Removing rporatio
Removing rporation
Removing porati
Removing poratio
Removing poration
Removing tem
Removing trus
Removing rust
Removing sn
Removing orp,
Removing rp,
Removing firs
Removing irs
Removing irst
Removing 015
Removing esources
Removing sources
Removing ources
Removing urces
Removing rces
Removing vet
Removing nom
Removing interna
Removing internat
Removing internati
Removing internatio
Removing internation
Removing internationa
Removing nterna
Removing nternat
Removing ngs
Removing toc
Removing arn
Removing tock
Removing rning
Removing arni
Removing arnin
Removing earni
Removing earnin
Removing nings
Removing arnings
Removing ..
Removing ee
Removing aly
Removing 01
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="tokenization">
<h2>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this heading">#</a></h2>
<p>Finally, we define a <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> function that splits a given text into subwords according to our trained model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">pre_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">encoded_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">encode_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">model</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">encoded_words</span><span class="p">,</span> <span class="p">[])</span>


<span class="n">tokenized_text</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="s2">&quot;investment opportunities in the company&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenized_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;investment&#39;, &#39;op&#39;, &#39;port&#39;, &#39;un&#39;, &#39;ities&#39;, &#39;in&#39;, &#39;the&#39;, &#39;compan&#39;, &#39;y&#39;]
</pre></div>
</div>
</div>
</div>
<p>This concludes our detailed step-by-step implementation of the Unigram Language Model.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/lecture",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/nlp_deep/tokenization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="wordpiece.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">WordPiece Step-by-Step Implementation</p>
      </div>
    </a>
    <a class="right-next"
       href="sentencepiece.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">SentencePiece Tokenizer</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">Dataset Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vocabulary-initialization">Vocabulary Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-initialization">Model Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-encoding">Word Encoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-computation">Loss Computation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-scores">Compute Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-optimization">Model Optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization">Tokenization</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://entelecheia.me" target="_blank">Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>